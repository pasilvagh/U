volume|issue|url|title|abstract
6|1|http://www.jucs.org/jucs_6_1|Automata, Logic, and Computability: J.UCS Special Issue Dedicated to Professor Sergiu Rudeanu Festschrift|
6|1||Under the Sign of Boole|  Solomon Marcus (Romanian Academy, Mathematics, Romania)  Abstract: The note presents some personal thoughts on  Professor S. Rudeanu's scientific and human personality.        Keywords: Boolean logic, language and algebra, thought               Categories: F.4.0  
6|1||Weak Inclusion Systems: Part Two|  Virgil Emil Cazanescu (Fundamentals of Computer Science, Faculty of Mathematics, University of Bucharest, Romania)   Grigore Rosu (Department of Computer Science and Engineering, University of California, USA)  Abstract: New properties and implications of inclusion  systems are investigated in the present paper. Many properties of lattices, factorization systems and special practical cases can be abstracted and adapted to our framework, making the various versions of inclusion systems useful tools for computer scientists and mathematicians.        Keywords: category theory, logic               Categories: F.4.1  
6|1||The Lattice Structure of Pseudo_Wajsberg Algebras|  Rodica Ceterchi (Faculty of Mathematics,  Academiei 14, Bucharest University, Romania)  Abstract: We explore some properties related to the underlying lattice structure of pseudo-Wajsberg algebras. We establish a residuation result and we characterize the Boolean center of pseudo-Wajsberg algebras.        Keywords: Boolean center, MV algebra, Wajsberg algebra, lattice, pseudo-MV algebra, pseudo-Wajsberg algebra, residuated monoid               Categories: F.4.1  
6|1||A Pi-Calculus Machine|" -calculus"">top.name=""UJSeries_Window"";   Gabriel Ciobanu (Department of Computer Science, Romania)   Mihai Rotaru (Institute of Theoretical Computer Science, Romanian Academy, Romania)  Abstract: In this paper we investigate the -calculus  guards, proposing a formalism which use exclusively machine tradition concepts: state, resource, transition. The reduction mechanism is similar to the token-game of Petri nets. We provide a multiset semantics for the -calculus by using this formalism. Moreover, our machines have a graphical representation which emphasizes their structure. As a consequence, we give a new improved graphical representation for the asynchronous -calculus.        Keywords: -calculus, abstract machine, concurrent processes, graphical representation of processes, multiset semantics, nets               Categories: F.3.1  "
6|1||Galois Connections and Data Mining|  Dana Cristofor (University of Massachusetts at Boston, Department of Mathematics and Computer Science, USA)   Laurentiu Cristofor (University of Massachusetts at Boston, Department of Mathematics and Computer Science, USA)   Dan A. Simovici (University of Massachusetts at Boston, Department of Mathematics and Computer Science, USA)  Abstract:   We investigate the application of Galois connections to the identification of frequent item sets, a central problem in data mining.  Starting from the notion of closure generated by a Galois connection, we define the notion of extended closure, and we use these notions to improve the classical Apriori algorithm.  Our experimental study shows that in certain situations, the algorithms that we describe outperform the Apriori algorithm. Also, these algorithms scale up linearly.    Keywords: Galois connection, closure, extended closure, frequent set of items, support               Categories: E.5, H.2.0  
6|1||Behavioural Coherence in Object-Oriented Algebraic Specification|  Razvan Diaconescu (Institute of Mathematics of the Romanian Academy, Romania)   Kokichi Futatsugi (Japan Advanced Institute of Science and Technology, Japan)  Abstract:   We extend the classical hidden algebra formalism by a re-arrangement of the basic concepts. This re-arrangement of the hidden algebra formalism permits an extension to novel concepts which bring new practical strength to the specification and verification methodologies. The main novel concept, which constitutes the core of this work, is that of behavioural coherence, which is essentially a property of preservation of behavioural structures. We define this concept and study its main denotational and computational properties, and also show how the extension of hidden algebra with behavioural coherence still accommodates the coinduction proof method advocated by classical hidden algebra and, very importantly, permits operations with several hidden sorts in the arity. The emphasis of this paper is however on the methodologies related to behavioural coherence. We present the basic methodologies of behavioural coherence by means of examples actually run under the  system, including many proofs with the system exiled to appendices.    Keywords: behavioural coherence, behavioural equivalence, hidden algebra               Categories: F.3.2  
6|1||Monotone, Horn and Quadratic Pseudo-Boolean Functions|  Stephan Foldes (RUTCOR, Rutgers University, USA)   Peter L. Hammer (RUTCOR, Rutgers University, USA)  Abstract: A pseudo-Boolean function (pBf) is a mapping from {0,1}^n to the real numbers. It is known that pseudo-Boolean functions have polynomial representations, and it was recently shown that they also have disjunctive normal forms (DNFs). In this paper we relate the DNF syntax of the classes of monotone, quadratic and Horn pBfs to their characteristic inequalities.        Keywords: Binary optimization, Boolean functions, Horn functions, Set functions, Truth functions, pseudo-Boolean functions               Categories: F.4, G.2  
6|1||A Representation Theorem for Monadic Pavelka Algebras|  George Georgescu (Department of Fundamentals of Computer Science, Faculty of Mathematics, University of Bucharest, Romania)   Ioana Leustean (Department of Fundamentals of Computer Science, Faculty of Mathematics, University of Bucharest, Romania)  Abstract:   In this paper we define the monadic Pavelka algebras as algebraic structures induced by the action of quantifiers in Rational Pavelka predicate logic. The main result is a representation theorem for these structures.    Keywords: MV-algebra, Pavelka algebra, monadic Pavelka algebra, monadic V-algebra               Categories: F.4.1  
6|1||Mixed Relations as Enriched Semiringal Categories|  Radu Grosu (School for EECS, University of Pennsylvania, USA)   Dorel Lucanu (Faculty of Computer Science, A.I.Cuza University, Romania)   Gheorghe Stefanescu (Fundamentals of Computer Science, University of Bucharest, Romania)  Abstract: A study of the classes of finite relations as  enriched strict monoidal categories is presented in [CaS91]. The relations there are interpreted as connections in flowchart schemes, hence an angelic   theory of relations is used. Finite relations may be used to model the connections between the components of dataflow networks [BeS98, BrS96], as well. The corresponding algebras are slightly different enriched strict monoidal categories modeling a forward-demonic theory of relations.          In order to obtain a full model for parallel programs one needs to mix control and reactive parts, hence a richer theory of finite relations is needed. In this paper we (1) define a model of such mixed finite relations, (2) introduce enriched (weak) semiringal categories as an abstract algebraic model for these relations, and (3) show that the initial model of the axiomatization (it always exists) is isomorphic to the defined one of mixed relations. Hence the axioms gives a sound and complete axiomatization for the these relations.                   Keywords: (enriched) semiringal category, abstract data type, mixed relations, network  algebra, parallel programs               Categories: F.3.2  
6|1||Free-Extendible Prefix-Free Sets and an Extension of the Kraft-Chaitin Theorem|  Cristian Grozea (Faculty of Mathematics Bucharest University, Romania)  Abstract: First, the dual set of a finite prefix-free set is  defined. Using this notion we describe equivalent conditions for a finite prefix-free set to be indefinitely extendible. This lead to a simple proof for the Kraft-Chaitin Theorem. Finally, we discuss the influence of the alphabet size on the indefinite extensibility property.                   Keywords: Kraft's inequality, Prefix-free set               Categories: F.2.2, H.  
6|1||The Automorphism Group of a Hypercube|  Frank Harary (Applied Computational Intelligence Laboratory, Department of Electrical and Computer Engineering, University of Missouri, USA)  Abstract:   We present explicitly in this expository note the automorphism group of the hypercube Qd of dimension d as a permutation group acting on its 2d nodes. This group (Qd) acts on the node set Vd of Qd and thus has degree 2d. It is expressed as the binary operation called exponentiation which combines the two symmetric groups S2 (of degree and order 2) and Sd (of degree d and order d!). Specifically,  (Qd) = [S2]Sd.   has order 2dd!.   Keywords: automorphism group, hypercube, permutation graph               Categories: F.4.1  
6|1||Connections Between MVn Algebras and n-valued Lukasiewicz-Moisil Algebras - IV|  Afrodita Iorgulescu (Department of Computer Science, Academy of Economic Studies, Romania)  Abstract:   We introduce two chains of unary operations in the MVn algebra of Revaz Grigolia; they will be used in establishing many connections between these algebras and n-valued Lukasiewicz-Moisil algebras (LMn algebras for short). The study has four parts. It is by and large self-contained.  The main result of the first part is that MV4 algebras coincide with LM4 algebras. The larger class of ``relaxed''-MVn algebras is also introduced and studied. This class is related to the class of generalized LMn pre-algebras.  The main results of the second part are that, for n  5, any MVn algebra is an LMn algebra and that the canonical MVn algebra can be identified with the canonical LMn algebra.    In the third part, the class of good LMn algebras is introduced and studied and it is proved that MVn algebras coincide with good LMn algebras.  In the present fourth part, the class of -proper LMn algebras is introduced and studied. -proper LMn algebras coincide (can be identified) with Cignoli's proper n-valued Lukasiewicz algebras.  MVn algebras coincide with -proper LMn algebras (n  2).  We also give the construction of an LM3(LM4) algebra from the odd (respectively even)-valued LMn algebra (n  5), which proves that LM4 algebras are as much important than LM3 algebras; MVn algebras help to see this point.    Keywords: MVn algebra, n-valued Lukasiewicz-Moisil algebra               Categories: F.4.1  
6|1||A Canonical Model Construction for Substructural Logics|  Hajime Ishihara (School of Information Science, Japan Advanced Institute of Science and Technology, Japan)  Abstract: In this paper, we introduce a class of substructural logics, called normal substructural logics, which includes not only relevant logic, BCK logic, linear logic and the Lambek calculus but also weak logics with strict implication, and de ne Kripke- style semantics (Kripke frames and models) for normal substructural logics. Then we show a correspondence between axioms and properties on frames, and give a canonical construction of Kripke models for normal substructural logics.         Keywords: Kripke-type semantics, canonical model, linear logic, relevant  logics, strict implication, substructural logics               Categories: F.4.1  
6|1||Computational Complementarity and Shift Spaces|"  Marjo Lipponen (Department of Mathematics, Finland)  Abstract: Computational complementarity was introduced to mimic the physical complementarity in terms of finite automata (with outputs but no initial state). Most of the work has been focussed on ""frames"", i.e., on fixed, static, local descriptions of the system behaviour. The first paper aiming to study the asymptotical description of complementarity was restricted to certain types of sofic shifts. In this paper we continue this work and extend the results to all irreducible sofic shifts. We also study computational complementarity in terms of labelled graphs rather than automata.                   Keywords: complementarity principles, finite automata, graphs, sofic shifts               Categories: F.1.1  "
6|1||Simulating H Systems by P Systems|  Gheorghe Paun (Institute of Mathematics of the Romanian Academy, Romania)   Takashi Yokomori (Department of Mathematics, School of Education, Waseda University, Japan)  Abstract: H systems are DNA computing models, based on the  operation of splicing. P systems are membrane computing models, where objects can evolve in parallel in a hierarchical membrane structure. In particular, the objects can be strings and the evolution rules can be based on splicing. Both H systems with certain controls on the use of splicing rules and P systems of various types are known to be computationally universal, that is, they characterize the recursively ennumerable languages. So, they are equivalent as the generative power.                          The present paper presents a direct simulation of some controlled H systems by splicing P systems. We achieve this goal for three basic regulation mechanisms: H systems with permitting contexts, H systems with forbidding contexts, and communicating distributed H systems. We can say that in this way we get a uniform implementation of the three types of H systems in the form of a computing cell.                   Keywords: H systems, splicing rule, universal models of computation               Categories: F.1.1  
6|1||On Equational Craig Interpolation|  Grigore Rosu (Department of Computer Science & Engineering, University of California, San Diego and Fundamentals of Computing, Faculty of Mathematics, University of Bucharest, Romania)   Joseph Goguen (Department of Computer Science & Engineering, University of California, USA)  Abstract: Generalizations of Craig interpolation are investigated for equational logic. Our approach is to do as much as possible at a categorical level, before drawing out the concrete implications.                  
6|1||Notes on Partially-Ordered Structures in Computer Science: I. PA-Ordered Semirings and Some Related Structures|  Dragos Vaida (Department of Fundamentals of Computer Science, University of Bucharest, Romania)  Abstract: While the existence of inverses is a natural  condition in Algebra it is seldom satisfied in Computer Science applications. Since the group-theoretical orientation has to be abandoned we consider an advantage when the non-conventional structures needed are linked to an already existing knowledge. We propose semirings as a candidate and we aim at the Computer Science applications such as processes semantics, parallel composition, Fuzzy Theory, images ordering or MV-algebras. After the definition of pa-ordered semiring four typical examples are given. Some results concerning additively idempotent semirings are extended to monoids considered as their natural background. A direct sum representation is given for lower semilattice-ordered Gelfand semirings s-ordered. A sufficient condition is given for having the natural quasi-order an s-order. A multiplicative ordering is built up and its application to Visual Data is indicated. Wrt complements in pa-semirings we give sufficient conditions for the existence of some sums and for commutativity.              Keywords: quasi-order, s-order, semiring               Categories: F.4.1  
6|1||Extractors for the Real World|  Kundi Xue (School of Computer and Information Sciences, Georgia Southwestern State University, USA)   Marius Zimand (Department of Computer and Information Sciences, Towson University, Towson, MD, USA and Department of Computer Science, University of Bucharest, Romania)  Abstract: Extractors are a special type of binary graphs that can be utilized to improve the quality of randomness sources that generate strings with small entropy. The paper explores constructions of extractors that are practical and easy to implement. Randomized and deterministic constructions are presented and compared with some previously known constructions that achieve very good asymptotical performances. One of our methods is shown to have a better behavior for reasonable values of the involved parameters.                   Keywords: Random bits, extractors, hash functions, source of randomness               Categories: F.2.2, G.2.2, G.3  
6|10|http://www.jucs.org/jucs_6_10|J.UCS Special Issue on Multithreaded Processors and Chip-Multiprocessors|
6|10||On Dynamic Speculative Thread Partitioning and the MEM-Slicing Algorithm|  Lucian Codrescu (Electrical and Computer Engineering, Georgia Institute of Technology, USA)   D. Scott Wills (Electrical and Computer Engineering, Georgia Institute of Technology, USA)  Abstract: A dynamic speculative multithreaded processor automatically extracts thread level parallelism from sequential binary applications without software support. The hardware is responsible for partitioning the program into threads and managing inter-thread dependencies. Current published dynamic thread partitioning algorithms work by detecting loops, procedures, or partitioning at fixed intervals. Research has thus far examined these algorithms in isolation from one another. This paper makes two contributions. First, it quantitatively compares different dynamic partitioning algorithms in the context of a fixed microarchitecture. The architecture is a single-chip shared memory multiprocessor enhanced to allow thread and value speculation. Second, this paper presents a new dynamic partitioning algorithm called MEM-slicing. Insights into the development and operation of this algorithm are presented. The technique is particularly suited to irregular, non-numeric programs, and greatly outperforms other algorithms in this domain. MEM-slicing is shown to be an important tool to enable the automatic parallelization of irregular binary applications. Over SPECint95, an average speedup of 3.4 is achieved on 8 processors.               Keywords: analysis and design aids, architectures, control structure performance, multiprocessor               Categories: B.1.2, C.1.2  
6|10||Performance of Switch Blocking on Multithreaded Architectures|  K. Gopinath (Department of Computer Science & Automation Indian Institute of Science, India)   M.K. Krishna Narasinhan (Department of Computer Science & Automation Indian Institute of Science, India)  Abstract: Block multithreaded architectures tolerate large memory and synchronization latencies by switching contexts on every remote-memory-access or on a failed synchronization request. We study the performance of a waiting mechanism called switch-blocking where waiting threads are disabled (but not unloaded) and signalled at the completion of the wait in comparison with switch_spinning where waiting threads poll and execute in a round-robin fashion. We present an implementation of switch-blocking on a cycle-by-cycle simulator for Alewife (a block multithreaded machine) for both remote memory accesses and synchronization operations and discuss results from the simulator. Our results indicate that while switch-blocking almost always has better performance than switch-spinning, its performance is similar to switch-spinning under heavy lock contention. Support for switch-blocking for remote memory accesses may be appropriate in the future due to their strong interactions with synchronization operations.               Keywords: algorithms, blocking, competitive analysis, locks, performance, producer_consumer synchronization, spinning, theory-barriers, waiting time               Categories: C.1.2, C.4, D.4.1, D.4.8  
6|10||Execution and Cache Performance of the Scheduled Dataflow Architecture|  Krishna Kavi (The University of Alabama, USA)   Joseph Arul (The University of Alabama, USA)   Roberto Giorgi (Universita' di Siena, Italy)  Abstract:   This paper presents an evaluation of our Scheduled Dataflow (SDF) Processor. Recent focus in the field of new processor architectures is mainly on VLIW (e.g. IA-64), superscalar and superspeculative architectures. This trend allows for better performance at the expense of an increased hardware complexity and a brute-force solution to the memory-wall problem. Our research substantially deviates from this trend by exploring a simpler, yet powerful execution paradigm that is based on dataflow concepts. A program is partitioned into functional execution threads, which are perfectly suited for our non-blocking multithreaded architecture. In addition, all memory accesses are decoupled from the thread's execution. Data is pre-loaded into the thread's context (registers), and all results are post-stored after the completion of the thread's execution. The decoupling of memory accesses from thread execution requires a separate unit to perform the necessary pre-loads and post-stores, and to control the allocation of hardware thread contexts to enabled threads.  The analytical analysis of our architecture showed that we could achieve a better performance than other classical dataflow architectures (i.e., ETS), hybrid models (e.g., EARTH) and decoupled multithreaded architectures (e.g., Rhamma processor). This paper analyzes the architecture using an instruction set level simulator for a variety of benchmark programs. We compared the execution cycles required for programs on SDF with the execution cycles required by the programs on DLX (or MIPS). Then we investigated the expected cache-memory performance by collecting address traces from programs and using a trace-driven cache simulator (Dinero-IV). We present these results in this paper.  Keywords: dataflow architectures, decoupled architectures, memory latency, multithreaded architectures, superscalars               Categories: C.1.2, C.1.3, D.1.1  
6|10||Compiler Generated Multithreading to Alleviate Memory Latency|  Kristof E. Beyls (Dept. of Electronics and Information Systems University of Ghent, Belgium)   Erik H. D'Hollander (Dept. of Electronics and Information Systems University of Ghent, Belgium)  Abstract: Since the era of vector and pipelined computing, the computational speed is limited by the memory access time. Faster caches and more cache levels are used to bridge the growing gap between the memory and processor speeds. With the advent of multithreaded processors, it becomes feasible to concurrently fetch data and compute in two cooperating threads. A technique is presented to generate these threads at compile time, taking into account the characteristics of both the program and the underlying architecture. The results have been evaluated for an explicitly parallel processor. With a number of common programs the data-fetch thread allows to continue the computation without cache miss stalls.               Keywords: cache optimization, compiler optimization, data locality, multithreading, prefetching, run-time data relocation, tiling                
6|10||On the Thread Scheduling Problem|  Wing-Ning Li (Department of Computer Science and Computer Engineering, University of Arkansas, USA)   Jing-Fu Jenq (Department of Computer Science, Montclair State University, USA)  Abstract: This paper considers the thread scheduling problem. The thread scheduling problem abstracts the problem of minimizing memory latency, using a directed data dependency graph generated form a compiler, to improve run time effciency. Two thread scheduling problems are formulated and shown to be strongly NP-complete. New methods and algorithms for analyzing a data dependency graph in order to compute the theoretical best runtime (lower bound of the finishing time) and to estimate the required minimum number of PEs needed to achieve certain finishing time are presented. The new methods and algorithms improve upon some of the existing analysis and transformation techniques.               Keywords: complexity, memory latency, multi-threaded architecture, scheduling                
6|10||Data Driven Network Of Workstations (D²NOW)|  Paraskevas Evripidou (Department of Computer Science, University of Cyprus, Cyprus)   Costas Kyriacou (Department of Computer Science, University of Cyprus, Cyprus)  Abstract: This paper presents the Data Driven Network Of Workstations (DNOW), a multithreaded architecture that is based on the Decoupled Data Driven model of execution. This model decouples the synchronization from the computation portions of a program and allows them to execute asynchronously. At compile time a Multithreaded program is created with a Data-Driven thread synchronization graph superimposed on it.                          DNOW is built using commodity control-flow microprocessors. The support for the data driven synchronization of threads, is provided by the Thread Synchronization Unit (TSU). The TSU is attached in the COAST (Cache On A STick) L2 Cache slot of Pentium workstations and thus it has an implicit interface, using snooping, to the Pentium microprocessor. Workstations are connected via a Telegraphos interconnection network, which is a high throughput ATM-like switch. Telegraphos uses short packets and guarantees no packet-drop, which is a must for fine grain data-driven computation. DNOW exhibits the tolerance to long memory and communication latencies, of the data-driven model, with very little overhead and also exploits short-term optimal cache placement and replacement policies. In our prototype implementation the TSU is implemented using FPGAs and it has very low hardware overhead.               Keywords: NOW, distributed shared memory, multithreading               Categories: B.3.2, C.1.2, C.1.3  
6|10||MSparc: Multithreading in Real-Time Architectures|  Alexander Metzner (Carl von Ossietzky University Oldenburg, Germany)   Juergen Niehaus (Carl von Ossietzky University Oldenburg, Germany)  Abstract: This paper presents the use of multithreaded  processors in real-time architectures. In particular we will handle real-time applications with hard timing constraints. In our approach, events (e.g. timer interrupts, signals from the environment, etc) are distinguished into three classes according to the reaction times that have to be met. Since two of these classes are well known in real-time systems, we will focus on the new class, for which the special features of a multithreaded processor together with a real-time scheduler realized in hardware are employed. Doing so enables us to realize the handling of events from this new class in software while still meeting the demands on reaction time. Additionally, the predictability of the application and the ease of implementing them are increased. The processor, named MSparc, which we developed to support these features, is based on block multithreading and is outlined in this paper, too. We then present an architecture, designed for rapid prototyping of embedded systems, to show the feasibility of this approach. Finally, a case study shows the potential of multithreading for embedded systems.               Keywords: MSparc, multithreading, rapid  prototyping, real-time systems               Categories: C.1  
6|11|http://www.jucs.org/jucs_6_11|J.UCS Special Issue on Formal Specifications of Computer-Based Systems|
6|11||Nondeterministic Admissible Interference|  John Mullins (Ecole Polytechnique de Montreal, Canada)  Abstract: In this article we address the issue of confidentiality of information in the context of downgrading systems i.e. systems admitting information flow between secrecy levels only through a downgrader. Inspired by the intuition underlying the usual definition of admissible information flow, we propose an analogue based on trace equivalence as developed in the context of concurrency theory and on a modification of the usual definition of purge function. We also provide unwinding conditions to guarantee a consistent and complete proof method in terms of communicating transition systems. We take advantage of this framework to investigate its compositionality issues w.r.t. the main operators over communicating transition systems. We conclude the article with a short presentation of this work s most promising aspects in the perspective of future developments.               Keywords: confidentiality, information flow properties, intransitive noninterference, noninterference, program verification, security models, specification techniques               Categories: D.2.1, D.2.4, F.3.1  
6|11||Use of E-LOTOS in Adding Formality to UML|  Robert Clark (University of Stirling, UK)   Ana Moreira (Universidade Nova de Lisboa, Portugal)  Abstract: E-LOTOS, a new version of the ISO standard specification language LOTOS, is currently being developed. We describe how it can be used to give a formal meaning to, and to discover inconsistencies in, UML models. As part of this work, we give mappings from UML constructs to E-LOTOS. Emphasis is placed on dealing with UML use case, class and interaction diagrams as these play the dominant part in the development of a UML analysis or high-level design model. Requirements are usually inconsistent and incomplete and we deal with how this can be modelled in a formal language.               Keywords: E-LOTOS, UML, formal modelling, inconsistent specifications                
6|11||An Outline of PVS Semantics for UML Statecharts|  Issa Traoré (Department of Electrical and Computer Engineering, University of Victoria, Canada)  Abstract: The current UML standard provides definitions for the semantics of its components. These definitions focus mainly on the static structure of UML, but they don t include an execution semantics. These definitions include several semantic variation points leaving out the door open for multiple interpretations of the concepts involved. This situation can be handled by formalizing the semantic concepts involved. In this paper we present an approach for the formalization of one of the multiple diagrams of UML, namely statechart diagrams. That is achieved by using the PVS Specification Language as formal semantics domain. We present also how the approach can be used to conduct a formal analysis using the PVS model-checker.               Keywords: PVS, UML, formal methods, object-orientation, open distributed systems, specification               Categories: D.1.5, D.2.4, D.3.1  
6|11||Modeling Information System Behavior with Dynamic Relations Nets|  Laurent Allain (Institut Superieur d'Electronique du Nord, Departement Informatique, France)   Pascal Yim (Ecole Centrale de Lille, France)  Abstract: In this paper we highlight three main qualities for a processing model: processing abstraction, dynamic behavior and graphical representation. We define a model closely related to high-level Petri Nets. Dynamic Relations Nets (DRN) allow the specification of data, processing, events and constraints within a unique graphical representation. Annotations of the net use a set based abstract language. Constraints arise from three levels: from places (related to the notion of abstract type), from markings (we can then express global constraints between places), and from transitions (in order to specify processing as state transformations). The DRN formalism has been successfully applied to a number of case studies. In this paper, we develop the standard `IFIP case , which has been handled with a lot of modeling methods. A DRN specification has a well defined operational semantics. Therefore a DRN can also be viewed as an executable specification of information systems. We briefly introduce a tool designed to operate an application developed with DRNs, namely NetSpec, based on the use of an active database management system. This tool allows an automated code generation (C/SQL) from a DRN specification.               Keywords: Petri nets, code generation, constraints, dynamic behavior, information systems.               Categories: D.2.2, D.3.4, H.4.2  
6|11||Towards Two-Level Formal Modeling of Computer-Based Systems|  Gabor Karsai (Vanderbilt University, USA)   Greg Nordstrom (Vanderbilt University, USA)   Akos Ledeczi (Vanderbilt University, USA)   Janos Sztipanovits (Vanderbilt University, USA)  Abstract: Embedded Computer-based Systems are becoming  highly complex and hard to implement because of the large number of concerns the designers have to address. These systems are tightly coupled to their environments and this requires an integrated view that encompasses both the information system and its physical surroundings. Therefore, mathematical analysis of these systems necessitates formal modeling of both sides and their interaction. There exist a number of suitable modeling techniques for describing the information system component and the physical environment, but the best choice changes from domain to domain. In this paper, we propose a two-level approach to modeling that introduces a meta-level representation. Meta-level models define modeling languages, but they can also be used to capture subtle interactions between domain level models. We will show how the two-level approach can be supported with computational tools, and what kind of novel capabilities are offered.                 Categories: D.2.2  
6|11||A Survey of Formal Methods Applied to Leader Election in IEEE 1394|  Savi Maharaj (University of Stirling, United Kingdom)   Carron Shankland (University of Stirling, United Kingdom)  Abstract: We present a survey of formal specification techniques applied to the Tree Identify Protocol of the IEEE 1394 High Performance Serial Bus 1 . Specifications written in a variety of formalisms are compared with regard to a number of criteria including expressiveness, readability, standardisation, and level of analysis.               Keywords: comparative case study, concurrency, formal methods, leader election protocol, networks, standards               Categories: D.2.1, F.3.1  
6|12|http://www.jucs.org/jucs_6_12|Managing Editor's Column|
6|12||Grammar Systems with Negated Conditions in their Cooperation Protocols|  Henning Bordihn (Fakultät für Informatik, Otto-von-Guericke-University, Germany)   Markus Holzer (Departement d'I.R.O., Université de Montreal, Canada)  Abstract:   The investigation on Boolean operations on the stop conditions of derivation modes for cooperating distributed grammar systems is continued by considering the logical negation of such conditions. The focus is on the negation of the t-mode of derivation, where such non-t-components may stop rewriting only if they still have a production applicable to the current sentential form. In many cases, hybrid cooperating distributed grammar systems with non-t-components turn out to give new characterizations of the class of programmed context-free languages or recurrent programmed context-free languages, where the latter class coincides with the biologically motivated family of languages generated by ET0L systems with random context. Thus, the results presented in this paper can shed new light on some longstanding open problems in the theory of regulated rewriting.    Keywords: formal languages, grammar systems, programmed grammars, regulated rewriting               Categories: F.4.2, F.4.3  
6|12||Incompleteness in Linear Time|  Salvatore Caporaso (Dipartimento di Informatica dell'Università di Bari, Italy)   Giovanni Pani (Dipartimento di Informatica dell'Università di Bari, Italy)   Emanuele Covino (Dipartimento di Informatica dell'Università di Bari, Italy)  Abstract: A class LT 0 of functions computable in a proper sub_class of Lintime is defined, and formalized in a system LT0 of monadic and atomic (quantifier-free) logic. In spite of its poor computational complexity power and logical apparatus, this system has enough power to describe its own proof-predicate. Therefore it might qualify as smallest known system in which Gödel-like diagonalization can be applied. A proof is given that the identically true functions of LT 0 are productive. Hence this incompleteness phenomenon doesn t depend on the technicalities adopted to show it.               Keywords: computational complexity, incompleteness, linear time               Categories: F.4.1  
6|12||Active Documents: Concept, Implementation and Applications|  Eva Heinrich (Massey University, New Zealand)   Hermann Maurer (Graz University of Technology, Austria)  Abstract: In this paper we present the notion of active documents. The basic idea is that in the future, users of documents in any networked system should not just be able to communicate with other users, but also with documents. To put it differently, we believe that communication in networks should be understood in a more general sense than it usually is. Although our notion will, at first glance, almost look like science fiction, we will show that good approximations can indeed be implemented. We conclude this short paper by pointing out a number of important applications of our new concept and mention cases where it has been applied already, successfully.               Keywords: WBT, eLearning, knowledge management, web based teaching               Categories: H.4, H.5, J.7, K.3  
6|12||Some Elements of Z Specification Style: Structuring Techniques|  Anthony MacDonald (Department of Computer Science and Electrical Engineering, and Software Verification Research Centre, The University of Queensland, Australia)   David Carrington (Department of Computer Science and Electrical Engineering, and Software Verification Research Centre, The University of Queensland, Australia)  Abstract: This article investigates the issue of structuring Z specifications. It uses examples from a large specification (the production cell) to examine both conventions for using Z and notational extensions, including Object-Z. Because of the importance of good structure within a specification, specifiers need to be aware of a range of structuring techniques and understand where each is applicable.               Keywords: Z notation, formal specification, specification structure               Categories: D.2.1, F.3.1, F.4.3  
6|12||New Tools for Cellular Automata in the Hyperbolic Plane|  Maurice Margenstern (Laboratoire d'Informatique Théorique et Appliquée, Université de Metz, I.U.T. de Metz, Département d'Informatique, Île du Saulcy, France)  Abstract: In this paper, we introduce a new technique in order to deal with cellular automata in the hyperbolic plane. The subject was introduced in [7] which gave an important application of the new possibility opened by the first part of that paper. At the same time, we recall the results that were already obtained in previous papers.                          Here we go further in these techniques that we opened, and we give new ones that should give better tools to develop the matter.               Keywords: cellular automata, hyperbolic plane, tessellations               Categories: F.1, F.1.1, G.2  
6|2|http://www.jucs.org/jucs_6_2|Managing Editor's Column|
6|2||The Price of Routing in FPGAs|  Florent de Dinechin (Projet Arénaire, LIP-CNRS-INRIA, École Normale Superieure de Lyon, France)  Abstract: Studying the architectural evolution of mainstream  field programmable gate arrays (FPGAs) leads to the following remark: in these circuits, the proportion of silicon devoted to reconfigurable routing is increasing, reducing the proportion of silicon available for computation resources. A quantitative analysis shows that this trend, if pursued, will lead to a widening gap between FPGA performance and VLSI performance. Some prospective solutions to this problem are discussed.               Keywords: FPGA, hardware complexity, reconfigurable computing, routing resources               Categories: B.7  
6|2||Potential-Function_Based Analysis of an Off-Line Heap Construction Algorithm|  Alan Roberts (Department of Computer Science, University of Sydney, Australia)   Antonios Symvonis (Department of Computer Science, University of Sydney, Australia)  Abstract:   In this paper we examine the problem of heap construction on a rooted tree T from a packet routing perspective. Each node of T initially contains a packet which has a key-value associated with it. The aim of the heap construction algorithm is to route the packets along the edges of the tree so that, at the end of the routing, the tree is heap ordered with respect to the key values associated with the packets. We consider the case where the routing is performed according to the matching model and we present and analyse an off-line algorithm that heap orders the tree within 2h(T) routing steps, where h(T ) is the height of tree T. The main contribution of the paper is the novel analysis of the algorithm based on potential functions. It is our belief that potential functions will be the main vehicle in analysing fast non-recursive routing algorithms.    Keywords: heap construction, matching routing model, off-line/on-line algorithms, packet routing, potential functions                
6|3|http://www.jucs.org/jucs_6_3|Wonders of the Invisible Workplace: IT and Process Reinvention|"  Patricia A. Carlson (Rose-Hulman Institute of Technology, IN)  Abstract:   This introduction briefly summarizes the six articles that makeup this special issue on IT and process reengineering, and places them against a backdrop of the role of IT within the 21stcentury organization. Maintaining high-quality information technology (IT) is essential as organizations move toward a ""system of systems"" and a ""team of team."" Added to this milieu of managed change are emerging new requirements for leadership and challenging new roles for knowledge workers in the next decade. This article examines three goals for IT in organizations: increased productivity, mediated change, and empowered workforce. Four enablers are identified as the means through which IT can accomplish modernization: (1) using next-generation IT as cognitive tools, (2) understanding the dynamics of organizational culture in order to purposefully change culture, (3) nurturing human performance as a source of yet unrealized gains, (4) leading people as well as managing resources.    Keywords: computers and education, computers and society, information systems, management of computing and information systems               Categories: C.5, H.4, J.4, K.3, K.6  "
6|3||The Information Society as a Complex System|  Ioannis Antoniou (International Solvay Institutes for Physics and Chemistry and Vrije Universiteit Brussel, Belgium)   Mike Reeve (University of Southampton, UK)   Vic Stenning (Imperial College, UK)  Abstract: We are all very conscious of living through a revolution - one in which the industrial society is being superseded by the information society. Every day brings new evidence of the breakneck pace of the changes that are currently underway. But while broad awareness may be unavoidable, understanding is not so easy. Both the pace of the revolution and its multi-faceted nature make it difficult to gain a clear perspective. But here the new science of complexity can perhaps help. It provides a coherent theory that is directly applicable to the emerging society, potentially providing new insights and new understanding. This paper examines several facets of the current revolution from a complexity perspective, and suggests that the relationship between the emerging science and the emerging society will be a rich one.               Keywords: complexity, information society               Categories: K.4  
6|3||Methodologies and Tools For Continuous Improvement of Systems|  William D. Schindel (International Centers for Telecommunications Technology, Inc., and System Sciences, LLC)   Gloria M. Rogers (Rose-Hulman Institute of Technology, USA)  Abstract: Continuous improvement of hard technology (software, electronic, mechanical, chemical, biological, etc.) systems and institutional (mixed human and technology based) systems is examined from a system perspective, applying system engineering and assessment methodologies and tools. Class and containment hierarchies are used to simplify the modeling of complex systems and their dynamic processes, particularly system families with both shared standardized content and necessary diversity, resolving addressing an historical tension. The engineering concept of _embedded system_ is formalized as modeled patterns of embedding management intelligence in both hard technology systems and human institutions. Embedded intelligence models describe intelligent performance, human learning, technical system life cycle improvement, and institutional improvement of all systems. The resulting models describe situationally aware, conscious systems, whether adaptive man_made systems or continuously improving institutions. Models include system requirements, design, verification, and change management. Assessment of system performance against goals determines priority for continuing system improvement. After treating human and hard technology systems on a unified basis, their significant differences are recognized through knowledge worker educational processes, personal reflection on performance, and use of electronic portfolios exhibiting best work. Tools supporting these methodologies are Intranet infrastructure providing computer support of the collaborative work of specifying institutional and technical system requirements, design, assessment, and improvement change management. This approach originates from integrating methodologies and tools of a collegiate educational institution and a commercial engineering enterprise, applied to educational and industrial client systems, environments, technologies, and markets. The resulting approach creates a unified framework for continuous improvement of systems.               Keywords: accreditation, assessment, business reengineering, collaborative work, consciousness models, continuous improvement, education, embedded system, hierarchy theory, knowledge engineering, life cycle, management, methodology, operations support system (OSS), portfolio, productivity, reverse engineering, software engineering, system engineering, tools, use case               Categories: A.1, H.1, I.2.4, K.3.1, K.6.4  
6|3||Coffein: Construction and Presentation of Design Knowledge|  Stefanie Thies (University of Paderborn, Germany)  Abstract: Design is a hard problem: ill defined and  open-ended. Schoen [Schön 83] characterized the process of designing an artifact as a successive refinement of reflection and redesign. Critiquing - the communication of reasoned opinion about an artifact - plays a central role in the design process. A computational critiquing mechanism provides an effective form of human-computer interaction to support these important aspects of design [Fischer 91]. Systems which realize such a computational critiquing mechanism are called Critiquing Systems. These systems provide context sensitive advice and rationale for an artifact designed by a user. This is realized by delivering so-called critiques, which contain relevant information for the user to the task at hand and are some kind of rule of thumb. But design experts are not programmers and programmers are not designers. So we need a module which supports design experts in stating their knowledge in form of critiques. The basis for this module is a a visual critiquing language (here called visual CiLa), completed by a knowledge construction supporting component. Furthermore a single design expert normally does not have all existing design knowledge. So the necessary information for building a complete design system is distributed among different stakeholders. Therefore we additionally need concepts and algorithms to combine and structure the critiquing knowledge of different design experts to construct a trustful, consistent and wise codesigner. This aspect is done by a module constructing the knowledge base and a module for constructing the virtual codesigner. These two aspects - design knowledge construction and presentation - are realized in a tool called Coffein. This article deals with the way Coffein works and how it influences the design process.               Keywords: information systems, knowledge based sysem, knowledge construction, life-long-learning, multi-expert system, scientific visualization, visual language               Categories: H.5.1  
6|3||Integrated Applications of Electronic Structure Computations in the Undergraduate Chemistry Curriculum|  Rita K. Hessley (The University of Cincinnati, USA)   Daniel L. Morris, Jr. (Rose-Hulman Institute of Technology, USA)   Michael R. R. Mueller (Rose-Hulman Institute of Technology, USA)  Abstract: This paper describes the integrated use of electronic structure computations in the undergraduate chemistry curriculum including organic, physical, and analytical chemistry courses. This computational tool is used to enhance student learning and understanding of chemical principles along with exposing students to a modern research tool in chemistry. The electronic structure computations are used for homework, classroom activities (including examinations), and laboratory experiments (both computational and wet-lab). Some examples of these uses of electronic structure computations in organic, analytical, and physical chemistry courses are discussed.               Keywords: academic Computing, chemistry, electronic structure computations, undergraduate chemistry curriculum               Categories: J.  
6|3||Electronic Submission, Managing and Approval of Grant Proposals at the German Research Foundation based on Standard Internet and Office Tools|  Dieter W. Fellner (Braunschweig University of Technology, Germany)   Marco Zens (Braunschweig University of Technology, Germany)  Abstract: Today, grant proposals submitted to the German Research Foundation (DFG) are paper documents. They are received by ordinary mail, manually entered into a proprietary software system and, finally, information relevant to the specific task is extracted manually and sent to other departments involved in the reviewing/approval process. Of course, all these activities are purely hard-copy based. This paper gives a first report on a research project _GoldenGate_ which focuses on the development of a prototype system for a complete electronic workflow including submission, managing and approval of applications for research funding at the DFG. Typically one would use one of the available Information/Workflow Management Systems, but after careful consideration we made the decision to use a set of standard software tools and formats (i.e. Hyperwave Information Server, MS Office 97, XML) as the key components of our new system and combine them with minimal but flexible interfaces. These ideas, the situation at the DFG, technical details of our present implementation and preliminary results are presented in this paper.                 Categories: H.4.1, H.5.3  
6|3||Perceptions about Internet Use by Teaching Faculty at Small Christian Colleges and Universities|  Jessie Lennertz (Taylor University, USA)  Abstract: This study investigated the self-reported effects of Internet use on faculty at small Christian colleges and universities by age, years of Internet use, academic field, and on faculty communication style, teaching style, personal productivity, fulfillment of the organization s mission, social networks, research, and professional development. Findings: Faculty believed that their communication had changed and that they can communicate with others more quickly, get faster replies to questions, and obtain more relevant data. Faculty disagreed that their teaching style had changed and that they had changed the way they conduct a class. Faculty believe that their productivity has changed. Most faculty disagreed that the Internet has made them more comfortable sharing their feelings about God. Faculty believe that the Internet has changed the type of jobs and the way students look for jobs, that there are fewer barriers to joining an electronic group, and that the volume of people they keep in frequent touch with has increased. Most faculty agreed that the way they do research has changed and that the Internet makes it easier to get information about advances in their fields. Faculty disagreed that the Internet could be substituted for conferences and that the Internet has made it possible for them to serve on boards. Key Words: Internet, faculty, communication, professional development, personal productivity, research, social networks, teaching, mission.                 Categories: A.1, K.4.2, K.4.3  
6|4|http://www.jucs.org/jucs_6_4|J.UCS Special Issue on BCTCS|
6|4||Formal Specification from an Observation-Oriented Perspective|  Meurig Beynon (Department of Computer Science, University of Warwick, UK)   Jaratsri Rungrattanaubol (Department of Computer Science, University of Warwick, UK)   Jane Sinclair (Department of Computer Science, University of Warwick, UK)  Abstract: A formal specification of an algorithm is a very  rich mathematical abstraction. In general, it not only specifies an input-output relation, but also - at some level of abstraction - constrains the states and transitions associated with computing this relation. This paper explores the relationship between a formal specification of an algorithm and the many different ways in which the associated states and transitions can be embodied in physical objects and agency. It illustrates the application of principles, tools and techniques that have been developed in the Empirical Modelling Project at Warwick and considers how such an approach can be used in conjunction with a formal specification for exploration and interpretation of a subject area. As a specific example, we consider how Empirical Modelling can be helpful in gaining an understanding of a formal development of a heapsort algorithm.               Keywords: agent-oriented modelling, dependency, formal specification, heapsort, invariants, pre- and  post-conditions               Categories: F.3.1  
6|4||Using Genetic Algorithms to Solve the Motion Planning Problem|"  Craig Eldershaw (Oxford University Computer Laboratory, United Kingdom)   Stephen Cameron (Oxford University Computer Laboratory, United Kingdom)  Abstract: Motion planning is a field of growing importance as more and more computer controlled devices are being used. Many different approaches exist to motion planning|none of them ideal in all situations. This paper considers how to convert a general motion planning problem into one of global optimisation. We regard the general problem as being the classical configuration space findpath problem, but assume that the configurations of the device can be bounded by a hierarchy of hyper-spheres rather than being explicitly computed. A program to solve this problem has been written employing Genetic Algorithms. This paper describes how this was done, and some preliminary results of using it.               Keywords: complex geometries, motion planning, path optimisation               Categories: G.1.6, I.2.10, I.2.8, I.2.9  "
6|4||Functional Reading of Logic Programs|  Silvija Seres (Oxford University Computing Laboratory, Wolfson Building, Parks Road, UK)   Michael Spivey (Oxford University Computing Laboratory, Wolfson Building, Parks Road, UK)  Abstract: We propose an embedding of logic programming into  lazy functional programming in which each predicate in a Prolog program becomes a Haskell function, in such a way that both the declarative and the procedural reading of the Prolog predicate are preserved.                           The embedding computes by means of operations on lazy lists. The state of each step in computation is passed on as a stream of answer substitutions, and all the logic operators of Prolog are implemented by explicit Haskell operators on these streams. The search strategy can be changed by altering the basic types of the embedding and the implementation of these operators. This model results in a perspicuous semantics for logic programs, and serves as a good example of modularisation in functional programming.               Keywords: algebraic methods, functional embedding, logic programming, program  transformation               Categories: D.1  
6|4||Region-Based Discrete Geometry|  M. B. Smyth (Department of Computing, Imperial College, UK)  Abstract: This paper is an essay in axiomatic foundations for discrete geometry intended, in principle, to be suitable for digital image processing and (more speculatively) for spatial reasoning and description as in AI and GIS. Only the geometry of convexity and linearity is treated here. A digital image is considered as a finite collection of regions, regions are primitive entities (they are not sets of points). The main result (Theorem 20) shows that finite spaces are sufficient. The theory draws on both region-based topology (also known as mereotopology) and abstract convexity theory.               Keywords: convexity, discrete geometry, mereotopology, regions                
6|4||Specifying and Verifying Real-Time Systems using Second-Order Algebraic Methods: A Case Study of the Railroad Crossing Controller|  L. J. Steggles (Department of Computer Science, University of Newcastle, UK)  Abstract: Second-order algebraic methods provide a natural and expressive formal framework in which to develop correct computing systems. In this paper we consider using second-order algebraic methods to specify real-time systems and to verify their associated safety and utility properties. We demonstrate our ideas by presenting a detailed case study of the railroad crossing controller, a benchmark example in the real-time systems community. This case study demonstrates how real-time constraints can be modelled naturally using second-order algebras and illustrates the substantial expressive power of second-order equations.               Keywords: algebraic specification methods, formal verification, real-time systems               Categories: C.3, F.3.1  
6|4||Ensuring Termination in ESFP|  Alastair Telford (The Computing Laboratory, The University, Canterbury, UK)   David Turner (The Computing Laboratory, The University, Canterbury, UK)  Abstract: In previous papers we have proposed an elementary discipline of strong functional programming (ESFP), in which all computations terminate. A key feature of the discipline is that we introduce a type distinction between data which is known to be finite, and codata which is (potentially) infinite. To ensure termination, recursion over data must be well-founded, and corecursion (the definition schema for codata) must be productive, and both of these restrictions must be enforced automatically by the compiler. In our previous work we used abstract interpretation to establish the productivity of corecursive definitions in an elementary strong functional language. We show here that similar ideas can be applied in the dual case to check whether recursive function definitions are strongly normalising. We thus exhibit a powerful termination analysis technique which we demonstrate can be extended to partial functions.               Keywords: abstract interpretation, functional programming, termination analysis               Categories: D.1.1  
6|5|http://www.jucs.org/jucs_6_5|Managing Editor's Column|
6|5||A New Approach to Communicating X-Machines Systems|  Horia Georgescu (Faculty of Mathematics, Bucharest University, Romania)   Cristina Vertan (Faculty of Mathematics, Bucharest University, Romania)  Abstract: This paper presents a new model for the specification of communicating X-machine systems (CXMS). In previous papers, systems of X-machines have been implemented in two ways: using an unique X-machine which simulates the concurrent behaviour of several processes [1], or using several X-machines which communicate through asynchronous channels [2].                         This article introduces an X-machine system for which the communication between components is done through synchronous channels. The model supposes that each X-machine has a local memory, an input and an output tape. The X-machines act simultaneously. The states of each component of the system are partitioned into processing and communicating states. Passing messages between the X-machines involves only communicating states. It is shown that, taking advantage of the behaviour of X-machines, communication using channels may be implemented, thus providing a synchronous message passing.               Keywords: communicating X-machine systems, communication using channels, concurrent processes               Categories: D.1.3, F.1.2, H.2.4  
6|5||Treeworld: A Conceptual Model for Large-Scale Hypermedia|  D. B. Skillicorn (Department of Computing and Information Science Queen's University, Kingston, Canada)  Abstract: Existing interfaces to large-scale hypermedia such as the world wide web have poor conceptual models and poor rendering of navigational and contextual information. New technologies that make it cheaper to use three-dimensional representations suggest the use of richer conceptual models. We discuss criteria for assessing more powerful conceptual models and design decisions that have to be made to exploit richer interfaces. The Treeworld model is suggested as one attractive example of such a model.               Keywords: 3-d glasses, Treeworld, conceptual model, focus + context, hierarchy, large-scale hypermedia, navigation, relevance structuring, search, teleportation, visualisation, world wide web               Categories: H.5  
6|5||Knowledge Management and Environmental Informatics|  Klaus Tochtermann (FAW ­ Research Institute for Applied Knowledge Processing, Germany)   Hermann Maurer (IICM, TU Graz, Austria)  Abstract: The objective of this paper is to identify synergy fields and relationships between knowledge management and environmental informatics. From the perspective of knowledge management many sophisticated techniques, concepts, and methodologies developed in the domain of environmental informatics can build the starting point for finding answers to open questions in knowledge management. For example, meta-knowledge management can capitalise on existing results gained in the area of metadata management, which plays a key role in environmental informatics. Up to now, many tools for knowledge processing have been applied in the domain of environmental informatics to help solve environmental problems. New knowledge management tools can improve this situation which in turn contributes directly or indirectly to a significant improvement of the protection of our environment. In order to achieve its objective, the paper introduces knowledge management with a strong focus on information technology. This introduction is followed by a literature survey on knowledge processing in environmental applications. Thereafter, several environmental information systems are analysed in the light of knowledge management. A special emphasis is placed on how geographical information systems can be used for knowledge management. Finally, the paper closes with suggestions of further areas of research in the synergy field of knowledge management and environmental informatics.               Keywords: data bases, environmetal data, information systems, knowledge management, visualization               Categories: H.1, H.2, H.3, H.4, J.3  
6|6|http://www.jucs.org/jucs_6_6|Managing Editor's Column|
6|6||Performance of RDBMS-WWW Interfaces under Heavy Workload|  Stathes Hadjiefthymiades (Department of Informatics, University of Athens, Greece)   Ioannis Varouxis (Department of Informatics, University of Athens, Greece)   Drakoulis Martakos (Department of Informatics, University of Athens, Greece)  Abstract: The WWW is currently considered as the most  promising and rapidly evolving software platform for the deployment of applications in wide area networks as well as enterprise intranets. Interfacing legacy systems like RDBMS to the WWW has become a very important issue to the computing industry. We discuss the efficiency of RDBMS gateways throughout periods of increased workload. We present a client/server architecture aiming to diminish overheads encountered in conventional gateways. The performance gain is assessed through a series of measurements. Alternative architectures were subject to the same measurements to assess the performance achieved by technologies like ODBC, JDBC, Dynamic SQL, ISAPI, NSAPI and CORBA.               Keywords: CGI, Java, RDBMS, SQL, Server API, WWW, gateway, performance               Categories: H.3.3, H.3.4, H.4  
6|6||Invariant Patterns in Crystal Lattices: Implications for Protein Folding Algorithms|"  William E. Hart (Sandia National Laboratories, USA)   Sorin Istrail (Celera Genomics, USA)  Abstract: Crystal lattices are infinite periodic graphs that occur naturally in a variety of geometries and which are of fundamental importance in polymer science. Discrete models of protein folding use crystal lattices to define the space of protein conformations. Because various crystal lattices provide discretizations of the same physical phenomenon, it is reasonable to expect that there will exist ""invariants"" across lattices related to fundamental properties of the protein folding process. This paper considers whether performance-guaranteed approximability is such an invariant for HP lattice models. We define a master approximation algorithm that has provable performance guarantees provided that a specific sublattice exists within a given lattice. We describe a broad class of crystal lattices that are approximable, which further suggests that approximability is a general property of HP lattice models.              Keywords: HP model, Protein folding, approximation algorithm, lattice models               Categories: F.2, J.3  "
6|7|http://www.jucs.org/jucs_6_7|J.UCS Special Issue on Requirements Engineering - The Light Control Case Study|
6|7||The Light Control Case Study: A Synopsis|  Egon Börger (Università di Pisa, Italy)   Reinhard Gotzhein (Universität Kaiserslautern, Germany)  Abstract: In this synopsis, we classify the solutions to the LCCS contained in this Special Issue according to a number of criteria. Furthermore, we provide brief descriptions of the focus of each solution, the major achievements and possible shortcomings. We leave it to the reader to establish a ranking of the different approaches, taking into account that the objectives of the contributions differ from each other and influence in particular the choice of languages, methods, and tools. Therefore, the synopsis is mainly based on information received from the authors, it does not present an in_depth analysis of the solutions. Nevertheless, we hope that this synopsis supports the reader in finding the right access to this Special Issue.               Keywords: building automation, classification, requirements engineering                
6|7||The Light Control Case Study: Problem Description|  Stefan Queins (University of Kaiserslautern, Germany)   Gerhard Zimmermann (University of Kaiserslautern, Germany)   Martin Becker (University of Kaiserslautern, Germany)   Martin Kronenburg (University of Kaiserslautern, Germany)   Christian Peper (University of Kaiserslautern, Germany)   Rolf Merz (University of Kaiserslautern, Germany)   Juergen Schaefer (University of Kaiserslautern, Germany)  Abstract: This document contains a range of needs and requirements concerning the construction of a light control system for a floor of a university building. A description of the building architecture and of some pre-installed (light-)hardware is included. This problem description was the common input for all participants of the requirements engineering case study Light Control.               Keywords: building automation, problem description, requirements engineering                
6|7||Capturing Requirements by Abstract State Machines: The Light Control Case Study|  Egon Börger (Università  di Pisa, Dipartimento di Informatica, Italy)   Elvinia Riccobene (Università  di Catania, Dipartimento di Matematica e Informatica, Italy)   Joachim Schmid (Siemens AG, Germany)  Abstract: We show how to capture informally stated  requirements by an ASM (Abstract State Machine) model. The model removes the inconsistencies, ambiguities and incomplete parts in the informal description without adding details which belong to the subsequent software design. Such models are formulated using application-domain-oriented terminology and standard software engineering notation and bridge the gap between the application-domain and the system design views of the underlying problem in a reliable and practical way, avoiding any formal overhead. The basic model architecture reflects the three main system parts, namely for the manual and automatic light control and for handling failures and services. We refine the ground model into a version that is executable by AsmGofer and can be used for high-level simulation, test and debugging purposes.               Keywords: ASM, case study, light control, refinement, requirements               Categories: D.2.1  
6|7||Analyzing the Light Control System with PVS|  Adriaan de Groot (Computing Science Institute, University of Nijmegen, The Netherlands)   Jozef Hooman (Computing Science Institute, University of Nijmegen, The Netherlands)  Abstract: The interactive theorem prover PVS is used to formalize the user needs of the Light Control system. First the system is modeled at a high level of abstraction, in terms of properties the user can observe. After resolving ambiguities and conflicts, a refinement is defined, using dimmable light actuators. Correctness of the refinement has been proved in PVS, under the assumption that there are no internal delays. Next these internal delays are taken into account, leading to a new notion of delay-refinement which allows abstraction from delays such that systems with delays can be seen as an approximation of an undelayed specification.               Keywords: PVS, requirements engineering, specification               Categories: D.2.1  
6|7||Applying the SCR Requirements Method to the Light Control Case Study|  Constance Heitmeyer (Naval Research Laboratory, USA)   Ramesh Bharadwaj (Naval Research Laboratory, USA)  Abstract: To date, the SCR (Software Cost Reduction)  requirements method has been used in industrial environments to specify the requirements of many practical systems, including control systems for nuclear power plants and avionics systems. This paper describes the use of the SCR method to specify the requirements of the Light Control System (LCS), the subject of a case study at the Dagstuhl Seminar on Requirements Capture, Documentation, and Validation in June 1999. It introduces a systematic process for constructing the LCS requirements specification, presents the specification of the LCS in the SCR tabular notation, discusses the tools that we applied to the LCS specification, and concludes with a discussion of a number of issues that arose in developing the specification.               Keywords: formal verification, requirements, software, software engineering, specifications, tools and techniques               Categories: D.2.1, D.3.1  
6|7||Application of the FOREST Approach to the Light Control Case Study|  Martin Kronenburg (University of Kaiserslautern, Germany)   Christian Peper (University of Kaiserslautern, Germany)  Abstract: Forest is a requirements engineering approach designed to support the creation of precise and intelligible problem specifications of reactive systems. It integrates a product model, a process model, and an editing tool. In this paper, we present the results of applying the Forest approach to the Light Control Case Study. This includes the presentation of excerpts of the resulting problem specification, as well as the discussion of the strengths and shortcomings of the Forest approach.               Keywords: formal requirements specification, object-orientation, problem specification, real-time temporal logic               Categories: C.3, D.2.1, D.2.2, F.3.1, F.4.3  
6|7||Incremental Development of Real-Time Requirements: The Light Control Case Study|  Graeme Smith (Software Verification Research Centre, University of Queensland, Australia)   Colin Fidge (Software Verification Research Centre, University of Queensland, Australia)  Abstract: System requirements frequently change while the system is still under development. Usually this means going back and revising the requirements specification and redoing those development steps already completed. In this article we show how formal requirements can be allowed to evolve while system development is in progress, without the need for costly redevelopment. This is done via a formalism which allows requirements engineering steps to be interleaved with formal development steps in a manageable way. The approach is demonstrated by a significant case study, the Light Control System.               Keywords: embedded systems, formal specification, real-time systems, refinement, requirements engineering               Categories: C.3, D.2.1, D.2.4, J.7  
6|7||Requirements Capture and Evaluation in Nimbus: The Light-Control Case Study|  Jeffrey M. Thompson (University of Minnesota, Department of Computer Science and Engineering, USA)   Michael W. Whalen (University of Minnesota, Department of Computer Science and Engineering, USA)   Mats P. E. Heimdahl (University of Minnesota, Department of Computer Science and Engineering, USA)  Abstract:   Evaluations of methods and tools applied to a reference problem are useful when comparing various techniques. In this paper, we present a solution to the challenge of capturing the requirements for the Light Control System case study, which was proposed before the Dagstuhl Seminar on Requirements Capture, Documentation, and Validation in June of 1999.    The paper focuses primarily on how the requirements were specified: what techniques were used, and what the results were. The language used to capture the requirements is RSML-e; a state-based specification language with a fully specified formal denotational semantics. In addition, the Nimbus environment - a toolset supporting RSML-e - is used to visualize and execute the high-level requirements.    Keywords: formal requirements modeling, light control system, requirements execution and simulation, specification-based prototyping, state-based specification languages               Categories: D.2.1  
6|8|http://www.jucs.org/jucs_6_8|Managing Editor's Column|
6|8||Efficient Identification of Classes of P-Time Functions|  Sandra Fontani (University of Siena, Italy)  Abstract:   We consider the problem of identifying a class of p­time functions in efficient time. We restrict our attention to particular classes of p-time functions, called uniform and we try to identify each function of such a class by guessing, after a small number of examples, some index for it or its next value. In both cases we introduce two efficient identification paradigms, called efficient and very efficient identification respectively. We find a characterization for efficient identification and, as a corollary, we show that the entire class P is not efficiently identifiable. A necessary condition is shown for very efficient identification, which becomes sufficient if and only if P = NP. We give some examples of well-known uniform classes which are very efficiently identifiable in both identification paradigms.    Keywords: learning theory               Categories: I.2.6  
6|8||Syntax, Parsing and Production of Natural Language in a Framework of Information Compression by Multiple Alignment, Unification and Search|  J. Gerard Wolff (University of Wales, UK)  Abstract:   This article introduces the idea that information compression by multiple alignment, unification and search (ICMAUS) provides a framework within which natural language syntax may be represented in a simple format and the parsing and production of natural language may be performed in a transparent manner.   In this context, multiple alignment has a meaning which is similar to its meaning in bio­informatics but with significant differences, while unification means a simple merging of matching patterns, a meaning which is related to but simpler than the meaning of that term in logic. The concept of search in the present context means search for alignments which are `good' in terms of information compression, using heuristic methods or arbitrary constraints (or both) to restrict the size of the search space.  These concepts are embodied in a software model, SP61. The organisation and operation of the model are described and a simple example is presented showing how the model can achieve parsing of natural language.   Notwithstanding the apparent paradox of `decompression by compression', the ICMAUS framework, without any modification, can produce a sentence by decoding a compressed code for the sentence. This is illustrated with output from the SP61 model. The article includes four other examples ­ one of the parsing of a sentence in French and three from the domain of English auxiliary verbs. These examples show how the ICMAUS framework and the SP61 model can accommodate `context sensitive' features of syntax in a relatively simple and direct manner.   An important motivation for this research is the possibility of developing the ICMAUS framework as a unifying framework for diverse aspects of computing in addition to those described in this article. Other aspects which appear to fall within the scope of the ICMAUS framework but which are outside the scope of this article, include the representation of natural language semantics, best­match pattern recognition and information retrieval, deductive and probabilistic reasoning, planning and problem solving, and unsupervised inductive learning.   Keywords: MDL, MML, information compression, multiple alignment, natural language, parsing, production, syntax, unification               Categories: I.2.7  
6|8||The kth-Order Nonhomomorphicity of S-Boxes|  Yuliang Zheng (School of Network Computing, Monash University, Australia)   Xian-Mo Zhang (School of Information Technology and Computer Science, University of Wollongong, Australia)  Abstract: Nonhomomorphicity is a new nonlinearity criterion  of a mapping or S-box used in a private key encryption algorithm. An important advantage of nonhomomorphicity over other nonlinearity criteria is that the value of nonhomomorphicity is easy to estimate by the use of a fast statistical method. Due to the Law of Large Numbers, such a statistical method is highly reliable. Major contributions of this paper are (1) to explicitly express the nonhomomorphicity by other nonlinear characteristics, (2) to identify tight upper and lower bounds on nonhomomorphicity, and (3) to find the mean of nonhomomorphicity over all the S-boxes with the same size. It is hoped that these results on nonhomomorphicity facilitate the analysis and design of S-boxes.               Keywords: Boolean Functions, S-boxes, cryptanalysis, cryptography, nonhomomorphicity               Categories: E.3  
6|9|http://www.jucs.org/jucs_6_9|Managing Editor's Column|
6|9||Uniquely Parsable Accepting Grammar Systems|  Carlos Martín-Vide (Research Group on Mathematical Linguistics, Rovira i Virgili University, Spain)   Victor Mitrana (University of Bucharest, Faculty of Mathematics, Romania)  Abstract: We extend the restrictions which induce unique parsability in Chomsky grammars to accepting grammar systems. It is shown that the accepting power of global RC-uniquely parsable accepting grammar systems equals the computational power of deterministic pushdown automata. More computational power, keeping the parsability without backtracking, is observed for local accepting grammar systems satisfying the prefix condition. We discuss a simple recognition algorithm for these systems.                 Categories: F.4.2, F.4.3  
6|9||Uncertainty Propagation in Heterogeneous Algebras for Approximate Quantified Constraint Solving|  Stefan Ratschan (Research Institute for Symbolic Computation, Austria)  Abstract: When trying to solve quantified constraints (i.e., first-order formulas over the real numbers) exactly, one faces the following problems: First, constants coming from measurements are often only approximately given. Second, solving such constraints is in general undecidable and for special cases highly complex. Third, exact solutions are often extremely complicated symbolic expressions. In this paper we study how to do approximate computation instead of working on approximate inputs and producing approximate output. For this we show how quantiffied constraints can be viewed as expressions in heterogeneous algebra and study how to do uncertainty propagation there. Since set theory is a very fundamental approach for representing uncertainty, also here we represent uncertainty by sets. Our considerations result in a general framework for approximate computation that can be applied in various different domains.               Keywords: computational logic, constraints, interval computation, uncertainty               Categories: F.4.1, I.2.3, I.2.4  
6|9||Nonlinear Computation with Switching Map Systems|  Yuzuru Sato (Institute of Physics, Graduate School of Arts and Sciences, University of Tokyo, Japan)   Takashi Ikegami (Institute of Physics, Graduate School of Arts and Sciences, University of Tokyo, Japan)  Abstract: A dynamical systems based model of computation is studied. We demonstrate the computational capability of a class of dynamical systems called switching map systems. There exists a switching map system with two types of baker s map to emulate any Turing machines. The baker s maps are corresponding to the elementary operations of Turing machines such as left/right head-moving and read/write symbols. A connection between the generalized shifts by C. Moore [Moore 91] and the input-output mappings by L. Blum et al. [Blum, Cucker, Shub and Smale 98] is shown with our model. We present four concrete examples of switching map systems corresponding to the Chomsky hierarchy. Taking non-hyperbolic mappings as elementary operations, it is expected that the switching map systems shows a new model of computation with nonlinearity as an oracle.               Keywords: Henon map, Smale's horseshoe, baker's map, switching map systems               Categories: F.1  
volume|issue|url|title|abstract
7|1|http://www.jucs.org/jucs_7_1|J.UCS Special Issue on Tools for System Design and Verification|
7|1||DisCo Toolset - The New Generation|  Timo Aaltonen (Tampere University of Technology, Finland)   Mika Katara (Tampere University of Technology, Finland)   Risto Pitkänen (Tampere University of Technology (Currently with Nokia Networks), Finland)  Abstract: Formal methods have been considered one possible solution to the so-called software crisis. Tools are valuable companions to formal methods: they assist in analysis and understanding of formal specifications and enable the use of rigorous techniques in industrial projects. In this paper, an overview of the new DisCo toolset is given. DisCo is a formal specification method for reactive and distributed systems. It focuses on collective behaviour of objects and provides a refinement mechanism that preserves safety properties. The toolset currently includes a compiler, a graphical animation tool, and a scenario tool for representing execution traces as Message Sequence Charts. A prototype verification back-end based on the PVS theorem prover also exists, and a model checking back-end based on Kronos as well as code generation facilities have been planned. In this paper, the operation of the DisCo toolset is illustrated by applying it to an example specification describing a simple cash-point service system.               Keywords: TLA, animation, formal specification, reactive systems, real time, tools               Categories: D.2.1, D.2.2  
7|1||The Korrigan Environment|  Christine Choppy (LIPN, Université Paris XIII, France)   Pascal Poizat (IRIN, Université de Nantes, France)   Jean-Claude Royer (IRIN, Université de Nantes, France)  Abstract: This paper presents an environment to support the use of specification for mixed systems, i.e. systems with both dynamic (behaviour, communication, concurrency) and static (data type) aspects. We provide an open and extensible environment based on the KORRIGAN specification model. This model uses a hierarchy of view concepts to specify data types, behaviours and compositions in a uniform way. The key notion behind a view is the symbolic transition system. A good environment supporting such a model needs to interface with existing languages and tools. At the core of our environment is the CLIS library which is devoted to the representation of our view concepts and existing specification languages. Our environment is implemented using the object-oriented language PYTHON. It provides an integration process for new tools, a specification library, a parser library, LOTOS generation and object-oriented code generation for KORRIGAN specifications.               Keywords: computer-aided software engineering, software libraries               Categories: D.2, D.2.2  
7|1||An Open Software Architecture for the Verification of Industrial Controllers|  Heinz Treseler (University of Dortmund, Germany)   Olaf Stursberg (University of Dortmund, Germany)   Paul W. H. Chung (Loughborough University, UK)   Shuanghua Yang (Loughborough University, UK)  Abstract: The paper presents a tool architecture which supports the formal verification of logic controllers for processing systems. The tool's main intention is to provide a front-end for modelling the controller as well as the processing systems. The models are automatically transformed into representations which can be analysed by existing model checking algorithms. While the first part of the paper gives an overview of the complete architecture, the second part introduces a newly developed modelling interface: Process Control Event Diagrams (PCEDs) are formally defined as a suitable means to represent the flow of information in controlled processes. The transformation of PCEDs into verifiable code is described, and the whole procedure of modelling, model transformation and verification is illustrated with a simple processing system.               Keywords: formal verification, logic controller, model checking, process control event diagram, tool development               Categories: D.2.4, D.3.1, I.6.3, I.6.5, J.0  
7|1||Declarative Term Graph Attribution for Program Generation|  Wolfram Kahl (University of the Federal Armed Forces Munich, Germany)   Frank Derichsweiler (University of the Federal Armed Forces Munich, Germany)  Abstract: We show how the declarative spirit of attribute grammars can be employed to define an attribution mechanism for term graphs, where the non-uniqueness of inherited attributes demands an appropriately generalised treatment.    Since term graphs are a useful data structure for symbolic computation systems such as theorem provers or program transformation systems, this mechanism provides a powerful means to generate concrete programs (and other relevant text or data structures) from their abstract term graph representations.    We have implemented this declarative term graph attribution mechanism in the interactive term graph program transformation system HOPS and show a few simple examples of its use.               Keywords: declarative attribute grammars, graph traversals, program generation, term graph attribution               Categories: D.1.1, D.1.2, D.2.2, D.2.6, F.4.2  
7|1||Fred: An Approach to Generating Real, Correct, Reusable Programs from Proofs|"  John Crossley (School of Computer Science and Software Engineering, Monash University, Australia)   Iman Poernomo (School of Computer Science and Software Engineering, Monash University, Australia)  Abstract:   In this paper we describe our system for automatically extracting ""correct"" programs from proofs using a development of the Curry-Howard process.   Although program extraction has been developed by many authors (see, for example, [HN88], [Con97] and [HKPM97]), our system has a number of novel features designed to make it very easy to use and as close as possible to ordinary mathematical terminology and practice. These features include 1. the use of Henkin's technique [Hen50] to reduce higher-order logic to many-sorted (first-order) logic; 2. the free use of new rules for induction subject to certain conditions; 3. the extensive use of previously programmed (total, recursive) functions; 4. the use of templates to make the reasoning much closer to normal mathematical proofs and 5. a conceptual distinction between the computational type theory (for representing programs) and the logical type theory (for reasoning about programs).  As an example of our system we give a constructive proof of the well known theorem that every graph of even parity, which is non-trivial in the sense that it does not consist of isolated vertices, has a cycle. Given such a graph as input, the extracted program produces a cycle as promised.    Keywords: program synthesis, proofs as programs, reusable software               Categories: D.2.4, F.3.1  "
7|1||RAVEN: Real-Time Analyzing and Verification Environment|  Jürgen Ruf (University of Tuebingen, Germany)  Abstract: In this paper we present the real-time verification and analysis tool RAVEN. RAVEN is developed for verifying timed systems on various levels of abstraction. It integrates a real-time model checker for real-time specifications, it offers algorithms for analyzing critical delay times, for inspecting data values and event occurrences and for detecting dead_locks and live-locks. The counter example generator provides helpful information for error recovering by printing system execution paths (failing a given specification) to the integrated wave_form browser. All included algorithms are based on a common data structure enabling a compact representation and possibilities for acceleration. By some examples we show that our approach outperforms some state-of-the-art verification tools.               Keywords: analysis, formal verification, model checking, real-time systems               Categories: C.3, F.3.1, I.6.4  
7|10|http://www.jucs.org/jucs_7_10|Managing Editor s Column|
7|10||Towards a Virtual University|  Amitava Datta (Institut für Informatik, Universität Freiburg, Germany)   Thomas Ottmann (Institut für Informatik, Universität Freiburg, Germany)  Abstract:   We discuss a possible framework for virtualizing the delivery of university courses. With the advent of new technological innovations like high speed computer networks and multimedia computers, there is an increasing awareness that direct face to face teaching is not the only possible mode of teaching in a university system.  There is a demand for preparing high quality multimedia course materials across all disciplines which can be used by learners who either cannot attend live lectures or prefer to study in an off-line mode. Our group at the University of Freiburg has developed a robust tool called Authoring on the Fly (AOF) for recording live classroom sessions as multimedia documents and the synchronous playback of the diffeerent media streams in such a document in an off-line setting. In this paper we discuss the facilities this tool provides for virtualizing university courses as well as improving the offering of courses in a traditional university setting. We discuss the progress we have made in high quality delivery of lectures through multimedia documents and its implications for both off-line and classroom teaching. Further, we discuss our current attempts in virtualizing the assignment submission and correction process as a follow up of the virtual delivery of courses. We also discuss the possible implications of virtual delivery of courses and creation of a virtual university from the point of view of university students, professors and administrators.  Keywords: computers in education, mixed mode teaching, multimedia course materials, virtual delivery of courses, virtual university               Categories: K.3.1  
7|10||Three Variants of the DT0L Sequence Equivalence Problem|  Juha Honkala (Department of Mathematics, University of Turku and Turku Centre for Computer Science (TUCS), Finland)  Abstract: We discuss three variants of the DT0L sequence equivalence problem. One of the variants generalizes the sequence equivalence problem of D0L systems for DT0L systems.               Keywords: Lindenmayer system, decidability, equivalence problem               Categories: F.4.3  
7|10||How Do Frequency and Duration of Messaging Affect Impression Development in Computer-Mediated Communication?|  Yuliang Liu (Southern Illinois University Edwardsville, United States)   Dean Ginther (Texas A&M University-Commerce, United States)   Paul Zelhart (Texas A&M University-Commerce, United States)  Abstract: Computer-mediated Communication (CMC) has been commonly compared to face-to-face (FtF) communication in recent CMC literature. Research comparisons suggested depersonalizing effects of CMC. However, this experimental study indicates that CMC is a potentially viable mode of social-emotion-oriented communication. In this study, the effects of frequency and duration of messaging on impression development in CMC were investigated. Undergraduate participants were randomly assigned to each of the four experimental groups. For a period of two weeks, participants monitored discussion lists that differed in relation to the frequency and duration of messaging in asynchronous CMC environments. ANOVA results indicated that duration and frequency had significant main effects on impression development in asynchronous CMC environments. No interaction effects were found. The results of this study not only theoretically support the social-emotion-oriented model in CMC, but also lay foundations for further research in many popular types of interactive CMC environments, including e-learning, e-commerce, and e-health.               Keywords: computer-mediated communication, duration of messaging, frequency of messaging, impression development, nonverbal cues, social information processing model, social-emotion-oriented model               Categories: C.2, J.4, K.3, K.4, K.6  
7|11|http://www.jucs.org/jucs_7_11|Abstract State Machines 2001: New Developments  and Applications - J.UCS Special Issue|
7|11||Partial Updates: Exploration|  Yuri Gurevich (Microsoft Research One Microsoft Way, USA)   Nikolai Tillmann (One Microsoft Way, USA)  Abstract: The partial update problem for parallel abstract state machines has manifested itself in the cases of counters, sets and maps. We propose a solution of the problem that lends itself to an efficient implementation and covers the three cases mentioned above. There are other cases of the problem that require a more general framework.               Keywords: ASM thesis, Abstract state machine, AsmL, partial updates, submachines, synchronous parallelism, updates               Categories: D.3.3, F.1.1, F.1.2, F.3.2  
7|11||Verification of ASM Refinements Using Generalized Forward Simulation|  Gerhard Schellhorn (University of Augsburg, Germany)  Abstract: This paper describes a generic proof method for the correctness of refinements of Abstract State Machines based on commuting diagrams. The method generalizes forward simulations from the refinement of I/O automata by allowing arbitrary m:n diagrams, and by combining it with the refinement of data structures.               Keywords: Abstract State Machines, I/O-Automata, commuting diagrams, compiler cerification, correctness proofs, data refinement, dynamic logic, forward simulation, interactive theorem proving, refinement, transition systems               Categories: D.2.1, D.2.4, F.3.1, F.3.2, F.4.1  
7|11||A Logic for Abstract State Machines|  Robert F. Stärk (Computer Science Department, ETH Zürich, Switzerland)   Stanislas Nanchen (Computer Science Department, ETH Zürich, Switzerland)  Abstract: We introduce a logic for non distributed, deterministic Abstract State Machines with parallel function updates. Unlike other logics for ASMs which are based on dynamic logic, our logic is based on an atomic predicate for function updates and on a definedness predicate for the termination of the evaluation of transition rules. We do not assume that the transition rules of ASMs are in normal form, for example, that they concern distinct cases. Instead we allow structuring concepts of ASM rules including sequential composition and possibly recursive submachine calls. We show that several axioms that have been proposed for reasoning about ASMs are derivable in our system. We provide also an extension of the logic with explicit step information which allows to eliminate modal operators in certain cases. The main technical result is that the logic is complete for hierarchical (non-recursive) ASMs. We show that, for hierarchical ASMs, the logic is a definitional extension of first-order predicate logic.               Keywords: Abstract State Machines, dynamic logic, logical foundations of specification languages, modal logic               Categories: D.2.4, F.3.1, F.4.1  
7|11||A Neural Abstract Machine|  Egon Börger (Dipartimento di Informatica, Università di Pisa, Italy)   Diego Sona (Dipartimento di Informatica, Università di Pisa, Italy)  Abstract:   In an attempt to capture the fundamental features that are common to neural networks, we define a parameterized Neural Abstract Machine (NAM) in such a way that the major neural networks in the literature can be described as natural extensions or refinements of the NAM. We illustrate the refinement for feedforward networks with back-propagation training. The NAM provides a platform and programming language independent basis for a comparative mathematical and experimental analysis and evaluation of different implementations of neural networks. We concentrate our attention here on the computational core (Neural Kernel NK) and provide abstract interfaces for the other NAM components.    Keywords: abstract state machines, distributed computation, neural abstract machine, neural networks               Categories: D.2.1, D.2.2, F.1.1, I.2.5  
7|11||Formal Definition of SDL-2000 -  Compiling and Running SDL Specifications as ASM Models|  Robert Eschbach (Department of Computer Science, University of Kaiserslautern, Germany)   Uwe Glässer (Microsoft Research, Redmond)   Reinhard Gotzhein (Department of Computer Science, University of Kaiserslautern, Germany)   Martin von Löwis (Department of Computer Science, Humboldt-University Berlin, Germany)   Andreas Prinz (Department of Computer Science, Humboldt-University Berlin, Germany)  Abstract: In November 1999, the current version of SDL (Specification and Description Language), commonly referred to as SDL-2000, has passed ITU-T, an international standardization body for telecommunication. The importance and acceptance of SDL in the telecommunication industry surpasses that of UML, which can be seen as the major competitor. A crucial difference between SDL and UML is the existence of a formal SDL semantics as part of the international standard, which has a positive impact on the quality of the entire language definition. In this paper, we treat fundamental questions concerning practicability, adequacy and maintainability of the formalization approach, provide insights into the formal semantics definition and point out several effects on the SDL standard.               Keywords: ASM, Abstract State Machines, FDT, Formal Description Technique, Formal Semantics, SDL, Specification and Description Language               Categories: D.3.1, F.3.2, F.4.3  
7|11||ASM-Based Testing: Coverage Criteria and Automatic Test Sequence|  Angelo Gargantini (C.E.A.­ Università di Catania Piazza Universita, Italy)   Elvinia Riccobene (Dipartimento di Matematica e Informatica ­ Universita di Catania, Italy)  Abstract: This paper tackles some aspects concerning the exploitation of Abstract State Machines (ASMs) for testing purposes. We define for ASM specifications a set of adequacy criteria measuring the coverage achieved by a test suite, and determining whether sufficient testing has been performed. We introduce a method to automatically generate from ASM specifications test sequences which accomplish a desired coverage. This method exploits the counter example generation of the model checker SMV. We use ASMs as test oracles to predict the expected outputs of units under test.               Keywords: Abstract State Machines, formal methods, test sequence generation, testing               Categories: D.2.2, D.2.5  
7|11||Compiling Abstract State Machines to C++|  Joachim Schmid (Siemens Corporate Technology, Germany)  Abstract: Abstract State Machines (ASMs) have been widely used to specify soft-ware and hardware systems. Only a few of these specifications are executable, although there are several interpreters and some compilers. This paper introduces a compilation scheme to transform an ASM specification in the syntax of the ASM-Workbench into C++. In particular, we transform algebraic types, pattern matching, functional expressions, dynamic functions, and simultaneous updates to C++ code. The main aim of this compilation scheme is to preserve the specification structure in the generated code without generating inefficient code. The implemented compiler was used successfully in the industrial FALKO application at Siemens Corporate Technology.               Keywords: ASM-Workbench, FALKO, abstract state machines               Categories: D.1.1, D.3.3  
7|11||An Abstract State Machine Specification and Verification of the Location Consistency Memory Model and Cache Protocol|  Charles Wallace (Computer Science Dept., Michigan Technological University, USA)   Guy Tremblay (Dept. d'informatique, Université du Québec à Montréal, Canada)   Jose N. Amaral (Computing Science Dept., University of Alberta, Canada)  Abstract:   We use the Abstract State Machine methodology to give formal operational semantics for the Location Consistency memory model and cache protocol. With these formal models, we prove that the cache protocol satisfies the memory model, but in a way that is strictly stronger than necessary, disallowing certain behavior allowed by the memory model.    Keywords: cache memories, multiprocessors, requirements/specifications, shared memory               Categories: B.3.2, C.1.2, D.2.1  
7|12|http://www.jucs.org/jucs_7_12|Managing Editor's Column|
7|12||A Generic NP-hardness Proof for a Variant of Graph Coloring|  Hans L. Bodlaender (Institute of Information and Computing Sciences, Utrecht University, The Netherlands)  Abstract:   In this note, a direct proof is given of the NP-completeness of a variant of GRAPH COLORING, i.e., a generic proof similar to the proof of Cook of the NP-completeness of SATISFIABILITY. Then, transformations from this variant of GRAPH COLORING to INDEPENDENT SET and to SATISFIABILITY are shown.  These proofs could be useful in an educational setting, where basics of the theory of NP-completeness must be explained to students whose background in combinatorial optimisation and/or graph theory is stronger than their background in logic. In addition, I believe that the proof given here is slightly easier than older generic proofs of NP-completeness.    Keywords: NP-completeness, computational complexity, education, graphs               Categories: F.2.2  
7|12||Transclusions in the 21st Century|  Harald Krottmaier (Graz University of Technology, Austria)   Hermann Maurer (Graz University of Technology, Austria)  Abstract: When quoting some part of a document authors usually cut and paste the relevant content into the new document. Thereby the connection between this selected part and the original document is lost. Transclusions - first mentioned in 1960 by Ted Nelson - address this problem of  lost context . With transclusions it is possible to store information about the original document and the exact position of the quote in the newly created document and provide the reader with additional navigational features. Document formats and information systems matured over the last 40 years. This paper gives an overview of some document formats available today in the WWW environment and points to some requirements for server systems providing transclusions. Thereafter we present some ideas on how to implement transclusions based on a Hyperwave Information Server (HIS).               Keywords: Hyperwave Information Server, transclusion               Categories: H.1, H.3  
7|2|http://www.jucs.org/jucs_7_2|J.UCS Special Issue on Tools for System Design and Verification - Part 2|
7|2||Modeling Sequences within the RelView System|  Rudolf Berghammer (Christian-Albrechts-Universität Kiel, Germany)   Thorsten Hoffmann (Christian-Albrechts-Universität Kiel, Germany)  Abstract: We use a relational characterization of binary direct sums to model sequences within the relation-algebraic manipulation and prototyping system RelView in a simple way. As an application we formally derive a RelView program for computing equivalence classes of an equivalence relation, where we combine relation-algebraic calculations with the so-called Dijkstra-Gries program development method. Also a refinement of the simple modeling is presented, which leads to the classical datatype of stacks, and a further application is sketched.               Keywords: RelView system, equivalence classes, formal program derivation, relational algebra, relational modelling and programming               Categories: D.1.4, D.2.2, D.2.4, G.2.2  
7|2||A Practical Extension Mechanism for Decision Procedures: the Case Study of Universal Presburger Arithmetic|  Alessandro Armando (Università degli Studi di Genova, Italia)   Silvio Ranise (DIST - Università degli Studi di Genova, Genova, Italia and LORIA - Université Henri Poincaré, France)  Abstract: In this paper, we propose a generic mechanism for extending decision procedures by means of a lemma speculation mechanism. This problem is important in order to widen the scope of decision procedures incorporated in state-of-the-art verification systems. Soundness and termination of the extension schema are formally stated and proved. As a case study, we consider extensions of a decision procedure for the quantifier-free fragment of Presburger Arithmetic to significant fragments of non-linear arithmetic.               Keywords: affnization, augmentation, decision procedures, formal verification, lemma speculation, universal Presburger Arithmetic over integers, universal arithmetic over integers               Categories: F.3.1, I.1.1, I.1.2, I.2.3  
7|2||Verification of Parameterized Protocols|  Kai Baukus (Institute of Computer Science and Applied Mathematics CAU Kiel, Germany)   Yassine Lakhnech (VERIMAG, Centre Equation, France)   Karsten Stahl (Institute of Computer Science and Applied Mathematics CAU Kiel, Germany)  Abstract:   Recently there has been much interest in the automatic and semi-automatic verification of parameterized networks, i.e., verification of a family of systems  , where each  is a network consisting of i processes.   In this paper, we present a method for the verification of so-called universal properties of fair parameterized networks of similar processes, that is, properties of the form  where  is a quantifier-free LTL formula and the pi refer to processes.  To prove an universal property of a parameterized network, we first model the infinite family of networks by a single fair WS1S transition system, that is, a transition system whose variables are set (2nd-order) variables and whose transitions are described in WS1S. Then, we abstract the WS1S system into a finite state system that can be model-checked. We present a generic abstraction relation for verifying universal properties as well as an algorithm for computing an abstract system.  However, the abstract system may contain infinite computations that have no corresponding fair computations at the concrete level, and hence, in case the property of interest is a progress property, verification may fail because of this. Therefore, we present methods that allow to synthesize fairness conditions from the parameterized network and discuss under which conditions and how to lift fairness conditions of this network to fairness conditions on the abstract system. We implemented our methods in a tool, called PAX, and applied it to several examples.    Keywords: WS1S, abstraction, model checking, parameterized systems, verification               Categories: F.3.1  
7|2||Diagram Refinements for the Design of Reactive Systems|  Dominique Cansell (Université de Metz & LORIA, France)   Dominique Mery (Université Henri Poincare & LORIA, France)   Stephan Merz (Institut für Informatik, Universität München, Germany)  Abstract: We define a class of predicate diagrams that represent abstractions of - possibly infinite-state - reactive systems. Our diagrams support the verification of safety as well as liveness properties. Non-temporal proof obligations establish the correspondence between the original specification, whereas model checking can be used to verify behavioral properties. We define a notion of refinement between diagrams that is intended to justify the top_down development of systems within the framework of diagrams. The method is illustrated by a number of mutual-exclusion algorithms.               Keywords: TLA, abstraction, diagrams, refinement, temporal logic, verification               Categories: D.2.2, D.2.4, F.3.1  
7|2||The Coalgebraic Class Specification Language CCSL|  Jan Rothe (Institut Theoretische Informatik, TU Dresden, Germany)   Hendrik Tews (Institut Theoretische Informatik, TU Dresden, Germany)   Bart Jacobs (Department Computer Science, Univ. Nijmegen, The Netherlands)  Abstract:   This paper presents the Coalgebraic Class Specification Language CCSL that is developed within the loop project on formal methods for object-oriented languages. CCSL allows the (coalgebraic) specification of behavioral types and classes of object-oriented languages. It uses higher-order logic with universal modal operators to restrict the behavior of objects. A front-end to the theorem provers pvs [ORR + 96] and ISABELLE [Pau94] compiles CCSL specifications into the logic of these theorem provers and allows to mechanically reason about the specifications.    Keywords: binary methods, coalgebra, modal logic, specification               Categories: D.2.1, D.2.4, F.3.1, F.4.1  
7|2||Correctness of Efficient Real-Time Model Checking|  Wolfgang Reif (University of Augsburg, Germany)   Gerhard Schellhorn (University of Augsburg, Germany)   Tobias Vollmer (University of Augsburg, Germany)   Jürgen Ruf (University of Tübingen, Germany)  Abstract: In this paper we describe the formal specification and verification of an efficient algorithm based on bitvectors for real-time model checking with the KIV system.                         We demonstrate that the verification captures the essentials of the C++ algorithm as implemented in the RAVEN model checker. Verification revealed several possibilities to reduce the size of the code and to improve its efficiency.               Keywords: correctness proofs, interactive theorem proving, invariants, model checking, optimization techniques, program verification, structured algebraic specifications, temporal logic               Categories: D.2.1, D.2.4, F.3.1, F.3.2, F.4.1  
7|3|http://www.jucs.org/jucs_7_3|Managing Editor's Column|
7|3||Development and Evaluation of Web-based In-Service Training System for Improving the ICT Leadership of Schoolteachers|  Kanji Akahori (Tokyo Institute of Technology, Japan)   Hidetsugu Horiguschi (National Institute of Educational Policy Research, Japan)   Katsuaki Suzuki (Iwate Prefectures University, Japan)   Masatoshi Nambu (Jyoetu University of Education, Japan)  Abstract: This paper describes an analysis of the effectiveness of an in-service training system developed by a project sponsored by the foundation of the Information-technology Promotion Agency, Japan (IPA). We developed and carried out a 10 days training course for 65 teachers in three different locations. The three main elements of this course were (1) training curriculum, (2) CD_ROM materials, and (3) Web-based support system. The participants of this course were hoping to become Information Technology (IT) leaders in their schools. An analysis was conducted to investigate the factors influencing the effectiveness of the training. Based on our analysis, we were able to draw the following conclusions: (1) Web-based training support system and CD-ROM materials were very effective to improve teachers  knowledge and skills, regardless of prior knowledge and skills (2) Traditional instructional style (i.e. one-way instructor-centered style) was generally an ineffective training method. (3) CD-ROM materials significantly enhanced the effectiveness of teachers  creating materials (such as a Web page), especially when the CD-ROM was used for self-study. These findings will be useful for educators and educational designers who plan and conduct in-service training programs.               Keywords: Web-based learning, distance education, teacher education, teacher training system, training program assessment               Categories: K.3  
7|3||Agent-oriented Support Environment in Web-based Collaborative Learning|  Tomoko Kojiri (Nagoya University, Japan)   Yushi Ogawa (Nagoya University, Japan)   Toyohide Watanabe (Nagoya University, Japan)  Abstract: Currently, the web-based learning support systems  are one of interesting and hot topics in points of the utilization of Internet and the application of computers to education. In particular, the web-based collaboration is very applicable means to make unfamiliar students, who are unknown with each other, discuss together in the same virtual interaction space. However, there are some problems derived from the gap between the real world and virtual environment: coordination for discussions, cooperative reactions, comprehension of learning progress, etc. These problems may be dependent on the fact that the actions of students cannot be influenced from the behaviors of others directly. In this paper, we address a coordination mechanism to promote cooperative actions/reactions for progressive discussions. Our idea is to apply an agent-oriented framework to this coordination mechanism and introduce two different types of agents. One is a coordinator and the other is a learner. The coordinator monitors the learning progress of group and promotes the discussion, if necessary, so as to reach their common goal successfully. The learners are assigned to individual students, and act as interaction mediators among students in place of the corresponding students. Of course, the coordinator is a passive entity and learners are active entities in our collaborative learning space.               Keywords: Collaborative learning environment, coordinator, learner, learning situation, personal learning history               Categories: K.3.1, K.3.2  
7|3||A Synchronous EFL Writing Environment for the Internet|  Chin-Hwa Kuo (Computers and Networking (CAN) Laboratory, Department of Computer Science and Information Engineering, Tamkang University, Taiwan)   David Wible (Research in English Acquisition and Pedagogy (REAP) Group, Department of English, Tamkang University, Taiwan)   Chia-Lin Chou (Internet & Multimedia Application, Tech. Lab Telecommunication Laboratories, Yang-Mei, Taiwan)  Abstract: In this paper, we describe the design and implementation of a synchronous EFL computer assisted English writing environment. In addition to supporting the basic writing function requirements, two novel mechanisms, namely, (1) synchronous text co-editing, and (2) voice delivery, have been designed to provide fundamental capabilities over the Internet. As a result, the designed system exploits the integration of computers and networking capabilities with linguistic and pedagogical principles crucial to web-based language learning. The system integrates CMC tools with database technology for the specific purpose of archiving the communications between tutors and students. Since the platform offers a bank of comments that are frequently used in these online tutorials, the system can store and tabulate each token instance when a comment is used. This database then offers instant cumulative profiles into tutor-learner interaction and into the common language errors or difficulties uncovered in the tutorials. Such an archive supports research into language learning difficulties and into patterns of tutor-learner interaction. This data is valuable in the assessment of pedagogical effectiveness and in the development of online tutorial materials that meet the attested needs of learners.               Keywords: Computer Assisted Language Learning (CALL), co-editing, learner corpus, voice transmission               Categories: K.3  
7|3||Towards a Systematic Study of Representational Guidance for Collaborative Learing Discourse|  Daniel D. Suthers (Dept. of Information and Computer Sciences, University of Hawai'i, USA)  Abstract: The importance of collaborative and social learning processes is well established, as is the utility of external representations in supporting learners'  active expression, examination and manipulation of their own emerging knowledge. However, research on how computer-based representational tools may support collaborative learning is in its infancy. This paper motivates such a line of research, sketches a theoretical analysis of the roles of constraint and salience in the representational guidance of collaborative learning discourse, and reports on an initial study that compared textual, graphical, and matrix representations. Differences in the predicted direction were observed in the amount of talk about evidential relations and the use of epistemological categories.               Keywords: collaborative learning, representational bias, visual languages               Categories: K.3.1  
7|3||An Online Writing Platform for Language Teachers|  David Wible (Graduate Institute of Western Languages and Literature, Tamkang University, Tamsui, Taiwan)   Chin-Hwa Kuo (Computer and Networks (CAN) Laboratory, Department of Computer Science and Information Engineering, Tamkang University, Tamsui, Taiwan)   Nai-lung Tsao (Computer and Networks (CAN) Laboratory, Department of Computer Science and Information Engineering, Tamkang University, Tamsui, Taiwan)   Anne Liu (Graduate Institute of Western Languages and Literature, Tamkang University, Tamsui, Taiwan)  Abstract: Abstract: The purpose of this paper is to describe  one module in a highly integrated language learning environment. The module described is an asynchronous interactive online environment for EFL writing which integrates the potential of computers, Internet, and linguistic analysis to address the highly specific needs of second language composition classes. The system accommodates learners, teachers, and researchers. A crucial consequence of the interactive nature of this system is that users actually create information through their use, and this information enables the system to improve with use. In addition to the tools provided for teachers to mark essays and automatically track the feedback they have given each learner, the system supports the automated capture of a learner corpus of written English in the process. The essays written by users and the comments given by teachers are archived in a searchable online database. Learners can retrieve this information to examine their own recurring problems in the target language. Teachers can do the same in order to discover these problem areas for individual learners and for a class as a whole. The modular system provides interfaces with functions to facilitate an array of user tasks such as teachers'  correction of essays and learners'  writing and revision processes. Error analysis of learner essays has led to content creation for automated online help. One sort of help feature can detect certain errors automatically and offer appropriate help pages. Another type of help feature can track the number of times a teacher has marked the same error type in one learner's writing and, when this number reaches a threshold, automatically offer help on this error to this learner.               Keywords: CALL, EFL writing, corpus linguistics, web-based  learning environments               Categories: K.3  
7|4|http://www.jucs.org/jucs_7_4|Managing Editor's Column|
7|4||The Message-Minimizing Load  Redistribution Problem|  David J. Haglin (Minnesota State University currently visiting The University of Manchester, USA)   Rupert W. Ford (Centre for Novel Computing, The University of Manchester, U.K.)  Abstract: The Message Minimizing Load Redistribution Problem is described which arises from the need to redistribute work when performing load balancing in a parallel computing environment. We consider a global perspective and seek a redistribution plan that minimizes the overall processing time. We define the cost associated with a solution to be the number of packets needed to balance out the workload. The impact of the interconnection network is ignored. This problem can arise in many applications. One such example being the U.K. Meteorological Office's operational weather forecasting and climate prediction models.                               This problem is equivalent to the Pure Unit-Cost Transportation Problem. A simple proof of -completeness is given, and various heuristics and approximation issues are investigated. Several theoretical results are shown that may impact the design of an algorithm. Simulation results are presented.               Keywords: high performance computing, load balancing, parallel processors               Categories: C.1.2, C.2.4, F.2.2, G.2.1, J.2  
7|4||Computational Complexity of the Place/Transition-Net Symmetry Reduction Method|  Tommi A. Junttila (Laboratory for Theoretical Computer Science Helsinki University of Technology, Finland)  Abstract:   Computational complexity of the sub­tasks in the symmetry reduction method for Place/Transition-nets is studied. The task of finding the automorphisms (symmetries) of a net is shown to be polynomial time many-one equivalent to the problem of finding the automorphisms of a graph. Deciding whether two markings are symmetric is shown to be a problem equivalent to the graph isomorphism problem. This remains to be the case even if a generator set for the automorphism group of the net is known. The problem of constructing the lexicographically greatest marking symmetric to a given marking (a canonical representative for the marking) is classified to belong to the lower levels of the polynomial hierarchy, namely to be FPNP[log n] - hard but in FPNP. It is also discussed how the self-symmetries of a marking can be exploited. Calculation of such symmetries is classified to be as hard as computing graph automorphism groups. Furthermore, the coverability version of testing marking symmetricity is shown to be an NP-complete problem. It is proven that canonical representative markings and the symmetric coverability problem cannot be combined in a straightforward way.   Keywords: Petri nets, computational complexity, symmetry               Categories: D.2.4, F.2  
7|4||Can Knowledge Management Help in Poverty-stricken Countries and Crisis Situations|"  Jennifer Lennon (Department of Computer Science University of Aucklan, New Zealand)   Hermann Maurer (Graz University of Technology and Know-Center, Austria)  Abstract: At first sight, knowledge management for  poverty-stricken countries appears to be a contradiction in terms. It sounds ""high-tech"" and not very applicable for ""third world"" countries that may not possess the necessary infrastructure. However, the aim of the paper is to show that this is not only false but that Knowledge Management (KM) has a big role to play. We begin by giving an introduction to KM systems in general before considering how they may be applied in poverty and crisis situations. We then consider specific functions of these systems before looking at some problems and possible solutions of implementing such a system.               Keywords: databases, environmental  issues, information systems, knowledge management, poverty, third world               Categories: K.4  "
7|5|http://www.jucs.org/jucs_7_5|Future of Computer Science: J.UCS Special Issue Dedicated to Professor Hermann Maurer|
7|5||Computational Geometry - Some Easy Questions and their Recent Solutions|  Franz Aurenhammer (Graz University of Technology, Austria)  Abstract: We address three basic questions in computational geometry which can be phrased in simple terms but have only recently received (more or less) satisfactory answers: point set enumeration, optimum triangulation, and polygon decomposition.               Keywords: combinatorial geometry, computational geometry, minimum-weight triangulation, point set data base, polygonal skeleton               Categories: F.2.2  
7|5||Telecommunication Services and Service Management Challenges|  John Buford (Verizon, USA)  Abstract: Trends in telecommunications networks including network convergence, requirements for QoS and service level agreements, and open service architectures are impacting the service mangement systems and processes. New results in three areas of IP service management are described. The architecture of a new platform for service management is presented. This is the first reported service assurance platform to use ASP technology as its infrastructure. A new performance mangement suite is described. This suite currently supports measurement and reporting of web and stream servers and VoIP softswitches. Finally, a recent result in customer care automation for processing large volumes of email sent to a customer care center is reviewed.               Keywords: IP services, network management, service management, telecommunications               Categories: C.2.3  
7|5||Glimpses into the Future of Computer Science Education|  Gitta Domik (University of Paderborn, Germany)  Abstract: This paper discusses necessary changes to the computer science curriculum at universities for the future. The alterations are grouped into the following five areas: content and body of knowledge, pedagogy, audience, training-on-the-job, and professional skills. The paper argues that extending the scope of knowledge beyond the narrow borders of primary computer science topics (breadth in computer science) will lay a solid foundation for building the necessary skills for the future work force.               Keywords: breadth in computer science, curriculum, education, women in computer science               Categories: K.3  
7|5||180 Wrapped Tubes|  Herbert Edelsbrunner (Department of Computer Science, Duke University, Durham and Raindrop Geomagic, Research Triangle Park, USA)  Abstract: The 180 models collected in this paper are produced by sampling and wrapping point sets on tubes. The surfaces are represented as triangulated 2-manifolds and available as stl-files from the author s web site at www.cs.duke.edu/~edels. Each tube is obtained by thickening a circle or a smooth torus knot, and for some we use the degrees of freedom in the thickening process to encode meaningful information, such as curvature or torsion.               Keywords: Surface reconstruction, differential geometry, geometric design               Categories: G.2.m  
7|5||Graphics Content in Digital Libraries: Old Problems, Recent Solutions, Future Demands|  Dieter W. Fellner (Braunschweig University of Technology, Germany)  Abstract: Working with the ubiquitous  Web  we immediately realize its limitations when it comes to the delivery or exchange of non-textual, particularly graphical, information. Graphical information is still predominantly represented by raster images, either in a fairly low resolution to warrant acceptable transmission times or in high resolutions to please the reader s perception thereby challenging his or her patience (as these large data sets take their time to travel over congested internet highways).                         Comparing the current situation with efforts and developments of the past, e.g. the Videotex systems developed in the time period from 1977 to 1985, we see that a proper integration of graphics from the very beginning has, once again, been overlooked.                         The situation is even worse going from two-dimensional images to three-dimensional models or scenes. VRML, originally designed to address this very demand has failed to establish itself as a reliable tool for the time window given and recent advances in graphics technology as well as digital library technology demand new approaches which VRML, at least in its current form, won t be able to deliver.                           After summarizing the situation for 2D graphics in digital documents or digital libraries this paper concentrates on the 3D graphics aspects of recent digital library developments and tries to identify the future challenges the community needs to master.               Keywords: 3D graphics, computer graphics, digital documents, digital libraries, electronic documents, graphical information, pattern recognition               Categories: H.3.7, I.3.5  
7|5||Issues in Compiling|  Gerhard Goos (Fakultät für Informatik, Universität Karlsruhe, Germany)  Abstract: We consider the state of the art in compiler construction and where to go from here. Main topics are improved exploitation of present (and future) hardware features, the interaction between compiling techniques and processor design, and the use of compiling techniques in application areas such as component-based software engineering and software reengineering.               Keywords: compilers, program synthesis, program transformation, reusable software, software/program verification               Categories: D.3.4, I.2.2  
7|5||Animations for Teaching Purposes: Now and Tomorrow|  Tobias Lauer (University of Freiburg, Germany)   Rainer Müller (University of Freiburg, Germany)   Thomas Ottmann (University of Freiburg, Germany)  Abstract: Animation is commonly seen as an ideal tool for teaching dynamic phenomena. While there have been very few studies testing this hypothesis, animations are used extensively in teaching, particularly in the field of algorithms. We highlight features that we consider important for animation systems, describe the development of algorithm animation by examples, and present a new Java-based system supporting annotation and recording of animations. We also outline a way to annotate animations and movies given in the MPEG video format. By listing several case studies we describe new ways and possibilities of how animation systems may be used in the future.               Keywords: algorithm animation, animation system, annotation capturing, education, multimedia authoring, presentation recording               Categories: K.3.1  
7|5||Algorithms and Experiments: The New (and Old) Methodology|  Bernard M. E. Moret (University of New Mexico, USA)   Henry D. D. Shapiro (University of New Mexico, USA)  Abstract: The last twenty years have seen enormous progress in  the design of algorithms, but little of it has been put into practice. Because many recently developed algorithms are hard to characterize theoretically and have large running_time coefficients, the gap between theory and practice has widened over these years. Experimentation is indispensable in the assessment of heuristics for hard problems, in the characterization of asymptotic behavior of complex algorithms, and in the comparison of competing designs for tractable problems.                           Implementation, although perhaps not rigorous experimentation, was characteristic of early work in algorithms and data structures. Donald Knuth has throughout insisted on testing every algorithm and conducting analyses that can predict behavior on actual data, more recently, Jon Bentley has vividly illustrated the difficulty of implementation and the value of testing. Numerical analysts have long understood the need for standardized test suites to ensure robustness, precision and efficiency of numerical libraries. It is only recently, however, that the algorithms community has shown signs of returning to implementation and testing as an integral part of algorithm development. The emerging disciplines of experimental algorithmics and algorithm engineering have revived and are extending many of the approaches used by computing pioneers such as Floyd and Knuth and are placing on a formal basis many of Bentley's observations.                               We reflect on these issues, looking back at the last thirty years of algorithm development and forward to new challenges: designing cache_aware algorithms, algorithms for mixed models of computation, algorithms for external memory, and algorithms for scientific research.               Keywords: algorithm engineering, cache-aware algorithms, efficiency, experimental algorithmics, external memory algorithms, implementation, methodology                
7|5||Will Internet Ever Be Secure ?|  Reinhard Posch (Graz University of Technology, Austria)  Abstract: The users of the Internet in general have not developed a perception of where what security is crucial and beneficial for their applications. At present the average user is provided very few information independent of what is transported over the service and how this is done. What is needed for a secure Internet, is that security is answered on a system level or on an application level and that an appropriate level of security is reached and still is accepted by the user? These questions are primarily questions on a technical level but have a great dimension of awareness which has to be kept in mind. However, the main question is not how to secure the Internet in place but how to develop mechanisms and tools for the Internet that can seamlessly improve an ever changing media which opens up new dimensions of security risks with every new protocol system and application. Security will remain a race where comfort is often seen as a competitor.               Keywords: Internet security               Categories: H.0  
7|6|http://www.jucs.org/jucs_7_6|J.UCS Special Issue: I-Know  01 - International Conference on Knowledge Management, Part 1|
7|6||Knowledge Management and Collaborative Virtual  Environments|  Ivan Tomek (Jodrey School of Computer Science, Acadia University, Canada)  Abstract: Knowledge management systems provide three basic services: information capture, storage and organization, and access. This paper argues that collaborative virtual environments (CVEs) provide features that make them uniquely suited as an integral part of information capture. After introducing CVEs, we present our work in this area and outline our future plans.               Keywords: collaborative virtual environments, computer supported collaborative work, information capture, knowledge management               Categories: C.2, D.2.6, H.1.2, H.3, H.5  
7|6||Learning in the Learning Organization|  Joachim P. Hasebrook (educational financial portal [efiport] AG, Germany)  Abstract: Humans are not able to cope with the exponential growth of information and the increasing speed of information and business processes fostered by information and communication technologies. Technical support not only for information storage and retrieval but also for information selection, process planning, and decision support is needed. Most of the ICT investments, however, do not foster innovation or productivity. Recent studies show that ICT-based training is the main instrument of knowledge management. On-line media and self-directed learning environments are among the most effective training solutions in terms of cost, time and logistics. In the last few years, the percentage of employees participating in training courses increased. At the same time, there has been a decline of training budgets. E-Learning is able to deliver more valuable training for less money only if it is part of an integrated knowledge and skills management system. Two case studies of knowledge and meta data management systems are discussed.               Keywords: multimedia information Systems, office automation, social and behavioral science               Categories: H.4.1, H.5.1, J.4  
7|6||Mastering the Human Barriers in Knowledge Management|"  Kurt-Martin Lugger (Institute for Organization and Human Resource Management, Karl-Franzens-University Graz, Austria)   Herbert Kraus (Institute for Organization and Human Resource Management, Karl-Franzens-University Graz, Austria)  Abstract: ""New"" essential resources and success factors keep being invested and provide fertile grounds, not only in the consultancy industry, for ever more glossy brochures to create success. The production factor of knowledge is currently at the focus of many theories and numerous publications. It remains to be seen whether we are seeing real innovations. Knowledge has always been prerequisite to creating products or services, an essential input, a ""silent production factor"".                         The modern, complex environment has also made products and processes more complex and extensive. The ability to adapt to changing conditions increasingly determines success or failure. All aspects of enterprises are affected, even the ""smallest units"", the human element. In this context, it is becoming increasingly important to be able to share knowledge with colleagues. Knowledge transfer is basically characterised by a question-and-answer principle. The focus is on the incalculable human factor. This causes more or less distinct transfer barriers.                         Prejudices, fear of criticism, lack of confidence, constant time pressures and other factors are some barriers to transfer caused by the individual. Besides organisations may create barriers, too, through rigid hierarchies, red tape, and outdated procedures.                          By means of the barrier matrix and the barrier cube we have presented eight different constellations from the scientist's view. At a very theoretical level we have also touched briefly on how to solve these problems.                                  Knowledge management does not yet seem to attach enough importance to the issue of communication, particularly to internal communication. In addition to individual and organisational transfer barriers, communication media can also contribute to problems and barriers in knowledge transfer.                 Categories: H.5, H.m  "
7|6||Sustainability and Jobs in the Knowledge Economy|"  Peter Johnston (European Commission, Information Society DG)  Abstract: The rapid emergence of a global knowledge economy both shortens the timetable for progress on sustainable development and also offers a potential ""win-win"" alternative to the traditional trade-off between growth and environmental sustainability.                         The Lisbon Strategy and e-Europe initiative to accelerate development of the knowledge economy in Europe already addresses several aspects of social and economic sustainability. However, the trends in most resource-use and environmental impact indicators are still worsening, and much more needs to be done to realise the potential benefits of structural change in business and employment, notably in the service sector.                             The Stockholm and Göteborg EU Summits, and the subsequent Rio+10 conference give a timely and unique opportunity to establish European coherence and leadership in seeking sustainable development in the knowledge economy.                                 However, we also need a new clarification of individual and business-level responsibilities for lifestyle and business organisation changes, and a much wider take-up of innovative ""win-win"" solutions for growth with reductions in resource use and impacts.               Keywords: European Union, information society, knowledge economy, sustainable development               Categories: J.4  "
7|6||Knowledge Management in Superorganisms|  F. J. Radermacher (Forschungsinstitut fuer anwendungsorientierte Wissensverarbeitung FAW, Germany)  Abstract: This paper deals with a general approach to knowledge management in companies and organizations. It strongly builds on insights concerning knowledge processing in superorganisms and reflects years of FAW experiences in applications. The paper in particular shows how (1) human resources, (2) issues of organization and (3) new IT systems interact in achieving a higher level of competence and competitiveness. In this context, dealing with non-explicit sources of knowledge is a major issue, too.               Keywords: IT systems, human resources, knowledge management, non-explicit knowledge, organizations, superorganisms               Categories: H.3  
7|6||Discovering Knowledge Through Visual Analysis|  Jim Thomas (Pacific Northwest National Laboratory, USA)   Paula Cowley (Pacific Northwest National Laboratory, USA)   Olga Kuchar (Pacific Northwest National Laboratory, USA)   Lucy Nowell (Pacific Northwest National Laboratory, USA)   Judi Thomson (Pacific Northwest National Laboratory, USA)   Pak Chung Wong (Pacific Northwest National Laboratory, USA)  Abstract: This paper describes our vision for the near future in digital content analysis as it relates to the creation, verification, and presentation of knowledge. We focus on how visualization enables humans to make discoveries and gain knowledge. Visualization, in this context, is not just the picture representing the data but also a two-way interaction between humans and their information resources for the purposes of knowledge discovery, verification, and the sharing of knowledge with others. We present visual interaction and analysis examples to demonstrate how one current visualization tool analyzes large, diverse collections of text. This is followed by lessons learned and the presentation of a core concept for a new human information discourse.               Keywords: Information visualization, digital content and media, digital libraries, higher-order interaction, human-computer interaction, knowledge management, visual paradigms               Categories: H.5, H.5.1, H.5.2, I.3, I.3.8  
7|6||MPEG and its Relevance for Content-based Multimedia Retrieval|  Werner Haas (Institute of Information Systems  &  Information Management, Joanneum Research, Austria)   Harald Mayer (Institute of Information Systems  &  Information Management, Joanneum Research, Austria)  Abstract: The utilization of new emerging standards such as MPEG-7 is expected to be a major breakthrough for content-based multimedia data retrieval. The main features of the MPEG standards series and of related standards, formats and protocols are presented. It is discussed, how they, despite their partially early and immature stage, can best be utilized to yield effective results in the context of a knowledge management environment. Complementary to that, the current status and state of the art in content-based retrieval for images, video and audio content is briefly presented. In the context of the KNOW-Center we are developing a prototype platform to implement a user friendly and highly informative access to audiovisual content as a potential component for a future knowledge management system. The technical requirements and the system architecture for the prototype platform are described.               Keywords: MPEG, content-based search and retrieval, databases, knowledge management               Categories: H.3, H.3.1, K.1  
7|7|http://www.jucs.org/jucs_7_7|J.UCS Special Issue: I-Know  01 - International Conference on Knowledge Management, Part 2|
7|7||Personal Digital Libraries and Knowledge Management|  David L. Hicks (Aalborg University Esbjerg, Denmark)   Klaus Tochtermann (Know-Center, Austria)  Abstract: The efficient management of knowledge has become imperative for almost all types of organizations. Many approaches exist for dealing with knowledge management at a corporate level. But there is also a need to support knowledge management also at an individual level, a level which takes the specific needs, experiences and skills of knowledge workers into account. While largely unexplored within the field of knowledge management, in the field of digital libraries advanced personalization and customization concepts exist. Within this context, this paper examines these concepts and how they can be exploited to address the challenges which are typical for knowledge management. As the paper will show, many synergies exist, if knowledge management at an individual level is dealt with in combination with personal digital libraries.               Keywords: digital libraries, information systems, knowledge management, personalization               Categories: H.1, H.2, H.3, H.4, J.3  
7|7||SEAL-II - The Soft Spot between Richly Structured and Unstructured Knowledge|  Andreas Hotho (Institute AIFB, University of Karlsruhe, Germany)   Alexander Maedche (FZI Research Center for Information Technologies at the University of Karlsruhe, Germany)   Steffen Staab (Institute AIFB, University of Karlsruhe and Ontoprise GmbH, Germany)   Rudi Studer (Institute AIFB, University of Karlsruhe and FZI Research Center for Information Technologies at the University of Karlsruhe and Ontoprise GmbH, Germany)  Abstract: Recently, the idea of semantic portals on the Web or on the intranet has gained popularity. Their key concern is to allow a community of users to present and share knowledge in a particular (set of) domain(s) via semantic methods. Thus, semantic portals aim at creating high-quality access - in contrast to methods like information retrieval or document clustering that do not exploit any semantic background knowledge at all. However, by way of this construction semantic portals may easily suffer from a typical knowledge management problem. Their initial value is low, because only little richly structured knowledge is available. Hence the motivation of its potential users to extend the knowledge pool is small, too.                         We here present SEAL-II, a methodology for semantic portals that extends its previous version, by providing a range of ontology-based means for hitting the soft spot between unstructured knowledge, which virtually comes for free, but which is of little use, and richly structured knowledge, which is expensive to gain, but of tremendous possible value. Thus, we give the portal builder tools and techniques in an overall framework to start the knowledge process at a semantic portal. SEAL-II takes advantage of the ontology in order to initiate the portal with knowledge, which is more usable than unstructured knowledge, but cheaper than richly structured knowledge.               Keywords: knowledge portal, ontology               Categories: H.0  
7|7||Metadata Standards: What, Who & Why|  Erik Duval (Departement Computerwetenschappen, Katholieke Universiteit Leuven, Belgium)  Abstract:   In order to be able to (re-)use digital content, interested users must be able to identify and locate relevant documents. This requires descriptive data, nowadays generally referred to as metadata. Technical standards for a scaleable deployment on a global scale are required if we want to achieve a critical mass of resources. In this paper, we present the current status of ongoing work in this area, with a particular emphasis on the IEEE LTSC Learning Object Metadata standard [IEEE, 2001] and related developments in the context of the ISSS Learning Technologies Workshop [ISSS, 2001].    Keywords: learning technology standardization, metadata               Categories: H.3  
7|7||Knowledge Management More Effort - More Success?|"  Barbara Tillian (Gosch Consulting GmbH, Austria)  Abstract: Interested readers find a lot of ideas, concepts and implementation attempts for the modern subject ""knowledge management"". A midsize consulting company now faces the problem of finding the answer to: ""what do we need to implement to stay in touch with knowledge and where does the cost/profit relationship just put a stop our possibilities?"" The biggest problem for these companies is their size: they are too big to exchange information and knowledge during coffee or lunch breaks. On the other hand the extensive, company wide systems of the corporates are too expensive and usually not hitting the target. Against this background I'd like to present a possible solution for day-to-day knowledge management using the hands-on experience of Gosch Consulting GmbH, a midsize IT-consulting company. Looking at our company from the knowledge point of view we realized early on that certain standards have been partly implemented within the company even before the knowledge management hype started. This motivated us to take a closer look at the practicability of our tools and to look into and introduce some of the new concepts and ideas. The objective was to examine their efficiency and effectiveness for our own company first and then to find the balance between ""must"" and ""nice to have"". Equally important was the fact that the instru-ments had to enhance the quality and value of the company and also of the individual employee.               Keywords: knowledge management               Categories: K.6.1  "
7|7||A Guided Tour through the Siemens Business Services Knowledge Management Framework|  Dirk Ramhorst (SIEMENS Siemens Business Services GmbH & Co. OHG, Germany)  Abstract: This case study illustrates the knowledge management framework that was designed during the introduction of knowledge management instruments at Siemens Business Services GmbH & Co. or SBS, as it is known. The knowledge management framework will give the reader an understanding of the holistic approach to knowledge management and the different stages of implementation. It also introduces the key learning processes experienced by Siemens Business Services (SBS) during the various implementation phases. The knowledge management (KM) requirements, challenges and solutions within the service business are highlighted. The case study also shows the challenges and objectives of knowledge management (KM) programs, in general, and at Siemens Business Services (SBS), in particular. Based on the experience of the implementation of KM at SBS, the case study closes with critical success factors for other KM implementations, both within and outside Siemens.               Keywords: information systems, knowledge management               Categories: H.2, H.3  
7|7||New Learning of Adults in the  Information and Knowledge Society|  Wolfgang Schinagl (Economic Chamber of Styria, Austria)  Abstract: New Learning in analogy to New Economy means a new paradigm of learning. Old Learning was learning with a continuous learning history in mind. New Learning means, that the continuity of a learning history is stored in a computer memory and can be quickly accessed. The external storage generates a better and more precise continuity of individual historical learning experiences and shifts the focus of cognitive energy to cognitive creativity. If knowledge is managable as the new discipline knowledge management offers, this new approach will make sense.               Keywords: cognitive creativity, eLearning, knowledge management, new learning, self learning               Categories: K.3.1, K.3.2, K.7.3  
7|8|http://www.jucs.org/jucs_7_8|Formal Aspects of Software Engineering -  J.UCS Special Issue in Honor of Professor Peter Lucas|
7|8||The Transition from VDL to VDM|  Cliff B. Jones (Department of Computing Science, University of Newcastle, UK)  Abstract:   This paper describes (one person's view of) how the Vienna Development Method grew out of the earlier work on the Vienna Definition Language. Both of these activities were undertaken at the IBM Laboratory Vienna during the 1960s and 70s.    Keywords: VDL, VDM, denotational semantics, formal methods, language definition, operational semantics               Categories: D.2.4, D.3.1, F.3, F.3.2  
7|8||On Teaching Software Engineering based on Formal Techniques - Thoughts about and Plans for - A Different Software Engineering Text Book|  Dines Bjørner (Informatics and Mathematical Modelling, Technical University of Denmark, Denmark)  Abstract: We present the didactic bases for a different kind of text book on Software Engineering - one that is based on semiotics, proper description principles, informal narrations and formal specifications, on phase, stage and stepwise development from developing understandings of the domain, via requirements to software design. Each of the concepts: Semiotics, description, documents, abstraction & modelling, domains, requirements and software design, are covered systematically while enunciating a number of method principles for selecting and applying techniques and tools for the effcient construction of efficient software. The proposed textbook presents many, what are believed to be novel development concepts: Domain engineering with its emphasis on domain attributes, stake{holder perspectives and domain facets (intrinsics, support technologies, management & organization, rules & regulation, human behaviour, etc.), requirements engineering with its decomposition into domain requirements (featuring such techniques as projection, instantiation, extension and initialization), interface requirements and machine requirements, etc.               Keywords: formal methods, software engineering               Categories: D.2, D.3.1, F.4.3  
7|8||An Eclectic View of the Irish School of Constructive Mathematics, from [Lucas 1978] to [Mac an Airchinnigh 2001]|  Micheal Mac an Airchinnigh (University of Dublin, Trinity College, Ireland)  Abstract: In this paper I celebrate the evolution of the  Vienna Development Method (VDM) along its Irish branch and attempt to tell the story that Peter Lucas played in it.                           There are two parts to the paper. In the first part I tell my story of the early day of the origins of the Irish School of the VDM (), beginning with prehistory in 1978 up until the radical decisions of 1995 which led to the Irish School of Constructive Mathematics .                               In 1995 the School committed itself to the development of the modelling of (computing) systems in full generality. This was achieved by embracing Category Theory and by exploring a geometry of formal methods using techniques of fiber bundles. From fiber bundles to sheaves was a natural step. Concurrently, the School moved from the algebra of monoids to categories, and from categories to topoi (alt. toposes). The second part of the paper illustrates, with simple examples, how I introduce topos logic into modelling in 2001.               Keywords: VDM, constructive mathematics, intuitionistic logic, modelling, topos theory               Categories: F.4, G.  
7|8||"Ten Years of Historical Development ""Bootstrapping"" VDMTools"|"  Peter Gorm Larsen (IFAD A/S, Denmark)  Abstract:   This article provides a historical overview of a decade of the development of the IFAD VDM Toolboxes commonly referred to as VDMTools. All along, the existing tools have been used in the development of new major components. This kind of ""bootstrapping "" approach where a CASE tool is developed by taking """"its own medicine"" is seldom used. However, we believe that this approach is important to be able to better understand what the most important improvements are for the users in practice. This article also describes how the different components have been maintained by a changing development team. We feel that the decisions we have made regarding the parts of the tool which have been formally specified and the parts which have been developed conventionally may provide valuable input for others considering the use of formal specification. The overall organisation of the development environment may also be interesting for other developers.   Keywords: VDM, formal methods, software engineering, tool support               Categories: D.2.1  "
7|8||Test-Design through Abstraction - A Systematic Approach Based on the Refinement Calculus|  Bernhard K. Aichernig (Graz University of Technology, Austria)  Abstract:   This article discusses the calculation of test-cases for interactive systems. A novel approach is presented that treats the problem of test-case synthesis as a formal abstraction problem. It is shown that test-cases can be viewed as formal contracts and that such test-cases are in fact abstractions of requirements specifications. The refinement calculus of Back and von Wright is used to formulate abstraction rules for calculating correct test-cases from a formal specification. The advantage of this abstraction approach is that simple input-output test-cases, as well as testing scenarios can be handled. Furthermore, different testing strategies like partition testing and mutation testing can be formulated in one theory.    Keywords: formal methods, refinement calculus, test-case generation, testing               Categories: D.2.1, D.2.5  
7|8||Data Distribution Specification for High Performance Computing|  Hans P. Zima (Institute for Software Science, University of Vienna, Austria)  Abstract: High performance computing (HPC) architectures are specialized machines which can reach their peak performance only if they are programmed in a way which exploits the idiosyncrasies of the architecture. An important feature of most such architectures is a physically distributed memory, resulting in the requirement to take data locality into account independent of the memory model offered to the user. In this paper we discuss various ways for managing data distribution in a program, comparing in particular the low-level message-passing approach to that in High Performance Fortran (HPF) and other high performance languages. The main part of the paper outlines a method for the specification of data distribution semantics for distributed-memory architectures and clusters of SMPs. The paper concludes with a discussion of open issues and references to future work.               Keywords: data distribution, distributed memory, high performance computing, parallel architectures               Categories: C.4  
7|8||"""Bagatelle in C arranged for VDM SoLo"""|"  José N. Oliveira (Universidade do Minho, Braga, Portugal, Senior R&D Partner, Portugal)  Abstract:   This paper sketches a reverse engineering     discipline which combines formal and semi-formal methods. Central to the     former is denotational semantics, expressed in the ISO/IEC 13817-1 standard     specification language (VDMSL). This is strengthened with algebra of     programming, which is applied in ""reverse order"" so as to     reconstruct formal specifications from legacy code. The latter include     code slicing, a ""shortcut"" which trims down the     complexity of handling the formal semantics of all program variables at the     same time.  A key point of the approach is its constructive style. Reverse     calculations go as far as absorbing auxiliary variables, introducing mutual     recursion (if applicable) and reversing semantic denotations into standard     generic programming schemata such as cata/paramorphisms.  The approach is illustrated for a small piece of code already studied     in the code-slicing literature: Kernighan and Richtie's word     count C programming     ""bagatelle"".  Keywords: algebra of programming, denotational semantics, reverse engineering, slicing               Categories: D.2.1, F.3.1  "
7|9|http://www.jucs.org/jucs_7_9|Managing Editor's Column|
7|9||Codifiable Languages and the Parikh Matrix Mapping|  Adrian Atanasiu (Faculty of Mathematics, Bucharest University Academiei, Romania)   Carlos Martín-Vide (Research Group on Mathematical Linguistics, Rovira i Virgili University, Spain)   Alexandru Mateescu (Faculty of Mathematics, Bucharest University Academiei, Romania)  Abstract: We introduce a couple of families of codifiable languages and investigate properties of these families as well as interrelationships between diffeerent families. We also develop an algorithm based on the Earley algorithm to compute the values of the inverse of the Parikh matrix mapping over a codifiable context-free language. Finally, an attributed grammar that computes the values of the Parikh matrix mapping is defined.               Keywords: injectivity, the Parikh mapping, the Parikh matrix mapping               Categories: F., G.  
7|9||Efficient Measure Learning|  Sandra Fontani (University of Siena, Italy)  Abstract: We study the problem of efficient identification of particular classes of p-time languages, called uniform. We require the learner to identify each language of such a class by constantly guessing, after a small number of examples, the same index for it. We present three identification paradigms based on different kind of examples: identification on informant (positive and negative information), measure identification (positive information in a probabilistic setting), identification with probability (positive and negative information in a probabilistic setting). In each case we introduce two efficient identification paradigms, called efficient and very efficient identification respectively. We characterize efficient identification on informant and with probability and, as a corollary, we show that the two identification paradigms are equivalent. A necessary condition is shown for very efficient identification on informant, which becomes sufficient if and only if P = NP. The same condition is sufficient for very efficient identiffication with probability if and only if NP=RP. We show that (very) efficient identification on informant and with probability are strictly stronger than (very) efficient measure identiffication.               Keywords: learning theory               Categories: I.2.6  
7|9||Determinism, Nondeterminism, Alternation, and Counting|  Sanjay Gupta (Department of Computer Science, Virginia Polytechnic Institute and State University, USA)  Abstract: Toda proved a remarkable connection between the polynomial hierarchy and the counting classes. Tarui improved Toda s result to show the connection to a weak form of counting and provided an elegant proof. This paper shows that a key step in Tarui s proof can be done uniformly using the depth-first traversal and provides the algorithm that generalizes Toda s result to arbitrary alternating Turing machines (ATMs). Tarui s proof is carefully dissected to obtain an interesting relationship between the running time of the constructed counting machine and the diffeerent parameters of the original ATM: the number of alternation blocks, the number of non-deterministic steps, and the number of deterministic steps.               Keywords: alternating Turing machines, computational complexity, counting classes, theory of computation               Categories: F.1  
7|9||More Than WORDs - Collaborative Tailoring of a Word Processor|  Helge Kahler (University of Bonn, Germany Department of Computer Science III, Research Group HCI & CSCW, Germany)  Abstract: Tailorability (or adaptability) of software becomes more important with the increasing use of off-the-shelf-software. On the other hand, computers support the work of many groups which in turn have to tailor a commonly used software to support individual as well as group needs. This includes not only groupware, i. e., software that directly supports collaborative work, but also single user software. Research has shown that often adaptations to single user software are distributed among colleagues, thus leading to a systematization in a group's adaptations. Based on this observation an empirical field-study on the collaborative tailoring habits of users of a particular word processor was carried out. Based on these and literature research an add-on to this word processor was developed which provides a public and a private repository for adaptations as well as a mailing function for users to exchange adaptations. Some notification and annotation mechanisms are also provided. Results of two forms of evaluation indicate that users of different levels of qualification are able to handle the tool and consider it a relevant alternative to existing mailing mechanisms.               Keywords: CSCW, Groupware, Tailoring               Categories: H.1.2, H.4.3  
7|9||On Speculation Control in Simultaneous Multithreaded Processors|  Ulrich Sigmund (VIONA Development GmbH, Germany)   Theo Ungerer (University of Augsburg, Germany)  Abstract: A simultaneous multithreaded (SMT) processor is  able to issue and execute instructions from several threads simultaneously. A SMT processor reaches its highest performance, when all issue slots are utilized by non-speculative instructions provided that the workload is sufficient. SMT processors are able to utilize their resources by executing instructions of multiple threads simultaneously, whereas single-threaded processors fill their resources with highly speculative instructions that must frequently be discarded due to misspeculations. Consequently, we explore speculation control in SMT processor models with the target to increase performance by restricting the number of in-flight speculative instructions. We vary the sizes of internal buffers, the instruction fetch bandwidth, the instruction selection strategies and branch prediction models with the target to increase performance of the simulated SMT processor models. Our results show (1) that retirement buffer sizes of 16 or 32 entries increase performance compared to smaller and to larger buffer sizes, (2) that the instruction fetch bandwidth can be decreased to two times four instructions per cycle without performance loss even for eight threaded eight issue processor models, (3) that an instruction selection strategy that discriminates speculative instructions in the fetch, decode, issue, and dispatch stages may increase overall performance, and (4) that a highly multithreaded processor with a sufficient workload may do without a branch prediction.               Keywords: MPEG-2 video decompression, SMT, multimedia  extension, simultaneous multithreading, speculation control               Categories: C.1  
volume|issue|url|title|abstract
8|1|http://www.jucs.org/jucs_8_1|Managing Editor's Column|
8|1||The Origins and the Development of the ASM Method for High Level System Design and Analysis|  Egon Börger (Università di Pisa, Italy)  Abstract: The research belonging to the Abstract State Machines approach to system design and analysis is surveyed and documented in an annotated ASM bibliography. The survey covers the period from 1984, when the idea for the concept of ASMs (under the name dynamic or evolving algebras or structures) appears for the first time in a foundational context, to the year 2001 where a mathematically well-founded, practical system development method based upon the notion of ASMs is in place and ready to be industrially deployed. Some lessons for the future of ASMs are drawn.               Keywords: abstract state machines, models of computation, specification methods, system analysis, system design               Categories: C.1, C.3, D.1, D.2, D.3, F.1.1, F.1.2, F.3.1, F.3.2, F.4.2, F.4.3, G.0, H.1, I.6  
8|1||An Implicit Recursive Language for the  Polynomial Time-space Complexity Classes|  Emanuele Covino (Dipartimento di Informatica dell'Università di Bari, Italy)   Giovanni Pani (Dipartimento di Informatica dell'Università di Bari, Italy)  Abstract:   Abstract: We define a language over an algebra of words by means of a version of predicative recursion, and we prove that it represents a resource-free characterization of the computations performed by a register machine in time O(nk), for each denite k; starting from this result, and by means of a restricted form of composition, we give a characterization of the computations of a register machine with a polynomial bound simultaneously imposed over time and space complexity.  Keywords: implicit computational  complexity, predicative recursion, time-space classes               Categories: F.1.3  
8|1||On a New Powerful Model for Knowledge Management and its Applications|"  Hermann Maurer (Graz University of Technology, Austria)   Klaus Tochtermann (Know-Center, Austria)  Abstract: In this paper we present the Maurer - Tochtermann Model for Knowledge Management (KM) and present strong evidence that this model has powerful ramification. First, it shows clearly that KM is not just ""old wine in new bottles"" but an important and new area of research and applications, second, it shows clearly where KM differs from classical distributed information systems or data bases, third, it is shown to embrace a number of pragmatic problems that have often been considered the heart of KM, and fourth, it gives a clear indication of the areas that will be of increasing importance for KM in the future. We claim that the model can and should be the basis of future efforts in IT-oriented KM.               Keywords: Data Bases, Document Management, Information Systems, Intelligent Agents, Knowledge Management               Categories: H.1, H.2, H.4  "
8|1||On Second Generation Distributed Component Systems|  Klaus Schmaranz (Institute for Information Processing and Computer Supported New Media (IICM), Austria)  Abstract: Two of today's most used buzz-words in the context of software development are the terms Componentware and Distributed Object-System. The combination of both ideas is then called a Distributed Component-System, meaning a componentware approach where the components are distributed across the network. Today's approaches fulfill the application developers' needs only partly. Also, most are more or less cumbersome to use. I want to call such part-solutions like e.g. Corba, Enterprise Java­Beans and others first generation distributed component systems. In fact, Corba has a different origin, but for the moment let me consider it to be a first generation componentware system, too.  In this paper I want to identify the requirements that have to be fulfilled to design and implement a second generation distributed component system. One main aspect is behind all of the ideas of second generation systems: a good distributed component system is one that the application programmers don't notice.  The open-source project Dinopolis is currently in its early implementation phase and can be considered the first second-generation distributed component system according to the requirements that are identified in the following. Therefore the very basic cornerstones of Dinopolis are discussed at the end of this paper.  Keywords: Componentware, Dinopolis, Distributed Component  System, Distributed Object System, Distributed Relations, Java, Middleware, Network Transparency Aspects, Robust Globally Unique Handles               Categories: D.1.5, D.2, D.2.6, D.2.7  
8|10|http://www.jucs.org/jucs_8_10|J.UCS Special Issue: Hypermedia - State of the Art 2002|
8|10||Research in Structural Computing|  David L. Hicks (Department of Computer Science, Aalborg University Esbjerg, Denmark)   Uffe K. Wiil (Department of Computer Science, Aalborg University Esbjerg, Denmark)   Peter J. Nürnberg (Department of Computer Science, Aalborg University Esbjerg, Denmark)  Abstract: Structural computing is one of the most recent  research threads to emerge in the field of hypermedia. Though a relatively new line of study, research results have already started to emerge in the structural computing field. This paper examines a number of structural computing research projects to provide an overview of the current state of the field as well as a look at the direction of ongoing projects. It also briefly discusses additional areas of research in structural computing that will be important to consider as research in the field continues.               Keywords: hypermedia  architectures, open hypermedia, structural computing               Categories: D.2.11, H.5.4  
8|10||Design for All as a Challenge for Hypermedia Engineering|"  Volker Mattick (Chair of Programming Systems and Compiler Construction, FuLDIT Research Group, University of Dortmund, Germany)  Abstract: Design for All is an important challenge for hypermedia engineering. We analyze this challenge and show that it is necessary to find a way of describing partially designed hypermedia documents that can then be transformed into different hypermedia applications according to user needs and call this concept ""semi-documents"". We sketch similarities and differences to existing formalisms and conclude that there are three areas in which functional languages can make a contribution: the development of an embedded special-purpose language for describing semi-documents, the building of generators which produce hypermedia applications from semi-document, and the realization of support tools for the development of semi-documents.               Keywords: design techniques, functional programming, hypermedia engineering               Categories: D.1.1, D.2.2, H.5.4  "
8|10||An Object-oriented Approach to Design, Specification, and Implementation of Hyperlink Structures Based on Usual Software Development|  Alexander Fronk (Software-Technology, University of Dortmund, Germany)  Abstract: Different models and methodologies for the development of hypermedia systems and applications have emerged in the recent years. Software-technical methods and principles enriched with ideas mainly driven from the applications  needs are often sponsor to those models and methodologies. Hence, they deal with very specific problems occurring in the hypermedia domain, thereby extending design notations like UML or State Charts and adapting them to modeling this domain. In the present paper, we propose a very usual software-technical approach to the development of hyperlink structures which form the basis for navigation in hyperdocuments. Our approach uses standard UML, algebraic specification and object-oriented implementation to cover the construction of hyperlink structures, from design through to specification and realization. We thereby equate the development of hypermedia documents with usual software development. Instead of adopting software-engineering and notations to hypermedial concerns, we adopt the latter to the former and show the advantages of this approach.               Keywords: hypermedia, methodologies, object-oriented languages, software engineering, systems development               Categories: D.2, D.2.10, D.3.2, I.7.2, K.6.1  
8|10||The TrailTRECer Framework: Applying Open Hypermedia Concepts to Trails|  Erich Gams (Salzburg Research - SunTREC, Austria)   Siegfried Reich (Salzburg Research - SunTREC, Austria)  Abstract: Being lost in space and overloaded with information are two key problems users are confronted with, when searching for appropriate information. Trails built from information about the users' browsing paths and activities, are an established approach to assist users in navigating vast information spaces. However, existing trail-based systems are focusing on browsers only and therefore do not fully exploit the notion of trails. The TrailTRECer framework addresses these issues by being open to any application and any activity. The usability of the framework and the concept of user trails were tested by building a navigation support system with different trail-enabled clients.               Keywords: navigation support, open hypermedia, trail-based system, trails               Categories: H.3.3, H.5.4  
8|10||Components of a Model of Context-Sensitive Hypertexts|  Alexander Mehler (University of Trier, Germany)  Abstract: On the background of rising Intranet applications the automatic generation of adaptable, context-sensitive hypertexts becomes more and more important [El-Beltagy et al., 2001]. This observation contradicts the literature on hypertext authoring, where Information Retrieval techniques prevail, which disregard any linguistic and context-theoretical underpinning. As a consequence, resulting hypertexts do not manifest those schematic structures, which are constitutive for the emergence of text types and the context-mediated understanding of their instances, i.e. natural language texts. This paper utilizes Systemic Functional Linguistics (SFL) and its context model as a theoretical basis of hypertext authoring. So called Systemic Functional Hypertexts (SFHT) are proposed, which refer to a stratified context layer as the proper source of text linkage. The purpose of this paper is twofold: First, hypertexts are reconstructed from a linguistic point of view as a kind of supersign, whose constituents are natural language texts and whose structuring is due to intra- and intertextual coherence relations and their context-sensitive interpretation. Second, the paper prepares a formal notion of SFHTs as a first step towards operationalization of fundamental text linguistic concepts. On this background, SFHTs serve to overcome the theoretical poverty of many approaches to link generation.               Keywords: coherence relations, context modelling, hypertext authoring, systemic functional linguistics               Categories: H.3.1, H.3.3, H.5.4, I.2.7, I.7  
8|10||Towards an XML-based Implementation of Structured Hypermedia Documents|  Jörg Westbomke (Research Institute for applied Knowledge Processing, Germany)   Gisbert Dittrich (University of Dortmund, Germany)  Abstract: Document structures are a crucial mechanism for the creation and the usability of complex hypermedia documents. They form a possibility to deal with the inherent complexity of such documents and with document structures it is also possible to support the reuse of parts of hypermedia documents. In several theoretical approaches different kinds of document structures have been proposed. For example in the Dexter Hypertext Model or in the hypermedia model developed by Klaus Tochtermann.  In the creation process of such hypermedia documents, which is strongly influenced by the offered functionality of the existing editors and tools, only simple kinds of structures could presently be used. Furthermore the use of hypermedia documents is often somehow connected to special system requirements, which makes it difficult to use these documents in a network. Especially the use of such hypermedia documents in the internet with all its different platforms and operating systems still cause many difficulties. The profit of hypermedia documents could obviously be increased, if broad forms of structuring could be used to build hypermedia documents and when these documents fulfill at the time the demands of interoperability and platform independency.  This papers presents a contribution to this topic by introducing techniques for the implementation of structured hypermedia documents, which fulfill the demands of system and platform independency. These techniques are consequently based on the Extensible Markup Language. To form the basis for an XML-based implementation of structured hypermedia documents, the concepts of the Tochtermann model were transformed into a XML document type definition. Because we understand the process of creating a hypermedia document as an integrative process, not only the document type definition itself is described, but also the aspects of displaying such a XML-based hypermedia document. Due to the continuous use of XML conform techniques the developed HMDoc hypermedia documents are platform and system independent and can therefore be easily used in networks like the internet.               Keywords: XML-based document notation, document structuring, hypermedia               Categories: H.1  
8|10||"Mental Models to Represent Dynamics  - Using the Example ""factorial"""|  Gisbert Dittrich (Dept. of Informatics, Dortmund University, Germany)  Abstract: To use hypertext/hypermedia elements in teaching at universities an author not only needs knowledge of the technological possibilities. In addition he/she has to renew a here so called mental model of the relevant aspects of the material to be transferred. For the author, this last mentioned problem seems to be a central and often very complicated and time consuming one.               Keywords: animation, mental model, presentation of dynamics               Categories: H.5.1, H.5.4  
8|10||XML and MPEG-7 for Interactive Annotation  and Retrieval using Semantic Meta-data|  Mathias Lux (Know-Center Graz, Austria)   Werner Klieber (Know-Center Graz, Austria)   Jutta Becker (Know-Center Graz, Austria)   Klaus Tochtermann (Know-Center Graz, Austria)   Harald Mayer (JOANNEUM Research, Austria)   Helmut Neuschmied (JOANNEUM Research, Austria)   Werner Haas (JOANNEUM Research, Austria)  Abstract: The evolution of the Web is not only accompanied by an increasing diversity of multimedia but by new requirements towards intelligent research capabilities, user specific assistance, intuitive user interfaces and platform independent information presentation. To reach these and further upcoming requirements new standardized Web technologies and XML based description languages are used. The Web Information Space has transformed into a Knowledge marketplace where worldwide located participants take part into the creation, annotation and consumption of knowledge. This paper points out the design of semantic retrieval frameworks and a prototype implementation for audio and video annotation, storage and retrieval using the MPEG-7 standard and semantic web reference implementations. MPEG-7 plays an important role towards the standardized enrichment of multimedia with semantics on higher abstraction levels and a related improvement of query results.               Keywords: Hypermedia systems, MPEG-7, Multimedia, Semantic Web, Web-based services, XML, content-based Multimedia Retrieval               Categories: H.3.1, H.3.2, H.3.3, H.3.7, H.5.1  
8|10||Software for a Multimedia Encyclopedia|  Helmut Mülner (JOANNEUM RESEARCH, Austria)  Abstract: This paper discusses some experiences with the development of features based on natural language processing for a multimedia encyclopedia.               Keywords: information retrieval, natural language processing, software development               Categories: H.3  
8|11|http://www.jucs.org/jucs_8_11|Managing Editor's Column|
8|11||Extentions of Affine Arithmetic: Application to Unconstrained Global Optimization|  Frédéric Messine (Université de Pau et des Pays de l'Adour UFR-Sciences et Techniques, Département d'Informatique, France)  Abstract: Global optimization methods in connection with interval arithmetic permit to determine an accurate enclosure of the global optimum, and of all the corresponding optimizers. One of the main features of these algorithms consists in the construction of an interval function which produces an enclosure of the range of the studied function over a box (right parallelepiped).       We use here affine arithmetic in global optimization algorithms, in order to elaborate new inclusion functions. These techniques are implemented and then discussed. Three new affine and quadratic forms are introduced. On some polynomial examples, we show that these new tools often yield more efficient lower bounds (and upper bounds) compared to several well-known classical inclusion functions. The three new methods, presented in this paper, are integrated into various Branch and Bound algorithms. This leads to improve the convergence of these algorithms by attenuating some negative effects due to the use of interval analysis and standard affne arithmetic.               Keywords: affine arithmetic, branch and bound algorithm, global optimization, inclusion functions, interval arithmetic               Categories: G.1.0, G.1.6  
8|11||Finding Plagiarisms among a Set of Programs with JPlag|  Lutz Prechelt (University Karlsruhe, Germany)   Guido Malpohl (University Karlsruhe, Germany)   Michael Philippsen (University Karlsruhe, Germany)  Abstract: JPlag is a web service that finds pairs of similar programs among a given set of programs. It has successfully been used in practice for detecting plagiarisms among student Java program submissions. Support for the languages C, C++ and Scheme is also available. We describe JPlag's architecture and its comparsion algorithm, which is based on a known one called Greedy String Tiling. Then, the contribution of this paper is threefold: First, an evaluation of JPlag's performance on several rather different sets of Java programs shows that JPlag is very hard to deceive. More than 90 percent of the 77 plagiarisms within our various benchmark program sets are reliably detected and a majority of the others at least raise suspicion. The run time is just a few seconds for submissions of 100 programs of several hundred lines each. Second, a parameter study shows that the approach is fairly robust with respect to its configuration parameters. Third, we study the kinds of attempts used for disguising plagiarisms, their frequency, and their success.               Keywords: plagiarism, search, similarity, string tiling, token               Categories: F.2.2, H.3.3, H.5.2, I.5.4, K.3.m, K.5.1  
8|12|http://www.jucs.org/jucs_8_12|Managing Editor's Column|
8|12||On the Simplification of HD0L Power Series|  Juha Honkala (Department of Mathematics University of Turku, Finland)  Abstract: Nielsen, Rozenberg, Salomaa and Skyum have shown that HD0L languages are CPDF0L languages. We will generalize this result for formal power series. We will also give a new proof of the result of Nielsen, Rozenberg, Salomaa and Skyum.               Keywords: D0L power series, Formal power series, Lindenmayer systems               Categories: F.4.3  
8|12||On the Semiautomatic Generation of WordNet Type Synsets and Clusters|"  Florentina Hristea (University of Bucharest, Romania)  Abstract: WordNet (WN) is a lexical knowledge base, first developed for English and then adopted for several Western European languages, which was created as a machine-readable dictionary based on psycholinguistic principles. Our paper is an attempt to discuss the semiautomatic generation of WNs for languages other than English, a topic of great interest since the existence of such WNs will create the appropriate infrastructure for advanced Information Technology systems. Extending the algorithmic approach proposed in [Nikolov and Petrova, 01] we introduce a semiautomatic method based on heuristics for generating noun and adjective synsets and clusters. This choice of involved parts of speech is determined by the fact that nouns and adjectives have completely different organizations in WN: the hierarchy and the N-dimensional hyper-space respectively. Our approach to WN generation relies on so-called ""class methods"", namely it uses as knowledge sources individual entries coming from bilingual dictio               Keywords: WordNet, cluster, e-set, synset, synset id               Categories: J.  "
8|2|http://www.jucs.org/jucs_8_2|Advances and Trends in Automata and Formal Languages A Collection of Papers in Honour of the 60th Birthday of Helmut Juergensen - J.UCS Special Issue|
8|2||On the Computational Complexity of Synchronized Context-Free Languages|  Henning Bordihn (Institut für Informatik, Universität Potsdam, Germany)   Markus Holzer (Institut für Informatik, Technische Universitaet München, Germany)  Abstract: We introduce counter synchronized contextfree grammars and investigate their generative power. It turns out that the family of counter synchronized contextfree languages is a proper superset of the family of contextfree languages and is strictly contained in the family of synchronized contextfree languages. Moreover, we establish the space and time complexity of the fixed membership, the general membership, and the nonemptiness problem for synchronized and counter synchronized contextfree languages and solve the mentioned complexity questions in terms of completeness results for complexity classes. In this way we present new complete problems for LOG(CF), NP, and PSpace. It is worth to mention that the main theorem on the PSpacecompleteness of the general membership problem of synchronized contextfree grammars relies on a remarkable normal form for these grammars, namely for every synchronized contextfree grammar one can effectively construct and equivalent grammar of same type without nonsynchronizing nonterminals, except the axiom.    Keywords: computational complexity, decision problems, formal languages, synchronized grammars               Categories: F.1.3, F.2.2, F.4.2, F.4.3  
8|2||Additive Distances and Quasi_Distances Between Words|  Cristian S. Calude (Computer Science Department, The University of Auckland, New Zealand)   Kai Salomaa (Department of Computing and Information Science, Queen's University Kingston, Canada)   Sheng Yu (Department of Computer Science, The University of Western Ontario, Canada)  Abstract: We study additive distances and quasi-distances  between words. We show that every additive distance is finite. We then prove that every additive quasi-distance is regularity-preserving, that is, the neighborhood of any radius of a regular language with respect to an additive quasi-distance is regular. Finally, similar results will be proven for context-free, computable and computably enumerable languages.        Keywords: some words               Categories: F.1.1, F.4.3  
8|2||Finding Median Partitions Using Information-Theoretical-Based Genetic Algorithms|  Dana Cristofor (Department of Computer Science, University of Massachusetts at Boston, USA)   Dan Simovici (Department of Computer Science, University of Massachusetts at Boston, USA)  Abstract: In a database with categorical attributes, each attribute  defines a partition whose classes can be regarded as natural clusters of rows. In this paper we focus on finding a partition of the rows of a given database, that is as close as possible to the partitions associated to each attribute. We evaluate the closeness of two partitions by using a generalization of the classical conditional entropy. From this perspective, we wish to construct a partition (referred to as the median partition) such that the sum of the dissimilarities between this partition and all the partitions determined by the attributes of the database is minimal. Then, the problem of finding the median partition is an optimization problem, over the space of all partitions of the rows of the database, for which we give an approximative solution. To search more e#ciently the large space of possible partitions we use a genetic algorithm where the partitions are represented by chromosomes. Our genetic algorithm obtains better clustering results than the classical k-means algorithm.        Keywords: Gini index, Shannon entropy, categorical attributes, clustering, genetic algorithm, median partition, partitioning               Categories: E.4, H.2  
8|2||Rationally Additive Semirings|  Zoltán Ésik (Department of Computer Science, The University of Szeged, Hungary)   Werner Kuich (Institut für Algebra und Computermathematik, Technische Universität Wien, Austria)  Abstract: We define rationally additive semirings that are a  generalization of (ω)-complete and (ω)-continuous semirings. We prove that every rationally additive semiring is an iteration semiring. Moreover, we characterize the semirings of rational power series with coefficients in , the semiring of natural numbers equipped with a top element, as the free rationally additive semirings        Keywords: complete semiring, fixed point, iteration semiring, power series, semiring               Categories: F.4.3  
8|2||On Quasi-Products of Tree Automata|  Ferenc Gécseg (University of Szegeds, Hungary)  Abstract: In this paper we introduce the concept of the quasi-product of tree automata. In a quasi-product the inputs of the component tree automata are operational symbols in which permutation and unification of variables are allowed. It is shown that in sets of tree automata which are homomorphically complete with respect to the quasi-product the essentially unary operations play the basic role among all operations with nonzero ranks. Furthermore, we give a characterization of homomorphically complete sets which is similar to the classical one.        Keywords: complete sets, products, tree automata               Categories: F.1.1  
8|2||Descriptional Complexity of Machines with Limited Resources|  Jonathan Goldstine (Department of Computer Science Pennsylvania State University, USA)   Martin Kappes (Avaya Labs, USA)   Chandra M.R. Kintala (Avaya Labs, USA)   Hing Leung (Department of Computer Science, New Mexico State University, USA)   Andreas Malcher (Department of Computer Science, University of Frankfurt, Germany)   Detlef Wotschke (Department of Computer Science, University of Frankfurt, Germany)  Abstract: Over the last 30 years or so many results have appeared on the descriptional complexity of machines with limited resources. Since these results have appeared in a variety of different contexts, our goal here is to provide a survey of these results. Particular emphasis is put on limiting resources (e.g., nondeterminism, ambiguity, lookahead, etc.) for various types of finite state machines, pushdown automata, parsers and cellular automata and on the effect it has on their descriptional complexity. We also address the question of how descriptional complexity might help in the future to solve practical issues, such as software reliability.        Keywords: ambiguity, cellular automata, descriptional complexity, finite automata, formal languages, nondeterminism, parsers, pushdown automata, software reliability               Categories: F.1, F.4  
8|2||Simply Normal Numbers to Different Bases|  Peter Hertling (Theoretische Informatik I, FernUniversität, Germany)  Abstract: Let b ≥ 2 be an integer. A real number is called simply normal to base b if in its representation to base b every digit appears with the same asymptotic frequency. We answer the following question for arbitrary integers a, b ≥ 2:if a real number is simply normal to base a, does this imply that it is also simply normal to base b? It turns out that the answer is different from the well–known answers to the corresponding questions for the related properties “normality”, “disjunctiveness”, and “randomness”.        Keywords: invariance properties, randomness               Categories: F.m, G.2  
8|2||Word Operation Closure and Primitivity of Languages|  H. K. Hsiao (Department of General Education, Chung-Shan Medical University, Taiwan)   C. C. Huang (Department of General Education, Chung-Shan Medical University, Taiwan)   S. S. Yu (Department of Applied Mathematics, National Chung-Hsing University,, Taiwan)  Abstract: Based on the general operation  of words, called bw_operation, the notions of primitive words, closed languages, bases of languages and operation_left_quotient_closed languages are defined and investigated. These notions turn out to be generalizations of the classical notions of primitive words, plus_closed (star_closed) languages, minimal generating sets and deletion_closed languages. Properties of the set of all primitive words, the bases of non_empty languages, right residuals and operation_left_quotient closed languages are studied under the general concept of word operation. Properties of bi_catenation and related languages are discussed as examples and also by their own interests.        Keywords: Word operation, base, closure, dense, primitivity, right residual               Categories: F.4.3  
8|2||Shuffle Decomposition of Regular Languages|" (nX)"">top.name=""UJSeries_Window"";   Masami Ito (Department of Mathematics, Kyoto Sangyo University, Japan)  Abstract: Let A   X* be a regular language. In the paper, we will provide an algorithm to decide whether there exist a nontrivial language B  (n, X) and a nontrivial regular language C  X* such that A = B  C        Keywords: (nX), regular language, shuffle  decomposition, shuffle product               Categories: F.1  "
8|2||Some Remarks on Codes Defined by Petri Nets|  Masami Ito (Department of Mathematics, Kyoto Sangyo University, Japan)   Jürgen Dassow (Otto-von-Guericke-Universität Magdeburg, Fakultät für Informatik, Germany)   Ralf Stiebe (Otto-von-Guericke-Universität Magdeburg, Fakultät für Informatik, Germany)  Abstract: With any Petri net we associated its CPN language which consists of all sequences of transitions which reach a marking with an empty place whereas all proper prefixes of the sequence lead to positive markings.  We prove that any CPN language can be accepted by a partially blind multicounter machine, and that any partially blind multicounter language is the morphic image of some CPN language. As a corollary we obtain the decidability of membership, emptiness and finiteness problem for CPN languages. We characterize the very strictly bounded regular languages, which are CPN languages, and give a condition for a Petri net, which ensures that its generated language is regular. We give a dense CPN language and prove that no dense regular language is a CPN language.        Keywords: Petri nets, codes, formal languages               Categories: F.4.2, F.4.3  
8|2||Synchronization and Stability of Finite Automata|  Jarkko Kari (Department of Mathematics and Turku Centere for Computer Science, Finland)  Abstract:   Let G = (V, E) be a strongly connected and aperiodic directed graph of uniform out-degree k. A deterministic finite automaton is obtained if the edges are colored with k colors in such a way that each vertex has one edge of each color leaving it. The automaton is called synchronized if there exists an input word that maps all vertices into the same fixed vertex. The road coloring conjecture asks whether there always exists a coloring such that the resulting automaton is synchronized. The conjecture has been proved for various types of graphs but the general problem remains open. In this work we investigate a related concept of stability, using techniques of linear algebra. We have proved in our earlier papers that the road coloring conjecture is equivalent to the conjecture that each strongly connected and aperiodic graph has a coloring where at least one pair of states is stable. In the present work we prove that stable pairs of states exist in all automata that are almost balanced in the sense that there is at most one state for each color where synchronization can take place.   Keywords: finite automata, synchronization               Categories: F.1.1  
8|2||Error-Correction, and Finite-Delay Decodability|  Stavros Konstantinidis (Department of Mathematics and Computing Science, Saint Mary's University, Canada)  Abstract: When the words of a language are communicated via a noisy channel, the language property of error-detection ensures that no word of the language can be transformed to another word of the language. On the other hand, the property of error-correction ensures that the channel cannot transform two different words of the language to the same word. In this work we use transducers to model noisy channels and consider a few simple transducer operations that can be used to reduce the language properties of error-detection and error-correction to the transducer property of functionality. As a consequence, we obtain simple polynomial-time algorithms for deciding these properties for regular languages. On the other hand the properties are not decidable for context-free languages. In addition we show that, in a certain sense, the class of rational channels can be used to model various error combinations. Using the same tools, we also obtain simple polynomial-time algorithms for deciding whether a given regular language is thin and whether a given regular code has decoding delay d, for given d, and for computing the minimum decoding delay of a given regular code.        Keywords: channel, decidability, decoding delay, error-correction, error-detection, regular language, transducer, unique decodability               Categories: F.  
8|2||Bridging Two Hierarchies of Infinite Words|  Solomon Marcus (Romanian Academy, Mathematics Calea Victoriei 125, Romania)  Abstract: Infinite words on a finite non-empty alphabet have been investigated in various respects. We will consider here two important strategies in approaching such words; one of them proceeds from particular to general, while the other proceeds from general to particular. As we shall see, the respective hierarchies don’t interfer. There is between them an empty space waiting for investigation.        Keywords: disjunctive, random infinite words, ultimately periodic infinite, uniformly recurrent               Categories: F.1, F.1.1  
8|2||Tiling the Hyperbolic Plane with a Single Pentagonal Tile|  Maurice Margenstern (Université de Metz, LITA, UFR MIM, Ile du Saulcy, France)  Abstract: In this paper, we study the number of tilings of the hyperbolic plane that can be constructed, starting from a single pentagonal tile, the only permitted transformations on the basic tile being the replication by displacement along the lines of the pentagrid. We obtain that there is no such tiling with five colours, that there are exactly two of them with four colours and a single trivial tiling with one colour. For three colours, the number of solutions depends of the assortment of the colours. For half of them, there is a continuous number of such tilings, for one of them there are four solutions, for the two other ones, there is no such tiling. For two colours, there is always a continuous number of such tilings.            By contrast, there is no such analog in the euclidean plane with the similar constraints.        Keywords: Hyperbolic plane, tilings               Categories: F.1, F.1.1, G.2  
8|2||On the Power of P Systems with Symport Rules|"  Carlos Martín-Vide (Research Group on Mathematical Linguistics, Rovira i Virgili University, Spain)   Andrei Paun (Department of Computer Science, University of Western Ontario, Canada N6A 5B7)   Gheorghe Paun (Institute of Mathematics of the Romanian Academy, Romania and Rovira i Virgili University, Spain)  Abstract: A purely communicative variant of P systems was considered recently, based on the trans-membrane transport of couples of chemicals. When using both symport rules (the chemicals pass together in the same direction) and antiport rules (one chemical enters and the other exits a membrane), one obtains the computational completeness, and the question was formulated what happens when only symport rules are considered. We address here this question. First, we surprisingly find that ""generalized"" symport rules are sufficient: if more than two chemicals pass together through membranes, then we get again the power of Turing machines. Three results of this type are obtained, with a trade-off between the number of chemicals which move together (at least three in the best case) and the number of membranes used. The same result is obtained for standard symport rules (couples of chemicals), if the passing through membranes is conditioned by some permitting contexts (certain chemicals should be present in the membrane). In this case, four membranes suffice. The study of other variants of P systems with symport rules (for instance, with forbidding contexts) is formulated as an open problem.        Keywords: antiport, computational universality, membrane computing, molecular computing, symport               Categories: F.1.1  "
8|2||Generation of Constants and Synchronization of Finite Automata|  Arto Salomaa (Turku Centre for Computer Science, Finland)  Abstract:   The problem about the synchronization of a finite deterministic automaton is not yet properly understood. The present paper investigates this and related problems within the general framework of a composition theory for functions over a finite domain N with n elements. The notion of depth introduced in this connection is a good indication of the complexity of a given function, namely, the complexity with respect to the length of composition sequences in terms of functions belonging to a basic set. The depth may vary considerably with the target function. Not much is known about the reachability of some target functions, notably constants. Synchronizability of a finite automaton amounts to the representability of some constant as a composition of the functions defined by the input letters. Properties of n such as primality or being a power of 2 turn out to be important, independently of the semantic interpretation. We present some necessary, as well as some sufficient, conditions for synchronizability. We also discuss a famous conjecture about the length of the shortest synchronizing word, and present some results about universal synchronizing words.    Keywords: complexity of compositions, functional compositions, functions over a finite domain, synchronization of finite automata               Categories: F.1.1  
8|2||How Large is the Set of Disjunctive Sequences?|  Ludwig Staiger (Institut für Informatik, Martin-Luther-Universität Halle-Wittenberg, Germany)  Abstract: We consider disjunctive sequences, that is, infinite sequences -words) having all finite words as infixes. It is shown that the set of all disjunctive sequences can be described in an easy way using recursive languages and, besides being a set of measure one, is a residual set in Cantor space.  Moreover, we consider the subword complexity of sequences: here disjunctive sequences are shown to be sequences of maximal complexity.  Along with disjunctive sequences we consider the set of real numbers having disjunctive expansions with respect to some bases and to all bases. The latter are called absolutely disjunctive real numbers. We show that the set of absolutely disjunctive reals is also a residual set and has representations in terms of recursive languages similar to the ones in case of disjunctive sequences. To this end we derive some fundamental properties of the functions translating a base r-expansion of a real  [0, 1] into .        Keywords: entropy, nowhere dense sets, subword complexity, ω-languages               Categories: F.1.1, F.4.1  
8|2||A Fast and Simple Algorithm for Constructing Minimal Acyclic Deterministic Finite Automata|  Bruce W. Watson (Software Construction Research Group, Department of Computer Science, Technological University of Eindhoven, the Netherlands; Department of Computer Science, University of Pretoria, South Africa; FST Labs & Ribbit Software Systems Inc.)  Abstract: In this paper, we present a fast and simple algorithm for constructing a minimal acyclic deterministic finite automaton from a denite set of words. Such automata are useful in a wide variety of applications, including computer virus detection, computational linguistics and computational genetics. There are several known algorithms that solve the same problem, though most of the alternative algorithms are considerably more difficult to present, understand and implement than the one given here. Preliminary benchmarking indicates that the algorithm presented here is competitive with the other known algorithms.        Keywords: automata construction algorithms, minimal acyclic deterministic finite automata               Categories: F.1.1  
8|3|http://www.jucs.org/jucs_8_3|Managing Editor's Column|
8|3||Membrane Computing: The Power of (Rule) Creation|  Fernando Arroyo (Dpto. de Lenguajes, Proyectos y Sistemas Informaticos, Escuela de Informática, Spain)   Angel Baranda (Dpto. de Inteligencia Artificial Facultad de Informática, Spain)   Juan Castellanos (Dpto. de Inteligencia Artificial Facultad de Informática, Spain)   Gheorghe Paun (Institute of Mathematics of the Romanian Academy, Romania)  Abstract: We consider a uniform way of treating objects and rules in P systems: we start with multisets of rules, which are consumed when they are applied, but the application of a rule may also produce rules, to be applied at subsequent steps. We find that this natural and simple feature is surprisingly powerful: systems with only one membrane can characterize the recursively enumerable languages, both in the case of rewriting and of splicing rules, the same result is obtained in the case of symbol-objects, for the recursively enumerable sets of vectors of natural numbers.               Keywords: Chomsky hierarchy, membrane computing, molecular computing, rewriting, splicing               Categories: F.1.1, F.4.2, F.4.3  
8|3||Some Notes on Fine Computability|  Vasco Brattka (Theoretische Informatik 1, Informatikzentrum FernUniversität, Germany)  Abstract: A metric defined by Fine induces a topology on the unit interval which is strictly stronger than the ordinary Euclidean topology and which has some interesting applications in Walsh analysis. We investigate computability properties of a corresponding Fine representation of the real numbers and we construct a structure which characterizes this representation. Moreover, we introduce a general class of Fine computable functions and we compare this class with the class of locally uniformly Fine computable functions defined by Mori. Both classes of functions include all ordinary computable functions and, additionally, some important functions which are discontinuous with respect to the usual Euclidean metric. Finally, we prove that the integration operator on the space of Fine continuous functions is lower semi-computable.               Keywords: Computable analysis, Walsh analysis               Categories: F.1  
8|3||Is Democracy Possible in the Internet?|  Jenny Shearer (Department of Computer Science, University of Auckland, New Zealand)   Hermann Maurer (Institute for Information Systems and Computer Media Graz University of Technology, Austria)  Abstract: Concepts of democracy have been developed and refined since Aristotle's time. However it is not until the new millennium that a unique set of circumstances, social, technical, and economic, have enabled a realistic plan of an e-democratic world to emerge. It is the lot of the internet generation to carry this vision through a maze of regulatory and commercial obstacles. The most important development on the internet in terms of its impact is e-commerce and the flow of support from governments and the market. It may appear that social and political aspirations for the internet have been eclipsed. However, on the contrary, global online commerce is providing opportunities for e-democracy to meet ethical and strategic challenges. The ultimate goal is to create peaceful change in key areas of global governance. We investigate some of those aspects in this paper.               Keywords: Cyber Ethics, Freedom of Speech, Internet Legislation, e-Democracy               Categories: K.4, K.5, K.7  
8|4|http://www.jucs.org/jucs_8_4|Managing Editor's Column|
8|4||HWOES: A Hyperwave Online Employment Service|  Jennifer Lennon (Department of Computer Science, University of Auckland, New Zealand)   H. Liu (Department of Computer Science, University of Auckland, New Zealand)   Hermann Maurer (Technical University Graz and KNOW Center, Austria)  Abstract: In this paper we propose several significant advances in online employment services. We address issues such as privacy, interaction, and scalability to worldwide services. The details of each user are managed in completely relevant-to-service formats and both jobseekers & employers have considerable control over just how many of their own personal details are visible at any time. Perhaps most interestingly, virtual connections are maintained that support the various stages of negotiation in iterative, computer-supported cycles.               Keywords: e-commerce, interactive negotiations, online employment services               Categories: J.  
8|4||Modelling Agents as Observable Sources|  Mirko Viroli (DEIS, Università di Bologna, Via Rasi e Spinelli, Italy)   Andrea Omicini (DEIS, Università di Bologna, Via Rasi e Spinelli, Italy)  Abstract:   Observation is a fundamental interaction pattern in today's computer-based systems. Adopting observation as the main modelling criterion, computer-based systems can be represented as composed by three class of entities: observers, observables (or sources), and coordinators, that is, the entities managing the observer/source interaction.  Also, agents and agent societies are fundamental abstractions in modelling today's complex systems. When exploiting observation in the context of agent-based systems, the most natural interpretation for agents is to see them as either observers or coordinators. However, their situatedness and autonomy, their peculiar perception and representation of the environment, and their typical ability to infer new knowledge - in short, their individual viewpoint over the world -, make agents suitable for an interpretation as observable sources.  Accordingly, this paper discusses the implications of using observation to model agent systems, and focuses on the interpretation of agents as observables. A formal framework is developed where multiagent systems are modelled as the composition of agents interacting by observing each other and by mutually affecting their observable behaviour.  Keywords: coordination patterns, formal models, multi-agent systems               Categories: D.2.1, F.1.2, F.3.1, F.4.3, I.2.11  
8|5|http://www.jucs.org/jucs_8_5|J.UCS Special Issue: I-Know  02 - People-Oriented Knowledge Management|
8|5||The New Mobility of Our Society Caused by Telecommunications|"  Johann Günther (Danube University Krems, Austria)  Abstract:   People have always been mobile. In the Middle Ages, masses moved because of pilgrimages. Today, these masses are called holiday travellers.  People have never been more mobile than today. Because of increasing prosperity and the abolishment of many borders in Europe, ""freedom"" has become a new symbol. Freedom causes movement. We have yet to overcome the borders of the countries behind the former Iron Curtain.  Our economy needed the division of labour, and therefore more mobility for goods and managers.  Moreover, liberalised markets brought about the ""global village"". In the 21st century, the global economy will be dominated by three key industries:  Changes in technologies and generations are common developments. Old styles are replaced by new ones. New technologies are replacing old ones. Telecommunications and Information Technology have propelled us into what we call the Information Society. More than 50 percent of employees in developed countries are working with information.  The Information Society did not only bring about change. Its instruments also helped us to become more mobile. Mobility is nothing new for people. We can now lead nomadic lives without being accountable to the state.  Keywords: Internet, information society, information technology, mobility, telecommunication               Categories: J., K.  "
8|5||The Knowledge-Attention-Gap: Do We Underestimate the Problem of Information Overload in Knowledge Management|  Ursula Schneider (Karl Franzens University, Austria)  Abstract: The generation of technical knowledge abounds while the underusage of existing knowledge potential remains a problem in business as well as in society. Generally speaking value can be extracted from knowledge in three ways:  Keywords: document-explosion, information overload, intelligent agents, knowledge management, positive ignorance               Categories: A.  
8|5||Knowledge on Demand: Knowledge and Expert Discovery|  Mark T. Maybury (The MITRE Corporation, USA)  Abstract: This article outlines new technologies in the areas of automated expertise finding, expert network discover, virtual place-based collaboration, and automated question answering. We illustrate each of these areas with implemented and in some cases empirically evaluated systems. Collectively, these illustrate new methods for automatic discovery of knowledge, experts, and communities in an effective and efficient manner.               Keywords: distributed collaboration, knowledge acquisition, knowledge management, natural language               Categories: H., H.1.2, H.3.3, H.5.1, H.5.2, I.2.1  
8|5||Ontology-Based Skills Management: Goals, Opportunities and Challenges|  Jacqueline R. Reich (Rentenanstalt/Swiss Life, Switzerland)   Peter Brockhausen (Rentenanstalt/Swiss Life, Switzerland)   Thorsten Lau (Rentenanstalt/Swiss Life, Switzerland)   Ulrich Reimer (Rentenanstalt/Swiss Life, Switzerland)  Abstract: Establishing electronically accessible repositories of people s capabilities, experiences, and key knowledge areas is key in setting up Enterprise Knowledge Management. A skills repository can be used for e.g. finding people, staffing, skills gap analysis, and professional development. The ontology based skills management system developed at Swiss Life uses RDF schema for storing ontologies. Its query interface is based on a combined RQL and HTML query engine.               Keywords: RDF, ontologies, skills management               Categories: H.3, H.4, I.2.4, K.4.3, K.6.1  
8|5||Bibliometric Analysis and Visualisation of Intellectual Capital|  Andrea Kasztler (ARC Seibersdorf research GmbH, Austria)   Karl-Heinz Leitner (ARC Seibersdorf research GmbH, Austria)  Abstract: On the basis of an example gained from the perspective of a person reading Intellectual Capital (IC) reports this paper explains the method of BibTechMonTM which is based on an analysis of the co-occurrence of different terms within databases and the algorithm to visualise the results [Kopcsa, A., Schiebel, E. (1998b)]. The application of this method for the IC report is currently a major step in improving the IC reporting system within ARC Seibersdorf research GmbH. In this paper the advantages and potentials of using BibTechMonTM in the context of IC reporting will be demonstrated by means of the 2001 IC report of ARC Seibersdorf research GmbH.               Keywords: intellectual capital report, knowledge map, network, relational capital               Categories: H.3.1, H.3.3, I.2.4  
8|5||Knowledge and Intellectual Capital Management Processes: Grounding Knowledge and Understanding of Organisational Learning|  Shantha Liyanage (The University of Auckland, New Zealand)  Abstract: The process of knowledge and intellectual capital management aims to improve organisational performance and efficiency. Knowledge is a distinct capability that contributes to the improvement of this efficiency. Learning is an integral part of the knowledge system and can be identified by deconstructing available organisational knowledge. This paper offers an interpretative perspective of knowledge and intellectual capital development, it also examines previously fractured contextual approaches to organisational management research, which often fail to include learning as a significant factor for both absorbing and recognising the knowledge capabilities of a firm. Based on the results from a study conducted across 140 companies as well as selected case studies, this paper investigates learning mechanisms and their role in building a firm s knowledge capabilities. This paper argues that learning is an integral part of the knowledge process in which learning acts as an endogenous factor for the development, absorption and utilisation of knowledge. The search continues for an appropriate epistemological framework in the area of management research under which organisational learning theories can be analysed while simultaneously remaining relevant and useful to the pragmatics of organisational knowledge development.               Keywords: absorptive capacity, dynamic capabilities, intellectual capital, knowledge interchanges, knowledge management, organisational learning, prior knowledge, situated learning               Categories: A.1  
8|5||Fostering Knowledge Communication:  Concept And Implementation|"  Rüdiger Reinhardt (University of St. Gallen, Institute for Media and Communications Management, Switzerland)   Beate Stattkus (University of St. Gallen, Institute for Media and Communications Management, Switzerland)  Abstract: The loss of an employee - voluntarily or involuntarily - represents a great risk of losing information and know how as well as breaks the natural knowledge flow. We developed the Knowledge Transfer Meeting Methodology in order to reduce the ""brain drain"" through a systematic hand-over. The Knowledge Transfer Meeting consists of five modules that support the retrieval and sharing of knowledge systematically and explicitly. The approach promotes a mentorship or partnership philosophy, motivating the leaving employee to share his or her knowledge and experience with a successor. For the implementation of the Knowledge Transfer Meeting Methodology in the company, we identify and train so-called ""facilitators"" who lead the participants through the process and hence support and spread the methodology within the company.               Keywords: knowledge management, knowledge tools, knowledge transfer               Categories: A.1, H.0, H.4.m  "
8|5||Knowledge Transfer in Recycling Networks: Fostering Sustainable Development|  Elisabeth Milchrahm (Institute for Information Science, Karl-Franzens-University Graz, Austria)   Arnulf Hasler (Institute for Innovation and Environmental Management, Karl-Franzens-University Graz, Austria)  Abstract: This paper reports on long-term research work of recycling networks in Germany and Austria from a knowledge-based perspective. Using data from expert interviews, we discuss the key determinants of inter-organizational knowledge transfer within networks. In particular, we highlight the factor of mutual trust as important determinant of knowledge transfer in company recycling networks. One important goal of our empirical research is the institutionalization of knowledge transfer through the implementation of a central recycling agency in order to build core capabilities and to create intellectual capital.               Keywords: company networks, knowledge networks, knowledge taxonomies, knowledge transfer, recycling agency, sustainable development               Categories: H.3, H.4, J.4  
8|5||The Role of Interaction Histories in Mental Model  Building and Knowledge Sharing in the Legal Domain|  Anita Komlodi (UMBC, USA)  Abstract: This paper reports on a study examining attorneys  and law librarians  use of their memory and information they record externally in searching for, using, and sharing legal information. The paper suggests automatically and manually recording search histories and basing user interface tools on this information to support mental model building and knowledge sharing in the legal information domain. The research described is part of the author s dissertation research [1] that examined the use of search histories in legal information seeking and use, and proposed interface design recommendations for information systems. While searching for and using information, attorneys learn about legal topics and use this knowledge in their work. They create mental models and share their new knowledge with colleagues. Computers can automatically record human-computer interaction events. This information can help searchers represent and share new knowledge. The recorded information can be provided back to the user through the user interface to support searching for and using information, learning about the subject matter and sharing this knowledge with others. In this study, attorneys and law librarians were interviewed and observed to assess their use of their memory and external memory aids while searching for and using legal information. The results reported here focus on the role of interaction histories and history-based interface tools in supporting mental model development of legal information seekers of a topical area and sharing this information with other users.               Keywords: information retrieval, legal informatics, search histories               Categories: D.2.2, H.3.3  
8|6|http://www.jucs.org/jucs_8_6|J.UCS Special Issue: I-Know  02 - Technology-Oriented Knowledge Management|
8|6||What to Expect from Software Experience  Exploitation|  Kurt Schneider (DaimlerChrysler AG, Research Center Ulm, Germany)  Abstract:   Software quality management and quality assurance are disciplines that require substantial knowledge of the methods and techniques to be applied. More important than a solid knowledge of methodology, however, is the ability to judge feasibility of approaches, and to tailor activities to the business unit culture and constraints. Software quality activities must be carefully integrated into an existing company or business culture. Making informed decisions requires more than knowledge - it calls for experience of what works and what does not work in a given environment. Experienced quality agents are a scarce resource. Exploiting a scarce resource - like experiences in software quality - more effectively is a straight-forward concept.  Five years ago, DaimlerChrysler set up a large research project with business units, called SEC (Software Experience Center). Its purpose was to explore opportunities for learning from experiences within and across different business units. Unlike more general approaches of knowledge management, SEC was entirely devoted to software processes: software development, software acquisition, and in particular software quality in both development and acquisition settings.  However, not all expectations that are often related to experience exploitation are realistic. In SEC, some of our initial expectations were met, others were not. This talk reports and reflects on our attempts to capture, engineer, and reuse experiences in the realm of software quality and software process improvement.  Keywords: process improvement, systematic learning from experience               Categories: H.3, K.6.3  
8|6||Automated Retrieval of Information in the Internet by Using Thesauri and Gazetteers as Knowledge Sources|"  Wolf-Fritz Riekert (University of Applied Sciences Stuttgart - School of Media, Germany)  Abstract: There is an immense number of information resources on the Internet that can be utilized free of charge. So many knowledge workers try to make use of this information in their daily tasks. Nevertheless, it is very hard to find the relevant information in the Internet by using the full-text retrieval techniques which are offered by most existing search engines.  This paper demonstrates that Thesauri, which have been used in established online retrieval systems for a long time, also open up new methods for the automated search for information in the Internet. In addition, thesaurus-like structures known as Gazetteers allow handling geographical references of information resources in a very effective way. The knowledge represented in thesauri and gazetteers can be used to process a variety of thematic and geographical queries and to retrieve the information of interest from the Internet. Comfortable ways of specifying queries can be offered to the users, e.g., by navigating in a hierarchical tree of descriptors, by using synonymous, related or foreign-language terms rather than fixed elements of a controlled vocabulary, or by indicating a geographical region of interest on a cartographic map.  In addition to the general principles, examples of powerful query processors and advanced user interfaces are presented which demonstrate the effective usage of the knowledge stored in thesauri and gazetteers. The implemented solutions turn out to be considerably more comfortable than the ""black box search"" offered by most existing library catalogs and Internet search engines.               Keywords: Gazetteer, Internet, Thesaurus, information retrieval               Categories: H.3.3  "
8|6||Instance Cooperative Memory to Improve Query Expansion in Information Retrieval Systems|  Lobna Jéribi (Laboratory of Information Science Engineering, INSA de Lyon, France)   Bèatrice Rumpler (LISI (Laboratory of Information Science Engineering), INSA de Lyon, France)  Abstract: The main goal of this research is to improve Information Retrieval Systems by enabling them to generate search outcomes that are relevant and customized to each specific user. Our proposal advocates the use of Instance Based Reasoning during the information retrieval process.   When conducting a search, the system retrieves a previous similar search experience and traces back previous human reasoning and behavior and then replicates it in the current situation. Thus, user information retrieval experiences or instances are saved to be reused in future similar cases. The resulting cooperative memory is used for user query expansion.   In order to improve the information retrieval experience, we propose to conceptualize and model both the user profile, and the information retrieval process. This leads us to define some similarity functions between user profiles and information retrieval situations. The reuse of past experiences serves to enrich the initial user query by words from documents found in similar cases. Unlike the classical Rocchio method, these documents are those already judged as valid by users with similar profile and in similar search situation. The value this method brings to the user is an icreasing relevance of the search outcomes while reducing user interaction with the system.   This method has been implemented in the COSYDOR (Cooperative System for Document Retrieval) prototype based on Intermedia (Oracle 8i). Tests and evaluations have been performed on the COSYDOR prototype using the test corpus of TREC (Text Retrieval Converence) and its standard procedures for performance analysis and benchmarking. The results of these analyses show a significant improvement of performance in the first search iterations compared to the Intermedia benchmark.               Keywords: cooperative memory relevance feedback, information retrieval, instance based learning, query expansion, user modeling               Categories: H., H.1.2, H.3.3, H.4.3  
8|6||Extracting and Visualizing Knowledge  from Film and Video Archives|  Howard D. Wactlar (Carnegie Mellon University, USA)  Abstract: Vast collections of video and audio recordings which have captured events of the last century remain a largely untapped resource of historical and scientific value. The Informedia Digital Video Library has pioneered techniques for automated video and audio indexing, navigation, visualization, search and retrieval and embedded them in a system for use in education and information mining. In recent work we introduce new paradigms for knowledge discovery by aggregating and integrating video content on-demand to enable summarization and visualization in response to queries in a useful broader context, starting with historic and geographic perspectives.               Keywords: digital video library, metadata extraction, video collage, video summarization, visualization               Categories: H.3.7, H.5.1, I.2.7  
8|6||Efficient Content-Based and  Metadata Retrieval in Image Database|  Solomon Atnafu (LISI - INSA de Lyon, France)   Richard Chbeir (LISI - INSA de Lyon, France)   Lionel Brunie (LISI - INSA de Lyon, France)  Abstract: Managing image data in a database system using metadata has been practiced since the last two decades. However, describing an image fully and adequately with metadata is practically not possible. The other alternative is describing image content by its low-level features such as color, texture, shape, etc. and using the same for similarity-based image retrieval. However, practice has shown that using only the low-level features can not as well be complete. Hence, systems need to integrate both low-level and metadata descriptions for an efficient image data management. However, due to lack of adequate image data model, absence of a formal algebra for content-based image operations, and lack of precision of the existing image processing and retrieval techniques, no much work is done to integrate the use of low-level and metadata description and retrieval methods. In this paper, we first present a global image data model that supports both metadata and low-level descriptions of images and their salient objects. This allows to make multi-criteria image retrieval (context-, semantic-, and content-based queries). Furthermore, we present an image data repository model that captures all data described in the model and permits to integrate heterogeneous operations in a DBMS. In particular, similarity-based operations (similarity-based join and selection) in combination with traditional ones can be carried out. Finally, we present an image DBMS architecture that we use to develop a prototype in order to support both content-based and metadata retrieval.               Keywords: image data model, image data repository model, image database, multi-criteria queries, similarity-based operations               Categories: H.2.4  
8|6||Topic Map Generation Using Text Mining|  Karsten Böhm (TextTech Ltd., Germany)   Gerhard Heyer (Leipzig University, Germany)   Uwe Quasthoff (Leipzig University, Germany)   Christian Wolff (Leipzig University, Germany)  Abstract: Starting from text corpus analysis with linguistic and statistical analysis algorithms, an infrastructure for text mining is described which uses collocation analysis as a central tool. This text mining method may be applied to different domains as well as languages. Some examples taken form large reference databases motivate the applicability to knowledge management using declarative standards of information structuring and description. The ISO/IEC Topic Map standard is introduced as a candidate for rich metadata description of information resources and it is shown how text mining can be used for automatic topic map generation.               Keywords: corpora, knowledge management, semantic relations, text mining, topic maps               Categories: H.3.1, H.3.3, H.3.5, H.5.3, I.2.7, I.7  
8|6||Usage-Centered Interface Design for Knowledge Management Software|  Harald Karner (Hyperwave R&D, Graz, Austria)   Georg Droschl (Hyperwave R&D, Graz, Austria)  Abstract: In IT-supported knowledge management (KM), the software user interface is at the boundary between persons and the knowledge management system (KMS). It plays a central role because seen from the users point of view, the user interface is the system. This paper presents a case study in which a particular User Interface Design methodology was employed to design a prototype KMS user interface for an inbound call center. In this example, we combine knowledge re-use and expert location.               Keywords: call center, interaction patterns, knowledge management, usage-centered design, user interface design               Categories: H.5.2  
8|6||Shark - a System for Management, Synchronization and Exchange of Knowledge in Mobile User Groups|  Thomas Schwotzer (Intelligent Networks and Management of Distributed Systems, TU Berlin, Germany)   Kurt Geihs (Intelligent Networks and Management of Distributed Systems, TU Berlin, Germany)  Abstract: New wireless protocols like W-LAN and Bluetooth allow establishing spontaneous networks and peer-to-peer exchange of information. At the same time standards like Semantic Web and Topic Maps gain acceptance that add semantics to information. This paper introduces Shark. Shark is an acronym and stands for  jucs_admin jucs_finalizer ujs_admin; A:a, g jucs_admin jucs_finalizer ujs_admin; T:g jucs_admin jucs_finalizer ujs_admin TimeCreated=2005/10/04 11:30:34 TimeModified=2005/10/04 11:30:34 Title=en:Riekert_W_F.pdf Type=Document issue_date=2002-06-28 issue_nr=6 journal=jucs volume_nr=               Keywords: information systems, knowledge management, knowledge work processes               Categories: C.2.4, H.1.2, H.4.3  
8|6||Knowledge Nodes: the Building Blocks of a Distributed Approach to Knowledge Management|  Matteo Bonifacio (University of Trento, Italy)   Paolo Bouquet (Department of Information and Communication Technologies University of Trento, Italy)   Roberta Cuel (Department of Computer and Management Sciences University of Trento, Italy)  Abstract: In this paper, we criticise the objectivistic approach that underlies most current systems for Knowledge Management. We show that such an approach is incompatible with the very nature of what is to be managed (i.e., knowledge), and we argue that this may partially explain why most knowledge management systems are deserted by users. We propose a different approach - called distributed knowledge management - in which subjective and social (in a word, contextual) aspects of knowledge are seriously taken into account. Finally, we present a general technological architecture in which these ideas are implemented by introducing the concept of knowledge node.               Keywords: context, distributed knowledge management, epistemology, knowledge nodes               Categories: H.  
8|6||Managing User Focused Access to Distributed Knowledge|  Rudi Studer (Institute AIFB, University of Karlsruhe, Germany, FZI Research Center for Information Technologies and Ontoprise GmbH, Germany)   York Sure (Institute AIFB, University of Karlsruhe, Germany)   Raphael Volz (Institute AIFB, University of Karlsruhe and FZI Research Center for Information Technologies, Germany)  Abstract: Community web sites exhibit the property that multiple content providers exist. Of course, any portal is only as useful as the quality and amount of its content. Developing original content is time consuming and expensive. To offset the cost, we present a novel framework, viz. SEAL (SEmantic portAL), that builds on Semantic Web standards. We illustrate our approach with examples from the OntoWeb community portal. Community web sites exhibit two dominating properties: They often need to integrate many different information sources and they require an adequate web site management system. SEAL exploits ontologies for fulfilling the requirements set forth by these two properties. Ontologies provide a high level of sophistication for web information integration as well as for web site management.               Keywords: information integration, knowledge portal, ontology               Categories: H.0  
8|7|http://www.jucs.org/jucs_8_7|Managing Editor's Column|
8|7||A Framework for Semantics of UML Sequence Diagrams in PVS|  Demissie B. Aredo (Department of Informatics, University of Oslo, Norway)  Abstract: This paper presents a framework for representing formal semantics of a subset of the Unified Modeling Language (UML) notation in a higher-order logic, more specifically semantics of UML sequence diagrams is encoded into the Prototype Verification System (PVS). The primary objective of our work is to make UML models amenable to rigorous analysis by providing their precise semantics. This approach paves a way for formal development of systems through a systematic transformation of UML models. This work is a part of a long-term vision to explore how the PVS tool set can be used to underpin practical tools for analyzing UML models. It contributes to the ongoing effort to provide mathematical foundation to UML notations, with the aim of clarifying the semantics of the language as well as supporting the development of semantically-based tools.               Keywords: PVS, UML, formal methods, formal semantics, object-orientation               Categories: D.1.5, D.2.4, D.3.1  
8|7||Bounded Flooding Routing Algorithm for Provisioning the Globally Optimal Route in a Hierarchical ATM Network|  Daniel Won-Kyu Hong (R&D Group, Korea)   Choong Seon Hong    Yoo Jae Hyoung (R&D Group, Korea)   Dong-Sik Yun (R&D Group, Korea)   Woo-Sung Kim (R&D Group, Korea)  Abstract: ATM virtual path (VP) contains bundles of virtual channels (VCs). A VP layer network can be used as a server layer network of VC layer networks and each VC layer network can be a client layer. Therefore the effective provision of VC services can be achieved by a better routing scheme of the VP layer network. However, the traditional hierarchical routing scheme of PNNI signaling protocol does not provide the globally optimal route in hierarchical transport network due to its successive network partitioning and topology abstraction. We propose a new VP routing scheme suitable for a nation-wide hierarchical transport network and a network model suitable for the scalable VP network management system. The routing algorithm can provide the globally optimal route in the hierarchical network environment from the perspectives of maximization of network resource utilization and satisfaction of the end user s QoS requirement. In addition, we describe the implementation model of the ATM virtual path network management system (VP-NMS). Lastly, we show the routing performance evaluated in the High Speed Information Network (HSIN) of Korea Telecom.               Keywords: ATM, ATM VP optimal route provision, hierarchical QoS routing, hierarchical network management, inter-domain network management system               Categories: C.2.0, C.2.3, C.2.4, G.2.2  
8|7||Heyting Algebras and Formal Languages|  Werner Kuich (Vienna University of Technology, Austria)   Norbert Sauer (University of Calgary, Canada)   Friedrich Urbanek (Vienna University of Technology, Austria)  Abstract: By introducing a new operation, the exponentiation of formal languages, we can define Heyting algebras of formal languages. It turns out that some well known families of languages are closed under this exponentiation, e. g., the families of regular and of context-sensitive languages.               Keywords: automata, formal languages, lattices               Categories: F.4.3  
8|8|http://www.jucs.org/jucs_8_8|J.UCS Special Issue on Spatial and Temporal Reasoning|
8|8||An Architecture for a Three-Tier  Path-Finder|  Michael Barley (University of Auckland, New Zealand)   Hans W. Guesgen (University of Auckland, New Zealand)   Gareth Karl   Abstract: This paper describes the architecture of a route finding system that computes an optimal route between two given locations efficiently and that considers user preferences when doing so. The basis of the system is an A* algorithm that applies heuristics such as the air distance heuristic or the Manhattan heuristic to compute the shortest path between the two locations. Since A* is not tractable in general, island search is used to divide the problem into smaller problems, which can be solved more easily. In addition to that, search control rules are introduced to express user preferences about the routes to be considered during the search.               Keywords: A* search, island search, route finding, search control rules               Categories: I.2.8  
8|8||The Design of an Object-based System for Representing and Classifying Spatial Structures and Relations|  Florence Le Ber (LORIA UMR, France)   Amedeo Napoli (LORIA UMR, France)  Abstract: Our work is concerned with the design of a knowledge-based system for recognizing agricultural landscape models on land-use maps. Landscape models are defined as sets of spatial structures and spatial relations. This paper focuses on the representation of topological relations inside an object-based representation system. In this system, relations are represented by objects with their own properties. We propose to define two types of properties: the first ones are concerned with relations as concepts while the second are concerned with relations as links between concepts. In order to represent the second type of properties, we have defined facets that are inspired from the constructors of description logics. We describe these facets and how they are used for classifying spatial structures and relations on land-use maps. The paper ends with a discussion on the present work and related work in qualitative spatial reasoning.               Keywords: Object-based knowledge representation, classification, landscape analysis, relation reification, topological relations               Categories: I.2.1, I.2.4  
8|8||Spatial-reasoning for Agents in Multiple Dimensions|  Debasis Mitra (Department of Computer Sciences, Florida Institute of Technology, USA)   Gérard Ligozat (LIMSI/CNRS, Université de Paris-Sud ORSAY Cedex, France)  Abstract: Suppose a group of mobile agents situated in some Euclidean space does not have any idea on where they are exactly located within that space. However, they do have some notion about their relative positions with respect to each other. This problem may be formulated as a multi-dimensional point-based qualitative reasoning problem with disjunctive constraints. In this article we have developed a set of incremental algorithms for finding feasible positions of a new agent relative to the other existing agents (located in 1D, 2D and the generalized d-D dimensional space for d_=1), given some qualitative spatial constraints between the new one and the other agents. Our approach is a domain-theoretic one, similar to that used in the traditional constraint-based reasoning works (CSP). This approach differs from the algebraic approach - that is traditionally deployed in the spatio-temporal reasoning areas. We have also obtained some tractability results here for the full binary constraint satisfaction problem (rather than the incremental problem, which is polynomial) based on a notion of strong pre-convexity. The article also hints toward many future directions for this work.               Keywords: multi-agent reasoning, multi-dimensional spatial reasoning, qualitative reasoning, reasoning with disjunction               Categories: I.2.4  
8|8||Reasoning with Intervals on Granules|  Sylviane R. Schwer (L.I.P.N. UPRESA CNRS 7030, Université Paris 13, France)  Abstract: The formalizations of periods of time inside a  linear model of Time are usually based on the notion of intervals, that may contain or may not their endpoints. This is not enough when the periods are written in terms of coarse granularities with respect to the event taken into account. For instance, how to express the inter-war period in terms of a years interval? This paper presents a new type of intervals, neither open, nor closed or open-closed and the extension of operations on intervals of this new type, in order to reduce the gap between the discourse related to temporal relationship and its translation into a discretized model of Time.               Keywords: granularity, intervals, time               Categories: G.2.0, I.1.1  
8|8||Scheduling Tasks to a Team of Autonomous Mobile Service Robots in Indoor Enviroments|  Hartmut Surmann (Fraunhofer Institute for Autonomous Intelligent Systems (AIS), Schloss Birlinghoven, Germany)   Antonio Morales (Jaume-I University, Robotic Intelligence Laboratory, Campus Riu Sec, Spain)  Abstract: This paper presents a complete system for  scheduling transportation orders to a fleet of autonomous mobile robots in service environments. It consists of the autonomous mobile robots, a user friendly interface to acquire the orders for the robots via internet and to store them in a database, a general language for modeling multistorey buildings with XML and the scheduling algorithms. The model description of the buildings is used to plan the paths for the robots and to estimate the cost and times for the orders. One challenging key problem - the multi robot cooperation - is solved by the scheduling algorithms and by giving autonomy to the service robots.               Keywords: Job scheduling, NP-hard problems, XML, autonomous mobile service robots, robot teams human machine interface (HMI), telerobotics               Categories: D.4.1, I.2.9  
8|9|http://www.jucs.org/jucs_8_9|Managing Editor's Column|
8|9||Co-operative and Interactive Distance Learning: Application of Team-Oriented and Selective Learning Strategies in a European Bank|  Joachim P. Hasebrook (efiport AG, Germany)  Abstract: Major companies, especially banks, invest in interactive distance learning replacing face-to-face training. Research has shown learning gains are mostly due to a shift in instruction. In this study, a WBT about currency management of a major German bank was examined. The communicational features of the WBT comprise a discussion forum, note taking, and automatic messaging of questions and answers between experts and students. The experimental design compared a face-to-face seminar with WBT learning. The results show that WBT participants learned as much as the seminar participants, but in about 70% of the seminar s study time. Young seminar participants performed better than older ones, while WBT learning did not produce an age effect. The results of the study demonstrate that the learners in the bank tend to choose traditional learning strategies, they do not cope optimally with co-operative and selective learning strategies, and they tend to appreciate audio-visual media. Experts did not voluntarily play an active role in the discussion processes. Communicational features, however, were used quite frequently. The users who were experienced in using a CBT and showed high self esteem gained most from WBT learning.               Keywords: Web based training, computer mediated communication, computer supported learning strategies               Categories: H.5.1, J.4  
8|9||Webs, Grids and Knowledge Spaces: Programmes, Projects and Prospects|  Hans-Georg Stork (European Commission, DG Information Society)  Abstract: Many believe that today s Web has not yet reached the full potential which globally distributed systems may achieve in terms of information access and use. Realizing this potential may indeed turn the Web into a vast knowledge and service space. We discuss some of the issues involved and present a number of activities initiated and supported by the European Commission that are likely to make significant contributions towards attaining this goal.               Keywords: European research funding, grid computing, knowledge technologies, semantic web               Categories: A.m, H.0, H.4, K.4.1  
volume|issue|url|title|abstract
9|1|http://www.jucs.org/jucs_9_1|Managing Editor's Column|
9|1||A  Multiply Hierarchical Automaton Semantics for the IWIM Coordination Model|  Richard Banach (Computer Science Dept., Manchester University, UK)   Farhad Arbab (Software Engineering Dept., CWI, The Netherlands)   George A. Papadopoulos (Computer Science Dept., University of Cyprus, Cyprus)   John R. W. Glauert (School of Information Systems, University of East Anglia, UK)  Abstract: The drawbacks of programming coordination activities directly within the applications software that needs them are briefly reviewed. Coordination programming helps to separate concerns, making complex coordination protocols into standalone entities, permitting separate development, verification, maintenance, and reuse. The IWIM coordination model is described, and a formal automata theoretic version of the model is developed, capturing the essentials of the framework in a fibration based approach. Specifically, families of worker automata have their communication governed by a state of a manager automaton, whose transitions correspond to reconfigurations. To capture the generality of processes in IWIM systems, the construction is generalised so that process automata can display both manager and worker traits. The relationship with other formalisations of the IWIM conception of the coordination principle is explored.               Keywords: IWIM, automata, coordination, fibration               Categories: C.2.4, D.1.3, D.2.6, D.3.3, F.1.1  
9|1||Relativizing Function Classes|  Christian Glaßer (Institut für Informatik, Julius-Maximilians-University Würzburg, Germany)   Gerd Wechsung (Institut für Informatik, Friedrich-Schiller-University Jena, Germany)  Abstract: The operators min?, max?, and #? translate classes of the polynomial-time hierarchy to function classes. Although the inclusion relationships between these function classes have been studied in depth, some questions concerning separations remained open.               Keywords: function classes, oracle separations, polynomial-time hierarchy               Categories: F.1.3  
9|1||Experimental Studies within the Software Engineering Process for Intelligent  Assistance in a GUI|  Maria Virvou (Department of Informatics, University of Piraeus, Greece)   Katerina Kabassi (Department of Informatics, University of Piraeus, Greece)  Abstract: This paper presents the research work towards improving human computer interaction by providing intelligent assistance to users. This has been approached by incorporating principles of a cognitive theory in a Graphical User Interface (GUI), that deals with file manipulation and is called IFM. The cognitive theory is called Human Plausible Reasoning (HPR) and has been used to simulate users'  reasoning in the user model of the system so that the GUI may provide spontaneous assistance to users'  errors. Such a goal is difficult to achieve and depends heavily on the development process. However, there is a shortage of reports on the software engineering process of intelligent assistants. Moreover, in the literature of intelligent assistants there is evidence that some important phases of their development process may have been omitted and thus the understanding of delicate issues has not improved significantly. Therefore, the focus of this paper is on presenting and discussing the software engineering process of the intelligent assistant developed. Special emphasis has been put on the description of the experimental studies, which were conducted prior and after the development of the system. Theses studies were used for the specification and refinement of the overall design as well as the adaptation of HPR in it. The experimental results have shown that the intelligent assistant may follow the users'  reasoning and provide helpful advice to a satisfactory extent as compared to human advisors.               Keywords: experimental studies, intelligent help, intelligent user interface, object-oriented software engineering, user modelling               Categories: D.2.10  
9|10|http://www.jucs.org/jucs_9_10|Managing Editor's Column|
9|10||What is the Value of Taxicab(6)?|  Cristian S. Calude (Department of Computer Science, University of Auckland, New Zealand)   Elena Calude (Institute of Information Sciences, Massey University at Albany, New Zealand)   Michael J. Dinneen (Department of Computer Science, University of Auckland, New Zealand)  Abstract: For almost 350 years it was known that 1729 is the smallest integer which can be expressed as the sum of two positive cubes in two different ways. Motivated by a famous story involving Hardy and Ramanujan, a class of numbers called Taxicab Numbers has been defined: Taxicab(k, j, n) is the smallest number which can be expressed as the sum of j kth powers in n different ways. So, Taxicab(3, 2, 2) = 1729, Taxicab(4, 2, 2) = 635318657. Computing Taxicab Numbers is challenging and interesting, both from mathematical and programming points of view. The exact value of Taxicab(6) = Taxicab(3, 2, 6) is not known, however, recent results announced by Rathbun [R2002] show that Taxicab(6) is in the interval [10 18 , 24153319581254312065344]. In this note we show that with probability greater than 99%, Taxicab(6) = 24153319581254312065344.               Keywords: Hardy-Ramanujan Number, Taxicab Number, sampling               Categories: G.3  
9|10||On Identification in ZZ2 Using Translates of Given Patterns|  Iiro Honkala (Department of Mathematics University of Turku, Finland)   Antoine Lobstein (CNRS and ENST, France)  Abstract: Given a finite set of patterns, i.e., subsets of  . What is the best way to place translates of them in such a way that every point belongs to at least one translate and no two points belong to the same set of translates? We give some general results, and investigate the particular case when there is only a single pattern and that pattern is a square or has size at most four.               Keywords: identifying code, multiprocessor  architecture, square lattice               Categories: E.4  
9|10||An Inoteroperability Testing Approach to Wireless Applications Protocols|  Ousmane Koné (Universite Paul Sabatier ­ IRIT 118 route de Narbonne, France)  Abstract: Internet services can now be used from mobile terminals. The main standard supporting this technology, WAP, will enable new services since it is compatible with network technologies like IP and UMTS. In parallel, powerful methods must be proposed to validate the underlying protocols in order to guaratee reliability and interoperability of new products. Our work, based on formal methods, contributes to WAP testing efforts by proposing an approach to the development of interoperability tests. We illustrate this approach with the design of tests suites for the WSP-protocol operating over a WAP transaction service.               Keywords: WAP protocol, compliance, formal testing, interoperability               Categories: C.2.2, D.2.1, D.2.5  
9|10||Why it is Difficult to Introduce e-Learning into Schools And Some New Solutions|  Jennifer Lennon (Department of Computer Science, University of Auckland, New Zealand)   Hermann Maurer (IICM, Graz University of Technology, Austria)  Abstract: Most informed educators agree that e-Learning should create a paradigm shift away from traditional teaching models, yet in practice this is extremely difficult to achieve. Typically, teachers use computer networks (internet or intranets) mainly for email, dissemination of information that frequently just mirrors traditional book material, assignments, and perhaps a discussion forum. In this paper, we examine reasons why there has been so little departure away from conventional teaching paradigms. We look beyond Virtual Learning Environments to Managed Learning Environments. We look at ways to make this transition a desirable option for both teachers and students. We suggest that when teachers and learners are properly supported within a Managed Learning Environment the workload of teachers is not increased and they enjoy teaching more, also, students learn better (i.e. more efficiently) and with higher motivation.               Keywords: WBT, constructionist learning, e-Learning, managed learning               Categories: K.3, K.4  
9|11|http://www.jucs.org/jucs_9_11|Formal Specifications of Computer-Based Systems - J.UCS Special Issue|
9|11||Monitoring Temporal Logic Specifications Combined with Time Series Constraints|  Doron Drusinsky (Naval Postgraduate School and Time-Rover, Inc., USA)   Man-Tak Shing (Naval Postgraduate School California, USA)  Abstract: Run-time monitoring of temporal properties and assertions is used for testing and as a component of execution-based model checking techniques. Traditional run-time monitoring however, is limited to observing sequences of pure Boolean propositions. This paper describes tools for observing temporal properties over time series, namely, sequences of propositions with constraints on data value changes over time. Using such Temporal Logic with time Series (TLS), it is possible to monitor important properties such as stability, monotonicity, temporal average and sum values, and temporal min/max values. The specification and monitoring of linear time temporal logic with real-time and time series constraints are supported by the Temporal Rover and the DBRover, which are in-process and remote run-time monitoring tools. The novel TLS extension described in this paper is based on practical experience and feedback provided by NASA engineers after using the DBRover to verify flight code. The paper also presents a novel hybrid approach to verify timing properties in rapid system prototyping that combines the traditional schedulability analysis of the design and the monitoring of timing constraint satisfaction during prototype execution based on a time-series temporal logic. The effectiveness of the approach is demonstrated with a prototype of the fish farm control system software.               Keywords: Execution-based Model Checking, Rapid Prototyping, Real-time Systems, Run-time Execution Monitoring, Temporal Logic               Categories: D.2.1, D.2.4, D.2.5, D.2.6, D.3.1, F.3.1  
9|11||Automatically Generated CSP Specifications|  Frantisek Scuglik (Brno University of Technology, Czech Republic)   Miroslav Sveda (Brno University of Technology, Czech Republic)  Abstract: Two possibilities of automated CSP (Communicating Sequential Processes) support are introduced in [11] and [10] using either behavioral diagrams or application source code. While in the first approach a tool generates CSP specification from behavioral diagrams, based on UML Composite States diagram, in the second approach an application source code is translated directly into CSP specification using a compiler. This paper reviews tools related to both techniques.               Keywords: CSP, UML, formal specification, grammar, model, translator               Categories: I.6.4  
9|11||On the Use of Graph Transformation in the Formal Specification of Model Interpreters|  Gabor Karsai (Institute for Software Integrated, Systems ISIS Vanderbilt University, USA)   Aditya Agrawal (Institute for Software Integrated, Systems ISIS Vanderbilt University, USA)   Feng Shi (Institute for Software Integrated, Systems ISIS Vanderbilt University, USA)   Jonathan Sprinkle (Institute for Software Integrated, Systems ISIS Vanderbilt University, USA)  Abstract: Model-based development necessitates the transformation of models between different stages and tools of the design process. These transformations must be precisely, preferably formally, specified, such that end-to-end semantic interoperability is maintained. The paper introduces a graph-transformation-based technique for specifying these model transformations, gives a formal definition for the semantics of the transformation language, describes an implementation of the language, and illustrates its use through an example.               Keywords: domain-specific modeling languages, formal specifications, graph grammars, graph transformations, model-driven architecture, model-integrated computing               Categories: D.2.2  
9|11||Defining a Formal Coalgebraic Semantics for The Rosetta Specification Language|  Cindy Kong (Department of Electrical Engineering and Computer Science, Information and Telecommunication Technology Center, The University of Kansas, USA)   Perry Alexander (Department of Electrical Engineering and Computer Science, Information and Telecommunication Technology Center, The University of Kansas, USA)   Catherine Menon (Department of Computer Science, The University of Adelaide, Australia)  Abstract: Rosetta is a systems level design language that allows algebraic specification of systems through facets. The usual approach to formally describe a specification is to define an algebra that satisfies the specification. Although it is possible to formally describe Rosetta facets with the use of algebras, we choose to use the dual of algebra, i.e. coalgebra, to do so. Coalgebras are particularly suited for describing state-based systems. This makes formally defining state-based Rosetta quite straightforward. For non-state-based Rosetta, the formalization is not as direct, but can still be done with coalgebras by focusing on the behaviors of systems specified. We use denotational semantics to map Rosetta syntactic constructs into a language understood by the coalgebras.               Keywords: algebraic specification, coalgebra, denotational semantics, formal semantics, state-based, system behavior, system level design language               Categories: F.1.1, F.3.2, F.4.3  
9|11||An Information Flow Method to Detect Denial of Service Vulnerabilities|  Stéphane Lafrance (École Polytechnique de Montréal, Canada)   John Mullins (École Polytechnique de Montréal, Canada)  Abstract: Meadows recently proposed a formal cost-based framework for the analysis of denial of service, showing how to formalize some existing principles used to make cryptographic protocols more resistant to denial of service by comparing the cost to the defender against the cost to the attacker. The firrst contribution of this paper is to introduce a new security property called impassivity designed to capture the abiity of a protocol to achieve these goals in the framework of a generic value-passing process algebra called Security Process Algebra (SPPA) extended with local function calls, cryptographic primitives and special semantic features in order to handle cryptographic protocols. Impassivity is defined as an information flow property founded on bisimulation-based non-deterministic admissible interference. A sound and complete proof method for impassivity is provided. The method extends previous results of the authors on bisimulation-based non-deterministic admissible interference and its application to the analysis of cryptographic protocols. It is illustrated by its application to the TCP/IP protocol. Key Words: Denial of service, Protocols, Ad               Keywords: admissible interference, bisimulation, denial of service, equivalence-checking, protocols               Categories: C.2.2, C.2.4  
9|12|http://www.jucs.org/jucs_9_12|Skills Management - Managing Competencies in the Knowledge-based Economy - J.UCS Special Issue|
9|12||Transparency and Transfer of Individual  Competencies - A Concept of Integrative Competence Management|  Kai Reinhardt (Fraunhofer Institute for Factory Operation and Automation IFF Magdeburg, Germany)   Klaus North (University of Applied Science Wiesbaden, Germany)  Abstract: The present state of research on competence management does not provide any suitable model that can be used in practice. Neither results from organizational nor from cognitive and social sciences meet the requirements for an application-oriented competence management completely as yet. An integrative competence management must be able to synchronise individual with organisational competencies. This linking is still neglected in research. A convenient solution has not been described yet. This article presents a model for an integrated competence management model, which gives approaches from both cognitive science and organizational science a practical framework of action.               Keywords: competence based view, competence management, competence profiling, competence transfer, knowledge management, resource based view, skill management               Categories: A.1, H.1, H.1.1, H.3, H.3.1, H.3.3, H.4, H.4.1, I.2.4, I.2.6, K.4.3, K.6.1  
9|12||Skill and Competence Management as a Base of an  Integrated Personnel Development (IPD) - A Pilot Project in the  Putzmeister, Inc./Germany|"  Simon Beck (University of Hohenheim, Germany)  Abstract: The knowledge and the competence of the firm members are substantial success factors in the world-wide competition. For a ""Hidden Champion"" like the middle-sized manufacturer of Top-Class Concrete Pumps and Plastering Machines, Putzmeister, Inc./Germany, a systematic and anticipating Competence Development System is essential. The article describes a pilot project started in spring 2002 to gain more specific knowledge about the implementation of a strategic computer aided, employee orientated Skill Management System in the Company. The main success factors found are first, an acceptance strategy, which includes the participation of motivated groups of pilots, the integration of the workers council, the support of the management as well as much information and transparency about the objectives and the purpose of the system. Especially a good co-operation with the workers council is from great importance. Finally enough personnel and organizational resources must be given to the project.               Keywords: competence management, knowledge management system, personnel development, pilot project, skill management, skill management system               Categories: A.m  "
9|12||Sharing Knowledge on Knowledge - The eXact Peripheral Expertise Awareness System|  Markus Won (Institute for Computer Science III, University of Bonn, Germany)   Volkmar Pipek (Institute for Socio-Informatics (IISI), Germany)  Abstract: This paper presents an innovative approach to solve the problem of missing transparency over competencies within virtual organizations. We based our work on empirical studies on the problem to cope with the problem of competence finding in such distributed organizations. Former studies have shown that central storage of profiles is inappropriate due to missing flexibility and high costs of maintenance. The focus of our approach presented here is to support the peripheral awareness of competence-indicating events. Those events can be collected, stored and interpreted by the system without further work of the users. This idea is based on existing works on the awareness in computer-supported cooperative work scenarios.               Keywords: awareness, expertise, groupware, knowledge management               Categories: H.5.3  
9|12||A Practical Knowledge-based Approach to Skill Management and Personal Development|  Wolfgang Hiermann (BEKO, Austria)   Max Höfferer (BEKO, Austria)  Abstract: BEKO-SMS is a knowledge-based skill management system that combines project planning and human resource management. Application and system functions model specific skills and relationships used in a particular project. The definition of skills, skill trees, skill updating and other processes form the basis for the success factors of the SMS. We conclude that efficient project resource planning would not be possible without SMS and the skill manager.               Keywords: human resource planning, project planning, skill database, skill management, skill updating, skills               Categories: J.1, K.6.1  
9|12||Organisational Memory Information Systems An example of a Group Memory System for the Management of Group Competencies|  José Braga de Vasconcelos (University Fernando Pessoa, Faculty of Science and Technology, Portugal)   Chris Kimble (University of York, Department of Computer Science, UK)   Álvaro Rocha (University Fernando Pessoa, Faculty of Science and Technology, Portugal)  Abstract: As people transform data, information and experiences into shared corporate knowledge, the management of individual competencies has become increasingly important to knowledge intensive organisations (KIO). Knowledge gained during the normal execution of daily tasks is easily lost in the new and more dynamic business environment. The ability to find versatile employees and to be able to leverage their knowledge to meet differing corporate needs, is a matter of pivotal importance for KIOs. Employees  competencies, in the form of their technical and cognitive capabilities, are closely related to the ability of a company to exploit existing, and to create new, knowledge.               Keywords: competence management, group memory, knowledge management, knowledge-intensive organisations, ontologies, organisational memory               Categories: H.1  
9|12||Applying Competence Prerequisite Structures for eLearning and Skill Management|  Cord Hockemeyer (University of Graz, Austria)   Owen Conlan (Trinity College Dublin, Ireland)   Vincent Wade (Trinity College Dublin, Ireland)   Dietrich Albert (University of Graz, Austria)  Abstract: Several approaches for formalising prerequisite structures on skills or competencies based on the psychological theory of knowledge space have been suggested and applied for adaptive eLearning. In this paper, we will discuss how these structures may be applied in skill management in a broader sense. After introducing some formal structures for prerequisite relationships between competencies, we will briefly present an example of an adaptive eLearning system based on this approach (APeLS). Several other aspects of the system which promise to be useful for advanced skill management are discussed. In the final part of this paper, we will discuss such broader applications of the model with respect to personal as well as to organisational skill management.               Keywords: eLearning, personalised hypermedia, skill management               Categories: H.5.4, J.4, K.4.3  
9|12||A Formal Approach to Ontology-Based Semantic Match of Skills Descriptions|  Simona Colucci (Politecnico di Bari, Italy)   Tommaso Di Noia (Politecnico di Bari, Italy)   Eugenio Di Sciascio (Politecnico di Bari, Italy)   Francesco M. Donini (Universita della Tuscia, Italy)   Marina Mongiello (Politecnico di Bari, Italy)   Marco Mottola (Accenture, Italy)  Abstract: Skills management has been recently acknowledged as one of the key factors to adequately face the increasing competitiveness between knowledge intensive companies.                Keywords: knowledge representation, matchmaking, ontologies, skill management               Categories: I.2.4, K.6.1  
9|12||Skill Assessment in Problem Solving and Simulated Learning Environments|  Luca Stefanutti (Department of Psychology, University of Graz, Austria)   Dietrich Albert (Department of Psychology, University of Graz, Austria)  Abstract: Simulated learning environments provide an efficient means for improving individual skills in specific problem solving and learning situations. One crucial aspect of an optimal system for simulated training environments is its capability to keep track of the improvements of the user along the whole training process. In this paper we present a set-theoretical formal framework that can be applied for the efficient assessment of the skills of an individual in a simulated learning environment. The basic concept underlying our approach is that of a functional skill mapping of the simulated learning environment through problem spaces.               Keywords: knowledge structure, problem solving, simulated learning environment, skill assessment               Categories: J.4  
9|12||Individual Knowledge as a Bridge between Human and Customer Capital|  Juan G. Cegarra-Navarro (University Polytechnic of Cartagena, Spain)   Beatriz Rodrigo-Moya (University National Education of Distance, Spain)  Abstract: This paper will study the influence of three components of human capital focusing on operative personnel under a dynamic perspective. It considers learning flows and the knowledge stocks that the employees of the organization generate because of the relationships that they maintain with their clients. The influence of individual knowledge in these learning flows will be examined. These being components such as: learning capacities, automatic and conscious knowledge, on the flows of the relational learning process including transfer, transformation and harvesting phases of knowledge. In order to study the relative importance of the individual knowledge components in each phase of the relational process, the scale established by [Kohli and Jaworski 1990] will be used in this research. The paper is structured in four parts. In the first, a theoretical reference on individual knowledge on the relational learning process will be established. In the second part, some hypothesis and the necessary methodology will be proposed. In the third part the results will be shown and finally, in the conclusions some interesting aspects on the role of individual knowledge in the process described will be shown. Conclusions are based on a study of eighty-four organizations. This investigation establishes important conclusions on the role of individual knowledge in the generation of the customer capital. Concretely, the explicit knowledge of the employees is the most meaningful in the relational learning process, although it is also true that the tacit knowledge and individual learning capacities have a special importance in the harvesting phase of knowledge.               Keywords: customer capital, explicit and collective, individual knowledge, integration, interpretation, intuition processes               Categories: J.4, J.5  
9|12||A Tool Kit for Measurement of Organisational Learning: Methodological Requirements and an Illustrative Example|  Anna Mette Fuglseth (The Norwegian School of Economics and Business Administration, Norway)   Kjell Groenhaug (The Norwegian School of Economics and Business Administration, Norway)  Abstract: Few studies attempt to measure organisational learning. Measurement is critical to evaluate relationships between initiatives to support learning and organisational performance. This paper proposes a theory-based tool kit for measurement of organisational learning. By tool kit we mean a collection of methods that each captures elements of the phenomenon  organisational learning . The paper clarifies the term and discusses requirements of theories and methods to be included in the tool kit. Some examples of theories with methods are given. Emphasis is placed on Kelly s Personal Construct Theory with the accompanying Role Construct Repertory Test to illustrate methodological requirements.               Keywords: measurement, organisational learning, personal construct theory, role construct repertory test               Categories: A.m, J.4  
9|12||Identifying Employee Competencies in Dynamic Work Domains: Methodological Considerations and a Case Study|  Tobias Ley (Know-Center Graz, Austria)   Dietrich Albert (University of Graz, Austria)  Abstract: We present a formalisation for employee competencies which is based on a psychological framework separating the overt behavioural level from the underlying competence level. On the competence level, employees draw on action potentials (knowledge, skills and abilities) which in a given situation produce performance outcomes on the behavioural level. Our conception is based on the competence performance approach by [Korossy 1997] and [Korossy 1999] which uses mathematical structures to establish prerequisite relations on the competence and the performance level. From this framework, a methodology for assessing competencies in dynamic work domains is developed which utilises documents employees have created to assess the competencies they have been acquiring. By means of a case study, we show how the methodology and the resulting structures can be validated in an organisational setting. From the resulting structures, employee competency profiles can be derived and development planning can be supported. The structures also provide the means for making inferences within the competency assessment process which in turn facilitates continuous updating of competency profiles and maintenance of the structures.               Keywords: case study, competence-performance approach, competency management, human resource development, knowledge space theory, repertory grid technique, skills management               Categories: H.3.1, H.3.2, H.3.3, H.3.7, H.5.1  
9|12||Bad Management and its Consequences in a  Problematic European Union Member|  Eduardo Tomé (High Institute for Social Service, Portugal)  Abstract: This paper analyses the Portuguese current economic situation, and points out to the decisive importance of management decisions, in order to explain the present state of affairs and to win over the massive challenges that lie ahead. The main conclusion is that, investments in training, education and skills can help Portugal to achieve success in trade. Evidence of that was obtained applying three simple economic models to statistical data on around 30 exporter economic sectors, related to the years from 1989 to 2001 (see section 4). That basic idea will be completed with three others that reinforce it: (1) the Portuguese future economic evolution will depend heavily on its external record (see section 3), (2) bad management caused Portugal to have traditionally low levels of education, skills and training (see section 3), (3) a new skills management attitude will be needed focusing in the importance of education, skills and training as real success factors (see section 5). The findings presented are somewhat preliminary, and may be extended and deepened by further and more detailed research (see section 7).               Keywords: Portugal, education, exports, skills management, training               Categories: K.4  
9|2|http://www.jucs.org/jucs_9_2|J.UCS Special Issue on Tools for System Design and Verification|
9|2||Moby/RT: A Tool for Specification and Verification of Real-Time Systems|  Ernst-Rüdiger Olderog (Department of Computing Science University of Oldenburg, Germany)   Henning Dierks (Department of Computing Science University of Oldenburg, Germany)  Abstract: The tool Moby/RT supports the design of realtime systems at the levels of requirements, design specifications and programs. Requirements are expressed by constraint diagrams [Kleuker, 2000], design specifications by PLC-Automata [Dierks, 2000], and programs by Structured Text, a programming language dedicated for programmable logic controllers (PLCs), or by programs for LEGO Mindstorm robots. In this paper we outline the theoretical background of Moby/RT by discussing its semantic basis and its use for automatic verification by utilising the model-checker UPPAAL [Larsen et al., 1997].               Keywords: Constraint Diagrams, PLC-Automata, formal verification, real-time, requirements  capture, specification               Categories: D.2.1, D.2.2, D.2.4, D.4.7, F.3.1, F.4.1  
9|2||Checking Object System Designs Incrementally|  Hans-Dieter Ehrich (Technical University Braunschweig, Germany)   Maik Kollmann (Technical University Braunschweig, Germany)   Ralf Pinger (SIEMENS AG Transportation Systems, Germany)  Abstract: We present a method for checking global conditions for object systems in a way that avoids state space explosion. The objects referred to in a global condition are checked step by step against local conditions and communication requirements derived from the global condition. The derivation is automatic, based on information about the system structure contained in the global condition. The approach is demonstrated using model checking, but the idea works for other approaches to verification or testing as well. In our current investigation, a multi-object variant of CTL is used for expressing global conditions. The local conditions and communication requirements can be verified independently using standard model checkers. The method is illustrated by a large example (about 10 24 states) where our method shows a spectacular speedup over global model checking.               Keywords: model checking, modelling and design, multi-object logic, object system, temporal logic, verification               Categories: F.3.1, I.6.4  
9|2||Optimized Temporal Logic Compilation|  Andreas Krebs (University of Tübingen, Germany)   Jürgen Ruf (University of Tübingen, Germany)  Abstract: Verification and validation are the major tasks during the design of digital hardware/software systems. Often more than 70% of the development time is spent for locating and correcting errors in the design. Therefore, many techniques have been developed to support the debugging process. Recently, simulation and test methods have been accompanied by formal methods such as equivalence checking and property checking. However, their industrial applicability is currently restricted to small or medium sized designs or to a specific phase in the design process. Therefore, simulation is still the most commonly applied verification technique.               Keywords: emulation, simulation, system-Level, temporal logic, verification               Categories: B.8.1, I.6.6  
9|2||A Case Study in Verification of UML  Statecharts: the PROFIsafe Protocol|  Robi Malik (Department of Computer Science, University of Waikato Hamilton,, New Zealand)   Reinhard Mühlfeld (Siemens Corporate Technology, Germany)  Abstract: We discuss our experience obtained during the PROFIsafe verification and test case generation project at Siemens Corporate Technology. In this project, a formal analysis of the PROFIsafe protocol for failsafe communication has been carried out. A formal model based on denite-state machines has been obtained from the UML specification of the protocol. This model has been analysed with formal verification techniques, and several important properties have been proven. Based on the verified model, a set of test cases for the automatic execution of conformance tests has been derived. The paper explains how the UML statecharts defining the PROFIsafe protocol are translated into denite-state machines, and points out important aspects and problems occurring during the modelling and verification of industrial applications.               Keywords: reliability, verification               Categories: C.2.2, D.2.2, D.2.4  
9|2||HOL-Z 2.0: A Proof Environment for Z-Specifications|  Achim D. Brucker (Albert-Ludwigs-University Freiburg, Germany)   Frank Rittinger (Albert-Ludwigs-University Freiburg, Germany)   Burkhart Wolff (Albert-Ludwigs-University Freiburg, Germany)  Abstract: We present a new proof environment for the specification language Z. The basis is a semantic representation of Z in a structure-preserving, shallow embedding in Isabelle/HOL. On top of the embedding, new proof support for the Z schema calculus and for proof structuring are developed. Thus, we integrate Z into a well-known and trusted theorem prover with advanced deduction technology such as higher-order rewriting, tableaux-based provers and arithmetic decision procedures. A further achievement of this work is the integration of our embedding into a new tool-chain providing a Z-oriented type checker, documentation facilities and macro support for refinement proofs, as a result, the gap has been closed between a logical embedding proven correct and a tool suited for applications of nontrivial size.               Keywords: Z, refinement, theorem proving               Categories: D.2.1, D.2.4, F.3.1, F.4.1  
9|2||Tool Support for the Interactive Derivation of Formally Correct Functional Programs|  Walter Guttmann (University of Ulm, Germany)   Helmuth Partsch (University of Ulm, Germany)   Wolfram Schulte (Microsoft Research, USA)   Ton Vullinghs (University of Ulm, Germany)  Abstract: This paper describes the program transformation system Ultra. The intended use of Ultra is to assist programmers in the formal derivation of correct and efficient programs from high-level descriptive or operational specifications. We illustrate its utility by deriving a version of the Heapsort algorithm from a non-deterministic specification.              Keywords: Ultra, constructive program development, equational reasoning, functional programming, heapsort, non-deterministic specification, program transformation, unfold-fold               Categories: D.1.1, D.2.2, F.3.1, I.2.2  
9|3|http://www.jucs.org/jucs_9_3|J.UCS Special Issue on Compiler Optimization meets Compiler Verification (COCV 2002)|
9|3||Using Program Checking to Ensure the Correctness of Compiler Implementations|  Sabine Glesner (Institute for Program Structures and Data Organization University of Karlsruhe, Germany)  Abstract: We evaluate the use of program checking to ensure the correctness of compiler implementations. Our contributions in this paper are threefold: Firstly, we extend the classical notion of black-box program checking to program checking with certificates. Our checking approach with certificates relies on the observation that the correctness of solutions of NP-complete problems can be checked in polynomial time whereas their computation itself is believed to be much harder. Our second contribution is the application of program checking with certificates to optimizing compiler backends, in particular code generators, thus answering the open question of how program checking for such compiler backends can be achieved. In particular, we state a checking algorithm for code generation based on bottom-up rewrite systems from static single assignment representations. We have implemented this algorithm in a checker for a code generator used in an industrial project. Our last contribution in this paper is an integrated view on all compiler passes, in particular a comparison between frontend and backend phases, with respect to the applicable methods of program checking.               Keywords: certificates, code generation, compiler, compiler architecture, compiler generators, implementation correctness, program checking               Categories: D.2.4, D.3.4, F.3.1, F.4.2  
9|3||VOC: A Methodology for the Translation Validation of OptimizingCompilers|  Lenore Zuck (New York University, United States)   Amir Pnueli (Weizmann Institute of Science, Israel and New York University, USA)   Yi Fang (New York University, USA)   Benjamin Goldberg (New York University, USA)  Abstract: There is a growing awareness, both in industry and academia, of the crucial role of formally verifying the translation from high-level source-code into low-level object code that is typically performed by an optimizing compiler. Formally verifying an optimizing compiler, as one would verify any other large program, is not feasible due to its size, ongoing evolution and modification, and, possibly, proprietary considerations. Translation validation is a novel approach that offers an alternative to the verification of translators in general and compilers in particular: Rather than verifying the compiler itself, one constructs a validation tool which, after every run of the compiler, formally confirms that the target code produced in the run is a correct translation of the source program. The paper presents voc, a methodology for the translation validation of optimizing compilers. We distinguish between structure preserving optimizations, for which we establish a simulation relation between the source and target code based on computational induction, and structure modifying optimizations, for which we develop specialized permutation rules. The paper also describes voc-64 - a prototype translation validator tool that automatically produces verification conditions for the global optimizations of the SGI Pro-64 compiler.               Keywords: SGI Pro-64, global optimizations, optimizing compilers, permutation rules, translation validation, verification conditions, voc-64               Categories: D.2.4, D.3.4, I.6.4  
9|3||An Automatic Verification Technique for Loop and Data Reuse Transformations based on Geometric Modeling of Programs|  K. C. Shashidhar (DESICS Division, IMEC vzw, Kapeldreef 75, B-3001 Heverlee, and Department of Computer Science, Katholieke Universiteit Leuven, Belgium)   Maurice Bruynooghe (Department of Computer Science, Katholieke Universiteit Leuven, Belgium)   Francky Catthoor (DESICS Division, IMEC vzw, Kapeldreef 75, B-3001 Heverlee, and Department of Computer Science, Katholieke Universiteit Leuven, Belgium)   Gerda Janssens (Department of Computer Science, Katholieke Universiteit Leuven, Belgium)  Abstract: Optimizing programs by applying source-to-source transformations is a prevalent practice among programmers. Particularly so, while programming for high-performance and cost-effective embedded systems, where the initial program is subject to a series of transformations to optimize computation and communication. In the context of parallelization and custom memory design, such transformations are applied on the loop structures and index expressions of array variables in the program, more often manually than with a tool, leading to the non-trivial problem of checking their correctness. Applied transformations are semantics preserving if the transformed program is functionally equivalent to the initial program from the input-output point of view. In this work we present an automatic technique based on geometric modeling to formally check the functional equivalence of initial and transformed programs under loop and data reuse transformations. The verification is transformation oblivious needing no information either about the particular transformations that have been applied or the order in which they have been applied. Our technique also provides useful diagnostics to locate the detected errors.               Keywords: geometric modeling, program equivalence, program transformations, restructuring compilers, transformation verification                
9|3||Alias Verification for Fortran Code Optimization|  Thi Viet Nga Nguyen (Ecole des Mines de Paris, France)   Francois Irigoin (Ecole des Mines de Paris, France)  Abstract: Alias analysis for Fortran is less complicated than for programming languages with pointers but many real Fortran programs violate the standard: a formal parameter or a common variable that is aliased with another formal parameter is modified. Compilers, assuming standard-conforming programs, consider that an assignment to one variable will not change the value of any other variable, allowing optimizations involving the aliased variables. Higher performance results but anything may happen: the program may appear to run normally, or produce incorrect answers, or behave unpredictably. The results may depend on the compiler and the optimization level.               Keywords: alias, dummy aliasing, optimization, verification               Categories: D.2.4, D.2.5, D.3.4  
9|4|http://www.jucs.org/jucs_9_4|J. UCS Special Issue on Dynamic Symbolic Languages|
9|4||The Future of PCs and Implications on  Society|  Hermann Maurer (Graz University of Technology, Austria)   Ron Oliver (Edith Cowan University, Australia)  Abstract: In this paper we argue that in about ten years time PCs as we now know them, will no longer exist. Their functionality will be totally integrated into mobile telephony devices, or putting it differently, in ten years time mobile phones will incorporate all functions one would expect from a powerful PC. These new devices, let us call them eAssistants, will be with us all the time and will change our lives enormously. In this paper we take a first look at both the technological and applied aspects of this prediction.               Keywords: display technology, future computers, societal implications, wearable PC               Categories: H.4, J.0, K.4, K.8  
9|4||Foundations of MIRACLE: Multimedia Information Repository, A Computer-supported Language Effort|"  Hermann Maurer (Graz University of Technology, Austria)   Robert Stubenrauch (JOANNEUM RESEARCH, Austria)   Daniela G. Camhy (Graz University, Austria)  Abstract: Research in neurosciences, cognitive psychology and media sciences indicates that ""visual thinking"" carries a potential of the human mind that is generally still neglected today but could heavily be fostered by novel types of communicating and archiving information. Computer technology (information systems, telecommunication and visual tools) in turn promises to provide a wide range of highly effective tools to support visual, dynamic communication. MIRACLE treads new paths to address a crucial issue: In what way and to what extent can and should current and future systems support new ways of communicating and archiving information using dynamic, visual information?               Keywords: computer-supported communication, constructed languages, converging technology, information archiving, information retrieval, language independent communication, multimedia, visual communication, visual languages               Categories: A.1, H.3.7, H.4.3, H.5.1, J.4, J.5  "
9|4||Applications  of MIRACLE: Working With Dynamic Visual Information|  Robert Stubenrauch (JOANNEUM RESEARCH, Austria)   Daniela G. Camhy    Jennifer Lennon (Auckland University, New Zealand)   Hermann Maurer (Graz University of Technology and JOANNEUM RESEARCH, Austria)  Abstract: Systems supporting new forms of communication and archiving of dynamic visual information have a range of potential applications, some of which are described in this paper on a conceptual basis. We present a visual language for dynamic (historic) maps, applications of pictorial lexicons, concepts for interactive support systems for assembly and repair, and a platform for abstract movies.               Keywords: abstract movies, computer-supported communication, dynamic maps, information archiving, information retrieval, interactive maps, multimedia, visual communication, visual languages               Categories: A.1, H.3.7, H.4.3, H.5.1, J.4, J.5  
9|4||A Cross-Disciplinary Bibliography  on Visual Languages for Information Sharing and Archiving|  Daniela G. Camhy (Graz University, Austria)   Robert Stubenrauch (JOANNEUM RESEARCH, Austria)  Abstract: This bibliography offers citations for people who are interested in learning more about visual language, new types of communicating and archiving information with emphases on novel technologies and theoretical works in these multidisciplinary areas. This bibliography is considered in its broadest sense and covers references of research in humanities and social sciences as well as computer technology. Far from being exhaustive, it nevertheless covers essential resources in a selective way, so that the material can provide starting points for many different directions. What is not included here are references to visual programming languages.               Keywords: computer-supported communication, constructed languages, information archiving, information retrieval, interactive maps, language independent communication, sign languages, visual communication, visual languages               Categories: A.2, H.3.7, H.4.3, H.5.1, J.4, J.5  
9|5|http://www.jucs.org/jucs_9_5|Managing Editor's Column|
9|5||Fibonacci Type Coding for the Regular Rectangular Tilings of the Hyperbolic Plane|  Maurice Margenstern (Laboratoire d'Informatique Théorique et Appliquée, Université de Metz, France)   Gencho Skordev (CeVis, University Bremen, Germany)  Abstract: The study of cellular automata (CA) on tilings of hyperbolic plane was initiated in [6]. Appropriate tools were developed which allow us to produce linear algorithms to implement cellular automata on the tiling of the hyperbolic plane with the regular rectangular pentagons, [8, 10]. In this paper we modify and improve these tools, generalise the algorithms and develop them for tilings of the hyperbolic plane with regular rectangular s-gons for s  5. For this purpose a combinatorial structure of these tilings is studied.               Keywords: cellular automata, hyperbolic plane, tiltings               Categories: F.1.1, F.1.3  
9|5||Cyclical Structure Converter (CSC): a System for Handling the Interaction of Structured and Semi-structured Data Sources|"  Jameson Mbale (Department of Computer Science, Harbin Institute of Technology, China)   Domenico Ursino (DIMET, Università ""Mediterranea"" di Reggio Calabria, Italy)   Xu Xiao Fei (Department of Computer Science, Harbin Institute of Technology, China)  Abstract: This paper aims at investigating the integration of structured data into a semi-structured environment. In particular, it introduces the Cyclic Structure Converter (CSC) system that performs this task. In CSC, correspondence assertions and integration rules provide the adequate intelligence to reconcile the (possible) heteroge_ neous semantics relative to involved information sources. CSC has also the capability to filter and process only the relevant operational data. CSC s versatility in maneuvering with di#erent data models allows it to be applied into any field, such as engineering, insurance, medicine, space science and education, to mention a few.               Keywords: cooperative information systems, information source integration, interschema property, semi-structured information sources               Categories: H.2.4, H.3.4  "
9|6|http://www.jucs.org/jucs_9_6|J.UCS Special Issue:I-Know  03 - Hot Spots in Knowledge Management|
9|6||The post-Nonaka Knowledge Management|  Peter Schütt (IBM Deutschland GmbH, Germany)  Abstract: The objective of this paper is to describe a new post-Nonaka generation of Knowledge Management that, for the first time, has the potential to meet people's expectations. It is divided into the three categories:  Keywords: ASHEN, Cynefin, KM factors, SECI, knowledge management optimization factors, knowledge worker, on demand workplace, productivity, scientific management, third generation knowledge management               Categories: A., H.  
9|6||"The Benefits of Knowledge Management - Results of the German Award ""Knowledge Manager 2002"""|  Klaus North (University of Applied Sciences Wiesbaden, Germany)   Tina Hornung (University of Applied Sciences Wiesbaden, Germany)  Abstract: In the paper the applications to the 2002 Knowledge Management Award are discussed in relation to measuring the benefits of KM. It is concluded that benefits of KM initiatives depend on the KM approach taken.               Keywords: balanced scorecard, knowledge management, measurement of benefits               Categories: A., H.  
9|6||Managing Operation Knowledge for the Metal Industry|  Sheng-Tun Li (National Kaohsiung First University of Science Technology, Taiwan)   Huang-Chih Hsieh (National Kaohsiung First University of Science Technology, Taiwan)  Abstract: The development of a knowledge management system (KMS) is becoming increasingly important for the metal industry in Taiwan. The ontology design and knowledge search are two major activities of knowledge management. In this paper, we introduce a three-stage life cycle for the ontology design and propose a Java/XML-based scheme for automatically generating knowledge search components to reduce the overhead in developing a KMS. The resulting ontology is classified as information ontology and domain ontology so that the objective of semantic match for knowledge search can be realized. The system is built on the top of the component-based KAON development suite which makes it more flexible and robust. We conduct a case study by applying the system to Metal Industries Research  [and]  Development Centre (MIRDC), Taiwan to confirm its effectiveness and efficiency in dealing with KM activities. In addition, the proposed reusable scheme endorses the encouraging feasibility of wide applications to different domains.               Keywords: KAON, Knowledge management system, metal industry, ontology               Categories: H.4.m, I.2.4, K.6.1  
9|6||Filters in the Strategy Formulation Process|  Leena Ilmola (Helsinki University of Technology, Finland)   Anna Kotsalo-Mustonen (Fountain Park Ltd., Finland)  Abstract: In the fast moving businesses the ability to be flexible and adaptive to change is crucial. When monitoring their operating environments for weak signals and for other disruptive information companies face filters that hinder the entry of the information to the company. We are discussing three filters: mentality filter, surveillance filter and power filter. Each filter has a logic of its own that hinders effective knowledge flow. We introduce a software tool that helps to overcome these filters especially in a strategy formulation process.               Keywords: filters, strategy process, weak signals               Categories: J.4  
9|6||The Richness of Diversity in Knowledge Creation: An Interdisciplinary Overview|  Matteo Bonifacio (University of Trento, Italy)   Alessandra Molani (University of Trento, Italy)  Abstract: The goal of this article is to explore some of the main reasons that sustain a distributed approach to Knowledge Management, and this will be done, first, showing how, according to very different theoretical disciplines, knowledge diversity is proposed as the very source of organizational innovation and adaptability, second providing some evidence coming from major applicative domains, third proposing some considerations on the role of technology.               Keywords: cognitivism, communites of practice, constructivism, distributed knowledge management, evolutionary theory, semantic heterogeneity, structuration theory, theory of complexity               Categories: A.0, A.1, H.1.0, H.1.1, K.4, K.6  
9|6||SCBS Social Capital Benchmarking System -  Profiting from Social Capital when Building Network Organisations|  Jose Maria Viedma (Polytechnic University of Catalonia, Spain)  Abstract: In knowledge economy, companies and organisations build sustainable competitive advantages not only relying on their internal intellectual capital but also on the intellectual capital of other companies, organisations and institutions and specifically on those of the cluster [Porter, 1990], microcluster or territory where the company is located. This kind of intellectual capital, basically external and of a relational nature is one of the main constituents of the networked organisation and (will be called) from now on Social Capital [Nahapiet and Ghoshal, 1998] because it is embedded in the social fabric (texture) of the nearby environment.               Keywords: benchmarking, clusters, intellectual capital, knowledge management, resources and capabilities, social capital               Categories: H.  
9|6||Unified Access to Heterogeneous Audiovisual Archives|  Y. Avrithis (National Technical University of Athens (NTUA), Greece)   G. Stamou (National Technical University of Athens (NTUA), Greece)   M. Wallace (National Technical University of Athens (NTUA), Greece)   F. Marques (Technical University of Catalonia (UPC), Spain)   Philippe Salembier (Technical University of Catalonia (UPC), Spain)   X. Giro (Technical University of Catalonia (UPC), Spain)   Werner Haas (Joanneum Research, Austria)   Heribert Vallant (Joanneum Research, Austria)   Michael Zufferey (Joanneum Research, Austria)  Abstract: In this paper, an integrated information system is presented that offers enhanced search and retrieval capabilities to users of heterogeneous digital audiovisual (a/v) archives. This innovative system exploits the advances in handlings a/v content and related metadata, as introduced by MPEG-4 and worked out by MPEG-7, to offer advanced services characterized by the tri-fold semantic phrasing of the request (query), unified handling and personalized response. The proposed system is targeting the intelligent extraction of semantic information from a/v and text related data taking into account the nature of the queries that users my issue, and the context determined by user profiles. It also provides a personalization process of the response in order to provide end_users with desired information. From a technical point of view, the FAETHON system plays the role of an intermediate access server residing between the end users and multiple heterogeneous audiovisual archives organized according to the new MPEG standards.               Keywords: FAETHON, MPEG-4, MPEG-7, audiovisual archive, personalization, search engine, semantic query, thesaurus, user profile               Categories: H.2.5, H.3.1, H.3.3, H.5.1  
9|6||Pruning-based Identification of Domain Ontologies|  Raphael Volz (FZI Research Center for Information, Technologies Karlsruhe, Germany)   Rudi Studer (FZI Research Center for Information, Technologies Karlsruhe, Germany)   Alexander Maedche (FZI Research Center for Information, Technologies Karlsruhe, Germany)   Boris Lauser (Library + Documentation Systems Division, FAO of the UN, Italy)  Abstract: We present a novel approach of extracting a domain ontology from large-scale thesauri. Concepts are identified to be relevant for a domain based on their frequent occurrence in domain texts. The approach allows to bootstrap the ontology engineering process from given legacy thesauri and identifies an initial domain ontology that may easily be refined by experts in a later stage. We present a thorough evaluation of the results obtained in building a biosecurity ontology for the UN FAO AOS project.               Keywords: knowledge management, ontologies, pruning, structural computing               Categories: H.3.7, H.5.4  
9|6||Automatic Discovery and Aggregation of Compound Names for the Use in Knowledge Representations|  Christian Biemann (University of Leipzig, Germany)   Uwe Quasthoff (University of Leipzig, Germany)   Karsten Böhm (University of Leipzig, Germany)   Christian Wolff (Chemnitz University of Technology, Germany)  Abstract: Automatic acquisition of information structures like Topic Maps or semantic networks from large document collections is an important issue in knowledge management. An inherent problem with automatic approaches is the treatment of multiword terms as single semantic entities. Taking company names as an example, we present a method for learning multiword terms from large text corpora exploiting their internal structure. Through the iteration of a search step and a verification step the single words typically forming company names are learnt. These name elements are used for recognizing compounds in order to use them for further processing. We give some evaluation of experiments on company name extraction and discuss some applications.               Keywords: corpora, knowledge management, named entity extraction, semantic relations, text mining, topic maps               Categories: H.3.3, H.5.3, I.2.6, I.2.7, I.7  
9|6||Process-oriented Knowledge Structuring|  Kai Mertins (Fraunhofer IPK Berlin, Germany)   Peter Heisig (Fraunhofer IPK Berlin, Germany)   Kay Alwert (Fraunhofer IPK Berlin, Germany)  Abstract: Within a business environment, where the fast and reliable access to knowledge is a key success factor, an efficient handling of the organizational knowledge is crucial. Therefore the need for methods and techniques, which allow to structure and maintain complex knowledge bases according to the requirements emerging from the daily work have a high priority. This article provides a business process oriented approach to structure organizational knowledge and information bases. The approach was developed within applied research in the industrial, service and administrative sector. Following this approach, three different types of knowledge structures and their visualization have been developed by the Fraunhofer IPK and are currently applied and tested in organizations. Beside the approach itself, these three types of knowledge structure and the cases of application shall be introduced here.               Keywords: browsing, business process, key word based search, knowledge base, knowledge bearer, knowledge carrier, knowledge domain, knowledge management, knowledge map, knowledge navigator, knowledge structure, post-structuring, pre-structuring, process assistant, process context, process modeling tool, topic map engine, visualization               Categories: D.2, D.4.1, E.1, H.1, H.3.1, H.5, K.6  
9|6||Towards the Semantic Grid: Putting Knowledge to Work in Design Optimisation|  Feng Tao (Department of Electronics and Computer Science, University of Southampton, UK)   Liming Chen (Department of Electronics and Computer Science, University of Southampton, UK)   Nigel Shadbolt (Department of Electronics and Computer Science, University of Southampton, UK)   Graeme Pound (School of Engineering Sciences, University of Southampton, UK)   Simon Cox (School of Engineering Sciences, University of Southampton, UK)  Abstract: Modern computational Problem Solving Environments (PSEs) become more and more complex and knowledge intensive in terms of their integrated toolsets, in particular for engineering design search and optimization. Whether these toolsets can be assembled effectively to produce satisfactory results depends heavily on using the best domain practice and following decisions made by skilled engineers in practical situations. In this paper, a knowledge based approach is used to acquire this knowledge from existing sources and model it in a maintainable fashion. Ontologies are used to develop the conceptualization of a knowledge base. In order to reuse this knowledge to provide guidance at knowledge intensive points, we propose a knowledge based advisor, which can give a context-aware critique to guide users through effective operations of building domain workflows. The concept of a state panel is proposed to collect system state information, which is then reasoned about together with various task models in the JESS (Java Expert System Shell) environment. Two reasoning strategies are designed for different advising styles. A multilayer and client-server style architecture is proposed to illustrate how this advisor can be deployed to make available its knowledge advising service to a real workflow construction PSE in a maintainable fashion. Throughout we use the example of these knowledge services in the context of design optimization in engineering.               Keywords: JESS, XML, knowledge base, knowledge engineering, ontology, production rules, workflow planning               Categories: I.2.5  
9|6||Knowledge Management for Computational Problem Solving|  D. T. Lee (Institute of Information Science, Academia Sinica, Taiwan)   G. C. Lee (Institute of Information Science, Academia Sinica, Taiwan)   Y. W. Huang (Institute of Information Science, Academia Sinica, Taiwan)  Abstract: Algorithmic research is an established knowledge engineering process that has allowed researchers to identify new or significant problems, to better understand existing approaches and experimental results, and to obtain new, effective and efficient solutions. While algorithmic researchers regularly contribute to this knowledge base by proposing new problems and novel solutions, the processes currently used to share this knowledge are inefficient, resulting in unproductive overhead. Most of these publication-centred processes lack explicit high-level knowledge structures to support efficient knowledge management. The authors describe a problem-centred collaborative knowledge management architecture associated with Computational Problem Solving (CPS). Specifically we articulate the structure and flow of such knowledge by making in-depth analysis of the needs of algorithmic researchers, and then extract the ontology. We also propose a knowledge flow measurement methodology to provide human-centred evaluations of research activities within the knowledge structure. This measurement enables us to highlight active research topics and to identify influential researchers. The collaborative knowledge management architecture was realized by implementing an Open Computational Problem Solving (OpenCPS) Knowledge Portal, which is an open-source project accessible at http://www.opencps.org.               Keywords: algorithmic research, collaborative knowledge management architecture, knowledge flow measurement, knowledge management, openCPS, problem-centred               Categories: H.1, H.3, H.4  
9|6||Converging Knowledge Management, Training and e-learning: Scenarios to Make it Work|  Lilia Efimova (Telematica Instituut, The Netherlands)   Janine Swaak (Telematica Instituut, The Netherlands)  Abstract: Companies are starting to recognise synergies between knowledge management, training and e-learning programs, but a closer look reveals that these integration ideas are rarely implemented in practice. The goal of this paper is to provide a starting point for collaboration between corporate KM and HR/learning teams by mapping existing practices of linking KM, training and e-learning efforts. We provide an overview of experiences and future ideas of collaboration derived from several studies, group them in three themes and then illustrate each theme with a scenario. The first theme gives examples of using HR and training instruments to support knowledge management. The second theme represents cases of using KM methods (namely a community of practice) to support HR learning management efforts. The last theme describes how KM and HR/learning teams could work on joint initiatives. Then we discuss the added value of the scenarios and propose further practical steps and research directions.               Keywords: e-learning, knowledge management, scenarios, training               Categories: A.1, H.4, J.4, K.3, K.6  
9|7|http://www.jucs.org/jucs_9_7|Professional Knowledge Management - Experiences and Visions - J.UCS Special Issue|
9|7||The Strong Effects of the Soft Factors of Knowledge Management|  Tomas Bohinc (T-Systems International, Germany)   Strausie Markham (T-Systems International, Germany)  Abstract: Knowledge culture is one aspect in corporate culture. It describes, how knowledge is identified, acquired, developed, distributed, used and retained. There are tree levels with which the culture can be described: basic underlying assumptions, norms and values, artifacts. Based on this description it is possible to analyse the current culture and define measures to change it towards a more knowledge oriented culture. A survey on the wm03 had shown, that in most organization still exist an overlap or an ambivalence which is characterized by non-knowledge-oriented culture elements. For the change of culture the tools that are developed for cultural change must be adapted for the specific needs of knowledge cultural change.               Keywords: corporate culture, knowledge management, leadership               Categories: A., H.  
9|7||A Note on Culture-sensitive Knowledge Management  in OE-sales Area of Robert Bosch GmbH|  Marc Kuhn (Robert Bosch GmbH, Germany)  Abstract: A knowledge oriented culture is often considered as a basic infrastructure for successful Knowledge Management. Decentralized knowledge activities at Bosch follow the given company culture and do not try to affect cultural aspects at short notice. The internal analysis of knowledge culture bases on a Bosch-specific three-level model. This model is used for research activities on Bosch internal  knowledge markets . As result, a specific  Knowledge Culture Index  can be defined. This Index helps to show the potentials of knowledge management solutions in one single organizational context.               Keywords: Bosch, decentral knowledge management, knowledge culture, knowledge culture index               Categories: A.1, A.m  
9|7||Defining Culture-Bound User Characteristics as a Starting-Point for the Design of Adaptive Learning Systems|  Elisabeth Kamentz (University of Hildesheim, Germany)   Christa Womser-Hacker (University of Hildesheim, Germany)  Abstract: In our study we set the goal to consider culture as a crucial factor of learning system design. This culture oriented approach is put in concrete terms by comparing US-American and German learning programs on four different levels: layout, interaction and navigation, presentation of content, and the didactic approach. The results of a questioning on culturally specific approaches to computers complete this investigation.               Keywords: HCI-usability, academic style, adaptivity, cultural dimensions, discourse structures, evaluation, learning software, learning style, user modeling               Categories: H.5.4, K.3.1  
9|7||Structural Case-Based Reasoning and Ontology-Based Knowledge Management: A Perfect Match?|  Ralph Bergmann (University of Hildesheim, Germany)   Martin Schaaf (University of Hildesheim, Germany)  Abstract: This article addresses the relations between ontology-based knowledge management implemented by logic-oriented knowledge representation/retrieval approaches and knowledge management using case-based reasoning. We argue that knowledge management with CBR does not only very much resemble but indeed is a kind of ontology-based knowledge management since it is based on closely related ideas and a similar development methodology, although the reasoning paradigms are different. Therefore, we conclude by proposing to merge logic-oriented and case-based retrieval and also to extend the current view of the semantic web architecture respectively.               Keywords: Case-based Reasoning, Knowledge Management, Ontology, Semantic Web, XML               Categories: H.3.1, H.3.3, I.2.1, I.2.4  
9|7||Case-Based Reuse of Software Examplets|  Markus Grabert (University College Cork, Ireland)   Derek Bridge (University College Cork, Ireland)  Abstract: We present a software tool for examplet reuse. We define examplets to be goal-directed snippets of source code, often written for tutorial purposes, that show how to use program library facilities to achieve some task. Our tool allows users to specify both their goal (in free text) and their `situation  (the source code on which they are working). The system combines text retrieval and spreading activation through a semantic net representation of the source code.               Keywords: casebased reasoning, retrieval, software reuse               Categories: D.2.13, I.2.4  
9|7||Organizing the Knowledge Used in Software Maintenance|  Márcio Greyck Batista Dias (Universidade Católica de Brasília, Brazil)   Nicolas Anquetil (Universidade Católica de Brasília, Brazil)   Käthia Marcal de Oliveira (Universidade Católica de Brasília, Brazil)  Abstract: Knowledge engineering emerged as a very promising area to help improve software engineering practice. One of its possible applications would be to help in solving the numerous problems that affect the software maintenance activity. Maintainers of legacy systems developed years ago with obsolete techniques and tools, and not documented, need all kinds of knowledge (application domain, programming skills, software engineering techniques, etc.) It is generally assumed that formalizing all this knowledge and recording it would be a worthwhile effort. However, research is still in a early stage and numerous questions need to be answered: What knowledge should be targeted first? Where to find this knowledge? etc. To answer these questions, one needs a precise understanding of what knowledge is at stake here. We, therefore, propose an ontology of the knowledge needed to perform software maintenance. This ontology would be most useful as a framework for future research in knowledge engineering for software maintenance.               Keywords: knowledge management, ontology, software maintenance               Categories: D.2, D.2.7, D.2.9, K.6.3  
9|7||Experience Base Schema Building Blocks of the PLEASERS Library|  Raimund L. Feldmann (University of Kaiserslautern, Germany)   Ralf Carbon (University of Kaiserslautern, Germany)  Abstract: Quality and process improvement programs usually require organizations to run a repository such as an experience base. However, setting up the schema of an experience base requires expert knowledge. But schema experts are not always available to support the setup of a new experience base. One promising solution is to capture their knowledge in patterns or building blocks. An initial collection of such building blocks is systematically documented in the PLEASERS (Product Line Approach for Software Engineering Repositories) library. In this article we describe the underlying conceptual model of the PLEASERS schema building blocks. Schema experts can use the introduced model to create sets of schema building blocks representing their knowledge.               Keywords: experience base schemata, knowledge & experience management, repository schema reuse, schema building blocks               Categories: D.2.11, D.2.13, D.2.2, H.2.1, H.2.3  
9|7||Managing Organizational Risk Knowledge|  Luciana de Landa Farias (Federal University of Rio de Janeiro - COPPE, Brazil)   Guilherme H. H. Travassos (Federal University of Rio de Janeiro - COPPE, Brazil)   Ana Regina Rocha (Federal University of Rio de Janeiro - COPPE, Brazil)  Abstract: Risk planning requires an organization global view, as it is strongly centered in the experience and knowledge acquired in former projects. The larger the experience of the project manager the better will be his ability in identifying risks, estimating their occurrence likelihood and impact, and defining the mitigation and contingency plans. However, project manager risk knowledge cannot stay in an individual level, but it must be made available to the organization. This paper describes an approach to risk planning in software projects based on the organizational risk knowledge reuse. A risk management process focused on the capture and utilization of organizational knowledge together with a support case tool make part of this approach. An experimental study of the relations between risk-causing facts and risks of software projects was accomplished and its results used to define such a tool.               Keywords: knowledge management, risks management, risks planning               Categories: D.2.0, D.2.9  
9|7||SemanticMiner - Ontology-Based Knowledge Retrieval|  Eddie Moench (ontoprise GmbH, Germany)   Mike Ullrich (ontoprise GmbH, Germany)   Hans-Peter Schnurr (ontoprise GmbH, Germany)   Jürgen Angele (ontoprise GmbH, Germany)  Abstract: During the analysis of knowledge processes in enterprises it often turns out that simple access to existing enterprise knowledge which is covered in documents is not possible. To enable access to a companys  document and data stocks Information Retrieval (IR) technologies play a central role. In the following we describe the underlying theory of the SemanticMiner system, including methods and technologies as well as continuing approaches to obtain Knowledge Retrieval (KR) by dint of semantic technologies.               Keywords: information retrieval, knowledge management, knowledge representation, logic, ontology               Categories: E.1, H.3.0, H.3.3, I.2.0, I.2.1, I.2.3, I.2.4  
9|7||On the Role of the Librarian Agent in Ontology-based Knowledge Management Systems|  Nenad Stojanovic (Institute AIFB, University of Karlsruhe, Germany)  Abstract: In this paper, we present an ontology-based approach for the improvement of searching in an information portal. The approach is based on incremental refinement of user's queries, according to the ambiguity of a query's interpretation. The so-called Librarian Agent plays the role of the human librarian in the traditional library - it uses information, about the domain vocabulary, the capacity of the knowledge repository and the behaviour of previous users in order to help users find the resources they are interested in. Moreover, the agent analyses the users  requests off-line and compares the users' interests with the capacity of the information repository, in order to find which new topics should be introduced or which topics users are no more interested in. We partially implemented the approach in the Web Portal of our Institute and some initial evaluation results are shown.               Keywords: information retrieval, ontology, query refinement               Categories: H.3, H.3.3  
9|7||Effective Integration of Knowledge Management into the Business Starts with a Top-down Knowledge Strategy|  Josef Hofer-Alfeis (Siemens AG, Corporate Information and Operations, Enabling Processes and Knowledge Management, Germany)  Abstract: A cornerstone in the integration of Knowledge Management (KM) in the business is the extension of the business strategy with a knowledge strategy. The Knowledge Strategy Process (KSP) at Siemens follows a top-down approach and helps the management to integrate knowledge strategy effectively in their business strategy. Furthermore, it brings the decision makers of a business unit on one table to draw up an action plan for their respective business unit. In six consequent steps, this action plan is generated to improve the way of working and learning by focusing on knowledge areas with highest impact on the major business ambitions. With a knowledge strategy, the pressure on impact measurements for KM is released, since sense and need for the KM program is understood and it is driven by the management. Only very reasonable cost-benefit checks will be required for larger investment plans by the business owner. An overview on diagnostics and mesurements for knowledge and KM as well as a list of open KM research issues is given for the full integration of KM into the business.               Keywords: KM strategy, cost-benefit check for KM projects, diagnostics and measurements for KM, integration of KM into business, knowledge strategy               Categories: A.  
9|8|http://www.jucs.org/jucs_9_8|7th Brasilian Symposium on Programming Languages J.UCS Special Issue|
9|8||LuaTS - A Reactive Event-Driven Tuple Space|  Marcus Amorim Leal (PUC-Rio, Brazil)   Noemi Rodriguez (PUC-Rio, Brazil)   Roberto Ierusalimschy (PUC-Rio, Brazil)  Abstract: With the goal of assessing the use of the tuple space model in the context of event-driven applications, we developed a reactive tuple space in the Lua programming language. This system, which we called LuaTS, extends the original Linda model with a more powerful associative mechanism for retrieving tuples, supports code mobility and includes a reactive layer through which the programmer can modify the behavior of the basic system calls. In this paper we describe the implementation of LuaTS and illustrate its main features with a few examples.               Keywords: distributed systems, event-oriented programming, tuple spaces               Categories: C.2.4, D.1.3  
9|8||Distributed Typed Concurrent Objects: a Programming Language for Distributed Computations with Mobile Resources|  Ãlvaro Reis Figueira (DCC-FC & LIACC. Universidade do Porto, Portugal)   HervÃ© Paulino (Departamento de Informatica, Faculdade de Ciencias e Tecnologia, Universidade Nova de Lisboa, Portugal)   Luis Lopes (DCC-FC & LIACC. Universidade do Porto, Portugal)   Fernando Silva (DCC-FC & LIACC. Universidade do Porto, Portugal)  Abstract: We describe a programming language for distributed computations that supports mobile resources and is based on a process calculus. The syntax, semantics and implementation of the language are presented with a focus on the novel model of computation.               Keywords: distributed computing, mobile resources, process-calculus               Categories: D.1.3, D.3.2  
9|8||Asynchronous Remote Method Invocation in Java|  Wendell Figueiredo Taveira (Computer Science Department, Federal University of Minas Gerais, Brazil)   Marco Tulio de Oliveira Valente (Computer Science Department, Federal University of Minas Gerais, Brazil)   Mariza Andrade da Silva Bigonha (Computer Science Department, Federal University of Minas Gerais, Brazil)   Roberto da Silva Bigonha (Computer Science Department, Federal University of Minas Gerais, Brazil)  Abstract: Java RMI is the computational model used to develop distributed systems in the Java language. Although widely used in the construction of distributed systems, the use of Java RMI is limited because this middleware does not allow asynchronous method invocations. This paper presents FlexRMI, a Java based system that supports asynchronous invocations of remote methods. FlexRMI is completely implemented in Java, making use of the reflection and dynamic proxy facilities of this language. The implementation is also compatible with standard Java RMI distributed systems.               Keywords: asynchronous remote method invocation, distributed programming               Categories: D.1.3, D.1.5, D.3.3  
9|8||Haskell#: Parallel Programming Made Simple and Efficient|  Francisco Heron de Carvalho Junior (Centro de Informatica Universidade Federal de Pernambuco, Brazil)   Rafael Dueire Lins (Departamento de Eletronica e Sistemas Universidade Federal de Pernambuco, Brazil)  Abstract: This paper presents the final result of the designing of a new specification for the Haskell# Language, including new features to increase its expressiveness, but without losing either efficiency or obedience to its original premisses.               Keywords: Petri Nets, fuctional programming, languages, parallelism               Categories: C.2.4, D.1.1, D.1.3, D.2.2, D.3.2, D.3.3  
9|8||Implementation of an Embedded Hardware Description Language Using Haskell|  Nélio Muniz Mendes Alves (Universidade Federal de Uberlandia, Brazil)   Sérgio de Mello Schneider (Universidade Federal de Uberlandia, Brazil)  Abstract: This paper describes an ongoing implementation of an embedded hardware description language (HDL) using Haskell as a host language. Traditionally, functional HDL s are made using lazy lists to model signals, so circuits are functions from lists of input values to lists of output values. We use another known approach for embedded languages, in which circuits are data structures rather than functions. This style of implementation permits one to inspect the structure of the circuit, allowing one to perform different interpretations for the same description. The approach we present can also be applied to other domain-specific embedded languages. We provide an elegant implementation of memories and a set of new signal types.               Keywords: domain-specific languages, embedded languages, hardware description               Categories: B.5.2, B.6.3, D.3.2, I.6.2  
9|8||Lazy Cyclic Reference Counting|  Rafael Dueire Lins (Universidade Federal de Pernambuco, Brazil)  Abstract: Reference counting is a widely employed memory management technique, in which garbage collection operations are interleaved with computation. Standard reference counting has the major drawback of being unable to handle cyclic structures. This paper presents an important optimisation to a recently published algorithm for cyclic reference counting. Proofs of the correctness of the original and lazy algorithms are provided, together with performance figures.               Keywords: cycles, garbage collection, memory management, reference counting               Categories: D.4.2, D.4.3, F.2.2  
9|8||Constant Propagation on Predicated Code|"  Jens Koop (Vienna University of Technology, Austria)   Oliver Rüthing (University of Dortmund, Germany)  Abstract: We present a new constant propagation (CP) algorithm for predicated code, for which classical CP-techniques are inadequate. The new algorithm works for arbitrary control flow, detects constancy of terms, whose operands are not constant themselves, and is optimal for acyclic code such as hyperblocks, the central ""compilation units"" for instruction scheduling of predicated code. The new algorithm operates on the predicated value graph, an extension of the well-known value graph of Alpern et al. [Alpern et al., 1988], which is tailored for predicated code and constructed on top of the predicate-sensitive SSA-form, which has been introduced by Carter et al. [Carter et al., 1999]. As an additional benefit, the new algorithm identifies off-predicated instructions in predicated code. They can simply be eliminated thereby further increasing the performance and simplifying later compilation phases such as instruction scheduling.               Keywords: IA-4, constant propagation, data-flow analysis, optimization, predicated SSA-form, predicated code, predicated value graph               Categories: C.1.0, D.3.4  "
9|8||Dependently Typed Pattern Matching|  Hongwei Xi (Computer Science Department Boston University, USA)  Abstract: The mechanism for declaring datatypes to model data structures in programming languages such as Standard ML and Haskell can offer both convenience in programming and clarity in code. With the introduction of dependent datatypes in DML, the programmer can model data structures with more accuracy, thus capturing more program invariants. In this paper, we study some practical aspects of dependent datatypes that affect both type-checking and compiling pattern matching. The results, which have already been tested, demonstrate that dependent datatype can not only o#er various programming benefits but also lead to performance gains, yielding a concrete case where safer programs run faster.               Keywords: DML, dependent types, pattern matching               Categories: D.3.2, D.3.3  
9|8||Practical Type Inference for Polymorphic Recursion: an Implementation in Haskell|  Cristiano Vasconcellos (Pontifícia Universidade Católica do Paraná, Brazil)   Lucília Figueiredo (Universidade Federal de Ouro Preto, Brazil)   Carlos Camarão (Universidade Federal de Minas Gerais, Brazil)  Abstract: This paper describes a practical type inference algorithm for typing poly-morphic and possibly mutually recursive definitions, using Haskell to provide a high-level implementation of the algorithm.               Keywords: polymorphic recursion, programming languages, type inference               Categories: D.3, D.3.3  
9|8||Towards a Calculus of State-based Software Components|  LuÃ­s Soares Barbosa (Dep. Informatica, Universidade do Minho, Portugal)  Abstract: This paper introduces a calculus of state_based software components modelled as concrete coalgebras for some Set endofunctors, with specified initial conditions. The calculus is parametrized by a notion of behaviour, introduced as a strong (usually commutative) monad. The proposed component model and calculus are illustrated through the characterisation of a particular class of components, classified as separable, which includes the ones arising in the so-called model oriented approach to systems  design.               Keywords: coalgebra, semantics, software components               Categories: D.3.1, F.3.2  
9|8||Object-Oriented Action Semantics Specifications|  Claudio Carvilhe (Catholic University of Parana, Brazil)   Martin A. Musicante (Catholic University of Parana, Brazil)  Abstract: Action Semantics is a framework for the formal specification of programming languages. Two different, recently proposed approaches provide modularity to the framework, allowing for specification reusability and extension. In this work, we analyze the previous approaches, and introduce Object-Oriented Action Semantics, a new form of modular organization of Action Semantics descriptions. Object-oriented Action Semantics does not modify the syntax in which actions are written, the addition of object-oriented features (like classes and objects) is done as an upper layer to the semantic entities and functions. A simple Pascal-like, imperative programming language is described using the formalism. The extension and reuse capabilities of Object_Oriented Action Semantics are demonstrated by adding new features to the description. The semantics of the object-oriented action notation is also presented.               Keywords: action semantics, formal semantics, object-oriented specification               Categories: D.3.1, D.3.2, F.3.2  
9|8||Developing Adaptive J2ME Applications Using AspectJ|  Ayla Dantas (Federal University of Pernambuco, Brazil)   Paulo Borba (Federal University of Pernambuco, Brazil)  Abstract: This paper evaluates the use of AspectJ, a general-purpose aspect-oriented extension to Java, to provide adaptive behavior for J2ME applications in a modularized way. Our evaluation is based on the development of a simple but non-trivial dictionary application where new adaptive behavior was incrementally implemented using AspectJ. Our main contribution is to show that the AspectJ language can be used to implement several adaptive concerns, which allow the application to have di#erent behaviors according to changes in its environment. We also compare our implementation with corresponding pure Java alternatives, identify disadvantages of using AspectJ and propose some possible patterns.               Keywords: AOP applications, adaptability, aspect-Oriented programming, separation of concerns, software architecture               Categories: D.2, D.2.11, D.3  
9|8||XOCL - an XML Language for Specifying Logical Constraints in Object Oriented Models|  Franklin Ramalho (Universidade Federal de Campina Grande, Brazil and Universidade Federal de Pernambuco, Brazil)   Jacques Robin (Universidade Federal de Pernambuco, Brazil)   Roberto Barros (Universidade Federal de Pernambuco, Brazil)  Abstract: In this paper, we present XOCL, an XML-based language to represent OCL (Object Constraint Language) constraints in UML models. XOCL was designed in two steps from the UML meta-model and OCL EBNF grammar published by OMG: (1) construction of a simple OCL meta-model and (2) derivation of an XML Schema for this meta-model. XOCL applications include full interoperability among UML modelling tools as well as finely grained structured input for automatic behavioral code generation and model checking.               Keywords: Meta-Modelling, OCL, UML, XMI, XML, XMLShema               Categories: D.1.5, D.1.6, D.2.12, D.3.3  
9|8||Aspect Weaving Strategies|  Eduardo Kessler Piveta (CEULP/ULBRA, Brazil)   Luiz Carlos Zancanella (Federal University of Santa Catarina Â­ UFSC, Brazil)  Abstract: We propose a model to support aspect-oriented programming in object-oriented languages, expressing general purpose aspects. To apply this model, the developer should implement the abstraction and composition mechanisms as well as one or more strategies defined in it. It could be applied to regular OO languages.               Keywords: aspect-oriented programming, object-oriented programming               Categories: D.3.0, D.3.4  
9|9|http://www.jucs.org/jucs_9_9|Spatial and Temporal Reasoning J.UCS Special Issue|
9|9||An Applied Calculus for Spatial Accessibility Reasoning|  Michael Pool (Information Extraction and Transport, Inc., USA)  Abstract: Recent attempts to perform formal knowledge representation and reasoning in cell biology have presented new challenges to spatial reasoning. In this paper we formalize two distinct notions of containment that were so motivated and which are relevant to reasoning about physical systems, a notion of being inside and a notion of being restricted. We develop a formal vocabulary for purposes of representing and reasoning about restrictive containment and formalize three kinds of accessibility that are each salient to attempts to reason about the possibility of interaction between pairs of objects in a system. We also consider the relation of this calculus to the well known Region Connection Calculus and related calculi for reasoning about containment. Finally, we discuss methods for implementing in a context of uncertainty, within a planning system and discuss an application to some simple representation and reasoning tasks in virology.               Keywords: Bayesian reasoning, molecular biology, qualitative spatial reasoning, spatial accessibility               Categories: I.2.4  
9|9||Abstract Representation of Object and Structural Symmetries Detection|  Vincent Dugat (IRIT-UPS, France)   Pierre Gambarotto (IRIT-UPS, France)   Yannick Larvor (IRIT-UPS, France)  Abstract: This paper describes a method for constructing an abstract representation of a shape from a classical polyhedral 3D representation of an object. This framework is suitable for qualitative reasoning. As an application we use this abstract representation to compute the structural symmetries of a 3D polyhedron. The starting point of the computation is a classical polyhedral 3D representation of the object. From the Medial Axis Transform (MAT) of this object we propose a more abstract representation based on a set of spheres extracted from the MAT and structured as one or several graphs. This framework can be used for several purposes. Here we focus on the problem of finding structural symmetries of the object. We use the automorphisms group of the computed graphs. Then we propose a method to compute the automorphisms that have a geometrical sense among the set of all automorphisms. We compare the brute force algorithm with a branch and bound strategy based on the orbits partition of the vertices.               Keywords: medial axis transform, qualitative reasoning, shape recognition, spatial reasoning, spatial representation               Categories: I.2.4, I.3.5  
9|9||Reasoning about Propagation of Properties over Regions|  Kazuko Takahashi (School of Science and Technology, Kwansei Gakuin University, Japan)  Abstract: We discuss how a property of some region is propagated to other regions. We propose a system called SRCC that enables the integration of spatial and semantic data. SRCC can represent the relative positions of regions, properties that hold in some regions, semantic relation between regions, and so on. We define the model and describe an algorithm that checks for the existence of a model for a given set of formulas based on this model. We prove the soundness and completeness of the algorithm and apply it to an example that inspects the causality of contamination in 2D space.               Keywords: GIS, RCC, qualitative spatial reasoning, semantic data               Categories: D.3.1, F.4.3  
9|9||Action Vectors: Modeling Spatial Relations between Objects and Routes|  Junko Araki (University of Tokyo, Japan)  Abstract: This paper describes cognitive mechanisms that interpret elliptical instructions used in navigation. We introduce action vectors, which are defined as an agent s previous positions on routes. In addition, a new perspective system, an action-oriented perspective system is presented. In this system, the action vectors are designated to reference objects. Using theory of the action vectors and the action-oriented system, we demonstrate specific spatial configurations between objects and the action vectors, which arise in cognitive process of interpreting elliptical instructions.               Keywords: elliptical route descriptions, human spatial cognition, navigation system, perspective systems               Categories: I.2.10, I.2.4, I.2.7  
9|9||Modeling and Comparing Farm Maps using Graphs and Case-based Reasoning|  Florence Le Ber (ENGEES, France and LORIA, Vandoeuvre-les-Nancy, France)   Amedeo Napoli (LORIA UMR 7503, BP 239, 54506 Vandoeuvre-les-Nancy, France)   Jean-Luc Metzger (LORIA, Vandoeuvre-les-Nancy, France)   Sylvie Lardon (ENGREF, France)  Abstract: In this paper, we present the knowledge­based system rosa working on spatial and functional organizations in agriculture. The reasoning in rosa combines hierarchical classification, case-based reasoning, and qualitative spatial reasoning. The goal of the system is twofold: formalizing and building a case base holding on farm spatial and functional organizations, and helping the analysis of new cases. Domain knowledge and cases are modeled with the help of the so-called spatial organization graphs (sogs), and represented within a description logic system. Hierarchical case-based reasoning, involving classification and qualitative spatial reasoning, is used to compare and explain farm spatial structures modeled by sogs. An example of case retrieval is proposed, followed by a global discussion on case­based reasoning in the rosa system and related work.               Keywords: agronomy, case-based reasoning, description logics, graphs, hierarchical classification, spatial structure analysis               Categories: I.2.1, I.2.4  
9|9||Modeling Motion by the Integration of Topology and Time|  Lledó Museros (Alicer, Ceramic Design Technology Institute, Spain)   M. Teresa Escrig (Universidad Jaume I, Engineering and Computer Science Department, Spain)  Abstract: A qualitative representational model and the corresponding reasoning process for integrating time and topological information is developed in this paper. In the calculus presented, topological information in function of the point of the time in which it is true is represented as an instance of the Constraint Satisfaction Problem. The resulting method can be applied to qualitative navigation of autonomous agents. The model presented in this paper will help us during the path planning task by describing the sequence of topological situations that the agent should find during its way to the target objective. A preliminary result of that application has been obtained by using qualitative representation of such spatial aspects for the autonomous simulated navigation of a Nomad-200 robot, on a structured environment of an easy corridor in a building.               Keywords: autonomous mobile robot navigation, constraint logic programming, integration, qualitative reasoning, spatial reasoning, temporal reasoning               Categories: D.1.6, H.1  
9|9||Direct Granularity Conversions among Temporal Constraints|  Claudio Bettini (University of Milan, Italy)   Simone Ruffini (University of Milan, Italy)  Abstract: This paper considers temporal constraints that can impose a minimum and maximum time distance between the occurrences of two events by specifying the minimum and maximum values in terms of a time granularity. When several constraints using different time granularities are part of the specification of a single problem, a reasonable question is how to convert the constraints in terms of a single granularity in order to apply standard temporal constraint algorithms. This paper investigates the problem of converting a distance constraint expressed in terms of a granularity into another one in terms of a different time granularity. An expressive formal model for time granularities is assumed including common granularities like hours and days as well as user-defined granularities like business days and academic semesters.               Keywords: temporal abstraction, temporal constraints, time granularity               Categories: I.2.4  
9|9||Propositional Interval Neighborhood Temporal Logics|  Valentin Goranko (Rand Afrikaans University, South Africa)   Angelo Montanari (University of Udine, Italy)   Guido Sciavicco (University of Udine, Italy)  Abstract: Logics for time intervals provide a natural framework for dealing with time in various areas of computer science and artificial intelligence, such as planning, natural language processing, temporal databases, and formal specification. In this paper we focus our attention on propositional interval temporal logics with temporal modalities for neighboring intervals over linear orders. We study the class of propositional neigh-borhood logics (PNL) over two natural semantics, respectively admitting and excluding point-intervals. First, we introduce interval neighborhood frames and we provide representation theorems for them, then, we develop complete axiomatic systems and semantic tableaux for logics in PNL.               Keywords: axiomatic systems, interval temporal logic, tableau systems               Categories: F.4.1, I.2.4  
9|9||Fuzziness and Uncertainty in Temporal Reasoning|  Didier Dubois (Institut de Recherche en Informatique de Toulouse, Université Paul Sabatier, France)   Allel HadjAli (Institut de Recherche en Informatique de Toulouse, Université Paul Sabatier, France)   Henri Prade (Institut de Recherche en Informatique de Toulouse, Université Paul Sabatier, France)  Abstract: This paper proposes a general discussion of the handling of imprecise and uncertain information in temporal reasoning in the framework of fuzzy sets and possibility theory. The introduction of fuzzy features in temporal reasoning can be related to different issues. First, it can be motivated by the need of a gradual, linguistic-like description of temporal relations even in the face of complete information. An extension of Allen relational calculus is proposed, based on fuzzy comparators expressing linguistic tolerance. Fuzzy Allen relations are defined from a fuzzy partition made by three possible fuzzy relations between dates (approximately equal, clearly smaller, and clearly greater). Second, the handling of fuzzy or incomplete information leads to pervade classical Allen relations, and more generally fuzzy Allen relations, with uncertainty. The paper provides a detailed presentation of the calculus of fuzzy Allen relations (including the composition table of these relations). Moreover, the paper discusses the patterns for propagating uncertainty about (fuzzy) Allen relations in a possibilistic way.               Keywords: Allen temporal relations, approximate reasoning, fuzzy interval, fuzzy relation, necessity measure, possibility theory               Categories: I.2.4  
volume|issue|url|title|abstract
10|1|http://www.jucs.org/jucs_10_1|Human Issues in Implementing eLearning Technology|
10|1||Situated Models and Metadata for Learning Management|  Heidrun Allert (Learning Lab Lower Saxony, University of Hanover, Germany)   Christoph Richter (Learning Lab Lower Saxony, University of Hanover, Germany)   Wolfgang Nejdl (Learning Lab Lower Saxony, University of Hanover, Germany)  Abstract: This paper depicts the interrelation between situated learning and learning management from an organizational and personal perspective. Based on this introduction we show how educational metadata can be used for approaches of situated learning and how we can take care of contexts using context specific role-based metadata.               Keywords: eLearning, metadata, situated learning               Categories: K.3.0  
10|1||"Game-Based Learning in Universities and Lifelong Learning: ""UniGame: Social Skills and Knowledge Training"" Game Concept"|"  Maja Pivec (FH JOANNEUM, Information Design, Austria)   Olga Dziabenko (FH JOANNEUM, Information Design, Austria)  Abstract: How to design effective learning opportunities? Why is learning by experience often more efficient than learning by studying? How to provide the learning experiences needed to respond to current challenges? Using computer games and games in general for educational purposes offers a variety of knowledge presentations and creates opportunities to apply the knowledge within a virtual world, thus supporting and facilitating learning processes. An innovative educational paradigm such as game-based learning, which is considered suitable for the given purpose, is described in this article. The connection of the collaborative social context of education with game-based learning is discussed in the first part of the paper.        The second part of the paper introduces the game concept of ""UniGame: Social Skills and Knowledge Training"". Game ideas along the educational background of the UniGame game concept are outlined. UniGame scenarios presented and possible use cases should stimulate users to apply game-based learning approach in the future for their classes.               Keywords: collaborative learning, constructivism, education, game, game-based learning, motivation               Categories: H.4.3, I.2.1, I.6.8, K.3.0, K.3.1, K.8.0  "
10|1||The Effect of Personality-Aware Computer-Human Interfaces on Learning|  Edmond Abrahamian (Saint Louis University, USA)   Jerry Weinberg (Southern Illinois University, USA)   Michael Grady (Saint Louis University, USA)   C. Michael Stanton (Saint Louis University, USA)  Abstract: Traditional software used for student-centered learning typically provides for a uniform user interface through which the student can interact with the software, and through which the information is delivered in a uniformly identical fashion to all users without regard to their learning style. This research classifies personality types of computer science undergraduate students using the Myers-Briggs Type Indicator, relates these types of personalities to defined learning preferences, and tests if a given user interface designed for a given learning preference enhances learning. The general approach of this study is as follows: given a set of user interfaces designed to fit personality types, provide a given user interface to participants with the matching personality type. In the control group, provide participants with a randomly chosen user interface. Observe the performance of all participants in a post-test. Additionally, observe if the test group had an enhanced learning experience. Quantitative results indicate that personality-aware user interfaces have a significant effect on learning. Qualitative results show that in most cases, users preferred user interfaces designed for their own personality type. Preliminary results show that for introverted intuitive persons and extraverted intuitive persons, the effect of a personality-aware human-computer interface on learning is significant.               Keywords: Human-Computer Interaction, MBTI, Myers-Briggs Type Indicator, e-learning               Categories: H.5.2, K.3.2  
10|1||User Context Aware Delivery of E-Learning Material: Approach and Architecture|  Andreas Schmidt (Forschungszentrum Informatik (FZI), Germany)   Claudia Winterhalter (Forschungszentrum Informatik (FZI), Germany)  Abstract: Current E-Learning solutions are not sufficiently aware of the context of the learner, that is the individual's characteristics and the organizational context such as the work processes and tasks. Nevertheless, this awareness can be achieved by modular learning objects and semantical metadata for their contextualization. By that delivering of learning material, which is relevant to the current situation of the learner, is supported. This paper presents a general approach and architecture.               Keywords: e-learning, learning objects, ontologies, user context-aware retrieval               Categories: H.3.3, K.3.1  
10|1||Discovering Student Models in e-learning Systems|  Floriana Esposito (Dipartimento di Informatica - Università di Bari, Italy)   Oriana Licchelli (Dipartimento di Informatica - Università di Bari, Italy)   Giovanni Semeraro (Dipartimento di Informatica - Università di Bari, Italy)  Abstract: In all areas of the e-era, personalization plays an important role. Particularly in e-learning a main issue is student modeling, that is the analysis of student behavior and prediction of his/her future behavior and learning performance. In fact, nowadays, the most prevailing issue in the e-learning environment is that it is not easy to monitor students' learning behaviors. In this paper we have focused our attention on the system (the Profile Extractor) based on Machine Learning techniques, which allows for the discovery of preferences, needs and interests of users that have access to an e-learning system. The automatic generation and the discovery of the user profile, to agree as simple student model based on the learning performance and the communication preferences, allow creating a personalized education environment. Moreover, we presented an evaluation of the accuracy of the Profile Extractor system using the classical Information Retrieval metrics.               Keywords: e-learning, learning objects, user context               Categories: K.3.1  
10|1||Experiences with Adaptive User and Learning Models in eLearning Systems for Higher Education|  Thomas Flor (Research and Technology, Software Architecture, Germany)  Abstract: Cooperative learning is characterized by communication and interaction in a group. Computer-supported cooperative/collaborative learning (CSCL) is a specific form doing away with previous spatial and temporal restrictions. At the starting point of our examinations lie known learning processes and their possible support through a CSCL system. Both the significance of different user models and the variety of styles and roles of learning are analyzed in CSCL systems and illustrated in scenarios supporting cooperative or collaborative learning processes. The practical evaluation of the methods and algorithms was done using an adaptive CSCL system to promote learning effects on the domain of software engineering.               Keywords: CSCL, adaptive eLearning, learning models, user modeling               Categories: H.5.1, H.5.3  
10|1||The Role of Adaptation and Personalisation in Classroom-Based Learning and in e-Learning|  Maja Pivec (FH JOANNEUM, Department of Information Design, Austria)   Konrad Baumann (FH JOANNEUM, Department of Information Design, Austria)  Abstract: The paper focuses on adaptability, knowledge mediation and knowledge flows in face-to-face classes compared to computer-based or Internet-based classes. The paper gives an overview of features of on-line learning systems that facilitate the learning process and gives some aspects on adaptation and personalisation issues within those systems. Some recent developments of intelligent tutors capable of expressing emotions are presented. Application examples of adaptable multimedia e-learning solutions for different user groups are described. An outlook on possible future developments and constraints is provided. The paper starts an important discussion about how to design effective human-computer interaction.               Keywords: learning, personalisation, teaching               Categories: H.5.1, I.2.6  
10|1||Intercultural Factors in Web-based Training Systems|  Edith Denman-Maier (Donau-Universitaet Krems, Austria)  Abstract: This paper is based on on-going research carried out in the framework of an EU project aimed at enhancing knowledge management (KM) in enterprises. It deals with the impact of intercultural factors on the accessibility and presentation of eLearning content.       It reports on preliminary findings and discusses the issues which have emerged so far in the contextual study and requirements analysis conducted in preparation for designing Web-based training modules.       Once the empirical research is completed and the data analyzed, guidelines will be proposed for developing Web-based training modules for culturally heterogeneous user groups sharing the same professional background. Special consideration will be given to interactive and community features.               Keywords: Web-based training, cross-cultural/intercultural factors, interaction patterns, knowledge management, usage-centered design, user interface design               Categories: H.5.2, J.4  
10|10|http://www.jucs.org/jucs_10_10|Formal Specification of Computer-Based Systems|
10|10||A MOF-Based Metamodeling Environment|  Matthew J. Emerson (Institute for Software Integrated Systems ISIS, Vanderbilt University, USA)   Janos Sztipanovits (Institute for Software Integrated Systems ISIS, Vanderbilt University, USA)   Ted Bapty (Institute for Software Integrated Systems ISIS, Vanderbilt University, USA)  Abstract: The Meta Object Facility (MOF) forms one of the core standards of the Object Management Group's Model Driven Architecture. It has several use-cases, including as a repository service for storing abstract models used in distributed object-oriented software development, a development environment for generating CORBA IDL, and a metamodeling language for the rapid specification, construction, and management of domain-specific technology-neutral modeling languages. This paper will focus on the use of MOF as a metamodeling language and describe our latest work on changing the MIC metamodeling environment from UML/OCL to MOF. We have implemented a functional graphical metamodeling environment based on the MOF v1.4 standard using GME and GReAT. This implementation serves as a testament to the power of formally well-defined metamodeling and metamodel-based model transformation approaches. Furthermore, our work gave us an opportunity to evaluate sevaral important features of MOF v1.4 as a metamodeling language:  Keywords: Model Driven Architecture, Model-Integrated Computing, graph transformations               Categories: D.2.2  
10|10||Platform Modeling and Model Transformations for Analysis|  Tivadar Szemethy (Institute for Software-Integrated Systems, Vanderbilt University, USA)   Gabor Karsai (Institute for Software-Integrated Systems, Vanderbilt University, USA)  Abstract: The model-based approach to the development of embedded systems relies on the use of explicit models in the design process. If these models faithfully represent the components of the system with respect to their properties as well as their interactions, then they can be used to predict the dynamic behavior of the system under construction. In this paper we argue for modeling the execution platform that facilitates the component interactions, and show how models of the application and the knowledge of the platform can be used to translate system configurations into another abstract formalism (timed automata, in our case) that allows system verification through model checking.               Keywords: graph transformations, model transformations, model-based development, models of computation, software verification               Categories: D.2.2  
10|10||Architectural Abstraction as Transformation of Poset Labelled Graphs|  Mark Denford (University of Technology, Australia)   Andrew Solomon (University of Technology, Australia)   John Leaney (University of Technology, Australia)   Tim O'Neill (University of Technology, Australia)  Abstract: The design of large, complex computer based systems, based on their architecture, will benefit from a formal system that is intuitive, scalable and accessible to practitioners. The work herein is based in graphs which are an efficient and intuitive way of encoding structure, the essence of architecture. A model of system architectures and architectural abstraction is proposed, using poset labelled graphs and their transformations. The poset labelled graph formalism closely models several important aspects of architectures, namely topology, type and levels of abstraction. The technical merits of the formalism are discussed in terms of the ability to express and use domain knowledge to ensure sensible refinements. An abstraction / refinement calculus is introduced and illustrated with a detailed usage scenario. The paper concludes with an evaluation of the formalism in terms of its rigour, expressiveness, simplicity and practicality.               Keywords: Abstraction, Architecture, Graphs, Refinement               Categories: D.2.1, D.2.2, F.3.1, F.4.2  
10|10||Synchronization Can Improve Reactive Systems Control and Modularity|  Cristina Cerschi Seceleanu (Turku Centre for Computer Science and Åbo  Akademi, Finland)   Tiberiu Seceleanu (UUniversity of Turku, Department of Information Technology, Finland)  Abstract: We concentrate on two major aspects of reactive system design: behavior control and modularity. These are studied from a formal point of view, within the framework of action systems. The traditional interleaving paradigm is completed with a barrier synchronization mechanism. This is achieved by introducing a new parallel composition operator, applicable to bot h discrete and hybrid models. While offering improvements with respect to control and modularity, the approach uses the correctness preserving mechanisms provided by the underlying reasoning environment 1.     Keywords: Action systems, Concurrency, Modular design, Reactive systems               Categories: D.1.3, F.3.1, F.3.2  
10|10||Tools for Parametric Verification. A Comparison on a Case Study|  Petr Matoušek (Brno University of Technology, Czech Republic)  Abstract: Protocol analysis involves several parameters in  model specification, for instance, transmission delay or the length of the transmitting window. Verification of the model with parameters is a semi-decision process that depends on the number of clocks, parameters and counters in the model. Using combination of different verification tools for timed models as HyTech, TReX and UPPaal we are able to find relation between parameters satisfying desired property. The paper gives a report on the synthesis of parameters of PGM protocol. We built a formal model based on extended time automata with parameters and verified the reliability property. Our results automatically obtained from the model are consistent with previous results derived manually. The paper describes our experience with parametric verification of multicast protocol PGM. Results mentioned in the work were made with collaboration with Mihaela Sighireanu (Mihaela.Sighireanu@liafa.jussieu.fr) from LIAFA, Paris.               Keywords: parametric verification, protocol, timed  model-checking               Categories: C.2.2, F.4.3, I.6.3  
10|11|http://www.jucs.org/jucs_10_11|Second International Workshop on Verification and Validation of Enterprise Information Systems J.UCS Special Issue|
10|11||FBT: A Tool for Applying Interval Logic Specifications to On-the-fly Model Checking|  Miguel J. Hornos (Dpto. de Lenguajes y Sistemas Informáticos, University of Granada, Spain)  Abstract: This paper presents the FBT (FIL to Buechi automaton Translator) tool which automatically translates any formula from FIL (Future Interval Logic) into its semantically equivalent Buechi automaton. There are two advantages of using this logic for specifying and verifying system properties instead of other more traditional and extended temporal logics, such as LTL (Linear Temporal Logic): firstly, it allows a succinct construction of specific temporal contexts, where certain properties must be evaluated, thanks to its key element, the interval, and secondly, it also permits a natural, intuitive, graphical representation. The underlying algorithm of the tool is based on the tableau method and is specially intended for application in on-the-fly model checking. In addition to a description of the design and implementation structure of FBT, we also present some experimental results obtained by our tool, and compare these results with the ones produced by an other tool of similar characteristics (i.e. based on an on-the-fly tableau algorithm), but for LTL.               Keywords: Buechi Automata, FIL (Future Interval Logic), GIL (Graphical Interval Logic), automatic verification, interval logic, on-the-fly model checking, specification, tableau method, temporal logic               Categories: D.2.1, D.2.4, F.3.1  
10|11||Automated Support for Enterprise Information Systems|  John Andrew Andrew van der Poll (University of South Africa, South Africa)   Paula Kotzé (University of South Africa, South Africa)   Willem Adrian Labuschagne (University of Otago, New Zealand)  Abstract: A condensed specification of a multi-level marketing (MLM) enterprise which can be modelled by mathematical forests and trees is presented in Z. We thereafter identify a number of proof obligations that result from operations on the state space. Z is based on first-order logic and a strongly-typed fragment of Zermelo-Fraenkel set theory, hence the feasibility of using certain reasoning heuristics developed for proving theorems in set theory is investigated for discharging the identified proof obligations. Using the automated reasoner OTTER, we illustrate how these proof obligations from a real-life enterprise may successfully be discharged using a suite of well-chosen heuristics.               Keywords: OTTER, Z, automated reasoning, formal specification, heuristics, set theory               Categories: D.2.4, F.3.1, F.4.1, I.2.3  
10|11||Checking Consistency between UML Class and State Models Based on CSP and B|  W. L. Yeung (Dept of Computing and Decision Sciences, Lingnan University, Hong Kong)  Abstract: The B Abstract Machine Notation (AMN) and the notation of Communicating Sequential Processes (CSP) have previously been applied to formalise the UML class and state diagrams, respectively. This paper discusses their integrated use in checking the consistency between the two kinds of UML diagrams based on some recent results of research in integrated formal methods. Through a small information system example, the paper illustrates a clear-cut separation of concerns in employing the two formal methods. Of particular interest is the treatment of recursive calls within a single class of objects.               Keywords: B Abstract Machine Notation, Communicating Sequential Processes, UML, formal methods               Categories: D.2.1, D.2.2  
10|12|http://www.jucs.org/jucs_10_12|Tuning SAT for Formal Verification and Testing|
10|12||MINCE: A Static Global Variable-Ordering Heuristic for SAT Search and BDD Manipulation|  Fadi A. Aloul (American University of Sharjah, UAE)   Igor L. Markov (University of Michigan, USA)   Karem A. Sakallah (University of Michigan, USA)  Abstract: The increasing popularity of SAT and BDD techniques in formal hardware verification and automated synthesis of logic circuits encourages the search for additional speedups. Since typical SAT and BDD algorithms are exponential in the worst-case, the structure of realworld instances is a natural source of improvements. While SAT and BDD techniques are often presented as mutually exclusive alternatives, our work points out that both can be improved via the use of the same structural properties of instances. Our proposed methods are based on efficient problem partitioning and can be easily applied as pre-processing with arbitrary SAT solvers and BDD packages without modifying the source code of SAT/BDD tools.       Finding a better variable ordering is a well recognized problem for both SAT solvers and BDD packages. Currently, the best variable-ordering algorithms are dynamic, in the sense that they are invoked many times in the course of the host algorithm that solves SAT or manipulates BDDs. Examples include the DLCS ordering for SAT solvers and variable sifting during BDD manipulations. In this work we propose a universal variable-ordering algorithm MINCE (MIN Cut Etc.) that pre-processes a given Boolean formula in CNF. MINCE is completely independent from target SAT algorithms and in some cases outperforms both the variable state independent decaying sum (VSIDS) decision heuristic for SAT and variable sifting for BDDs. We argue that MINCE tends to capture structural properties of Boolean functions arising from real-world applications. Our contribution is validated on the ISCAS circuits and the DIMACS benchmarks. Empirically, our technique often outperforms existing SAT/BDD techniques by a factor of two or more. Our results motivate the search for better dynamic ordering heuristics and combined static/dynamic techniques.               Keywords: BDDs, CNF, SAT, backtrack search, decision heuristics, formal verification, partitioning, variable ordering               Categories: I.1.2, I.2.8  
10|12||Using Global Structural Relationships of Signals to Accelerate SAT-based Combinational Equivalence Checking|  Rajat Arora (Cadence Design Systems, USA)   Michael S. Hsiao (Department of Electrical & Computer Engineering, Virginia Tech, USA)  Abstract: We propose a novel technique to improve SAT-based Combinational Equivalence Checking (CEC). The idea is to perform a low-cost preprocessing that will statically induce global signal relationships into the original CNF formula of the miter circuit under verification, and hence reduce the complexity of the SAT instance. This efficient and effective preprocessing quickly builds up the implication graph for the miter circuit under verification, yielding a large set of direct, indirect and extended backward implications. These two-node implications spanning the entire circuit are converted into binary clauses, and they are added to the miter CNF formula. The added clauses constrain the search space of the SAT solver and provide correlation among the different variables, which enhances the Boolean Constraint Propagation (BCP). Experimental results on large and difficult ISCAS'85, ISC AS'89 (full scan) and ITC'99 (full scan) CEC instances show that our approach is independent of the state-of-the-art SAT solver used, and that the added clauses help to achieve not eworthy speedup for each of the cases. Also, comparison with Hyper-Resolution (Hypre), Non-Increasing Variable Elimination Resolution (NIVER) and the propositional formula checker HeerHugo, suggests that our technique is more powerful, yielding non-trivial clauses that significantly simplify the SAT instance complexity.               Keywords: Boolean Formula, Boolean Satisfiability (SAT), Combinational Equivalence Checking (CEC), Propositional Formula, Static Logic Implications               Categories: B.6.2, F.4.m, I.2.6, I.2.8  
10|12||A Signal Correlation Guided Circuit-SAT Solver|  Feng Lu (University of California, USA)   Li-C. Wang (University of California, USA)   John Moondanos (Intel Corporation, USA)   Ziyad Hanna (Intel Corporation, USA)  Abstract: We propose two heuristics, implicit learning and explicit learning, that utilize circuit topological information and signal correlations to derive conflict clauses that could efficiently prune the search space for solving circuit based SAT problem instances. We implemented a circuit-SAT solver SC-C-SAT based on the proposed heuristics and the concepts used in other state-of-the-art SAT solvers. For solving unsatisfiable circuit examples and for solving difficult circuit-based problems at Intel, our solver is able to achieve speedup of one order of magnitude over other state-of-the-art SAT solvers that do not use the heuristics.               Keywords: ATPG, Boolean equivalence checking, Boolean satisfiability               Categories: B.7.2  
10|12||Function-Complete Lookahead in Support of Efficient SAT Search Heuristics|  John Franco (University of Cincinnati, USA)   Michal Kouril (University of Cincinnati, USA)   John Schlipf (University of Cincinnati, USA)   Sean Weaver (University of Cincinnati, USA)   Michael Dransfield (National Security Agency, USA)   W. Mark Vanfleet (National Security Agency, USA)  Abstract: Recent work has shown the value of using propositional  SAT solvers, as opposed to pure BDD solvers, for solving many real-world Boolean Satisfiability problems including Bounded Model Checking problems (BMC). We propose a SAT solver paradigm which combines the use of BDDs and search methods to support efficient implementation of complex search heuristics and effective use of early (preeprocessor) learning. We implement many of these ideas in software called SBSAT. We show that SBSAT solves many of the benchmarks tested competitively or substantially faster than state-of-the-art SAT solvers.      SBSAT differs from standard propositional SAT solvers by working directly with non-CNF propositional input, its input format is BDDs. This allows some BDD-style processing to be used as a preprocessing tool. After preprocessing, the BDDs are transformed into state machines (different state machines than the ones used in the original model checking problem) and a good deal of lookahead information is precomputed and memoized. This provides for fast implementation of a new form of look ahead, called local-function-complete lookahead (contrasting with the depth-first lookahead of zChaff [Moskewicz et al. 01] and the breadth-first lookahead of Prover [Stålmarck 94]). SBSAT provides a choice of search heuristics, allowing users to exploit domain-specific experience. We describe SBSAT in this paper.      We use SBSAT in conjunction with the tool bmc from Carnegie Mellon to translate a bounded model checking problem to classical propositional logic and then use SBSAT to solve the bmc output. We show this approach is faster than the now traditional approach of translating the bmc output to CNF clauses and using a CNF-based SAT solver, such as zChaff. The work continues that of [Franco et al. 01] and [Franco et al. 04].               Keywords: Binary Decision Diagrams, Bounded Model Checking, DAG, Satisfiability, Satisfiability Decision Heuristics, State Machines               Categories: B.6.1, F.4.1  
10|12||Improving SAT-based Bounded Model Checking by Means of BDD-based Approximate Traversals|  Gianpiero Cabodi (Politecnico di Torino, Dip. di Automatica e Informatica, Italy)   Sergio Nocco (Politecnico di Torino, Dip. di Automatica e Informatica, Italy)   Stefano Quer (Politecnico di Torino, Dip. di Automatica e Informatica, Italy)  Abstract: Binary Decision Diagrams (BDDs) have been widely  used in synthesis and verification. Boolean Satisfiability (SAT) Solvers, on the other hand, have been gaining ground only recently, with the introduction of efficient implementation procedures. Specifically, while BDDs have been mainly adopted to formally verify the correctness of hardware devices, SAT-based Bounded Model Checking (BMC) has been widely used for debugging.      In this paper, we combine BDD and SAT-based methods to increase the efficiency of BMC. We first exploit affordable BDD-based symbolic approximate reachability analysis to gather information on the state space. Then, we use the collected overestimated reachable state sets to restrict the search space of a SAT-based BMC. This is possible by feeding the SAT solver with a description that is the combination of the original BMC problem with the extra information coming from BDD-based symbolic analysis. We develop specific strategies to appropriately mix BDD and SAT efforts, and to efficiently convert BDD-based symbolic state set representations into SAT-oriented ones.Experimental results prove the validity of our strategy to reduce the amount of variable assignments and variable conflicts generated by SAT solvers, with a subsequent significant performance gain. We gather results with four among the most used SAT solvers, namely Chaff, Limmat, BerkMin, and Siege. We could reduce the number of conflicts up to more than 100x, and the verification time up to 30x.               Keywords: binary decision diagrams (BDDs), bounded model checking (BMC), reachability analysis, satisfiability  (SAT)               Categories: I.6.4, J.4  
10|2|http://www.jucs.org/jucs_10_2|Managing Editor's Column|
10|2||A Message-Optimal Distributed Graph Algorithm:  Partial Precedence Constrained Scheduling|  Pranay Chaudhuri (University of the West Indies, Cave Hill Campus, Barbados)   Hussein Thompson (University of the West Indies, Cave Hill Campus, Barbados)  Abstract: This paper presents a distributed algorithm for the partial precedence constrained scheduling problem. In the classical precedence constrained scheduling problem all the dependent tasks must be scheduled before the task itself can be scheduled. The partial precedence constrained scheduling problem is a generalized version of the original precedence constrained problem in the sense that the number of dependent tasks to be scheduled before the task itself can be scheduled is considered a variable. Using a directed graph to model the partial precedence constrained scheduling problem in which n nodes represent the tasks and e edges represent the precedence constraints, it is shown that the distributed algorithm requires O(e) messages and O(n) units of time and is optimal in communication complexity to within a constant factor.               Keywords: directed graph, distributed algorithm, precedence constraints, scheduling, task               Categories: F.2.2, G.1.0, G.2.2  
10|2||A Rapid Prototyping Environment for Multi-DSP Systems based on Accurate Performance Prediction|  Bernhard Rinner (Graz University of Technology, Austria)   Martin Schmid (Graz University of Technology, Austria)   Reinhold Weiss (Graz University of Technology, Austria)  Abstract: In this paper we present PEPSY, a novel prototyping environment for multi-DSP systems, with the primary goal to support the design and implementation of parallel digital signal processing (DSP) applications subject to various design constraints. Given a specification of the prototyping problem in the form of an application model, a hardware model and mapping constraints, PEPSY automatically maps and schedules the DSP application onto the multi-processor system and synthesizes the complete code for each processor. A detailed performance model of the parallel application is an integral part of PEPSY. Important performance parameters such as computation and communication times as well as memory consumption can be estimated prior to the implementation. PEPSY not only solves the standard mapping and scheduling problem, but it is also able to explore various important design goals for embedded systems and DSP applications such as minimizing memory and power consumption and enforcing the timeliness of tasks. Two complex case studies demonstrate the feasibility of our prototyping environment.               Keywords: data flow, embedded systems, multi-DSP, performance prediction, rapid prototyping, scheduling               Categories: B.8.2, C.3, D.2.2  
10|2||Securing Web-Based Exams|  Olivier Sessink (Wageningen University, Netherlands)   Rik Beeftink (Wageningen University, Netherlands)   Johannes Tramper (Wageningen University, Netherlands)   Rob Hartog (Wageningen University, Netherlands)  Abstract: Learning management systems may offer web-based exam facilities. Such facilities entail a higher risk to exams fraud than traditional paper-based exams. The article discusses security issues with web-based exams, and proposes precautionary measures to reduce the risks. A security model is presented that distinguishes supervision support, software restrictions, and network restrictions. Solutions to security problems are tools to supervise and monitor web-based exams, measures for exam computers with Windows and Linux, and secure network setups in common network architectures. The article intends to raise risk awareness among faculty in higher education, and to help technical staff to implement precautions.               Keywords: assessment, fraud prevention, security, supervision, web-based exam               Categories: K.3.0, K.3.1  
10|3|http://www.jucs.org/jucs_10_3|(Virtual) Communities of Practice within  Modern Organizations - J.UCS Special Issue|
10|3||Managing the KM Trade-Off: Knowledge Centralization versus Distribution|  Matteo Bonifacio (Department of Information Technology, University of Trento, Italy)   Pierfranco Camussone (Department of Economics, University of Trento, Italy)   Chiara Zini (Department of Economics, University of Trento, Italy)  Abstract: KM is more an archipelago of theories and practices rather than a monolithic approach. We propose a conceptual map that organizes some major approaches to KM according to their assumptions on the nature of knowledge. The paper introduces the two major views on knowledge -objectivist, subjectivist - and explodes each of them into two major approaches to KM: knowledge as a market, and knowledge as intellectual capital (the objectivistic perspective), knowledge as mental models, and knowledge as practice (the subjectivist perspective). We argue that the dichotomy between objective and subjective approaches is intrinsic to KM within complex organizations, as each side of the dichotomy responds to different, and often conflicting, needs: on the one hand, the need to maximize the value of knowledge through its replication, on the other hand, the need to keep knowledge appropriate to an increasingly complex and changing environment. Moreover, as a proposal for a deeper discussion, such trade-off will be suggested as the origin of other relevant KM related trade-offs that will be listed. Managing these trade-offs will be proposed as a main challenge of KM.               Keywords: bounded rationality, communities of practice, constructivism, intellectual capital, knowledge markets, mental models, organizational trade-offs, retrospective rationality               Categories: A.0, A.1, H.1.0, H.1.1  
10|3||Against Hierarchy and Chaos Knowledge Coproduction in Nets of Experts|"  David Fuhr (Fraunhofer ISST Berlin, Germany)   Frank Fuchs-Kittowski (Fraunhofer ISST Berlin, Germany)  Abstract: Communities of Practice (CoPs) are among the most promising concepts to promote the genesis, evolution and exchange of knowledge in organizations. However, there is a gap between CoP theories and their implementation in companies. Our case studies of four attempts to introduce CoP-related structures show that the different underlying management principles can systematically be analyzed in at least two dimensions, technology ""vs."" the social and exchange ""vs."" production. We argue that the choice is not contingent, but that emphasis on the social and the creative production of new knowledge leads to more productive structures in the area and in the sense of knowledge intensive services. For the conception of such approaches we show that it is useful to think in terms of another structure between ""teams"" and ""communities"", which we call ""nets of experts"".               Keywords: Deutsche Telekom, Siemens, Volkswagen, WiKo, case study, communities of practice, nets of experts               Categories: K.4.3, K.6.1  "
10|3||Participative Process Introduction: Three Case Studies From the indiGo Project|  Björn Decker (Fraunhofer IESE, Germany)   Jörg Rech (Fraunhofer IESE, Germany)   Klaus-Dieter Althoff (Fraunhofer IESE, Germany)   Andreas Klotz (Fraunhofer IESE, Germany)   Edda Leopold (Fraunhofer IESE, Germany)   Angie Voss (Fraunhofer IESE, Germany)  Abstract: In software engineering, the quality of development and business processes and their models is of utmost importance for (a) the quality of the software products developed and (b) the operational success of the organization. Nevertheless, many organizations neglect these processes and leave the knowledge about them in the heads of their experts. In this paper, we present the indiGo method and platform for eParticipative Process Learning. Furthermore, we present the results of a three case studies for the evaluation of these methods. The results indicate that processes introduced and modeled with process user participation result in process models with higher acceptance and better perceived quality.               Keywords: distributed participative process evolution, eParticipative Process Learning, indigo, process improvement, process inspection, process introduction               Categories: D.2.m, H.5.3, K.4.3  
10|3||Facilitating Knowledge Exchange and Decision Making within Learning Networks|  Dimitris Apostolou (Planet Ernst & Young, Greece)   Grigoris Mentzas (National Technical University of Athens, Greece)   Kostas Baraboutis (Planet Ernst & Young, Greece)   Soumi Papadopoulou (Planet Ernst & Young, Greece)  Abstract: The new knowledge-based economy necessitates increasingly the collaboration between different organisations. Despite the recent upsurge in knowledge management and decision support systems, the vast majority of these systems focus on individual organisations. This article introduces the concept of the Learning Network - inter-organisational structures, formally established to increase the participants' knowledge and innovative capability - and examines the main functions and roles of a Learning Network. It presents an integrated toolkit for supporting knowledge sharing and decision making in Learning Networks that consists of a software system and a methodology. It also briefly presents how the toolkit has been piloted in an automotive cluster. Finally it provides a constructive set of recommendations for using IT to support learning and knowledge sharing in Learning Networks.               Keywords: broker, communities of practice, learning management system, learning networks               Categories: I.2.4, I.2.6  
10|3||Knowledge Nodes: the Reification of Organizational Communities. The Pizzarotti Case Study|"  Roberta Cuel (Department of Computer and Management Sciences, University of Trento, Italy and Department of Computer Sciences, University of Verona, Italy)   Matteo Bonifacio (University of Trento, Italy)   Mirko Grosselle (Department of Computer and Management Sciences, University of Trento, Italy)  Abstract: In our work a new approach, the Distributed Knowledge Management (DKM) approach, is used and organizations are seen as constellations of communities, which ""own"" local knowledge and exchange it through meaning negotiation coordina_ tion processes. In order to reify communities within a DKM system, the concept of Knowledge Node (KN) is used and then applied in a case study: a complex Italian national firm, the Impresa Pizzarotti  [and]  C. S.p.A. All communities of practices are un_ veiled and reified as KNs within a high level architecture of a DKM system. In this paper it is argued that, even if knowledge has to be organized and made useful to the whole organization, there are types of knowledge that must be managed in an autonomous way, and the DKM approach is a good system to deal with coordination/negotiation processes.               Keywords: communities, distributed knowledge management, knowledge nodes               Categories: C.2.4, H.4.2  "
10|3||Supporting Knowledge Creation and Sharing in Communities Based on Mapping Implicit Knowledge|  Jasminko Novak (Fraunhofer Institute for Media Communication, MARS Exploratory Media Lab Schloss Birlinghoven, Germany)   Michael Wurst (University of Dortmund, Dept. of Artificial Intelligence, Germany)  Abstract: This paper discusses some implications of knowledge creation processes in informal social networks for the development of technologies to support them. The principal point of departure are social theories of learning and the theories of organisational knowledge creation. The focus is on models for the exchange and sharing of implicit knowledge. A model of personalised learning knowledge maps is presented as one possible way of addressing the problem of capturing, visualising and sharing implicit knowledge of a community of users. In particular, we discuss how this model resolves one critical shortcoming of the existing socialisation and externalisation approaches: the creation of a semantic representation of a shared understanding of the community which reflects implicit knowledge and incorporates personal views of individual users. Finally, we outline the application to a real-world interdisciplinary Internet platform netzspannung.org.               Keywords: communities of practice, knowledge Management, knowledge discovery, knowledge visualisation, semantic web               Categories: H.3.3, H.5.1, H.5.2, H.5.3  
10|3||Organic Perspectives of Knowledge Management: Knowledge Evolution through a Cycle of Knowledge Liquidization and Crystallization|  Koichi Hori (Research Center for Advanced Science and Technology, University of Tokyo, Japan)   Kumiyo Nakakoji (Research Center for Advanced Science and Technology, University of Tokyo, Japan)   Yasuhiro Yamamoto (Research Center for Advanced Science and Technology, University of Tokyo, Japan)   Jonathan Ostwald (University Corporation for Atmospheric Research, USA)  Abstract: Our research on knowledge management is rooted in the community perspective. We believe that knowledge systems should serve primarily to help people create and share new knowledge. But we also acknowledge the role of stable, structured and reliable information, both as a component of our systems and as a component of the organizations within which we work. The contribution of the paper is a framework for integrating organizational and community perspectives on knowledge management and its computational support. Our basic idea is that knowledge is not a static chunk of information, but rather, knowledge evolves in a cycle of knowledge liquidization and crystallization. The evolving process takes place through the interactions among conceptual worlds, representational worlds, and the real world. This paper first describes the knowledge liquidization and crystallization framework. We then illustrate the approach with three systems, Knowledge Nebula Crystallizer, livingOM, and ART-SHTA.               Keywords: ART-SHTA, Knowledge Nebula Crystallizer, community of practice, knowledge liquidization and crystallization, knowledge management, livingOM, organic perspective               Categories: H.3, H.5.3, H.5.4, I.2.4, I.2.6, K.6  
10|3||OntoShare - An Ontology-based Knowledge Sharing System for virtual Communities of Practice|  John Davies (BTexact, Orion 5-12, Adastral Park, UK)   Alistair Duke (BTexact, Orion 5-12, Adastral Park, UK)   York Sure (Institute AIFB, University of Karlsruhe, Germany)  Abstract: An ontology-based knowledge sharing system OntoShare and its evaluation as part of a case study is described. RDF(S) is are used to specify and populate an ontology, based on information shared between users in virtual communities. We begin by discussing the advantages that use of Semantic Web technology afford in the area of knowledge management tools. The way in which OntoShare supports WWW-based communities of practice is described. Usage of OntoShare semiaautomatically builds an RDF-annotated information resource for the community (and potentially for others also). Observing that in practice the meanings of and relationships between concepts evolve over time, OntoShare supports a degree of ontology evolution based on usage of the system - that is, based on the kinds of information users are sharing and the concepts (ontological classes) to which they assign this information. A case study involving OntoShare was carried out. The evaluation exercise for this case study and its results are described. We conclude by describing avenues of ongoing and future research.               Keywords: knowledge sharing community, semantic web               Categories: H.4.3  
10|3||Communities of Practice: An Integrated Technology Perspective|  Georg Droschl (Hyperwave R & D, Graz, Austria)  Abstract: It has been observed that for a Community of Practice (CoP) to be successful, a significant amount of time shall be devoted to understanding the needs of community members. Furthermore, a tool to support the CoP shall be selected based on the kind of activities that are most important for that CoP. Since many of the tools available today place emphasis on a single type of application such as e-learning or document management, unplanned selection may rise unwanted barriers. In this paper, we examine the benefits of integrating some of the following types of technologies into one single technological platform and their impact on CoP: (1) content- and document Management, (2) collaboration / groupware, (3) web conferencing, and (4) e-learning.               Keywords: communities of practice, e-Learning, enterprise content management, extranet, information technology, intranet, knowledge management, personalization               Categories: A.1, C.2.4, H.4, H.5, K.6  
10|3||Etiquette, Empathy and Trust in Communities of Practice: Stepping-Stones to Social Capital|  Jennifer Preece (University of Maryland Baltimore County, USA)  Abstract: Creating online communities of practice involves much more than creating software. Software houses online communities of practice activities but social interactions also depend on who is involved, what their goals are, their personalities and the community's norms and policies. By paying attention to these sociability issues, community members can influence how their community develops. Norms that lead to good online etiquette, empathy and trust between community members provide stepping-stones for social capital development.               Keywords: communities of practice, etiquette, explicit knowledge, online communities, sociability, social capital, social norms, tacit knowledge, trust               Categories: A.1, H.5, I.7  
10|4|http://www.jucs.org/jucs_10_4|Breakthrough and Challenges in Software Engineering|
10|4||Requirements Negotiation Using Multi-Criteria Preference Analysis|"  Hoh Peter In (Korea University, Korea)   David Olson (University of Nebraska, USA)  Abstract: Many software projects have failed because their requirements were poorly negotiated among stakeholders. Reaching agreements of negotiated requirements among stakeholders who have different concerns, responsibilities, and priorities is quite challenging. Formal (fully-automated) approaches of requirements negotiation require significant efforts of knowledge representation and validation, whereas informal (manual) approaches do not provide systematic methods of requirements negotiation. This paper proposes a novel light-weighted, yet systematic requirements negotiation model, called ""Multi-Criteria Preference Analysis Requirements Negotiation (MPARN)"" to guide stakeholders to evaluate, negotiate, and agree upon alternatives among stakeholders using multi-criteria preference analysis theory. This eight-step MPARN model was applied to requirements gathered for an industrial-academic repository system. The result showed that the MPARN model assisted stakeholders to have unbiased aspects within a requirements negotiation in a light-weighted way and increase stakeholders' levels of cooperation and trust by measuring each stakeholder's preference and value function explicitly through a step-by-step process.               Keywords: WinWin, conflict resolution, inconsistency management, multi-criteria preference analysis, requirements negotiation               Categories: D.2.1, K.6.3  "
10|4||Process Construction and Customization|"  Brian Henderson-Sellers (University of Technology, Australia)   Magdy Serour (University of Technology, Australia)   Tom McBride (University of Technology, Australia)   Cesar Gonzalez-Perez (University of Technology, Australia)   Lorraine Dagher (University of Technology, Australia)  Abstract: Adopting the most appropriate methodology for particular software developments remains a challenge for all industrial IT organizations. Previous attempts to promote a single approach as useful for all occasions has proven untenable. Rather, a combination of a metamodel and a repository of process/method components (""method engineering"") provides a more efficacious approach, particularly as elements of the method engineering approach are able to be automated. In this paper, we advocate the use of method engineering, illustrating its utility by the construction of methodologies at various levels of process capability.               Keywords: design, design methods, software process               Categories: D.2.10, K.6.3  "
10|4||Methodologies for Developing Multi-Agent Systems|  Jorge Gómez-Sanz (Universidad Complutense Madrid, Spain)   Juan Pavón   Abstract: As agent technology has matured with the deployment of a variety of applications, particularly in open and dynamic environments such as the web, several methodologies and tools have been proposed to support software engineers during the development process of such systems. This article takes an overall look at representative agent-oriented methodologies by considering how they support specific agent-related concepts. This serves to identify areas in which this technology has shown its potential to solve new problems, e.g., the ability to manage complexity with an organizational perspective, goal-driven modelling as a way to build robust behaviors for adaptive systems, or the definition of notation and mechanisms to implement high-level interactions and protocols between agents. In order to be fully applicable, the challenge today is the maturity of supporting tools, and new methods for validation and verification of multi-agent systems.               Keywords: agent-oriented methodologies, agent-oriented software engineering, intelligent agents, multi-agent systems, software agents               Categories: D.1, D.2, I.2.11  
10|4||Composition Contracts for Service Interaction|  Luís Filipe Andrade (ATX Software S.A., Portugal)   José Luiz Fiadeiro (University of Leicester, United Kingdom)  Abstract: In this paper, we address some of the challenges raised by the emerging service-oriented computing paradigm in what concerns the ability to define dynamic interactions between core services for flexible and agile business processes. We claim that, from this point of view, service interaction and composition is well beyond the reach of object-oriented and component_ based techniques. We argue instead for the use of architectural modelling techniques that promote the externalization of coordination mechanisms. We show how what we call composition laws and interfaces can be used to define the coordination logic according to which the behavior of a business process can be described in terms of interactions with given partners. These primitives provide a business modelling level that can be mapped onto the specifications that are being proposed for web services, e.g., BPEL, WS-Coordination or WS-Transaction.               Keywords: architectural connectors, composition, coordination, interaction, service-oriented computing, software architecture, web services               Categories: D.2, D.2.10, D.2.11  
10|4||Coupling-based Testing of O-O Programs|  Roger T. Alexander (Colorado State University, USA)   Jeff Offutt (George Mason University, USA)  Abstract: As we move from developing procedure-oriented to O-O programs, the complexity traditionally found in functions and procedures is moving to the connections among components. More faults occur as components are integrated to form higher level aggregates. Consequently, we need to place more effort on testing the connections among components. Although O-O technology provides abstraction mechanisms to build components to integrate, it also adds new compositional relations that can contain faults, which must be found during integration testing. This paper describes new techniques for analyzing and testing the polymorphic relationships that occur in O-O software. The application of these techniques can result in an increased ability to find faults and overall higher quality software.               Keywords: coverage testing, object-oriented software               Categories: D.2.5  
10|4||Two Experiences in Software Dynamics|  Artur Boronat (Polytechnic University of Valencia, Spain)   Jennifer Pérez (Polytechnic University of Valencia, Spain)   José. Á. Carsí (Polytechnic University of Valencia, Spain)   Isidro Ramos (Polytechnic University of Valencia, Spain)  Abstract: This paper presents an outline of a formal model management framework that provides breakthroughs for legacy systems recovery (RELS) and for data migration (ADAM). To recover a legacy system, we use an algebraic approach by using algebras in order to represent the models and manipulate them. RELS also generates automatically a data migration plan that specifies a data transfer process to save all the legacy knowledge in the new recovered data-base. The data migration solution is also introduced as a support for the O-O conceptual schemas evolution where their persistent layers are stored by means of relational databases, in the ADAM tool. Contents and structure of the data migration plans are specified using an abstract data migration language. Our past experience in both projects has guided us towards the model management research field. We present a case study that illustrates the application of both tools.               Keywords: data migration, data reverse engineering, migration patterns, rewriting rules               Categories: D.2.7, D.2.9, E.2, H.1.0, H.2.4  
10|4||Portlets as Web Components: an Introduction|  Oscar Díaz (University of the Basque Country, Spain)   Juan J. Rodríguez (University of the Basque Country, Spain)  Abstract: Today's organisations are increasingly relying on the web to support their operations and the integration of their processes with their partners'. Portlets, which are distributed web components that encapsulate web applications, are considered a promising breakthrough towards this aim. The goal is to define a component model to enable portlets to be easily plugged into web portals. This article outlines the main challenges associated with the definition and use of portlets. As any component model, portlets should have clear interfaces so that they can be plugged into third_party applications. This includes the communication between the consumer of a portlet and the portlet container, as well as the communication between the portlet container and the portlet itself. Two standards, WSRP and JSR168, address these issues. After outlining them, we conclude with some insights into the implementation of portlets.               Keywords: component-based development, portal applications, portlets, web services               Categories: D.2.2, H.4.m  
10|4||A Survey of Multimedia Software Engineering|  Mercedes Amor (University of Malaga, Spain)   Lidia Fuentes (University of Malaga, Spain)   Mónica Pinto (University of Malaga, Spain)  Abstract: Developing multimedia applications entails understanding a variety of advanced technologies, in addition, multimedia programming poses a significant challenge in terms of handling a variety of hardware devices, multimedia formats or communication protocols. Therefore, break-through software engineering technologies should be applied to produce reference architectures able to support ever-changing requirements. In this paper, we first present the challenges that designers must face in multimedia programming, and how current frameworks address them, specially regarding the management of architectural evolution. We then show what breakthrough approaches or technologies can be used to produce more reusable, extensible and open multi-media systems. We focus on presenting the benefits of applying component-based software development and application framework technologies. We also illustrate how to componentize all multimedia functionalities and (re)use the resulting components as COTS in application frame-works. This approach helps to add multimedia capabilities to an application without requiring specific knowledge on multimedia.               Keywords: components, framework, multimedia systems               Categories: D.1, D.1.5, D.2, D.2.13  
10|5|http://www.jucs.org/jucs_10_5|Second Brainstorming Week on Membrane Computing|
10|5||On Determinism of Evolution-Communication P Systems|  Artiom Alhazov (Rovira i Virgili University, Tarragona, Spain and Institute of Mathematics and Computer Science, Academy of Sciences of Moldova, Moldova)  Abstract: It is commonly believed that a significant part of  the computational power of membrane systems comes from their inherent non-determinism. Recently, R. Freund and Gh. Paun have considered deterministic P systems, and formulated the general question whether the computing (generative) capacity of non-deterministic P systems is strictly larger than the (accepting) capacity of their deterministic counterpart.      In this paper, we study the computational power of deterministic P systems in the evolution{communication framework. It is known that, in the generative case, two membranes are enough for universality. For the deterministic systems, we obtain the universality with three membranes, leaving the original problem open.               Keywords: Computational  completeness, Determinism, Membrane computing, P system               Categories: F.4.2, F.4.3  
10|5||Population P Systems|  Francesco Bernardini (University of Sheffield, UK)   Marian Gheorghe (University of Sheffield, UK)  Abstract: This paper introduces a notion of population P systems as a class of tissue P systems where the links between the cells can be modified by means of a specific set of bond making rules. As well as this, cell division rules which introduce new cells into the system, cell differentiation rules which change the set of rules that can be used inside of a cell, and cell death rules which remove cells from the system are also considered by introducing a particular notion of population P systems with active cells. The paper mainly reports universality results for the following models: (a) population P systems where cells are restricted to communicate only by means of the environment but never forming any bond, (b) population P systems with bond making rules with restricted communication rules, (c) population P systems possessing only the cell differentiation operation, and (d) population P systems equipped with cell division rules and bond making rules.               Keywords: Cell bonding, Cell differentiation, Cell division, Membrane computing, Turing computability               Categories: F.1.1, F.4.3  
10|5||P Systems with Symport/Antiport of Rules|"  Matteo Cavaliere (University of Sevilla, Spain)   Daniela Genova (University of South Florida, USA)  Abstract: Moving ""instructions"" instead of ""data"" using transport mechanisms inspired by biology is the basic idea of the computing device presented in this paper. Specifically, we propose a new class of P systems that use both evolution rules and symport/antiport rules. The idea of this kind of systems is the following: during a computation, symbol-objects (the ""data"") evolve using evolution rules, but they cannot be moved, on the other hand, the evolution rules (the ""instructions"") can be moved across the membranes using classical symport/antiport rules. We present a number of results using different combinations of evolution rules (catalytic, non-cooperative) and the weight of the symport/antiport rules. In particular, we show that using non-cooperative rules and antiports of unbounded weight makes it possible to obtain at least the Parikh set of ET0L languages. On the other hand, using catalytic rules (one catalyst) and antiports of weight 2, these system become universal. Several open problems are also presented.               Keywords: Antiport, Communication, Evolution, Membrane computing, P system, Symport               Categories: F.4.2, F.4.3  "
10|5||A Note on Complexity Measures for Probabilistic P Systems|  Andrés Cordón-Franco (University of Sevilla, Spain)   Fernando Sancho-Caparrini (University of Sevilla, Spain)  Abstract: In this paper we present a first approach to the definition of different entropy measures for probabilistic P systems in order to obtain some quantitative parameters showing how complex the evolution of a P system is. To this end, we define two possible measures, the first one to reflect the entropy of the P system considered as the state space of possible computations, and the second one to reflect the change of the P system as it evolves.               Keywords: Entropy, Natural Computing, P systems               Categories: F.1.1, G.2.2, H.1.1  
10|5||Finding the Maximum Element Using P  Systems|  Federico Fontana (University of Verona, Italy)   Giuditta Franco (University of Verona, Italy)  Abstract: A nondeterministic, maximally parallel methodology for finding the maximum element in a set of numerical values is presented, suitable for being implemented on P systems. Several algorithms of maximum search are then developed for different types of such systems, namely using priorities, nested membranes and linked transport, and their performances are evaluated accordingly. The proposed solutions are expected to find application inside membrane models devoted to compute algorithmic procedures in which the greatest element in a data set must be found. Dynamic algorithms for DNA sequence alignment are an example of such procedures.               Keywords: Maximum value, Membrane computing, Natural computing, P systems               Categories: F.1.1, F.2.1  
10|5||On P Systems with Promoters/Inhibitors|  Mihai Ionescu (Rovira i Virgili University, Spain)   Dragos Sburlan (Ovidius University of Constanta, Romania)  Abstract: This article shows how the computational universality can be reached using P systems with object rewriting non-cooperative rules, promoters/inhibitors at the level of rules, and only one catalyst. Both generative and accepting cases are studied. The theoretical issues presented are illustrated by several examples.               Keywords: P Systems, inhibitors, promoters, universality               Categories: F.4.2, F.4.3  
10|5||Simulating the Fredkin Gate with Energy-Based P Systems|"  Alberto Leporati (Universita degli Studi di Milano, Italy)   Claudio Zandron (Universita degli Studi di Milano, Italy)   Giancarlo Mauri (Universita degli Studi di Milano, Italy)  Abstract: Reversibility plays a fundamental role when the possibility to perform computations with minimal energy dissipation is considered. Many papers on reversible computation have appeared in literature, the most famous of which is certainly the work of Bennett on (universal) reversible Turing machines. Here we consider the work of Fredkin and Toffoli on conservative logic, which is a mathematical model that allows to describe computations which reflect some properties of microdynamical laws of physics, such as reversibility and conservation of the internal energy of the physical system used to perform the computations. The model is based upon the Fredkin gate, a reversible and ""conservative"" (according to a definition given by Fredkin and Toffoli) three-input/three-output boolean gate.  In this paper we introduce energy{based P systems as a parallel and distributed model of computation in which the amount of energy manipulated and/or consumed during computations is taken into account. Moreover, we show how energy-based P systems can be used to simulate the Fredkin gate. The proposed P systems that perform the simulations turn out to be themselves reversible and conservative.               Keywords: Energy-based P systems, Fredkin gate, conservative logic, conservativeness, reversibility               Categories: F.1.1, F.4.2  "
10|5||A Java Simulator for Membrane Computing|  Isabel A. Nepomuceno-Chamorro (University of Sevilla, Spain)  Abstract: Membrane Computing is a recent area of Natural Computing, a topic where much work has been done but still much remains to be done. There are some applications which have been developed in imperative languages, like C++, or in declaratives languages, as Prolog, working in the framework of P systems. In this paper, a software tool (called SimCM, from Spanish Simulador de Computacion con Membranas) for handling P systems is presented. The program can simulate basic transition P Systems where dissolution of membranes and priority rules are allowed. The software application is carried out in an imperative and object-oriented language - Java. We choose Java because it is a scalable and distributed language. Working with Java is the first step to cross the border between simulations and a distributed implementation able to capture the parallelism existing in the membrane computing area. This tool is a friendly application which allows us to follow the evolution of a P system easily and in a visual way. The program can be used to move the P system theory closer to the biologist and all the people who wants to learn and understand how this model works.               Keywords: Java, P system, Parallelism, Simulation               Categories: D.0, F.1.1  
10|5||P Systems with Active Membranes and Separation Rules|  Linqiang Pan (Huazhong University of Science and Technology, Hubei, China, and Rovira i Virgili University, Spain)   Tseren-Onolt Ishdorj (Rovira i Virgili University, Spain)  Abstract: The P systems are a class of distributed parallel computing devices of a biochemical type. In this paper, a new definition of separation rules in P systems with active membranes is given. Under the new definition, the efficiency and universality of P systems with active membranes and separation rules instead of division rules are investigated.               Keywords: Distributed computing, Membrane computing, Natural computing               Categories: C.1.4, F.1.1  
10|5||An Efficient Family of P Systems for Packing Items into Bins|  Mario J. Pérez-Jiménez (University of Sevilla, Spain)   Francisco José Romero-Campero (University of Sevilla, Spain)  Abstract: In this paper we present an effective solution to the Bin Paching problem using a family of recognizer P systems with active membranes. The analysis of the solution presented here will be done from the point of view of complexity classes. A CLIPS simulator for recognizer P systems is used to describe a session for an instance of Bin Packing, using a P system from the designed family.               Keywords: Bin Packing problem, CLIPS, Complexity classes, Membrane computing, Recognizer P systems               Categories: F.1.1, F.1.3, F.2.1  
10|6|http://www.jucs.org/jucs_10_6|Beyond the state-of-the-art of Knowledge Management|
10|6||A Systematic Approach for Knowledge Audit Analysis: Integration of Knowledge Inventory, Mapping and Knowledge Flow Analysis|  S. Y. Choy (The Hong Kong Polytechnic University, Hong Kong)   W. B. Lee (The Hong Kong Polytechnic University, Hong Kong)   C. F. Cheung (The Hong Kong Polytechnic University, Hong Kong)  Abstract: Knowledge audit lays a concrete foundation for any knowledge management programs. The central topic of this paper is to integrate various knowledge audit related techniques into pre-audit preparation, in-audit process and post-audit analysis in a systematic manner. Culture assessment, in the form of surveys and radar charts, along with orientation program make up the pre-audit preparation. Structured interviews are carried out to capture process-critical knowledge. Knowledge inventory, knowledge maps and knowledge flow analysis compose of post-audit analysis. Knowledge inventory is then built for stocktaking knowledge assets and thus revealing the key knowledge assets by measuring them against four performance criteria. Knowledge mapping together with social network analysis are to show the knowledge exchange path and make the key knowledge suppliers and customers visible. They are then being further applied into knowledge flow analysis, which serves to reveal the strength and weakness of the current knowledge flow. A case study of applying the designed instruments in the Engineering Division of the Hong Kong Dragon Airlines Limited and the related analysis are also present in this paper.               Keywords: knowledge audit, knowledge flow analysis, knowledge inventory, knowledge map, social network analysis               Categories: A.  
10|6||Facilitating Knowledge Communication through Joint Interactive Visualization|  Martin J. Eppler (University of Lugano, Switzerland)  Abstract: This paper presents further research findings on the use of software-based, collaborative visual communication tools for the transfer and creation of professional knowledge in organizational decision making contexts. The paper begins by describing typical knowledge communication situations and summarizes dominating problems in these contexts. It then reports on the real-life experiences in using three visual knowledge communication tools, namely the OnTrack visual protocol tool, the Parameter Ruler application, and the Synergy Map. The application experiences with these tools in four companies show that they can reduce some of the discussed problems. Their main benefits are focus, coordination, documentation, consistency, accountability and traceability. Their major improvement areas are accessibility and flexibility. Implications for further research and for further tool developments are highlighted.               Keywords: joint interaction, knowledge communication, knowledge disavowal, knowledge evasion, knowledge refusal, visualization               Categories: H.5.3, J.5  
10|6||SELaKT - Social Network Analysis as a Method for Expert Localisation and Sustainable Knowledge Transfer|  Tobias Mueller-Prothmann (Free University Berlin, Germany)   Ina Finke (Fraunhofer IPK, Institute for Production Systems and Design Technology, Germany)  Abstract: In many organisations, conservation of specialised expertise is picked out as a central theme only after experienced members have already left. The paper presents the SELaKT method, a method for Sustainable Expert Localisation and Knowledge T ransfer based on social network analysis (SNA). It has been developed during a project co-operation between the Department of Information Science at the Institute for Media and Communication Studies, Free University Berlin, and the Fraunhofer Institute for Production Systems and Design Technology IPK, Berlin. The SELaKT method uses recent insights into network analysis and pragmatically adapts SNA to suit organisational practice. Thus it provides a strategic tool to localise experts, to identify knowledge communities and to analyse the structure of knowledge flows within and between organisations. The SELaKT method shows its advances and increasing relevance for practical use by integration of specific organisational conditions and requirements into the process of analysis.               Keywords: applied research, collaboration, communities of practice, distributed knowledge management, expert localisation, implementation, knowledge networks, knowledge sharing, social network analysis, strategies, sustainability               Categories: A.0, A.1, H.3.0, J.4  
10|6||Knowledge Management Analysis of the Research & Development & Transference Process at HEROs: a Public University Case|  Jon Landeta Rodríguez (University of the Basque Country UPV/EHU, Spain)   Arturo Rodríguez Castellanos (University of the Basque Country UPV/EHU, Spain)   Stanislav Y. Ranguelov (University of the Basque Country UPV/EHU, Spain)  Abstract: In Higher Education and Research Organisations (HEROs), one of the most important activities in the R & D process is the effective management of knowledge transference. A correct analysis and diagnosis of that process through knowledge management methodology is essential for the correct orientation of organisation strategy. The aim of this paper is to describe the analysis carried out in order to diagnose the research  &  development  &  transference (R & D & T) activities at a public university in Spain. The diagnosis analyses the key phases in the knowledge transference process, because these different stages define important implications for the monitoring of the intellectual capital and the organisation s performance. Also with in the diagnostic analysis preformed here an methodological innovation is introduced related with the cause and effect relations of the knowledge collaboration and a process witch deals mainly with intangibles.               Keywords: Knowledge Management at Universities, Process Analysis, Research and Development Management               Categories: A.0, A.1, E.1, K.4  
10|6||Knowledge Integration as a Source of Competitive Advantage in Large Croatian Enterprises|  Niksa Alfirevic (Faculty of Economics, University of Split, Croatia)   Domagoj Racic (Judge Institute of Management, Cambridge University, UK and The Institute of Economics, Croatia)  Abstract: The paper discusses the integration of codified and tacit knowledge as a potential source of competitive advantage. The management of explicit knowledge is viewed through knowledge management practices, whereas the management of tacit knowledge is conceptualised through strategic human resource management. The paper presents the empirical results of testing of low- and high-synergy models of knowledge integration on a representative sample of large Croatian enterprises.               Keywords: competitive advantage, knowledge integration, knowledge management, strategic human resource management               Categories: A., H.  
10|6||Semantic-based Approach to Task Assignment of Individual Profiles|  Simona Colucci (Politecnico di Bari, Italy)   Tommaso Di Noia (Politecnico di Bari, Italy)   Eugenio Di Sciascio (Politecnico di Bari, Italy)   Francesco M. Donini (Universita della Tuscia, Italy)   Marina Mongiello (Politecnico di Bari, Italy)   Giacomo Piscitelli (Politecnico di Bari, Italy)  Abstract: This paper is focused on the problem of skill matching in an organizational context. We endow the classical weighted bipartite graph approach with a semantic based assignment of arcs weight and we describe a skill matching system implementing the approach. The system takes curricula and project specifications as inputs and extracts from them individual profiles respectively offered and requested, according to an ontology modeling skill management context. The suitability of each available individual to each task to assign is evaluated based on an algorithm whose returned scores are used as arc weights. As a result the semantics of profile descriptions is taken into account in the assignment process.               Keywords: Description Logics, knowledge elicitation, skill matching               Categories: H.3.3, I.2.4, K.6.1  
10|6||A Framework for the Successful Introduction of KM Using CBR and Semantic Web Technologies|  Mark Hefke (FZI Research Center for Information Technologies at the University of Karlsruhe, Germany)  Abstract: This document describes our current work on developing a framework which supports organizations in the successful implementation of Knowledge Management (KM). It follows the holistic approach of a KM introduction by considering technological, organizational and human aspects, as well as the organizational culture in equal measure. The framework provides recommendations based on Case-Based Reasoning (CBR) techniques and Semantic Web technologies. It supports the four processes of Aamodt  &  Plaza's CBR-cycle. The best practice cases for a successful KM implementation are structured by the use of an ontology.               Keywords: case-based reasoning, knowledge management, semantic Web               Categories: H.3.3  
10|6||"An Investigation into Sharing Metadata:  ""I'm not thinking what you are thinking"""|  Simone Stumpf (University College London, United Kingdom)   Janet McDonnell (University College London, United Kingdom)  Abstract: A small collection of metadata concepts has been jointly negotiated among a group of specialists to be relevant for classifying data used in their field. A series of comparisons are made to test levels of agreement between individuals when these concepts are used to tag data items. Inter-coder agreement measures are presented for a range of data sets and individuals with varying relationships to the data sets. The implications of the results for the use of metadata as a supporting mechanism for knowledge sharing are discussed.               Keywords: agreement, knowledge sharing, metadata               Categories: H.1, H.3, H.4  
10|7|http://www.jucs.org/jucs_10_7|8th Brazilian Symposium on Programming Languages - J.UCS Special Issue|
10|7||Total Functional Programming|  D. A. Turner (Middlesex University, UK)  Abstract: The driving idea of functional programming is to make programming more closely related to mathematics. A program in a functional language such as Haskell or Miranda consists of equations which are both computation rules and a basis for simple algebraic reasoning about the functions and data structures they define. The existing model of functional programming, although elegant and powerful, is compromised to a greater extent than is commonly recognised by the presence of partial functions. We consider a simple discipline of total functional programming designed to exclude the possibility of non-termination. Among other things this requires a type distinction between data, which is finite, and codata, which is potentially infinite.               Keywords: functional programming               Categories: D.1.1  
10|7||Partial Categorical Multi-Combinators and Church-Rosser Theorems|  Rafael Dueire Lins (Departamento de Eletronica e Sistemas, Universidade Federal de Pernambuco, Brazil)  Abstract: Categorical Multi-Combinators form a rewriting system developed with the aim of providing efficient implementations of lazy functional languages. The core of the system of Categorical Multi-Combinators consists of only four rewriting laws with a very low pattern-matching complexity. This system allows the equivalent of several -reductions to be performed at once, as functions form frames with all their arguments. Although this feature is convenient for most cases of function application it does not allow partially parameterised functions to fetch arguments. This paper presents Partial Categorical Multi-Combinators, a new rewriting system, which removes this drawback.               Keywords: categorical combinators, explicit substitutions, functional programming               Categories: D.3.2, F.4.1  
10|7||A Modular Rewriting Semantics for CML|  Fabricio Chalub (Universidade Federal Fluminense, Brazil)   Christiano Braga (Universidade Federal Fluminense, Brazil)  Abstract: This paper presents a modular rewriting semantics (MRS) specification for Reppy's Concurrent ML (CML), based on Peter Mosses' modular structural operational semantics specification for CML. A modular rewriting semantics specification for a programming language is a rewrite theory in rewriting logic written using techniques that support the modular development of the specification in the precise sense that every module extension is conservative. We show that the MRS of CML can be used to interpret CML programs using the rewrite engine of the Maude system, a high-performance implementation of rewriting logic, and to verify CML programs using Maude's built-in LTL model checker. It is assumed that the reader is familiar with basic concepts of structural operational semantics and algebraic specifications.               Keywords: Concurrent ML, modularity, rewriting logic, semantics of programming languages               Categories: F.3.1, F.3.2  
10|7||A Relational Model for Component Interconnection|  Marco Antonio Barbosa (Dep. Informática, Universidade do Minho, Portugal)   Luís Soares Barbosa (Dep. Informática, Universidade do Minho, Portugal)  Abstract: The basic motivation of component based development is to replace conventional programming by the composition of reusable off-the-shelf units, externally coordinated through a network of connecting devices, to achieve a common goal. This paper introduces a new relational model for software connectors and discusses some preliminary work on its implementation in HASKELL. The proposed model adopts a coordination point of view in order to deal with components' temporal and spatial decoupling and, therefore, to provide support for looser levels of inter-component dependency and effective external control.               Keywords: coalgebra, coordination models, relations               Categories: D.3.1, F.3.2  
10|7||Tactics for Remote Method Invocation|  Fernando Magno Quintão Pereira (Computer Science Department, Federal University of Minas Gerais, Brazil)   Marco Tulio de Oliveira Valente (Computer Science Department, Federal University of Minas Gerais, Brazil)   Wagner Salazar Pires (Computer Science Department, Federal University of Minas Gerais, Brazil)   Roberto da Silva Bigonha (Computer Science Department, Federal University of Minas Gerais, Brazil)   Mariza Andrade da Silva Bigonha (Computer Science Department, Federal University of Minas Gerais, Brazil)  Abstract: Conventional object oriented middleware platforms rely on the notion of remote interfaces to describe distributed services. This notation is very similar to the one currently used in centralized systems, which increases the productivity of programming. This paper is founded in the observation that remote interfaces foster a programming model that ignores the differences between local and remote interactions. This can result in distributed applications with poor performance, that are not robust to failures, and that can not scale beyond local networks. Therefore, we propose that remote interfaces should be accompanied by the specification of tactics that deal with typical events in distributed computing, such as concurrency, partial failures and high latencies. The paper proposes a tactics definition language and describes the implementation of a middleware system that supports this language.               Keywords: distributed programming, middleware, tactics definition language               Categories: C.2.4, D.1.5, D.3.3  
10|7||Implementing Coordinated Error Recovery for Distributed Object-Oriented Systems with AspectJ|  Fernando Castor Filho (State University of Campinas, Brazil)   Cecília Mary F. Rubira   Abstract: Exception handling is a very popular technique for incorporating fault tolerance into software systems. However, its use for structuring concurrent, distributed systems is hindered by the fact that the exception handling models of many mainstream object-oriented programming languages are sequential. In this paper we present an aspect-based framework for incorporating concurrent exception handling in Java programs. The framework has been implemented in AspectJ, a general purpose aspect-oriented extension to Java. Our main contribution is to show that AspectJ is useful for implementing the concerns related to concurrent exception handling and to provide a useful tool to developers of distributed, concurrent fault-tolerant applications.               Keywords: aspect-oriented programming, coordinated atomic actions, distributed programming, exception handling, separation of concerns               Categories: D.2, D.3, D.3.3  
10|7||Snippets: Support for Drag-and-Drop Programming in the Redwood Environment|  Brian T. Westphal (University of Nevada, USA)   Frederick C. Harris, Jr. (University of Nevada, USA)   Sergiu M. Dascalu (University of Nevada, USA)  Abstract: This paper presents an overview of the Redwood programming environment and details one of its key features, snippets. Through snippets, developers can both make use of a variety of predefined programming constructs and build their own reusable program components. Language-independent, snippets are descriptions of program parts that can be as simple as an assignment statement or as complex as a sophisticated optimization algorithm. In Redwood, snippets also provide support for a distinguishing facility of visual environments: direct manipulation via drag-and-drop. An example of working with snippets, including snippet definition, visualization, customization, and mapping to code is also presented in the paper.               Keywords: Redwood, design tool, drag-and-drop, programming environment, snippets, software development, visual programming               Categories: D.1.5, D.1.7, D.2.10, D.2.2, D.2.6, H.5.2  
10|7||MetaJ: An Extensible Environment for Metaprogramming in Java|  Ademir Alvarenga de Oliveira (Federal University of Minas Gerais, Brazil)   Thiago Henrique Braga (Federal University of Ouro Preto, Brazil)   Marcelo de Almeida Maia (Federal University of Ouro Preto, Brazil)   Roberto da Silva Bigonha (Federal University of Minas Gerais, Brazil)  Abstract: MetaJ is a programming environment that supports metaprogramming in the Java language. The environment is designed to allow extensions via plug-ins which permit the user to manipulate programs written in different languages. This facilities concern only syntactic aspects. Semantics aspects are language-dependent and are not addressed here, but could be tackled with other tools, which could even be layered on the top of MetaJ. Accessing patterns by example inside ordinary Java programs is a major feature of MetaJ programming. This paper presents a conceptual description of the environment, implementation details and three applications on analysis, restructuring and generation of programs.               Keywords: Java, generative programming, metaprogramming, metaprogramming tools, object-oriented frameworks, program transformation, refactoring               Categories: D.1.5, D.2.6, D.3.3  
10|7||LuaInterface: Scripting the .NET CLR with Lua|  Fabio Mascarenhas (Pontifical Catholic University of Rio de Janeiro, Brazil)   Roberto Ierusalimschy (Pontifical Catholic University of Rio de Janeiro, Brazil)  Abstract: We present LuaInterface in this paper, a library for scripting the .NET CLR with Lua. The .NET Common Language Runtime (CLR) aims to provide interoperability among objects written in several different languages. LuaInterface gives Lua the capabilities of a full CLS consumer. The Common Language Specification (CLS) is a subset of the CLR specification, with rules for language interoperability, and CLS consumers are languages that can use CLS_compliant libraries. LuaInterface lets Lua scripts instantiate and use CLR objects, and even create new CLR types. CLR applications may also use LuaInterface to embed a Lua interpreter, using Lua scripts to extend the application. LuaInterface is implemented as a bridge between the Lua interpreter and the CLR. The implementation required no changes to the interpreter, and the level of integration is the same that a Lua compiler would have.               Keywords: language interoperability, reflection, scripting               Categories: D.3.3  
10|7||Coroutines in Lua|  Ana Lúcia de Moura (Catholic University of Rio de Janeiro, Brazil)   Noemi Rodriguez (Catholic University of Rio de Janeiro, Brazil)   Roberto Ierusalimschy (Catholic University of Rio de Janeiro, Brazil)  Abstract: After a period of oblivion, a renewal of interest in coroutines is being observed. However, most current implementations of coroutine mechanisms are restricted, and motivated by particular uses. The convenience of providing true coroutines as a general control abstraction is disregarded. This paper presents and discusses the coroutine facilities provided by the language Lua, a full implementation of the concept of asymmetric coroutines. It also shows that this powerful construct supports easy and succint implementations of useful control behaviors.               Keywords: Lua language, control structures, coroutines, generators               Categories: D.3.3  
10|8|http://www.jucs.org/jucs_10_8|Formal Concept Analysis: Theory and Applications|
10|8||On the Intractability of Computing the Duquenne-Guigues Base|  Sergei O. Kuznetsov (All-Russia Institute for Scientific and Technical Information VINITI, Russia)  Abstract: Implications of a formal context (G, M, I) obey Armstrong rules, which allows for definition of a minimal (in the number of implications) implication base, called Duquenne-Guigues or stem base in the literature. A long-standing problem was that of an upper bound for the size of a stem base in the size of the relation I. In this paper we give a simple example of a relation where this boundary is exponential. We also prove #P-hardness of the problem of determining the size of the stem base (i.e., the number of pseudo-intents).               Keywords: computational complexity, implication base               Categories: F.2, H.2  
10|8||Breadth First Search Graph Partitions and Concept Lattices|  James Abello (DIMACS, Rutgers University, USA)   Alex J. Pogel (New Mexico State University, USA)   Lance Miller (University of Connecticut, USA)  Abstract: We apply the graph decomposition method known as rooted level aware breadth first search to partition graph-connected formal contexts and examine some of the consequences for the corresponding concept lattices. In graph-theoretic terms, this lattice can be viewed as the lattice of maximal bicliques of the bipartite graph obtained by symmetrizing the object-attribute pairs of the input formal context. We find that a rooted breadth-first search decomposition of a graph-connected formal context leads to a closely related partition of the concept lattice, and we provide some details of this relationship. The main result is used to describe how the concept lattice can be unfolded, according to the information gathered during the breadth first search. We discuss potential uses of the results in data mining applications that employ concept lattices, specifically those involving association rules.               Keywords: Bipartite Graph, Breadth First Search, formal concept analysis               Categories: G.2.2, G.2.3  
10|8||Conflict Avoidance in Additive Order Diagrams|  Bernhard Ganter (Algebra Institute, Dresden University of Technology, Germany)  Abstract: Additive diagrams are used by several interactive lattice layouters. We discuss a method to avoid unwanted incidences when working with additive diagrams.               Keywords: automatic diagram layout, lattice diagrams               Categories: H., H.3.m  
10|8||Modelling Lexical Databases with Formal Concept Analysis|  Uta Priss (School of Computing, Napier University, UK)   L. John Old (School of Computing, Napier University, UK)  Abstract: This paper provides guidelines and examples for visualising lexical relations using Formal Concept Analysis. Relations in lexical databases often form trees, imperfect trees or poly-hierarchies which can be embedded into concept lattices. Many-to-many relations can be represented as concept lattices where the values from one domain are used as the formal objects and the values of the other domain as formal attributes. This paper further discusses algorithms for selecting meaningful subsets of lexical databases, the representation of complex relational structures in lexical databases and the use of lattices as basemaps for other lexical relations.               Keywords: Formal Concept Analysis, lexical databases, semantic relations               Categories: I.2.4  
10|8||Exploiting the Potential of Concept Lattices for Information Retrieval with CREDO|  Claudio Carpineto (Fondazione Ugo Bordoni, Italy)   Giovanni Romano (Fondazione Ugo Bordoni, Italy)  Abstract: The recent advances in Formal Concept Analysis (FCA) together with the major changes faced by modern Information Retrieval (IR) provide new unprecedented challenges and opportunities for FCA-based IR applications. The main advantage of FCA for IR is the possibility of creating a conceptual representation of a given document collection in the form of a document lattice, which may be used both to improve the retrieval of specific items and to drive the mining of the collection's contents. In this paper, we will examine the best features of FCA for solving IR tasks that could not be easily addressed by conventional systems, as well as the most critical aspects for building FCA-based IR applications. These observations have led to the development of CREDO, a system that allows the user to query Web documents and see retrieval results organized in a browsable concept lattice. This is the second major focus of the paper. We will show that CREDO is especially useful for quickly locating the documents corresponding to the meaning of interest among those retrieved in response to an ambiguous query, or for mining the contents of the documents that reference a given entity. An on-line version of the system is available for testing at http://credo.fub.it.               Keywords: CREDO, concept lattices, information retrieval, web mining               Categories: H.3.3, H.5.4  
10|8||Galois Lattice Theory for Probabilistic Visual Landmarks|  Emmanuel Zenou (SUPAERO & LAAS­CNR, France)   Manuel Samuelides (SUPAERO & LAAS­CNR, France)  Abstract: This paper presents an original application of the Galois lattice theory, the visual landmark selection for topological localization of an autonomous mobile robot, equipped with a color camera. First, visual landmarks have to be selected in order to characterize a structural environment. Second, such landmarks have to be detected and updated for localization. These landmarks are combinations of attributes, and the selection process is done through a Galois lattice. This paper exposes the landmark selection process and focuses on probabilistic landmarks, which give the robot thorough information on how to locate itself. As a result, landmarks are no longer binary, but probabilistic. The full process of using such landmarks is described in this paper and validated through a robotics experiment.               Keywords: Galois lattices, autonomous mobile robotics, computer vision, concept lattices, formal concept analysis., localization, orientation, visual landmarks               Categories: H.3.7, H.5.4  
10|9|http://www.jucs.org/jucs_10_9|Managing Editor's Column|
10|9||Incremental Maintenance of Data Warehouses Based on Past Temporal Logic Operators|  Sandra de Amo (Universidade Federal de Uberlandia, Brazil)   Mírian Halfeld Ferrari Alves (Université François Rabelais  LI/Antenne de Blois, France)  Abstract: We see a temporal data warehouse as a set of temporal views defined in the past fragment of the temporal relational algebra extended with set-valued attributes and aggregation. This paper proposes an incremental maintenance method for temporal views that allows improvements over the re-computation from scratch. We introduce a formalism for temporal data warehouse specification that summarizes information needed for its incremental maintenance. According to this formalism, a temporal data warehouse W is a pair of two sets of views : the materialized component and the virtual component. The materialized component of W represents the set of views physically stored in the warehouse. The virtual component of W is a set of non-temporal expressions involving only relations kept in the materialized component. Several features of our approach make it especially attractive as a maintenance method for warehouses: (a) there is no need for storing the entire history of source databases, (b) maintenance of the temporal data warehouse is reduced to maintaining the (non-temporal) materialized component, and (c) the materialized component is self-maintainable. We build a uniform algorithm by combining two previously unrelated techniques based on auxiliary views. Our method is sufficiently general so that it can be easily adapted to treating databases with complex-valued attributes.               Keywords: self-maintenance, temporal data warehouse, temporal databases, temporal logic, temporal relational algebra               Categories: F.4.1, H.2, H.2.3, H.2.5  
10|9||"X-Global: a System for the ""Almost Automatic"" and Semantic Integration of XML Sources at Various Flexibility Levels"|"  Pasquale De Meo (DIMET, Università ""Mediterranea"" di Reggio Calabria, Italy)   Giorgio Terracina (Dipartimento di Matematica, Università della Calabria,, Italy)   Domenico Ursino (DIMET, Università ""Mediterranea"" di Reggio Calabria, Italy)  Abstract: In this paper we propose X-Global, a novel, almost automatic and semantic system for integrating a set of XML sources. X-Global is parametric w.r.t. the flexibility level against which the integration task is performed, indeed, it can operate on rigid contexts, when two concepts are merged only if they have exactly the same meaning, as well as on flexible and informal situations, when two concepts are merged if they have close, even if not exactly identical, meanings. In this paper we describe the system in all details, illustrate various theoretical results as well as several experiments we have carried out for verifying its performance. Finally, we examine related literature and point out similarities and differences between X-Global and several other approaches already proposed in the past.               Keywords: Information Source Integration, Interschema Property, XML               Categories: H.2.4, H.3.4  "
10|9||What we Expect from Digital Libraries|  Heinz Dreher (Institute for Information Systems and Computer Media (IICM), Graz, University of Technology, Austria)   Harald Krottmaier (Institute for Information Systems and Computer Media IICM, Graz, University of Technology, Austria)   Hermann Maurer (Institute for Information Systems and Computer Media IICM, Graz, University of Technology, Austria)  Abstract: Digital Libraries have been the subject of more than a decade of attention by researchers and developers, and yet in all this time the implementations have not matched the promises. By far the majority of systems have concentrated on content and provided limited or basic functions for users. In this article we offer a new look at what can be expected from a digital library system based on contemporary developments in Information and Communications Systems and Technology. First, we sketch out the basic functions which are provided to support finding and accessing material by a reader. Next we explain some extended functions which support the use and re-use of documents - links and annotations - and the need to support learners in addition to readers and writers. Finally, we present our visions for a modern digital library and e-Learning portal system which includes for example intelligent and conceptual search support including results visualization, white lists, and adaptive user interfaces.        Keywords: Hyperwave, active document, annotation, black list, conceptual search, digital library, e-Learning, links to the future, portal-systems, repositories of knowledge, searching, visualization, white list               Categories: H.3, H.4, H.5  
10|9||Object-Oriented Embedded System Development Based on Synthesis and Reuse of OO-ASIPs|  Maziar Goudarzi (Sharif University of Technology, I.R.Iran and University of Cambridge, UK)   Shaahin Hessabi (Sharif University of Technology, I.R.Iran, Iran)   Alan Mycroft (University of Cambridge, UK)  Abstract: We present an embedded_system design flow, discuss its details, and demonstrate its advantages. We adopt the object_oriented methodology for the system_level model because software dominates hardware in embedded systems and the object_oriented methodology is already established for software design and reuse. As the building_block of system implementation, we synthesise application_specific processors that are reusable, through programming, for several related applications. This addresses the high cost and risk of manufacturing specialised hardware tailored to only a single application. Both the processor and its software are generated from the model of the system by the synthesis and compilation procedures provided. We observe that the key point in object_oriented methodology is the class library, and hence, we implement methods of the class library as the instruction_set of the processor. This allows the processor to be synthesised just once, but, by programming, to be reused several times and specialised to new applications that use the same class library. An important point here is that the processor allows its instructions to be selectively overridden by software routines, this not only allows augmentation of processor capabilities in software, but also enables a structured approach to make software patches to faulty or outdated hardware. A case study illustrates application of the methodology to various applications modelled on top of a common basis class library, and moreover, demonstrates new application_specific opportunities in power management (and area_management for FPGA implementations) resulting from the structure of the processor based on de_activation of unused features.               Keywords: application_specific instruction processors, embedded system design, hardware/software synthesis, highlevel synthesis, object_oriented system design               Categories: C.3, C.5.4, J.6  
10|9||Symbolic Approach to the Analysis of Security Protocols|  Stéphane Lafrance (École Polytechnique de Montréal, Canada)  Abstract: The specification and validation of security protocols often requires viewing function calls - like encryption/decryption and the generation of fake messages - explicitly as actions within the process semantics. Following this approach, this paper introduces a symbolic framework based on value-passing processes able to handle symbolic values like fresh nonces, fresh keys, fake addresses and fake messages. The main idea in our approach is to assign to each value-passing process a formula describing the symbolic values conveyed by its semantics. In such symbolic processes, called constrained processes, the formulas are drawn from a logic based on a message algebra equipped with encryption, signature and hashing primitives. The symbolic operational semantics of a constrained process is then established through semantic rules updating formulas by adding restrictions over the symbolic values, as required for the process to evolve. We then prove that the logic required from the semantic rules is decidable. We also define a bisimulation equivalence between constrained processes, this amounts to a generalisation of the standard bisimulation equivalence between (non-symbolic) value-passing processes. Finally, we provide a complete symbolic bisimulation method for constructing the bisimulation between constrained processes.               Keywords: bisimulation, equivalence-checking, formal methods, noninterference, process algebra, protocols, symbolic               Categories: C.2.2, C.2.4  
10|9||Fast Two-Stage Lempel-Ziv Lossless Numeric Telemetry Data Compression Using a Neural Network Predictor|  Rajasvaran Logeswaran (Multimedia University, Malaysia)  Abstract: Lempel-Ziv (LZ) is a popular lossless data compression algorithm that produces good compression performance, but suffers from relatively slow processing speed. This paper proposes an enhanced version of the Lempel-Ziv algorithm, through incorporation of a neural pre-processor in the popular predictor-encoder implementation. It is found that in addition to the known dramatic performance increase in compression ratio that multi-stage predictive techniques achieve, the results in this paper show that overall processing speed for the multi-stage scheme can increase by more than 15 times for lossless LZ compression of numeric telemetry data. The benefits of the proposed scheme may be expanded to other areas and applications.               Keywords: Lempel-Ziv, lossless compression, neural networks, prediction, two-stage               Categories: E.2, H.3.m  
10|9||The Tiling of the Hyperbolic 4D Space by the 120-cell is Combinatoric|  Maurice Margenstern (Laboratoire d'Informatique Théorique et Appliquée, EA 3097, Universite de Métz, France)  Abstract: The splitting method was defined by the author in [Margenstern 2002a], [Margenstern 2002d]. It is at the basis of the notion of combinatoric tilings. As a consequence of this notion, there is a recurrence sequence which allows us to compute the number of tiles which are at a fixed distance from a given tile. A polynomial is attached to the sequence as well as a language which can be used for implementing cellular automata on the tiling.        The goal of this paper is to prove that the tiling of hyperbolic 4D space is combinatoric. We give here the corresponding polynomial and, as the first consequence, the language of the splitting is not regular, as it is the case in the tiling of hyperbolic 3D space by rectangular dodecahedra which is also combinatoric.               Keywords: cellular automata, hyperbolic plane               Categories: F.1.1, F.1.3  
10|9||Full Hash Table Search using Primitive Roots of the Prime Residue Group Z/p|  Joerg R. Muehlbacher (FIM, Johannes Kepler University of Linz, Austria)  Abstract: After a brief introduction to hash-coding (scatter storage) and discussion of methods described in the literature, it is shown that for hash tables of length p > 2, prime, the primitive roots r of the cyclic group Z/p of prime residues mod p can be used for a simple collision strategy q(p,i) = ri mod p for fi(k) = f0(k) + q(p,i) mod p. It is similar to the strategy which uses quadratic residues q(p,i) = i2 mod p in avoiding secondary clustering, but reaches all table positions for probing. A table of n primes for typical table lengths and their primitive roots is added. In cases where r = 2j is such a primitive root, the collision strategy can be implemented simply by repeated shifts to the left (by j places in all).  To make the paper self-contained and easy to read, the relevant definitions and the theorems used from the Theory of Numbers are included in the paper.               Keywords: collision strategy, cyclic group mod p, full table scatter storage techniques, hash tables, primitive roots of the prime residue group mod p               Categories: E.2, G.4  
10|9||Rewriting Tissue P Systems|  Madhu Mutyam (International Institute of Information Technology, India)   Vaka Jaya Prakash (Department of Computer Science and Engineering, Indian Institute of Technology Madras, India)   Kamala Krithivasan (Department of Computer Science and Engineering, Indian Institute of Technology Madras, India)  Abstract: By considering string-objects and rewriting rules, we propose a variant of tissue P systems, namely, rewriting tissue P systems. We show the computational efficiency of rewriting tissue P systems by solving the Satisfiability and the Hamiltonian path problems in linear time. We study the computational capacity of rewriting tissue P systems and show that rewriting tissue P systems with at most two cells and four states are computationally universal. We also show the universality result of rewriting tissue P systems with at most one cell and five states. Finally we propose some new directions for future work.               Keywords: Tissue P systems, computational universality, matrix grammars, rewriting tissue P systems               Categories: F.4.2, F.4.3  
10|9||A Formal Model of Forth Control Words in the Pi-Calculus|  James F. Power (National University of Ireland, Ireland)   David Sinclair (Dublin City University, Ireland)  Abstract: In this paper we develop a formal specification of  aspects of the Forth programming language. We describe the operation of the Forth compiler as it translates XSForth control words, dealing in particular with the interpretation of immediate words during compilation. Our goal here is to provide a basis for the study of safety properties of embedded systems, many of which are constructed using Forth or Forth-like languages. To this end we construct a model of the Forth compiler in the -calculus, and have simulated its execution by animating this model using the Pict programming language.               Keywords: Forth, operational semantics, picalculus               Categories: D.3.1, D.3.3, F.3.2  
10|9||On the Decomposition of Boolean Functions via Boolean Equations|  Sergiu Rudeanu (Faculty of Mathematics and Computer Science, The University of Bucharest, Romania)  Abstract: We propose an alternative solution to the problems solved in [1]. Our aim is to advocate the efficiency of algebraic methods for the solution of the Boolean equations which occur in the decomposition of Boolean functions.               Keywords: Boolean decomposition, Boolean equation, Boolean function               Categories: E.2, G.2  
10|9||ADDS: A Document-Oriented Approach for Application Development|  José Luis Sierra (Dpto.Sistemas Informáticos y Programación, Fac. Informática, Universidad Complutense, Spain)   Alfredo Fernández-Valmayor (Dpto.Sistemas Informáticos y Programación, Fac. Informática, Universidad Complutense, Spain)   Baltasar Fernández-Manjón (Dpto.Sistemas Informáticos y Programación, Fac. Informática, Universidad Complutense, Spain)   Antonio Navarro (Dpto.Sistemas Informáticos y Programación, Fac. Informática, Universidad Complutense, Spain)  Abstract: This paper proposes a document oriented paradigm to the development of content-intensive, document-based applications (e.g. educational and hypermedia applications, and knowledge based systems). According to this paradigm, the main aspects of this kind of applications can be described by means of documents. Afterwards, these documents are marked up using descriptive domain-specific markup languages and applications are produced by the automatic processing of these marked documents. We have used this paradigm to improve the maintenance and portability of content-intensive educational and hypermedia applications. ADDS (Approach to Document-based Development of Software) is an approach to software development based on the document oriented paradigm. A key feature of ADDS is that formulation of domain-specific markup languages is a dynamic and eminently pragmatic activity, and markup languages evolve according to the authoring needs of the different participants in the development process (domain experts and developers). The evolutionary nature of markup languages in ADDS leads to OADDS (Operationalization in ADDS), the proposed operationalization model for the incremental development of modular markup language processors. Finally, the document-oriented paradigm can also be applied in the construction of OADDS processors that are also described using marked documents. This paper presents our ADDS approach, including the operationalization model and its implementation as an object-oriented framework. The application of our document-oriented paradigm to the construction of OADDS processors is also presented.               Keywords: XML, domain-specific markup languages, modular language processors, software development approach, software evolution, software maintenance               Categories: D.1.0, D.2.13, D.2.3, D.2.7, D.3.2, D.3.3, D.3.4, I.7.2  
10|9||Geometric Retrieval for Grid Points in the RAM Model|  Spyros Sioutas (Department of Computer Engineering and Informatics, University of Patras, Greece)   Christos Makris (Department of Computer Engineering and Informatics, University of Patras, Greece)   Nektarios Kitsios (Department of Computer Engineering and Informatics, University of Patras, Greece)   George Lagogiannis (Department of Computer Engineering and Informatics, University of Patras, Greece)   John Tsaknakis (Department of Computer Engineering and Informatics, University of Patras, Greece)   Kostas Tsichlas (Department of Computer Engineering and Informatics, University of Patras, Greece)   Bill Vassiliadis (Department of Computer Engineering and Informatics, University of Patras, Greece)  Abstract: We consider the problem of d-dimensional searching (d  3) for four query types: range, partial range, exact match and partial match searching. Let N be the number of points, s be the number of keys specified in a partial match and partial range query and t be the number of points retrieved. We present a data structure with worst case time complexities O(t + logd-2 N), O(t + (d - s) + logs N), O(d + ) and O(t + (d - s) + s ) for each of the aforementioned query types respectively.  We also present a second, more concrete solution for exact and partial match queries, which achieves the same query time but has different space requirements. The proposed data structures are considered in the RAM model of computation.               Keywords: File Systems, Grid Model, Indexing, Multi-Dimensional Data Structures, Spatial Data               Categories: E.1, E.5  
volume|issue|url|title|abstract
11|1|http://www.jucs.org/jucs_11_1|Information Assurance and Security|
11|1||Physically Locating Wireless Intruders|  Frank Adelstein (ATC-NY, USA)   Prasanth Alla (ATC-NY, USA)   Rob Joyce (ATC-NY, USA)   Golden G. Richard III (University of New Orleans, USA)  Abstract: Wireless networks, specifically IEEE 802.11, are inexpensive  and easy to deploy, but their signals can be detected by eavesdroppers at great distances. Even with existing and new security measures, wireless networks have a higher risk than wired nets. WIDS, Wireless Intrusion Detection System, provides an additional layer of security by combining intrusion detection with physical location determination, using directional antennas. We briefly describe WIDS and present our initial results of remote station location using inexpensive hardware.               Keywords: 802.11, Wireless, antenna, intrusion detection system               Categories: D.4.6  
11|1||Low-Intrusive Consistent Disk Checkpointing: A Tool for Digital Forensics|  Sriranjani Sitaraman (Department of Computer Science, University of Texas, USA)   S. Venkatesan (Department of Computer Science, University of Texas, USA)  Abstract: An important problem in digital forensics is to record  a checkpoint of a disk drive mounted as a file system on a host machine without disrupting the disk s normal operations. We present a checkpointing methodology for a disk that has a Unix-like file system. While our algorithm is built around the Unix file system, it can be used to checkpoint disks formatted for other file systems such as NTFS, etc. Our algorithm satisfies several correctness conditions.               Keywords: Backup, Checkpointing, Consistency, Digital  Forensics, File system, Operating System, Snapshot               Categories: D.4.3, D.4.6  
11|1||Sliding Window Protocol for Secure Group Communication in Ad-Hoc Networks|  In Joe Khor (Oklahoma State University Tulsa, USA)   Johnson Thomas (Oklahoma State University Tulsa, USA)   Istvan Jonyer (Oklahoma State University Tulsa, USA)  Abstract: Existing ad hoc routing protocols are either unicast or multicast. In this paper we propose a simple extension to the Dynamic Source Routing Protocol (DSR) to cater for group communications where all node addresses are unicast addresses and there is no single multicast address. The proposed sliding window protocol for multiple communications results in significant improvement in total packet delivery. Due to the high frequency of mobility, attrition and reinforcement in ad hoc networks, in order to preserve confidentiality, it becomes necessary to rekey each time a member enters or leaves a logically defined group. We compare our group rekeying rate on sliding window protocol versus other kinds of Rekeying algorithms. The proposed sliding window protocol performs better. The proposed sliding window is therefore simple and improves both communications and security performance.               Keywords: Ad Hoc Network, DSR Routing Protocol, Re-keying performance, Secure Group Communications               Categories: C.2.0, D.4.6, I.6  
11|1||Increasing Robustness of LSB Audio Steganography by Reduced Distortion LSB Coding|  Nedeljko Cvejic (MediaTeam, Information Processing Laboratory, University of Oulu, Finland)   Tapio Seppänen (MediaTeam, Information Processing Laboratory, University of Oulu, Finland)  Abstract: In this paper, we present a novel high bit rate  LSB audio watermark ing method that reduces embedding distortion of the host audio. Using the proposed twostep algorithm, watermark bits are embedded into higher LSB layers, resulting in increased robustness against noise addition. In addition, listening tests showed that perceptual quality of watermarked audio is higher in the case of the proposed method than in the standard LSB method.               Keywords: LSB coding, audio steganography, data hiding   H.5.1               Categories: D.4.6, H.5.1  
11|1||Software/Hardware Co-Design of Efficient and Secure Cryptographic Hardware|  Nadia Nedjah (Department of Electronics Engineering and Telecommunications, State University of Rio de Janeiro, Brazil)   Luiza de Macedo Mourelle (Department of Electronics Engineering and Telecommunications, State University of Rio de Janeiro, Brazil)  Abstract: Most cryptography systems are based on the modular  exponentiation to perform the non-linear scrambling operation of data. It is performed using successive modular multiplications, which are time consuming for large operands. Accelerating cryptography needs  optimising the time consumed by a single modular multiplication and/or reducing the total number of modular multiplications performed. Using a genetic algorithm, we first yield the minimal sequence of powers, generally called addition chain, that need to be computed to finally obtain the modular exponentiation result. Then, we exploit the co-design methodology to engineer a cryptographic device that accelerates the encryption/decryption throughput without requiring considerable hardware area. Moreover the obtained designed cryptographic hardware is completely secure against known attacks.               Keywords: Addition-Chain, Co-Design, Cryptography, Evolutionary Computation, Genetic  Algorithm               Categories: H.3.1, H.3.2, H.3.3, H.3.7, H.5.1  
11|1||ProtoMon: Embedded Monitors for Cryptographic Protocol Intrusion Detection and Prevention|  Sachin P. Joglekar (University of North Texas, USA)   Stephen R. Tate (University of North Texas, USA)  Abstract: Intrusion Detection Systems (IDS) are responsible  for monitoring and analyzing host or network activity to detect intrusions in order to protect information from unauthorized access or manipulation. There are two main approaches for intrusion detection: signature-based and anomaly-based. Signature_based detection employs pattern matching to match attack signatures with observed data making it ideal for detecting known attacks. However, it cannot detect unknown attacks for which there is no signature available. Anomaly-based detection uses machine-learning techniques to create a profile of normal system behavior and uses this profile to detect deviations from the normal behavior. Although this technique is effective in detecting unknown attacks, it has a drawback of a high false alarm rate. In this paper, we describe our anomaly_based IDS designed for detecting malicious use of cryptographic and application-level protocols. Our system has several unique characteristics and benefits, such as the ability to monitor cryptographic protocols and application-level protocols embedded in encrypted sessions, a very lightweight monitoring process, and the ability to react to protocol misuse by modifying protocol response directly.               Keywords: Computer Security, Cryptographic Protocol Abuse, Intrusion Detection               Categories: C.2.0, D.4.6, K.6.5  
11|1||A Novel Scheme for Secured Data Transfer Over Computer Networks|  Rangarajan Athi Vasudevan (University of Michigan, USA)   Ajith Abraham (Chung-Ang University, Korea)   Sugata Sanyal (Tata Institute of Fundamental Research, India)  Abstract: This paper presents a novel encryption-less  algorithm to enhance security in transmission of data in networks. The algorithm uses an intuitively simple idea of a jigsaw puzzle to break the transformed data into multiple parts where these parts form the pieces of the puzzle. Then these parts are packaged into packets and sent to the receiver. A secure and efficient mechanism is provided to convey the information that is necessary for obtaining the original data at the receiver-end from its parts in the packets, that is, for solving the jigsaw puzzle. The algorithm is designed to provide information-theoretic (that is, unconditional) security by the use of a one-time pad like scheme so that no intermediate or unintended node can obtain the entire data. A parallelizable design has been adopted for the implementation. An authentication code is also used to ensure authenticity of every packet.               Keywords: Data Protection, Information Theory, Key management, One-time Pad, Perfect Secrecy, Security algorithm               Categories: E.3  
11|1||Gossip Codes for Fingerprinting: Construction, Erasure Analysis and Pirate Tracing|  Ravi S. Veerubhotla (Institute for Development and Research in Banking Technology, India)   Ashutosh Saxena (Institute for Development and Research in Banking Technology, India)   V. P. Gulati (Institute for Development and Research in Banking Technology, India)   A. K. Pujari (Department of Computer & Information Sciences, India)  Abstract: This work presents two new construction techniques for q-ary Gossip codes from t-designs and Traceability schemes. These Gossip codes achieve the shortest code length specified in terms of code parameters and can withstand erasures in digital fingerprinting applications. This work presents the construction of embedded Gossip codes for extending an existing Gossip code into a bigger code. It discusses the construction of concatenated codes and realisation of erasure model through concatenated codes.               Keywords: coding and information theory, digital libraries, multimedia information system               Categories: H.1.1, H.3.7, H.5.1  
11|1||A Reference Model for Security Level Evaluation: Policy and Fuzzy Techniques|  Valentina Casola (Dipartimento di Ingegneria dell'Informazione, Second University of Naples, Italy)   Rosa Preziosi (RCOST, Department of Engineering, University of Sannio, Italy)   Massimiliano Rak (Dipartimento di Ingegneria dell'Informazione, Second University of Naples, Italy)   Luigi Troiano (RCOST, Department of Engineering, University of Sannio, Italy)  Abstract: In a world made of interconnected systems which  manage huge amounts of confidential and shared data, security plays a significant role. Policies are the means by which security rules are defined and enforced. The ability to evaluate policies is becoming more and more relevant, especially when referred to the cooperation of services belonging to untrusted domains. We have focused our attention on Public Key Infrastructures (PKIs), at the state of the art security policies evaluation is manually performed by technical and organizational people coming from the domains that need to interoperate. However, policy evaluation must face uncertainties derived from different perspectives, verbal judgments and lack of information. Fuzzy techniques and uncertainty reasoning can provide a meaningful way for dealing with these issues. In this paper we propose a fuzzy technique to characterize a policy and to define a Reference Evaluation Model representing different security levels against which we are able to evaluate and compare policies. The comparison takes into account not only minimal system needs but evaluator s severity, too, furthermore it gives clear information regarding policy weakness that could be used to help security administrators to better enforce rules. Finally we present a case study which evaluates the security level of a legally recognized policy.               Keywords: Fuzzy Techniques   K.6.5, K.4.2, Policy, Public Key Infrastructure, Security Evaluation               Categories: K.4.2, K.6.5  
11|1||RSA-based Certified Delivery of E-Goods Using Verifiable and Recoverable Signature Encryption|  Aleksandra Nenadic (School of Computer Science, University of Manchester, UK)   Ning Zhang (School of Computer Science, University of Manchester, UK)   Barry Cheetham (School of Computer Science, University of Manchester, UK)   Carole Goble (School of Computer Science, University of Manchester, UK)  Abstract: Delivering electronic goods over the Internet is  one of the e-commerce applications that will proliferate in the  coming years. Certified e-goods delivery is a process where valuable  e-goods are exchanged for an acknowledgement of their reception. This  paper proposes an efficient security protocol for certified e-goods  delivery with the following features: (1) it ensures strong fairness  for the exchange of e-goods and proof of reception, (2) it ensures  non-repudiation of origin and non-repudiation of receipt for the  delivered e-goods, (3) it all ows the receiver of e-goods to verify,  during the exchange process, that the e-goods to be received are the  one he is signing the receipt for, (4) it uses an off-line and  transparent semi-trusted third party (STTP) only in cases when disput  es arise, (5) it provides the confidentiality protection for the  exchanged items from the STTP, and (6) achieves these features with  less computational and communicational overheads than related  protocols.               Keywords: certified delivery, fair exchange, non-repudiation, security protocols               Categories: C.2.2, D.4.6, K.6.5  
11|1||Information Quality Assurance by Lazy Exploration of Information Source Combinations Space in Open Multi-Agent Systems|  Jisun Park (The Laboratory for Intelligent Processes and Systems The University of Texas, USA)   K. Suzanne Barber (The Laboratory for Intelligent Processes and Systems The University of Texas, USA)  Abstract: Information quality assurance under the existence  of uncertainty can be investigated in the context of soft security,  where an agent maintains trustworthiness evaluations of its  information sources to assist in the evaluation of incoming  information quality from those sources. Since dependency inherently  exists in a system where agents do not have self-sufficient sensing  or data collection capabilities, finding an appropriate set of  information sources is important for assuring the quality of  information and for increasing the agent's goal achievement. This  research proposes an approach for selecting information sources as  partners. In order to increase the efficiency and the accuracy, we  use trustworthiness, information cost and goal coverage as the  metrics for information valuation while adopting a lazy exploration  of information sources combination space. Experimental results show  that the proposed approach increases the efficiency and results in  quality information acquisition.               Keywords: agent, information quality, multi-agent systems               Categories: H.3.3, I.2.11, I.2.8  
11|10|http://www.jucs.org/jucs_11_10|Compositional Construction and Reasoning Techniques for Software|
11|10||From Algebras to Objects: Generation and Composition|  A. M. Cruz (Sidereus, Consultoria Informática, Portugal)   L. S. Barbosa (Di-Cctc, Universidade do Minho, Portugal)   J. N. Oliveira (Di-Cctc, Universidade do Minho, Portugal)  Abstract: This paper addresses   objectification, a formal specification technique   which inspects the potential for object-orientation of a declarative   model and brings the 'implicit objects' explicit. Criteria for such   objectification are formalized and implemented in a runnable   prototype tool which embeds Vdm-sl into Vdm++. The paper also   includes a quick presentation of a (coinductive) calculus of such   generated objects, framed as generalised Moore machines.               Keywords: object composition, object­orientation, software formal specification               Categories: D.1.5, D.2.1, D.2.2  
11|10||Analyzing Module Diversity|  Alexandre Bergel (Software Composition Group, University of Bern, Switzerland)   Stéphane Ducasse (LISTIC - Language and Software Evolution Group, University of Savoie, France)   Oscar Nierstrasz (Switzerland, Software Composition Group, University of Bern)  Abstract: Each object­oriented programming language   proposes various grouping mechanisms to bundle interacting classes   (i.e., packages, modules, selector namespaces, etc). To understand   this diversity and to compare the different approaches, a common   foundation is needed. In this paper we present a simple module   calculus consisting of a small set of operators over environments   and modules. Using these operators, we are then able to specify a   set of module combinators that capture the semantics of Java   packages, C# namespaces, Ruby modules, selector namespaces, gbeta   classes, classboxes, MZScheme units, and MixJuice modules. We   develop a simple taxonomy of module systems, and show how particular   combinations of module operators help us to draw sharp distinctions   between classes of module systems that share similar   characteristics.               Keywords: C#, Java, Ruby, Small-talk, classboxes, module, package, selector namespaces, virtual classes               Categories: D.1.5, D.2.1, D.2.2, D.3.2, D.3.3  
11|10||A Non-Invasive Approach to   Assertive and Autonomous Dynamic Component Composition in the   Service-Oriented Paradigm|  Fei Cao (University of Alabama at Birmingham, USA)   Barrett R. Bryant (University of Alabama at Birmingham, USA)   Rajeev R. Raje (Indiana University Purdue University, USA)   Andrew M. Olson (Indiana University Purdue University, USA)   Mikhail Auguston (Naval Postgraduate School, USA)   Wei Zhao (University of Alabama at Birmingham, USA)   Carol C. Burt (University of Alabama at Birmingham, USA)  Abstract: Component-based software composition offers a   development approach with reduced time-to-market and cost while   achieving enhanced productivity, quality and   maintainability. Existent work on the composition paradigm focuses   on static composition, which is not sufficient in a distributed   environment, in which both constituent components and the assembled   distributed system are subject to dynamic adaptation. This paper   presents two types of dynamic composition for distributed   components: assertive and autonomous over a .NET based Web Services   environment. Three case studies are provided to illustrate the use   of assertive and autonomous composition.               Keywords: .NET, Common Language Runtime, Service Oriented Architecture, Web Services, aspect weaving, aspect-oriented programming, assertive composition, autonomous composition, dynamic component composition, intermediate code manipulation               Categories: D.2.12, D.2.13, D.2.3, D.2.7, D.3.3, H.3.5, I.2.8  
11|10||Coordinating Behavioral Descriptions of Components|  Silvia Amaro (National University of Comahue, Argentina)   Ernesto Pimentel (University of Malaga, Spain)   Ana M. Roldán (University of Huelva, Spain)  Abstract: Component-based Software Development is an   emerging discipline in the field of Software Engineering. In this   context, coordination languages may be used to specify the   interactive behavior of software components. Our proposal is   oriented towards defining a framework for describing the behavior of   components in terms of coordination models. In particular, we define   a way to complement interface description languages in order to   describe components such that the information about the services   provided by a component can be extended with details on how these   services should be used. We illustrate our approach by applying the   proposed framework to two substantially different coordination   models: Linda and Reo; the former representing the family of   data-oriented coordination models, and the latter a new   channel-based model. Although we consider both models to show the   feasibility of our proposal we hope this study help us to define an   interaction description language based on Reo for component   coordination, as has already been done in the context of   Linda.               Keywords: coordination, expressiveness, modular embedding, process algebra               Categories: D.2.12  
11|10||Modular Verification of a Component-Based Actor Language|  Marjan Sirjani (Department of Electrical and Computer Engineering,University of Tehran, Iran)   Frank S. de Boer (Centrum voor Wiskunde en Informatica, The Netherlands)   Ali Movaghar (School of Computer Science, IPM, Iran)  Abstract: Rebeca is an actor­based language for modeling concurrent and distributed systems as a set of reactive objects which communicate via asynchronous message passing. Rebeca is extended to support synchronous communication, and at the same time components are introduced to encapsulate the tightly coupled reactive objects which may communicate by synchronous messages. This provide us a language for modeling globally asynchronous and locally synchronous systems. Components interact only by asynchronous messages. This feature and also the event-driven nature of the computation are exploited to introduce a modular verification approach in order to overcome the state explosion problem in model checking. In this paper we elaborate on the corresponding theory of the modular verification approach which is based on the formal semantics of components in extended Rebeca.               Keywords: Rebeca, actor model, component, modular verification, reactive systems               Categories: D.2.4, F.3.1, F.3.2  
11|10||Probabilistic Models for Reo Connector Circuits|  Christel Baier (Institut fur Informatik I, University Bonn, Germany)  Abstract: Constraint automata have been used as an   operational model for Reo which offers a channel-based framework to   compose complex component connectors. In this paper, we introduce a   variant of constraint automata with discrete probabilities and   nondeterminism, called probabilistic constraint   automata. These can serve for compositional reasoning about   connector components, modelled by Reo circuits with unreliable   channels, e.g., that might lose or corrupt messages, or channels   with random output values that, e.g., can be helpful to model   randomized coordination principles.               Keywords: Markov decision process, Reo, bisimulation, composition, coordination, probabilistic constraint automata               Categories: D.2, F.4, G.3  
11|11|http://www.jucs.org/jucs_11_11|Visual Data Mining|
11|11||Semi-Automatic   Visual Subgroup Mining using VIKAMINE|  Martin Atzmueller (University of Würzburg, Germany)   Frank Puppe (University of Würzburg, Germany)  Abstract: Visual mining methods enable the direct   integration of the user to overcome major problems of automatic data   mining methods, e.g., the presentation of uninteresting results,   lack of acceptance of the discovered findings, or limited confidence   in these. We present a novel subgroup mining approach for   explorative and descriptive data mining implemented in the VIKAMINE   system. We propose several integrated visualization methods to   support subgroup mining. Furthermore, we describe three case studies   using data from fielded systems in the medical domain.               Keywords: data analysis, data mining, subgroup mining, visualization               Categories: H.5.1, H.5.2, I.2.1, I.2.6  
11|11||Scalable Visual Data Exploration of Large Data Sets via MultiResolution|  Daniel A. Keim (University of Konstanz, Germany)   Jörn Schneidewind (University of Konstanz, Germany)  Abstract: During the last decade Visual Exploration and Visual Data Mining techniques have proven to be of high value in exploratory data analysis since they combine human visual perception and recognition capabilities with the enormous storage capacity and the computational power of today's computer systems in order to detect patterns and trends in the data. But the ever increasing mass of information leads to new challenges on visualization techniques and concepts. Due to technological progress in computer power and storage capacity today's scientific and commercial applications are capable of generating, storing and processing massive amounts of data. Most existing visualization metaphors and concepts do not scale well on such large data sets as interaction capabilities and visual representations suffer from the massive number of data points. To bridge this gap, Visual Analytics aim to incorporate more intelligent means than to just retrieve and display the data items to filter the relevant from the non-relevant data. In this context the paper introduces a new approach based on a Multiresolution paradigm to increase the scalability of existing Visual data exploration techniques. The basic idea is to provide relevance driven compact representations of the underlying data set that present the data at different granularities. In the visualization step the available display space is then distributed according to the data granularity, to emphasize relevant information. The paper aims at introducing a technical base of Multiresolution visualization and provides an application example that shows the usefulness of the proposed approach.               Keywords: multiresolution, visual data exploration, visualization technique               Categories: H.0, H.4  
11|11||Visualizing Recommendation Flow on Social Network|  Jason J. Jung (INRIA Rhone-Alpes, France)  Abstract: In contrast with centralized recommender   systems, social recommendation algorithm is applied to the item   rating data on social networks. Meaningful recommendation can be   uncovered by the topology of social network as well as the   similarity between users. More importantly, this information becomes   propagated into the users in the estimated same groups. As the goal   of this paper, we propose a novel method for visual explanation of   the recommender system on social network. For experiments, we   simulate the recommendation flow by using the   MovieLens dataset on a social network constructed   with FOAF.               Keywords: reputation, social network, visualizing information flow               Categories: H.5, J.4  
11|11||Gravi++: Interactive Information Visualization to Explore Highly Structured Temporal Data|  Klaus Hinum (Institute of Software Technology and Interactive Systems,      Vienna University of Technology, Austria)   Silvia Miksch (Institute of Software Technology and Interactive Systems,      Vienna University of Technology, Austria)   Wolfgang Aigner (Institute of Software Technology and Interactive Systems,      Vienna University of Technology, Austria)   Susanne Ohmann (Department of Child and Adolescent Psychiatry, Medical      University of Vienna, Austria)   Christian Popow (Department of Child and Adolescent Psychiatry, Medical      University of Vienna, Austria)   Margit Pohl (Institute of Design and Assessment of Technology, Vienna      University of Technology, Austria)   Markus Rester (Institute of Design and Assessment of Technology, Vienna      University of Technology, Austria)  Abstract: Tracking and comparing psychotherapeutic data   derived from questionnaires involves a number of highly structured,   time-oriented parameters. Descriptive and other statistical methods   are only suited for partial analysis. Therefore, we created a novel   spring-based interactive Information Visualization method for   analysing these data more in-depth. With our method the user is able   to find new predictors for a positive or negative course of the   therapy due to the combination of various visualization and   interaction methods.               Keywords: interactive information visualization, medical domain, temporal data               Categories: H.3.3, H.5.1, J.3  
11|11||Visualization of High-dimensional Data via Orthogonal Curves|  César García-Osorio (Departament of Civil Engineering, University of Burgos, Spain)   Colin Fyfe (School of Computing, University of Paisley, United Kingdom)  Abstract: Computers are still much less useful than the   ability of the human eye for pattern matching. This ability can be   used quite straightforwardly to identify structure in a data set   when it is two or three dimensional. With data sets with more than 3   dimensions some kind of transformation is always necessary. In this   paper we review in depth and present and extension of one of these   mechanisms: Andrews' curves. With the Andrews' curves we use a curve   to represent each data point. A human can run his eye along a set of   curves (representing the members of the data set) and identify   particular regions of the curves which are optimal for identifying   clusters in the data set. Of interest in this context, is our   extension in which a moving three-dimensional image is created in   which we can see clouds of data points moving as we move along the   curves; in a very real sense, the data which dance together are   members of the same cluster.               Keywords: Andrews' curves, exploratory data analysis, grand tour methods, visual clustering               Categories: H.3.3, I.5.3, I.5.5  
11|11||Integrating Lite-Weight but Ubiquitous Data Mining into GUI Operating Systems|  Li Wei (University of California, USA)   Eamonn Keogh (University of California, USA)   Xiaopeng Xi (University of California, USA)   Stefano Lonardi (University of California, USA)  Abstract: Most visualization tools introduced in the   literature are specialized for a particular task. In this work, we   introduce a novel framework which allows visualization to take place   in the background of normal day to day operations of any GUI based   operating system such as MS Windows, OS X or Linux. Our system works   by replacing the standard file icons with automatically generated   icons that reflect the contents of the files in a principled way. We   call such icons Intelligent Icons. While there is little utility in   examining an individual icon, examining groups of them provides a   greater possibility of unexpected and serendipitous discoveries. The   utility of Intelligent Icons can be further enhanced by arranging   them on the screen in a way that reflects their   similarity/differences. We demonstrate the utility of our approach   on data as diverse as DNA, text files, electrocardiograms, and Space   Shuttle telemetry. In addition we show that our system is unique in   also supporting fast and intuitive similarity search.               Keywords: data mining, icon, visualization               Categories: H.3.0, H.3.3, H.3.4  
11|11||Connecting Segments for Visual Data Exploration and Interactive Mining of Decision Rules|  Francisco J. Ferrer-Troyano (Computer Science Department, University of Seville, Spain)   Jesús S. Aguilar-Ruiz (Computer Science Department, University Pablo de Olavide, Spain)   José C. Riquelme (Computer Science Department, University Pablo de Olavide, Spain)  Abstract: Visualization has become an essential support   throughout the KDD process in order to extract hidden information   from huge amount of data. Visual data exploration techniques provide   the user with graphic views or metaphors that represent potential   patterns and data relationships. However, an only image does not   always convey high-dimensional data properties successfully. From   such data sets, visualization techniques have to deal with the curse   of dimensionality in a critical way, as the number of examples may   be very small with respect to the number of attributes. In this   work, we describe a visual exploration technique that automatically   extracts relevant attributes and displays their ranges of interest   in order to support two data mining tasks: classification and   feature selection. Through di#erent metaphors with dynamic   properties, the user can re-explore meaningful intervals belonging   to the most relevant attributes, building decision rules and   increasing the model accuracy interactively.               Keywords: connecting segments, data mining, visual data exploration               Categories: E.1, E.2,, H.4  
11|11||Visualization and Manipulation of Incomplete and   Uncertain Dependencies by Decision Diagrams|  Denis V. Popel (Department of Computer Science, Baker University, USA)  Abstract: The data mining community is focused on a   variety of methods and algorithms to manipulate incompletely   specified or uncertain data and their dependencies. The major   obstacle in the representation and visualization of incompletely   specified data is the size explosion problem through defining   undefined or uncertain values, which commonly raises questions about   suggested heuristics and their practical applicability. Recently,   there is a renewed interest in resolving the size explosion problem   for incompletely specified and uncertain data based on symbolic   techniques. One of such techniques, decision diagram, has been   successfully applied to many knowledge visualization and data   manipulation problems.               Keywords: data mining, decision diagrams, incompletely specified functions, minimization               Categories: F.4.3, I.6.8  
11|12|http://www.jucs.org/jucs_11_12|Constructivity, Computability, and Logic     A Collection of Papers in Honour of the 60th Birthday of Douglas Bridges|
11|12||Constructive Suprema|  Marian Alexandru Baroni (CFR High School, Romania)  Abstract: Partially ordered sets are investigated from the   point of view of Bishop's constructive mathematics, which can be   viewed as the constructive core of mathematics and whose theorems   can be translated into many formal systems of computable   mathematics. The relationship between two classically equivalent   notions of supremum is examined in detail. Whereas the classical   least upper bound is based on the negative concept of partial order,   the other supremum is based on the positive notion of excess   relation. Equivalent conditions of existence are obtained for both   suprema in the general case of a partially ordered set; other   equivalent conditions are obtained for subsets of a lattice and, in   particular, for subsets of   Rnnn.               Keywords: constructive mathematics, partially ordered set, supremum               Categories: F.4.1  
11|12||Constructive Equivalents of the Uniform Continuity Theorem|  Josef Berger (Mathematisches Institut, Universität München, Germany)  Abstract: For the purpose of constructive reverse   mathematics, we show the equivalence of the uniform continuity   theorem to a series of propositions; this illuminates the   relationship between Brouwer's fan theorem and the uniform   continuity theorem               Keywords: constructive mathematics, reverse mathematics, uniform continuity               Categories: F.2.1, G.1.0  
11|12||Computability of the Spectrum of Self-Adjoint Operators|"  Vasco Brattka (Laboratory of Foundational Aspects of Computer Science, Department of Mathematics and Applied Mathematics, University of Cape Town, South Africa)   Ruth Dillhage (Computability and Logic Group,Department of Computer Science,University of Hagen, Germany)  Abstract: Self-adjoint operators and their spectra play a   crucial role in analysis and physics. For instance, in quantum   physics self-adjoint operators are used to describe measurements and   the spectrum represents the set of possible measurement results.   Therefore, it is a natural question whether the spectrum of a   self-adjoint operator can be computed from a description of the   operator. We prove that given a ""program"" of the operator one can   obtain positive information on the spectrum as a compact set in the   sense that a dense subset of the spectrum can be enumerated (or   equivalently: its distance function can be computed from above) and   a bound on the set can be computed. This generalizes some   non-uniform results obtained by Pour-El and Richards, which imply   that the spectrum of any computable self-adjoint operator is a   recursively enumerable compact set. Additionally, we show that the   spectrum of compact self-adjoint operators can even be computed in   the sense that also negative information is available (i.e. the   distance function can be fully computed). Finally, we also discuss   computability properties of the resolvent map.               Keywords: computable functional analysis               Categories: F.1.1, F.4.1, G.1  "
11|12||Algorithmic Irreducibility in a Cellular Automata Universe|  Gregory Chaitin (IBM T. J. Watson Research Center, USA)  Abstract: We discuss how to compute the halting probability Omega in the limit in a cellular automata world.               Keywords: cellular automaton, halting probability Omega               Categories: F.1  
11|12||Constructive Analysis of Iterated Rational Functions|  Jeremy Clark (107 rue de Sèvres, France)  Abstract: We develop the elementary theory of iterated rational functions over the Riemann sphere  in a constructive setting. We use Bishop­style constructive proof methods throughout. Starting from the development of constructive complex analysis presented in [Bishop and Bridges 1985], we give constructive proofs of Montel's Theorem along with necessary generalisations, and use them to prove elementary facts concerning the Julia set of a general continuous rational function with complex coefficients. We finish with a construction of repelling cycles for these maps, thereby showing that Julia sets are always inhabited.               Keywords: constructive analysis, iteration of rational functions               Categories: F.2.1, G.1.0  
11|12||Formal Topology and Constructive Mathematics: the Gelfand and Stone-Yosida Representation Theorems|  Thierry Coquand (Chalmers University, Sweden)   Bas Spitters (Radboud University Nijmegen, the Netherlands)  Abstract: We present a constructive proof of the   Stone-Yosida representation theorem for Riesz spaces motivated by   considerations from formal topology. This theorem is used to derive   a representation theorem for f-algebras. In turn, this theorem   implies the Gelfand representation theorem for C*-algebras of   operators on Hilbert spaces as formulated by Bishop and Bridges. Our   proof is shorter, clearer, and we avoid the use of approximate   eigenvalues.               Keywords: Riesz space, axiom of choice, constructive mathematics, f-algebra, formal topology               Categories: F.1.1, F.4.1, G.1  
11|12||Axiomatic Classes of Intuitionistic Models|  Robert Goldblatt (Victoria University of Wellington, New Zealand)  Abstract: A class of Kripke models for intuitionistic propositional logic is `axiomatic' if it is the class of all models of some set of formulas (axioms). This paper discusses various structural characterisations of axiomatic classes in terms of closure under certain constructions, including images of bisimulations, disjoint unions, ultrapowers and `prime extensions'. The prime extension of a model is a new model whose points are the prime filters of the lattice of upwardly­closed subsets of the original model. We also construct and analyse a `definable' extension whose points are prime filters of definable sets.   A structural explanation is given of why a class that is closed under images of bisimulations and invariant under prime/definable extensions must be invariant under arbitrary ultrapowers. This uses iterated ultrapowers and saturation.               Keywords: Kripke model, bisimulation, disjoint union, intuitionistic logic, iterated ultrapower, prime filter, saturated model, ultraproduct               Categories: F.4.1  
11|12||On Firmness of the State Space and Positive Elements of a Banach Algebra|  Robin S. Havea (Department of Mathematics and Computing Science, The University of the SouthPacific, Fiji)  Abstract: This paper is an investigation of positive elements in a Banach algebra.  Under the firmness of the state space of a Banach algebra, it is shown that even powers of positive Hermitian elements are in fact positive.               Keywords: Banach algebra, Hermitian elements, constructive mathematics, positive elements, state space               Categories: F.1  
11|12||Nonrandom Sequences between Random Sequences|  Peter Hertling (Institut für Theoretische Informatik und Mathematik,      Universität der Bundeswehr München, Germany)  Abstract: Let us say that an infinite binary sequence   q lies above an infinite   binary sequence p if q can be   obtained from p by replacing selected 0's in   p by 1's. We show that above any infinite binary   Martin-Löf random sequence p there exists an   infinite binary nonrandom sequence q above which   there exists an infinite binary random sequence   r. This result is of interest especially in   connection with the new randomness notion for sets of natural   numbers introduced in [Hertling and Weihrauch 1998, Hertling and   Weihrauch 2003] and in connection with its relation to the   Martin-Löf randomness notion for infinite binary   sequences.               Keywords: algorithmic information theory, algorithmic randomness, random binary sequences, random sets               Categories: F.1, H.1.1  
11|12||Permutability of Rules for Linear Lattices|  Sara Negri (Department Philosophy, University of Helsinki, Finland)  Abstract: The theory of linear lattices is presented as a   system with multiple-conclusion rules. It is shown through the   permutability of the rules that the system enjoys a subterm   property: all terms in a derivation can be restricted to terms in   the conclusion or in the assumptions. Decidability of derivability   with the rules for linear lattices follows through the termination   of proof-search.               Keywords: decidability, lattice theory, proof analysis               Categories: F.4.1  
11|12||Quotient Spaces and Coequalisers in Formal Topology|  Erik Palmgren (Department of Mathematics, Uppsala University, Sweden)  Abstract: We give a construction of coequalisers in formal   topology, a predicative version of locale theory. This allows for   construction of quotient spaces and identification spaces in   constructive topology.               Keywords: coequalisers, constructive topology, formal topology, locales, predicativit, quotients               Categories:  F.1.1, F.4.1  
11|12||Constructive Set Theory and Brouwerian Principles|  Michael Rathjen (Department of Mathematics, The Ohio State University, USA)  Abstract: The paper furnishes realizability models of constructive Zermelo-Fraenkel set theory, CZF, which also validate Brouwerian principles such as the axiom of continuous choice (CC), the fan theorem (FT), and bar induction (BI), and thereby determines the proof-theoretic strength of CZF augmented by these principles. The upshot is that CZF+CC+FT possesses the same strength as CZF, or more precisely, that CZF+CC+FT is conservative over CZF for  statements of arithmetic, whereas the addition of a restricted version of bar induction to CZF (called decidable bar induction, BID) leads to greater proof-theoretic strength in that CZF+BID proves the consistency of CZF.               Keywords: Brouwerian principles, constructive set theory, partial combinatory algebra, realizability               Categories: F.4.1  
11|12||Constructing Programs or Processes|  Steve Reeves (Department of Computer Science, University of Waikato, New Zealand)   David Streader (Department of Computer Science, University of Waikato, New Zealand)  Abstract: We define interacting sequential   programs, motivated originally by constructivist   considerations. We use them to investigate notions of implementation   and determinism. Process algebras do not define what can be   implemented and what cannot. As we demonstrate it is problematic to   do so on the set of all processes. Guided by constructivist notions   we have constructed interacting sequential programs which we claim   can be readily implemented and are a subset of processes.               Keywords: cause, constructive, determinism, process algebra, refinement               Categories: F.1  
11|12||Constructive Aspects of Markov Chains|  Fred Richman (Department of Mathematics, Florida Atlantic University, USA)  Abstract: This is a preliminary pass at examining some of the constructive issues in the theory of finite Markov chains. I trust that it is not all bad that there seem to be more questions raised than answered.               Keywords: Markov chains, constructive               Categories: F.1  
11|12||On the Meaning of Positivity Relations for Regular Formal Spaces|  Giovanni Sambin (Dipartimento di Matematica Pura ed Applicata, Università di Padova, Italy)   Giorgio Trentinaglia (Dipartimento di Matematica Pura ed Applicata, Università di Padova, Italy)  Abstract: A careful analysis of the original definition of   formal topology led to the introduction of a new primitive, namely a   positivity relation between elements and subsets. This is, in other   terms, a direct intuitionistic treatment of the notion of closed   subset in formal topology. However, since formal open subsets do not   determine formal closed subsets uniquely, the new concept of   positivity relation is not yet completely clear. Here we begin to   illustrate the general idea that positivity relations can be   regarded as a further, powerful tool to describe properties of the   associated formal space. Our main result is that, keeping the formal   cover fixed, by suitably redefining the positivity relation of a   regular formal topology one can obtain any given set-indexed family   of points as the corresponding formal space.               Keywords: formal reals, formal spaces, formal topology, positivity relation, regular formal topologies               Categories: F.1  
11|12||Functional Dependencies with Counting on Trees|  Klaus-Dieter Schewe (Department of Information Systems and Information Science, Research Centre, Massey University, New Zealand)  Abstract: The paper presents an axiomatisation for functional dependencies on trees that are defined using constructors for records, lists, sets and multisets. A simple form of restructuring permitting lists to be mapped onto multisets and multisets onto sets is added to the theory. Furthermore, the theory handles dependencies on sets treated as multisets. This adds the possibility to use the count of elements in the dependencies.               Keywords: axiomatisation, complex value databases, counting attributes, functional dependencies               Categories: F.4.1, H.2.1  
11|12||What is Continuity, Constructively?|  Peter Schuster (Mathematisches Institut, Universität München, Germany)  Abstract: The concept of continuity for mappings between metric spaces should coincide with that of uniform continuity in the case of a compact domain, and still give rise to a category. In Bishop's constructive mathematics both requests can be fulfilled simultaneously, but then the reciprocal function has to be abandoned as a continuous function unless one adopts the fan theorem. This perhaps little satisfying situation could be avoided by moving to a point-free setting, such as formal topology, in which infinite coverings are defined mainly inductively. The purpose of this paper is to discuss the earlier situation and some recent developments.               Keywords: constructive mathematics, continuity               Categories: F.1  
11|12||A Direct Proof of the Equivalence between Brouwer's Fan Theorem and König's Lemma with a Uniqueness Hypothesis|  Helmut Schwichtenberg (Mathematisches Institut, Universität München, Germany)  Abstract: From results of Ishihara it is known that the   weak (that is, binary) form of König's lemma (WKL) implies   Brouwer's fan theorem (Fan). Moreover, Berger and Ishihara [MLQ   2005] have shown that a weakened form WKL! of WKL, where as an   additional hypothesis it is required that in an effective sense   infinite paths are unique, is equivalent to Fan. The proof that WKL!   implies Fan is done explicitely. The other direction (Fan implies   WKL!) is far less directly proved; the emphasis is rather to provide   a fair number of equivalents to Fan, and to do the proofs   economically by giving a circle of implications. Here we give a   direct construction. Moreover, we go one step further and formalize   the equivalence proof (in the Minlog proof assistant). Since the   statements of both Fan and WKL!  have computational content, we can   automatically extract terms from the two proofs. It turns out that   these terms express in a rather perspicuous way the informal   constructions.               Keywords: Brouwer's fan theorem, König's lemma               Categories: F.1  
11|12||Constructive Results on Operator Algebras|  Bas Spitters (Institute for Computing and Information Sciences, Radboud University Nijmegen, The Netherlands)  Abstract: We present a to following results in the   constructive theory of operator algebras. A representation theorem   for finite dimensional von Neumann-algebras. A representation   theorem for normal functionals. The spectral measure is independent   of the choice of the basis of the underlying Hilbert space. Finally,   the double commutant theorem for finite von Neumann algebras and for   Abelian von Neumann algebras.               Keywords: Hilbert spaces, constructive mathematics, operator theory               Categories: F.1  
11|12||Hausdorff Measure and Lukasiewicz Languages|  Ludwig Staiger (Martin-Luther Universtät Halle-Wittenberg, Germany)  Abstract: The paper investigates fixed points and   attractors of infinite iterated function systems in Cantor space. By   means of the theory of formal languages simple examples of the   non-coincidence of fixed point and attractor (closure of the fixed   point) are given.               Keywords: Cantor space, Hausdorff measure, attractor, fractals, iterated function system, omega-languages, simple deterministic languages               Categories: F.1.1, F.4.1  
11|12||New Bounds for Positive Roots of Polynomials|  Doru Ştefănescu (Department of Mathematics, Faculty of Physics, University of Bucharest, Romania)  Abstract: We consider a nonconstant polynomial P with real coeţients that has at least one negative coeţient and derive new upper bounds for the real roots of P . We compare our bounds with those obtained by other methods.               Keywords: bounds for positive roots, roots of polynomial equations               Categories: F.2.1, G.1.5  
11|12||How the Mathematical Objects Determine the Mathematical Principles|  Dirk van Dalen (Department of Philosophy, Utrecht University, The Netherlands)  Abstract: In our description of Brouwer's universe we have discussed a few basic principles which have unusual consequences in practical mathematics.               Keywords: constructive analysis, iteration of rational functions               Categories: F.2.1, G.1.0  
11|12||Perhaps the Intermediate Value Theorem|  Wim Veldman (Institute for Mathematics, Astrophysics and Particle      Physics, Faculty of Science, Radboud University Nijmegen, the Netherlands)  Abstract: In the context of intuitionistic real analysis,   we introduce the set  consisting   of all continuous functions φ from [0, 1] to  such that   φ(0) = 0 and φ(1) = 1.  We let  be the set   of all φ in  for which   we may find x in [0, 1] such that φ(x) = . It is   well-known that there are functions in  that we can   not prove to belong to , and that,   with the help of Brouwer's Continuity Principle one may derive a   contradiction from the assumption that  coincides   with . We show   that Brouwer's Continuity Principle also enables us to define   uncountably many subsets  of  with the   property .               Keywords: intermediate value theorem, intuitionistic real analysis, perhaps               Categories: G.0  
11|12||On Complements of Sets and   the Efremovič Condition in Pre-apartness Spaces|  Luminita Simona Vîţă (University of Canterbury, New Zealand)  Abstract: In this paper we study various properties of   complements of sets and the Efremovič separation property in a   symmetric pre--apartness space.               Keywords: Efremovič property, Pre-apartness spaces               Categories: F.4.1  
11|12||A Constructive Approach to Sylvester's Conjecture|  Jan von Plato (University of Helsinki, Finland)  Abstract: Sylvester's conjecture states that, given   n distinct noncollinear points in a plane, there   exists a connecting line of two of the points such that no other   point is incident with the line. First a proof is given of the   six-point Sylvester conjecture from a constructive axiomatization of   plane incidence geometry. Next ordering principles are studied that   are needed for the seven-point case. This results in a symmetrically   ordered plane affine geometry. A corollary is the axiom of complete   quadrangles. Finally, it is shown that the problem admits of an   arithmetic translation by which Sylvester's conjcture is decidable   for any n.               Keywords: Sylvester's conjecture, constructive geometry, ordered geometry               Categories: F.4.1  
11|12||Sequential Computability of a Function. Effective Fine Space and Limiting Recursion|  Mariko Yasugi (Faculty of Science, Kyoto Sangyo University, Japan)   Yoshiki Tsujii (Faculty of Science, Kyoto Sangyo University, Japan)   Takakazu Mori (Faculty of Science, Kyoto Sangyo University, Japan)  Abstract: We consider real sequences in   I = [0, 1) and real functions on   I. It is first shown that, as for real sequences   from I, R-computability   (computability with respect to the Euclidean topology) implies   “ weak Fine-computability.” Using this result, we show   that “ Fine­sequential computability” and “      -sequential computability” are equivalent for effectively   locally Fine-continuous functions as well as for Fine-continuous   functions.               Keywords: Effective Fine Space, Effective Fine-continuous Function, Fine-sequential Computability of a Function, Limiting Recursion, Weakly Fine-computable Sequence               Categories: F.0, G.0  
11|2|http://www.jucs.org/jucs_11_2|Modern Technologies for Web-based Adaptive Systems|
11|2||Collaborative Web Browsing Based on Semantic Extraction of User Interests with Bookmarks|  Jason J. Jung (Intelligent E-Commerce Systems Laboratory, School of Computer and Information Engineering, Inha University, Korea)  Abstract: With the exponentially increasing amount of information available on the World Wide Web, users have b een getting more difficult to seek relevant information. Several studies have been conducted on the concept of adaptive approaches, in which the user s personal interests are taken into account. In this paper, we propose a user-support mechanism based on the sharing of knowledge with other users through the collaborative Web browsing, focusing specifically on the user s interests extracted from his or her own bookmarks. Simple URL based boo kmarks are endowed with semantic and structural information through the conceptualization based on ontology. In order to deal with the dynamic usage of bookmarks, ontology learning based on a hierarchical clustering method can be exploited. This system is composed of a facilitator agent and multiple personal agents. In experiments conducted with this system, it was found that approximately 53.1% of the total time was saved during collaborat ive browsing for the purpose of seeking the equivalent set of information, as compared with normal personal Web browsing.               Keywords: Web browsing, collaborative works, ontology               Categories: H.3.1, H.3.3, H.5.3, H.5.4  
11|2||RankFeed - Recommendation as Searching without Queries: New Hybrid Method of Recommendation|  Maciej Kiewra (Fujitsu Services, Spain)  Abstract: The paper describes RankFeed a new adaptive method of recommendation that benefits from similarities between searching and recommendation. Concepts such as: the initial ranking, the positive and negative feedback widely used in searching are applied to recommendation in order to enhance its coverage, maintaining high accuracy. There are four principal factors that determine the method s behaviour: the quality document ranking, navigation patterns, textual similarity and the list of recommended pages that have been ignored during the navigation. In the evaluation part, the local site s behaviour of the RankFeed ranking is contrasted with PageRank. Additionally, recommendation behaviour of RankFeed versus other classical approaches is evaluated.               Keywords: ROSA, Web mining, adaptive systems, information retrieval, personalization, recommendation               Categories: H.3.1, H.3.3  
11|2||Consensus-Based Hybrid Adaptation of Web Systems User Interfaces|  Janusz Sobecki (Institute of Applied Informatics, Wroclaw University of Technology, Poland)  Abstract: Consensus methods proved to be very effective in solving problems in many areas. In this paper a hybrid adaptation of web-based system user interfaces that us es consensus methods is presented. The hybrid recommendation is a combination of the following methods: demographic, content-based, and collaborative. Each of this meth od has its specific advantages and disadvantages. The hybrid adaptation enables over coming disadvantages of each separate solution.               Keywords: Web-based systems, consensus methods, hybrid adaptation, user interfaces               Categories: H.3.5, H.5.2, H.5.3, H.5.4  
11|2||Creation of Information Profiles in Distributed Databasesas a Game Problem|  Juliusz L. Kulikowski (Institute of Biocybernetics and Biomedical Engineering, Poland)  Abstract: There is considered a problem of information  profiles and information resources collection forming in distributed data- and/or knowledge bases as a result of an attempt to satisfy the information requirements of the customers represented by their information profiles. It is shown that the interests of managers of data- and knowledge bases are not fully convergent and that they participate in a composite, partially co-operative, partially non-co-operative n-persons games. There is given a formal description of the strategies used in such games, as well as the methods of decision making of the players on the level of open access (OADB) as well as on local (LDB) databases one.               Keywords: distributed databases, game theory, information market, information resources, strategy of database managers               Categories: H.2.7, H.3.2, H.3.5, I.6.8, K.6.4  
11|2||Processing Inconsistency of Knowledge on Semantic Level|  Ngoc Thanh Nguyen (Institute of Control and Systems Engineering, Wroclaw University of Technology, Poland)  Abstract: Inconsistency of knowledge may appear in many situations, especially in distributed environments in which autonomous programs operate. Inconsistency may lead to conflicts, for which the resolution is necessary for correct functioning of an intelligent system. Inconsistency of knowledge in general means a situation in which some autonomous programs (like agents) generate different versions (or states) of knowledge on the same subject referring to a real world. In this paper we propose two logical structures for representing inconsistent knowledge: conjunction and disjunction. For each of them we define the semantics and formulate the consensus problem, the solution of which would resolve the inconsistency. Next, we work out algorithms for consensus determination. Consensus methodology has been proved to be useful in solving conflicts and should be also effective for knowledge inconsistency resolution.               Keywords: conflicts, consensus methods, inconsistent knowledge               Categories: E.1, H.2.1, I.2.11, I.2.4  
11|2||An Application of the DEDS Control Synthesis Method|  Frantisek Capkovic (Institute of Informatics, Slovak Academy of Sciences, Slovakia)  Abstract: An application of the method suitable for modelling and control of general discrete event dynamic systems (DEDS) to special kinds of communication systems is presented in this paper. The approach is based on Petri nets (PN) defined in [Peterson 1981] and directed graphs (DG) described e.g. in [Diestel 1997]. It is supported by the previous author s works, especially [Capkovic 2003], [Capkovic 1998], [Tzafestas and Capkovic 1997].               Keywords: control synthesis, discrete event dynamic systems (DEDS)               Categories: G.2.3, H.4.3, I.6.3, I.6.4  
11|2||Structural Tendencies in Complex Systems Development and their Implication for Software Systems|  Andrzej Gecow (temporary Institute of Paleobiology, Polish Academy of Science, Poland)   Mariusz Nowostawski (University of Otago, New Zealand)   Martin Purvis (University of Otago, New Zealand)  Abstract: Contemporary distributed software systems, exposed  to highly unpredictable environments, are reaching extremely high complexity levels. For example, open heterogeneous multi-agent systems that may potentially be spread all around the globe are interacting with different types of dynamically changing web-services and web-technologies. Traditional control-based handling of adaptability may not be suitable any more in such systems. Therefore there is a tendency for exploring different adaptability models inspired by biological phenomena. Biological systems inherently are faced with complexity and unpredictable environments, and they exhibit high levels of ad aptability. In this article, we present a theoretical model of development of complex system, which was built originally by Andrzej Gecow, as a computational model in evolutionary biology. This model represents a generic complex system subjected to long sequences of adaptive changes. The model was used for analysis of development processes and also structural tendencies. By tendencies we mean some phenomena that should be expected in any complex system, subjected to a long development process. Some of these tendencies are not desirable, for example bloat of the system. Some of the phenomena, however, show characteristics of changes that improve the system. These characteristics can be applied to optimisation of self-producing and self-adapting algorithms of self-maintaining complex software systems. The main structural tendencies described in this article are: terminal modifications, terminal majority of additions, and covering (reconstructing within the system itself disappearing environmental signals).               Keywords: adaptable architectures, complex systems, software life cycle               Categories: C.1.3, D.2, G.m, H.1.1, K.4.m  
11|2||The Language Grounding Problem and its Relation to the Internal Structure of Cognitive Agents|  Radoslaw Piotr Katarzyniak (Institute of Control and Systems Engineering, Wroclaw University of Technology, Poland)  Abstract: An original approach to modelling internal structure of artificial cognitive agents and the phenomenon of language grounding is presented. The accepted model for the internal cognitive space reflects basic structural properties of human cognition and assumes the partition of cognitive phenomena into conscious and non-conscious. The language is treated as a set of semiotic symbols and is used in semantic communication. Semiotic symbols are related to the internal content of empirical knowledge bases in which they are grounded. This relation is given by the so-called epistemic satisfaction relations defining situations in which semiotic symbols are adequate (grounded) representations of embodied experience. The importance of non-conscio us embodied knowledge in language grounding and production is accepted. An example of application of the proposed approach to the analysis of grounding requirements is given for the case of logic equivalences extended with modal operators of possibility, belief and knowledge. Implementation issues are considered.               Keywords: cognitive agent, communication, formula satisfaction, language grounding, modal logic               Categories: H.1.0, H.1.2, H.5.2  
11|3|http://www.jucs.org/jucs_11_3|Integration of  Knowledge Management and (e)Learning|
11|3||Small Groups Learning Synchronously Online at the Workplace: The Interaction of Factors Determining Outcome and Acceptance|  Stefan Münzer (Saarland University, Germany)   Bo Xiao (Fraunhofer Institute for Integrated Publication and Information Systems, Germany)  Abstract: E-learning at the workplace might be accomplished by synchronous cooperative learning sessions of small groups using net-based communication. This form of learning is suitable both for course-based e-learning as well as for knowledge transfer within the company. The small groups learn self-regulated, i.e. without the guidance of an instructor. However, the learning tasks are pre-defined and a specific learning process is precisely described. In the present study, the goal of the cooperative learning sessions is to deepen pre-existing declarative knowledge. During cooperative learning, group members are required to actively use, acquire, enrich and exchange their knowledge. In a field study carried out in a large software company, a software tool was used which supported the specific process by phase-specific delivering of instructions and learning materials as well as by means of process control (including turn-taking, role assignment, and coordination of task flow). The results of the empirical evaluation demonstrate a high amount of topic-oriented contributions and the realization of the expected learning activities. However, feedback data indicated a low acceptance of the software tool because of its restrictive process control. It is discussed that there might have been a non-optimal interaction between the factors technology and target group in the study.               Keywords: computer-supported cooperative learning, empirical study, professional training, quality assurance, workplace learning               Categories: H.1.2, H.5.1, H.5.2, H.5.3, J.4  
11|3||Using Weblogs for Knowledge Sharing and Learning in Information Spaces|  Eric Ras (Fraunhofer Institute for Experimental Software Engineering, Germany)   Gabriela Avram (Centre de Recherche Public Henri Tudor, Luxembourg)   Patrick Waterson (Fraunhofer Institute for Experimental Software Engineering, Germany)   Stephan Weibelzahl (National College of Ireland, Ireland)  Abstract: There are various Knowledge Management Systems available currently and designed to support knowledge sharing and learning. An example of these are Experience-based Information Systems in the domain of Software Engineering, i.e., Information Systems designed to support experience management. Lately, these have become more and more sophisticated from a technical point of view. However, there are several shortcomings that appear to limit the input, the content of these systems and their usage. The problems identified in this paper relate to knowledge acquisition, learning issues, as well as to the users'  motivation and trust. We introduce an approach meant to enhance the content of the experience base and improve learning from experiences within information spaces, namely weblogs that are maintained during daily work and serve as input for both an experience base and for an information element base. In order to enhance learning, a pedagogical information agent is envisaged for retrieving suitable experiences to be further enriched with additional information elements and produce micro-didactical learning arrangements. In addition we consider the relevance of motivation and trust issues. An empirical study demonstrates that using weblogs for such an approach is feasible.               Keywords: Experience-based Information System, information space, micro-didactical learning arrangement, pedagogical information agent, weblog, wiki               Categories: A.1, D.2, H.4, J.4, K.3  
11|3||Integration of Communities into Process-Oriented Structures|  Andre Köhler (University of Leipzig, Germany)   Frank Fuchs-Kittowski (Fraunhofer-Institut für Software- und Systemtechnik ISST, Germany)  Abstract: This article aims at the integration of communities of practice into work processes. Linear structures are often inappropriate for the execution of knowledge intensive tasks and work processes. The latter are characterized by non-linear sequences and dynamic, social interaction. But for the work in communities of practice the leading path, that is needed for structuring the work, is often missing. Our article exposes the requirements in order to integrate the dynamic, social processes of the knowledge generation in communities of practice with formal described knowledge intensive processes. For the support of communities the Wiki-concept is introduced. In order to integrate communities into process structures a concept for an appropriate interface is presented. On the basis of this interface concept an information retrieval algorithm is used to connect the process-oriented structures with community-oriented structures. The prototype realisation of this concept is shown by a short example.               Keywords: Wiki, cooperative knowledge generation, knowledge  community, knowledge-intensive processes, process-oriented knowledge structures               Categories: H.3.3, H.3.5, H.5.3, H.5.4  
11|4|http://www.jucs.org/jucs_11_4|Integrating Business Processes and Knowledge Infrastructures|
11|4||Modeling Knowledge Work for the Design of Knowledge Infrastructures|  Ronald Maier (Dept. of Management Information Systems, Martin-Luther-University Halle-Wittenberg, Germany)  Abstract: During the last years, a large number of information and communication technologies (ICT) have been proposed to be supportive of knowledge management (KM). Several KM instruments have been developed and implemented in many organizations that require support by ICT. Recently, many of these technologies are bundled in the form of comprehensive, enterprise-wide knowledge infrastructures. The implementation of both, instruments and infrastructures, requires adequate modeling techniques that consider the specifics of modeling context in knowledge work. The paper studies knowledge work, KM instruments and knowledge infrastructures. Modeling techniques are reviewed, especially for business process management and activity theory. The concept of knowledge stance is discussed in order to relate functions from process models to actions from activity theory, thus detailing the context relevant for knowledge work.               Keywords: activity theory, business process management, knowledge infrastructure, knowledge management instrument, knowledge stance, knowledge work, modeling, process               Categories: H.1  
11|4||KMDL - Capturing, Analysing and Improving Knowledge-Intensive Business Processes|  Norbert Gronau (University of Potsdam, Germany)   Claudia Müller (University of Potsdam, Germany)   Roman Korf (University of Potsdam, Germany)  Abstract: Existing approaches in the area of knowledge-intensive processes focus on integrated knowledge and process management systems, the support of processes with KM systems, or the analysis of knowledge-intensive activities. For capturing knowledge-intensive business processes well known and established methods do not meet the requirements of a comprehensive and integrated approach of process-oriented knowledge management. These approaches are not able to visualise the decisions, actions and measures which are causing the sequence of the processes in an adequate manner. Parallel to conventional processes knowledge-intensive processes exist. These processes are based on conversions of knowledge within these processes. To fill these gaps in modelling knowledge-intensive business processes the Knowledge Modelling and Description Language (KMDL) got developed. The KMDL is able to represent the development, use, offer and demand of knowledge along business processes. Further it is possible to show the existing knowledge conversions which take place additionally to the normal business processes. The KMDL can be used to formalise knowledge-intensive processes with a focus on certain knowledge-specific characteristics and to identify process improvements in these processes. The KMDL modelling tool K-Modeler is introduced for a computer-aided modelling and analysing. The technical framework and the most important functionalities to support the analysis of the captured processes are introduced in the following contribution.               Keywords: K-Modeler, Knowledge Modeling Description Language, Process-oriented Knowledge Management, knowledge-intensive Business Processes               Categories: D.3.3, H.3.1, H.3.3, H.4.3, H.5.2, I.2.4, I.2.6, I.3.6, I.5.2, I.6.3, I.6.4  
11|4||Tube Map Visualization: Evaluation of a Novel Knowledge Visualization Application for the Transfer of Knowledge in Long-Term Projects|  Remo Aslak Burkhard (University of St.Gallen, Switzerland)   Michael Meier (vasp datatecture GmbH, Switzerland)  Abstract: This article introduces two theoretical concepts for the emerging field Knowledge Visualization and discusses a new visualization application that was used to communicate a long-term project to various stakeholders in an organization. First, we introduce a theoretical framework and a model for Knowledge Visualization. The framework and the model identify and relate the key-aspects for successful Knowledge Visualization applications. Next, we present an evaluation of an implemented Knowledge Visualization application: The Tube Map Visualization. A quality development process had to be established in an education centre for health care professions. Traditional project plans, flyers, and mails did not manage to get the attention, did present overview and detail insufficiently, and did not motivate the employees for actions. Because Visual Metaphors are effective for Knowledge Communication we developed a customized Knowledge Map based on the tube system metaphor. The Tube Map Visualization illustrates the whole project, where each tube line represents a target group and each station a milestone. The visualization was printed as a poster and displayed at prominent locations in the organization. The findings of an evaluation indicate that the Tube Map Visualization is a powerful metaphor to communicate a complex project to different target groups and to build up a mutual story. The employees considered it useful because it provides overview and detailed information in one image and because it initiates discussion. The Tube Map Visualization is therefore helpful to complement traditional project plans of (1) long-term projects where (2) different stakeholders are involved. The theoretical framework, the model, and the findings have implications for researchers in the fields of Knowledge Management, Knowledge Visualization, Information Visualization, and Communication Sciences.               Keywords: information  visualization, knowledge communication, knowledge visualization, project management, storytelling, visual metaphor               Categories: H.5.2, H.5.3  
11|4||A Methodology and a Toolkit that Integrate Technological, Organisational, and Human Factors to Design KM within Knowledge-Intensive Networks|  Tomaso Forzi (Research Institute for Operations Management Aachen University of Technology, Germany)   Meikel Peters (Institute of Industrial Engineering and Ergonomics Aachen University of Technology, Germany)  Abstract: A well-functioning Knowledge Management is a competitive advantage for enterprises that act in co-operative and distributed networks with knowledge intensive production processes. A Knowledge Management approach that integrates both, hard factors (e.g. Information Technology) and soft factors (e.g., cultural aspects) for distributed and dynamic entrepreneurial (inter-organisational) networks is currently missing. This paper presents research findings of a project that is developing a methodology as well as an appropriate toolkit to support a service provider responsible for the KM within distributed entrepreneurial networks. The project integrates explicitly both new Information and Communication Technology driven organisational concepts, human-oriented approaches and existing KM methodologies and instruments.               Keywords: collaborative networks, inter-organizational networked businesses, knowledge management, knowledge networks               Categories: C.2.1, C.2.3, C.2.4, I.2.4, I.2.6  
11|4||The Role of Knowledge Management Solutions in Enterprise Business Processes|  Valentina Janev (Mihajlo Pupin Institute, Serbia and Montenegro)   Sanja Vraneš (Mihajlo Pupin Institute, Serbia and Montenegro)  Abstract: Knowledge technologies, the software products that support all aspects of knowledge processing and exchange, are the subject of permanent interest for software engineers at research organizations, as well as, for market analysts in commercial organizations. In order to clarify the role of knowledge management solutions in an enterprise business process, in this paper we survey the market of knowledge management solutions and analyze their functionalities from operational and strategic business perspective. Although knowledge flows are identified on an operational level, discussion will show that knowledge management solutions here serve to utilize the enterprise knowledge in an efficient performance of daily work. We argue that data and information collected on the operational level are processed by knowledge management solutions on a strategic level thus creating new knowledge that is used for strategic management of customers, suppliers and partners. This paper gives an insight into knowledge management market that can help the strategic planners to easily begin a knowledge management initiative.               Keywords: business process, enterprises, knowledge management, market research, software tools               Categories: A.1, H.0, H.2.8, H.3.0, H.4.2  
11|4||A Knowledge Infrastructure Hierarchy Model for Call-Centre Processes|  Greg Timbrell (Queensland University of Technology, Australia)   Stefan Koller (Know-Center Graz, Austria)   Nev Schefe (Queensland University of Technology, Australia)   Stefanie N. Lindstaedt (Know-Center Graz, Austria)  Abstract: This paper explores a process view of call-centres and the knowledge infrastructures that support these processes. As call-centres grow and become more complex in their function and organisation so do the knowledge infrastructures required to support their size and complexity. This study suggests a knowledge-based hierarchy of advice-type call-centres and discusses associated knowledge management strategies for different sized centres. It introduces a Knowledge Infrastructure Hierarchy model, with which it is possible to analyze and classify call-centre knowledge infrastructures. The model also demonstrates different types of interventions supporting knowledge management in call-centres. Finally the paper discusses the possibilities of applying traditional maturity model approaches in this context.               Keywords: data bases, information systems, knowledge management               Categories: H.1, H.2, H.4  
11|4||Process Oriented Knowledge Management: A Service Based Approach|  Robert Woitsch (BOC Information Technologies Consulting GmbH, Austria)   Dimitris Karagiannis (University of Vienna, Institute for Computer Science and Business Informatics, Austria)  Abstract: This paper introduces a new viewpoint in knowledge management by introducing KM-Services as a basic concept for Knowledge Management. This text discusses the vision of service oriented knowledge management (KM) as a realisation approach of process oriented knowledge management. In the following process oriented knowledge management as it was defined in the EU-project PROMOTE (IST-1999-11658) is presented and the KM-Service approach to realise process oriented knowledge management is explained. The last part is concerned with an implementation scenario that uses Web-technology to realise a service framework for a KM-system.               Keywords: knowledge management process, knowledge management service               Categories: H.1  
11|4||Reconciling Knowledge Management and Workflow Management Systems: The Activity-Based Knowledge Management Approach|  Schahram Dustdar (Distributed Systems Group, Institute of Information Systems, Vienna University of Technology, Austria)  Abstract: Current trends in collaborative knowledge management emphasize the importance of inter- and intra-organizational business process support. Enactment of business processes has primarily been a domain of workflow management systems. In this paper we propose a hybrid architecture for reconciliation of knowledge management and workflow management systems in order to support process participants in organizations, who are increasingly distributed and need to share and distribute knowledge artifacts. Today one pressing challenge is to utilize software as to create, share, and exchange (knowledge) work in collaborative knowledge activities across locations, while still being business process aware. This paper develops a conceptual framework, discusses a software architecture, and presents examples of a software system implementation for activity-based knowledge management for global project teams.               Keywords: knowledge management, workflow               Categories: H.4  
11|4||Modelling and Implementing Pre-built Information Spaces. Architecture and Methods for Process Oriented Knowledge Management|  Karsten Böhm (University of Leipzig, Institute of Computer Science, Germany)   Wolf Engelbach (Fraunhofer Institute for Industrial Engineering IAO, Germany)   Joerg Härtwig (University of Leipzig, Institute of Computer Science, Germany)   Martin Wilcken (Fraunhofer Institute for Industrial Engineering IAO, Germany)   Martin Delp (University of Applied Sciences Kufstein Tirol, Austria)  Abstract: Process-oriented Knowledge Management aims to provide adequate information for employees, especially in weakly structured and information-intensive business processes. Beside a technical software solution, which uses a pre-structured, context-aware and collaborative information space that combines processes, domain specific semantic structures and document parts, this requires a methodology to model the process and other context-dimensions, such as roles. Moreover, a guideline and clear service modules are necessary to introduce process-oriented Knowledge Management in companies, especially in small and medium-sized enterprises (SME). Such solutions were developed in the cooperative research project PreBIS (Pre-Build Information Space).               Keywords: business processes, collaborative filtering, context-awareness, information retrieval, introduction method, knowledge management, modelling method, ontology               Categories: H.3, H.4, I.2.4, I.2.7, I.7, J.1  
11|5|http://www.jucs.org/jucs_11_5|Atomicity in System Design and Execution (Proceedings of Dagstuhl-Seminar 04181)|
11|5||The Atomic Manifesto|"  Cliff B. Jones (University of Newcastle upon Tyne, UK)   David Lomet (Microsoft Research, USA)   Alexander Romanovsky (University of Newcastle upon Tyne, UK)   Gerhard Weikum (MPI Saarbruecken, Germany)  Abstract: This paper is a manifesto for future research on ""atomicity"" in its many guises and is based on a five-day workshop on ""Atomicity in System Design and Execution"" that took place in Schloss Dagstuhl in Germany in April 2004.        Keywords: atomicity, dependability, formal methods, hardware, programming languages, transactions               Categories: A.0  "
11|5||Atomicity as a First-Class System Provision|"  J. Eliot B. Moss (Department of Computer Science University of Massachusetts, USA)   Ravi Rajwar (Intel Corporation Hillsboro, USA)  Abstract: We argue that atomicity, i.e., atomic actions with most of the traditional ""ACID"" properties, namely atomicity, consistency, and isolation but perhaps not durability, should be provided as a fundamental first class resource in computer systems. This implies coherent, convenient, and well-engineered support from the hardware, through the run-time system, programming language, and libraries, to the operating system. We articulate the advantages of this approach, indicate what has already been accomplished, and outline what remains to be done to realize the vision.               Keywords: atomicity, cache coherence, transactional memory, transactions               Categories: C.0  "
11|5||Investigating Atomicity and Observability|  Jon Burton (University of Newcastle upon Tyne, UK)   Cliff B. Jones (University of Newcastle upon Tyne, UK)  Abstract: Using the fiction of atomicity as a design abstraction and then refining atomicity as we develop an implementation is widely used in areas of concurrent computing such as database systems and transaction processing. In each of these and similar areas, associated notions of correctness are used in order to show that a particular implementation artefact which exhibits concurrency is correct in some sense with respect to a (possibly notional) description which executes with a greater degree of sequentiality. Of crucial importance in the proof and deployment of such notions of correctness is the issue of observability: i.e. in what broad sense do (human or computer) users of a particular implementation artefact observe the effects of its executions. For example, if a human user is allowed to observe directly the execution of a particular concurrent component then he or she will be able to detect the fact of concurrent - and so non-atomic - execution. In general, however, the notion of observability is treated implicitly or not at all. In this paper, we make it explicit and look at the issue of exploring more fully the connections between atomicity and observability. The ultimate aim of this consideration is to work towards constructing a more general framework for (software or hardware) development by refining atomicity.               Keywords: formal development method, observability, refinement of atomicity               Categories: F.3.1  
11|5||On Atomicity and Software Development|  Jörg Kienzle (School of Computer Science, McGill University, Canada)  Abstract: This paper shows how the concept of atomicity can ease the development of concurrent software. It illustrates by means of a case study how atomicity is used to reduce the complexity of concurrency by presenting simplified models or views of the system at certain stages of the development cycle. As the development process goes on, the atomic views from the early stages are refined - broken up into smaller pieces - to slowly introduce concurrency back into the system. Finally, at the design stage, low-level concepts that provide atomicity, such as transaction or monitors, are used to ensure consistent concurrent updating of the application state.               Keywords: OCL, UML, atomicity, concurrency, monitors, software development, transactions               Categories: D.1.3, D.1.5, D.2  
11|5||Replication: Understanding the Advantage of Atomic Broadcast over Quorum Systems|  Richard Ekwall (Ecole Polytechnique Federale de Lausanne, Switzerland)   Andre Schiper (Ecole Polytechnique Federale de Lausanne, Switzerland)  Abstract: Quorum systems (introduced in the late seventies)  and atomic broadcast (introduced later) are two techniques to manage replicated data. Despite of the fact that these two techniques are now well known, the advantage of atomic broadcast over quorum systems is not clearly understood. The paper explains exactly in what cases atomic broadcast is a better technique than quorum systems to handle replication.               Keywords: atomic broadcast, isolation, quorum systems, replication               Categories: C.2.4, D.4.5  
11|5||Precise Modelling of Compensating Business Transactions and its Application to BPEL|  Michael Butler (School of Electronics and Computer Science, University of Southampton, UK)   Carla Ferreira (Department of Computer Science, Technical University of Lisbon, Portugal)   Muan Yong Ng (School of Electronics and Computer Science, University of Southampton, United Kingdom)  Abstract: We describe the StAC language which can be used to specify the orchestration of activities in long running business transactions. Long running business transactions use compensation to cope with exceptions. StAC supports sequential and parallel behaviour as well as exception and compensation handling. We also show how the B notation may be combined with StAC to specify the data aspects of transactions. The combination of StAC and B provides a rich formal notation which allows for succinct and precise specification of business transactions. BPEL is an industry standard language for specifying business transactions and includes compensation constructs. We show how a substantial subset of BPEL can be mapped to StAC thus demonstrating the expressiveness of StAC and providing a formal semantics for BPEL.               Keywords: B method, compensation, formal specification, language semantics, long-running transactions               Categories: D.3.1, F.3.2, H.m  
11|5||Formal Construction of a Non-blocking Concurrent Queue Algorithm|  Jean-Raymond Abrial (ETH Zürich, Switzerland)   Dominique Cansell (Universite de Metz & LORIA, France)  Abstract: This paper contains a completely formal (and mechanically proved) development of some algorithms dealing with a linked list supposed to be shared by various processes. These algorithms are executed in a highly concurrent fashion by an unknown number of such independent processes. These algorithms have been first presented in [MS96] by M.M. Michael and M.L. Scott. Two other developments of the same algorithms have been proposed recently in [YS03] (using the 3VMC Model Checker developed by E. Yahav) and in [DGLM04] (using I/O Automata and PVS).               Keywords: atomicity, concurrency, formal proof, prover, refinement               Categories: D.1.3  
11|5||Relaxing Atomicity and Verifying Correctness: Considering the Case of an Asynchronous Communication Mechanism|  Jon Burton (University of Newcastle upon Tyne, UK)  Abstract: In an ideal world, where we could guarantee instantaneous, atomic data transfer - whatever the type of the data being transferred - shared memory communication between two concurrent processes could be implemented directly using single variables or registers, without any attendant access control policies or mechanisms. In practice, asynchronous communication mechanisms may be used to provide the illusion of atomic transfers of data while still allowing non-blocking reads and writes: that is, reads and writes may proceed concurrently without interfering with each other. In order to prove the correctness of such mechanisms, the natural approach would be to verify them against the specification provided by an idealised register with atomic, instantaneous - and so sequential - transfers of data. Yet such a verification is complicated by the fact that, in moving to the asynchronous communication mechanism from such a specification, additional concurrency has been introduced and so the (visible) behaviours of the mechanism are not directly comparable to those of the register. In this paper, we recall an extension of standard process algebraic refinement and show how it may be used to verify the correctness of a particular asynchronous communication mechanism, Simpson s 4-slot. In so doing, we look at a number of issues which seem significant in the consideration of correctness when the real atomicity of a specification has been relaxed in the move from specification to implementation.               Keywords: asynchronous communication, process algebra, relaxation of atomicity, verification               Categories: F.3.1  
11|6|http://www.jucs.org/jucs_11_6|Managing Editor's Column|
11|6||How to Draw Free Trees Inside Bounded Simple Polygons|  Alireza Bagheri (Software Systems R&D Laboratory Department of Computer Engineering & IT Amirkabir University of Technology, Iran)   Mohammadreza Razzazi (Software Systems R&D Laboratory Department of Computer Engineering & IT Amirkabir University of Technology, Iran)  Abstract: In this paper we investigate polyline grid drawing of free trees on 2D grids which are bounded by simple polygons. We focus on achieving uniform node distribution while we also try to achieve minimum edge crossings. We do not consider achieving symmetry as a mandatory task, but our algorithm can exploit some symmetries present in both the given trees and the given polygons. To our knowledge, our work is the first attempt for developing algorithms that draw graphs on regions which are bounded by simple polygons.               Keywords: computational geometry, free trees, graph drawing, simulated annealing, straight skeleton               Categories: G.2.2, I.3.5, I.6.3  
11|6||A Provably Efficient Computational Model For Approximate Spatiotemporal Retrieval|  Vasilis Delis (Computer Technology Institute, Greece)   Christos Makris (Computer Engineering and Informatics Department, University of Patras and Computer Technology Institute, Greece)   Spyros Sioutas (Computer Engineering and Informatics Department, University of Patras and Computer Technology Institute, Greece)  Abstract: The paper is concerned with the effective and efficient processing of spatiotemporal selection queries under varying degrees of approximation. Such queries may employ operators like overlaps, north, during, etc., and their result is a set of entities standing approximately in some spatiotemporal relation  with respect to a query object X. The contribution of the present work is twofold: i) it presents a formal mathematical framework for representing multidimensional relations at varying granularity levels, modelling relation approximation through the concept of relation convexity, ii) it subsequently exploits the proposed framework for developing approximate spatiotemporal retrieval mechanisms, combining a set of existing as well as new main memory and secondary memory data structures that achieve either optimal or the best known performance in terms of time and space complexity, for both the static and the dynamic setting.               Keywords: range queries of high dimensionality, spatiotemporal data modeling, spatiotemporal data structures, spatiotemporal databases               Categories: H.1.0, H.3.1, H.3.3  
11|6||Time Costs in Actor Computations|  Michele Di Santo (Research Centre on Software Technology, Dept. of Engineering, University of Sannio, Italy)   Franco Frattolillo (Research Centre on Software Technology, Dept. of Engineering, University of Sannio, Italy)  Abstract: Actor programs give rise to computation structures that evolve dynamically and unpredictably both in shape and size. Therefore, their execution times cannot be statically determined. This paper describes an approach to the problem of estimating time costs of actor programs. The approach takes into account the constraints imposed both by the semantics and implementation of the model. In particular, implementation constraints can be captured and exploited to drastically reduce the number of computations generable by the program, thus simplifying the execution time evaluation. Moreover, execution times are expressed in a parametric form by using a variant of the LogP model able to synthetically characterize the target hardware/software platform.               Keywords: actor computations, execution time, implementation constraints, parallel computations               Categories: C.4, D.2.8  
11|6||Analysis, Design, and Performance Evaluation of MS-RTCP: More Scalable Scheme for the Real-Time Control Protocol|  N. A. Elramly (Computer Science Department, Faculty of Science, Menoufia University, Egypt)   A. S. Habib (Computer Science Department, Faculty of Science, Menoufia University, Egypt)   O. S. Essa (Computer Science Department, Faculty of Science, Menoufia University, Egypt)   H. M. Harb (Computer Science Department, Faculty of Science, Emirates University, UAE)  Abstract: Recently, some problems related to the use of the Real-time Control Protocol (RTCP) in very large dynamic group have arisen. Some of these problems are: feedback delay, increasing storage state at every member, and ineffective RTCP bandwidth usage, especially for the receivers that obtain incoming RTCP reports through low bandwidth links. More schemes are proposed to alleviate the RTCP problems. The famous and recent one, which was introduced by EL-Marakby and was named Scalable RTCP (S-RTCP), still has several drawbacks. This paper will evaluate the previous model by introducing all its drawbacks. Consequently, we will demonstrate a design of More Scalable RTCP (MS-RTCP) scheme based on hierarchical structure, distributed management, and EL-Marakby scheme. Also, we will show how our scheme will alleviate all the drawbacks found in the S-RTCP. Finally, we will introduce our scheme implementation to analyze and evaluate its performance.               Keywords: RTCP scalability, distributed management, multimedia communication, multimedia protocols               Categories: C.2.2, C.2.6  
11|6||Automatic Test Data Generation for Data Flow Testing Using a Genetic Algorithm|  Moheb R. Girgis (Department of Computer Science, Faculty of Science Minia University, Egypt)  Abstract: One of the major difficulties in software testing is the automatic generation of test data that satisfy a given adequacy criterion. This paper presents an automatic test data generation technique that uses a genetic algorithm (GA), which is guided by the data flow dependencies in the program, to search for test data to cover its def-use associations. The GA conducts its search by constructing new test data from previously generated test data that are evaluated as effective test data. The approach can be used in test data generation for programs with/without loops and procedures. The proposed GA accepts as input an instrumented version of the program to be tested, the list of def-use associations to be covered, the number of input variables, and the domain and precision of each input variable. The algorithm produces a set of test cases, the set of def-use associations covered by each test case, and a list of uncovered def-use associations, if any. In the parent selection process, the GA uses one of two methods: the roulette wheel method or a proposed method, called the random selection method, according to the user choice. Finally, the paper presents the results of the experiments that have been carried out to evaluate the effectiveness of the proposed GA compared to the random testing technique, and to compare the proposed random selection method to the roulette wheel method.               Keywords: Genetic algorithms, automatic test data generation, data flow testing, software testing               Categories: D.2.5, K.6.3  
11|6||On Theoretical Upper Bound for Routing Estimation|  Fei He (Dept. CS&T and School of Software, Tsinghua University, China)   Guowu Yang (Dept. ECE, Portland State University, USA)   Lerong Cheng (Dept. ECE, Portland State University, USA)   Xiaoyu Song (Dept. ECE, Portland State University, USA)   Ming Gu (School of Software, Tsinghua University, China)   Jiaguang Sun (School of Software, Tsinghua University, China)  Abstract: Routing space estimation plays a crucial role in design automation of digital systems. We investigate the problem of estimating upper bounds for global routing of two-terminal nets in two-dimensional arrays. We show the soundness of the bounds for both wiring space and total wire-length estimation.               Keywords: CAD, algorithms, global routing, integrated circuits               Categories: B.7.2, F.2.2  
11|6||Fine-Grained Transclusions of Multimedia Documents in HTML|  Josef Kolbitsch (Graz University of Technology, Austria)  Abstract: Transclusions are a technique for virtually including existing content into new documents by reference to the original documents rather than by copying. In principle, transclusions are used in HTML for the inclusion of entire text documents, images, movies and similar media. The HTML specification only takes transclusions of entire documents into account, though. Hence it is not possible, for instance, to include a part of an existing image into an HTML document. In this paper, fine-grained transclusion of multimedia documents on the Web are proposed, which presents a logical realisation of the concept of transclusions in HTML. The proposal makes it possible, for instance, to include sections of existing images or small portions of entire movies into HTML documents. Two different approaches to implementing the functionality presented are detailed. The first architecture is based on a transparent extension module to conventional HTTP servers, whereas the alternative design makes use of a CGI program. Both approaches are fully self-contained, reside on an HTTP server and do not require browser plug-ins or any other special software components to be installed on client computers. An amendment to the HTTP specification is not required either. A prototype implementation demonstrates the proposal for a number of document types.               Keywords: authoring systems, hypermedia, multimedia, publishing systems, transclusions, web-based applications, xanalogical structure               Categories: H.1, H.3, H.4  
11|6||On Complexity of Collective Communications on a Fat Cube Topology|  Vladimir Kutálek    Václav Dvořák   Abstract: A recent renewed interest in hypercube interconnection network has been concentrated to the more scalable version known as a fat cube. The paper introduces several router models for fat nodes and uses them for cost comparison of both the hypercube and fat cube topologies. Analysis of time complexity of collective communications is done next and lower bounds on the number of communication steps are derived. Examples of particular communication algorithms on the 2D-fat cube topology with 8 processors are summarized and described in detail. The performed study shows that a large variety of fat cubes can provide much desired flexibility, trading cost for performance and manufacturability.               Keywords: collective communications, fat cube topology, interconnection networks, router architecture               Categories: H.3.1, H.3.2, H.3.3, H.3.7, H.5.1  
11|6||TESTAF: A Test Automation Framework for Class Testing using Object-Oriented Formal Specifications|  Aamer Nadeem (Center for Software Dependability, Mohammad Ali Jinnah University, Pakistan)   Muhammad Jaffar-ur-Rehman (Center for Software Dependability, Mohammad Ali Jinnah University, Pakistan)  Abstract: In this paper, we present a novel framework TESTAF to support automatic generation and execution of test cases using object-oriented formal specifications. We use IFAD VDM++ as the specification language, but the ideas presented can be applied equally well to other object-oriented formal notations. The TESTAF framework requires a VDM++ specification for a class, a corresponding implementation in C++, and a test specification, to generate and execute test cases, and evaluate the results. The test specification defines valid test sequences in an intermediate specification language based on regular expressions. The framework uses the formal specification of the class, and the test specification to generate empty test shells, which are then filled in with the test data to create concrete test cases. The test data for a method are generated from the input space defined by the method pre condition and the class invariant. The TESTAF applies boundary value analysis strategy to generate the test data. A test driver then executes the implementation with the test data, and uses a conjunction of method post condition and the class invariant as a test oracle to evaluate the results, while reporting failed test cases to the user.               Keywords: automated testing, formal specification, object-oriented software               Categories: D.2.5  
11|6||A Provably Secure and Efficient Verifiable Shuffle based on a Variant of the Paillier Cryptosystem|  Lan Nguyen (University of Wollongong, Australia)   Reihaneh Safavi-Naini (Centre for Computer Security Research, University of Wollongong, Australia)   Kaoru Kurosawa (Ibaraki University, Japan)  Abstract: We propose a variant of the Paillier cryptosystem that improves efficiency in encryption, re-encryption and decryption while preserving the homomorphic property. We then use this variant to construct a new verifiable shuffle system and prove its security. We show that the new shuffle scheme has the least number of rounds and exponentiations compared to all known shuffle schemes. Finally, we show how to construct a publicly verifiable mix-net using the shuffle system.               Keywords: Paillier's public-key system, mix-nets, privacy, verifiable shuffles               Categories: E.3  
11|6||Exploiting Agent Ontologies in B2C Virtual Marketplaces|  Domenico Rosaci (University Mediterranea of Reggio Calabria, Italy)  Abstract: In the last few years, an overwhelming amount of agent-based systems for supporting business-to-customer (B2C) e-commerce activities have been proposed. In this context, the use of agent ontologies for modelling the realities of both customers and sellers may play an important role. This paper deals with a formal model of agent ontologies, capable of describing the entities involved in the above realities (products, product features, product categories) as well as the behaviour of customers and sellers in performing their activities. Furthermore, we present some techniques that exploit the proposed ontology model for supporting the various B2C e-commerce stages represented in the Consumer Buying Behaviour (CBB) model. Finally, we briefly describe the OBA_B2C multi-agent architecture that implements in a JADE-based environment all the proposed techniques.               Keywords: agent ontology, b2c e-commerce, intelligent agent technology               Categories: H.3.4  
11|6||Domain Extenders for UOWHF: A Finite Binary Tree Algorithm|  Palash Sarkar (Indian Statistical Institute, India)  Abstract: We obtain a finite binary tree algorithm to extend the domain of a universal one-way hash function (UOWHF). The associated key length expansion is only a constant number of bits more than the minimum possible. Our finite binary tree algorithm is a practical parallel algorithm to securely extend the domain of a UOWHF. Also the speed-up obtained by our algorithm is approximately proportional to the number of processors.               Keywords: UOWHF, binary tree, hash function               Categories: E.3  
11|6||Model Checking, Automated Abstraction, and Compositional Verification of Rebeca Models|  Marjan Sirjani (Department of Electrical and Computer Engineering, University of Tehran and School of Computer Science, IPM, Iran)   Ali Movaghar (Department of Electrical and Computer Engineering, University of Tehran and School of Computer Science, IPM, Iran)   Amin Shali (Department of Electrical and Computer Engineering, University of Tehran, Iran)   Frank S. de Boer (Department of Software Engineering, Centrum voor Wiskunde en Informatica, Netherlands)  Abstract: Actor-based modeling, with encapsulated active objects which communicate asynchronously, is generally recognized to be well-suited for representing concurrent and distributed systems. In this paper we discuss the actor-based language Rebeca which is based on a formal operational interpretation of the actor model. Its Java-like syntax and object-based style of modeling makes it easy to use for software engineers, and its independent objects as units of concurrency leads to natural abstraction techniques necessary for model checking. We present a front-end tool for translating Rebeca to the languages of existing model checkers in order to model check Rebeca models. Automated modular verification and abstraction techniques are supported by the tool.               Keywords: abstraction techniques, actor model, model checking, modular verification, reactive systems               Categories: D.2.2, D.2.4  
11|6||A Fast T-decomposition Algorithm|  Jia Yang (Department of Computer Science, The University of Auckland, New Zealand)   Ulrich Speidel (Department of Computer Science, The University of Auckland, New Zealand)  Abstract: T-decomposition was first proposed and implemented as an algorithm by Mark Titchener. It has applications in communication of code sets and in the fields of entropy and similarity measurement. The first implementation of a T-decomposition algorithm by Titchener was subsequently followed by a faster version named tcalc, developed in conjunction with Scott Wackrow. An improved T-decomposition algorithm was published in 2003 by the authors with the implementation tlist. This paper introduces a new algorithm that builds on our 2003 algorithm. Comparative experimental results are given to show that the new version has a significantly better time performance than previous algorithms.               Keywords: T-decomposition, computable complexity measures, entropy, parsing               Categories: E.4  
11|6||Collect the Fitted Surfaces into Complex Based on C0 Continuity|  E. A. Zanaty (Mathematics Department, Faculty of Science, South Valley University, Egypt)   Moheb R. Girgis (Computer Science Department, Faculty of Science, Minia University, Egypt)  Abstract: Surface reconstruction addresses the problem of creating a surface model from a point set digitized from a physical object. After performing the surface fitting on the bases of individual patches (adjacent surfaces), it is necessary to improve the obtained results by connecting the adjacent surfaces according to the desired smoothness. This paper presents a fast method for collecting the adjacent surfaces into complex based on C0 continuity. The method works with the surfaces and their segments. Firstly, an arbitrary surface is selected, and the points with closest distances to that surface are extracted. Then, the points are sorted according to the Euclidean distance to the surface. Finally, the surface and the sorted points are joined together and presented to a refitting technique. This technique includes a procedure to decide if the data is similar to the current surface and for updating the surface parameters for each new point.               Keywords: reverse engineering, surface fitting, surface reconstruction               Categories: I., I.3, I.3.5  
11|7|http://www.jucs.org/jucs_11_7|The 9th Brazilian Symposium on Programming Languages|
11|7||A Constructive Approach to Language Definition|  Peter D. Mosses (Swansea University, United Kingdom)  Abstract: Most approaches to formal semantics are based on   the assumption that all the constructs of a language are defined   together. The details of the definition of each construct can (and   usually do) depend on which other constructs are included in the   given language. This limits reuse of definitions of common   constructs.     With the more constructive approach proposed here, the   semantics of each basic abstract programming construct is defined   separately and independently. The semantics of a full language is   obtained by translating its constructs into the basic abstract   constructs, whose definitions are thus reused verbatim.     The   frameworks of Modular SOS and Action Semantics can both be used in   conjunction with the proposed approach. Some illustrations are   given.               Keywords: action semantics, modularity, semantics of programming languages, structural operational semantics               Categories: D.3.1, D.3.3, F.3.2, F.3.3  
11|7||Hardware Design and Functional Programming: a Perfect Match|  Mary Sheeran (Chalmers University of Technology, Sweden)  Abstract: This paper aims to explain why I am still   fascinated by the use of functional languages in hardware design. I   hope that some readers will be tempted to tackle some of the hard   problems that I outline in the final section. In particular, I   believe that programming language researchers have much to   contribute to the field of hardware design.               Keywords: arithmetic and logic structures, circuit generation, functional programming, hardware description languages               Categories: B.2.2, B.6.3  
11|7||The Implementation of Lua 5.0|  Roberto Ierusalimschy (Department of Computer Science, PUC-Rio, Brazil)   Luiz Henrique de Figueiredo (IMPA-Instituto de Matematica Pura e Aplicada, Brazil)   Waldemar Celes (Department of Computer Science, PUC-Rio, Brazil)  Abstract: We discuss the main novelties of the   implementation of Lua 5.0: its register-based virtual machine, the   new algorithm for optimizing tables used as arrays, the   implementation of closures, and the addition of   coroutines.               Keywords: closures, compilers, coroutines, hash tables, virtual machines               Categories: D.3.2, D.3.3, D.3.4, E.2  
11|7||AspectLua - A Dynamic AOP Approach|  Néélio Cacho (Federal University of Rio Grande do Norte, Brazil)   Thaís Batista (Federal University of Rio Grande do Norte, Brazil)   Fabrício Fernandes (Federal University of Rio Grande do Norte, Brazil)  Abstract: In this paper we describe AspectLua - a dynamic aspect-oriented language based on Lua. It relies on a meta-object protocol, LuaMOP, which unifies the introspective and reflective mechanisms provided by Lua and handles the weaving process. In order to improve support for dynamicity, AspectLua allows the association of aspects with undeclared elements of the application code (virtual join points). In addition, it provides an automatic support for managing aspects execution order.               Keywords: AOP, Lua, MOP, dynamic aspects, reflection               Categories: D.2.3, D.3.3  
11|7||A Formal Semantics for Finalizers|  Marcus Amorim Leal (PUC-Rio, Brazil)   Roberto Ierusalimschy (PUC-Rio, Brazil)  Abstract: Automatic finalization is a common but   inherently complex language facility that makes the garbage   collection process semantically visible to client programs.  With   finalizers, memory management becomes more flexible, and garbage   collectors can be used to recycle other resources in addition to   memory.      Formal language models usually ignore   garbage collection, and therefore are unable to properly describe   finalization. In this paper we use an operational approach to   develop a new abstract model that explicitly represents memory   management actions in a garbage­collected programming language based   on the λ­calculus. We formally state and prove several important   properties related to memory management, and employ the model to   describe and explore a semantics for finalizers.               Keywords: finalization, garbage collection, memory management, semantics               Categories: D.3.3, D.4.2, F.3.2  
11|7||PEWS: A New Language for Building Web Service Interfaces|  Cheikh Ba (Université Francois Rabelais, LI/Campus de Blois, France)   Marcos Aurelio Carrero (Federal University of Paraná, Brazil)   Mirian Halfeld Ferrari (Université Francois Rabelais, LI/Campus de Blois, Frace)   Martin A. Musicante (Federal University of Paraná, Brazil)  Abstract: Recent proposals in the domain of interface description languages for web services stress the importance of specifying the dynamic, behavioral aspects of the services. The goal of this paper is to introduce a new interface description language, called PEWS, that uses predicate path expressions to define web service behaviours.  Our proposal represents a simple but expressive way to describe order and conditional constraints over web service operations. PEWS aims to be used not only to the specification of simple web services but also to be a tool for describing service composition.    In this paper, we use the Action Semantics framework to present the syntax and semantics of the most significant parts of PEWS and we introduce XPEWS, the XML-based version of PEWS used to publish service behaviours for future searches and composition. The definition of XPEWS is done by giving the XML Schema that defines the syntax of XPEWS programs.               Keywords: formal semantics, programming languages, web services               Categories: C.2.4, D.3.1, D.3.m  
11|7||mHaskell: Mobile Computation in a Purely Functional Language|  André Rauber Du Bois (School of Mathematical and Computer Sciences,Heriot-Watt University, UK, and,Escola de Informática,Universidade Católica de Pelotas, Brazil)   Phil Trinder (School of Mathematical and Computer Sciences,Heriot-Watt University, United Kingdom)   Hans-Wolfgang Loidl (Institut für Informatik,Ludwig-Maximilians-Universität Munich, Germany)  Abstract: We provide a complete description of   mHaskell, a new mobile programming language that   extends the Haskell functional language. We describe new stateful   mobility primitives that use higher-order channels, giving their   operational semantics and an implementation outline. We show how   medium-level coordination abstractions can be constructed using   monadic composition of the mobility primitives. We briefly outline   how high-level mobile coordination abstractions, or   mobility skeletons, can be defined using the   lower-level abstractions. The use of all three abstractions is   demonstrated with examples and a new case study: a distributed   stateless web server where a thread farm skeleton is used to   distribute work to remote locations.               Keywords: Haskell, functional programming, mobile computation,, programming languages               Categories: D.3.3  
11|7||Compiling Non­strict Functional Languages for the .NET Platform|  Monique Monteiro (Center of Informatics, Federal University of Pernambuco, Brazil)   Mauro Araújo (Center of Informatics, Federal University of Pernambuco, Brazil)   Rafael Borges (Center of Informatics, Federal University of Pernambuco, Brazil)   André Santos (Center of Informatics, Federal University of Pernambuco, Brazil)  Abstract: In this work, we propose a compilation strategy for non­strict functional languages targeting the Microsoft .NET Platform, a multilanguage platform which provides a large number of services to aid current software development. This strategy is based on the push/enter execution model, enables fast function calling mechanisms whenever possible and males use of new features present in .NET Framework, such as delegates and tail calls. Our case study was the compilation of the Haskell language, a standardized and well known non­strict functional language. Our main contribution is the construction of an environment for the testing of different compilation techniques for functional languages targeting .NET.               Keywords: .NET, Haskell, compilers, functional programming, languages interoperability, virtual machines               Categories: D.3.3  
11|7||Running Lua Scripts on the CLR through Bytecode Translation|  Fabio Mascarenhas (Departamento de Informatica, PUC-Rio, Brasil)   Roberto Ierusalimschy (Departamento de Informatica, PUC-Rio, Brazil)  Abstract: The .NET Common Language Runtime (CLR) aims to provide interoperability among code written in several different languages, but porting scripting languages to it, so that scripts can run natively, has been hard. This paper presents our approach for running scripts written in Lua, a scripting language, on the .NET CLR.  Previous approaches for running scripting languages on the CLR have focused on extending the CLR, statically generating CLR classes from user-defined types in the source languages. They required either language extensions or restrictions on the languages' dynamic features.    Our approach, on the other hand, focused on keeping the syntax and semantics of the original language intact, while giving the ability to manipulate CLR objects. We implemented a translator of Lua virtual machine bytecodes to CLR bytecodes. Benchmarks show that the code our translator generates performs better than the code generated by compilers that use the previous approaches.               Keywords: bytecodes, common language runtime, compilers, virtual machines               Categories: D.3.4  
11|7||An Experimental Evaluation of JAVA JIT Technology|  Anderson Faustino da Silva (Federal University of Rio de Janeiro, Brazil)   Vitor Santos Costa (Federal University of Rio de Janeiro, Brazil)  Abstract: Interpreted languages are widely used due to   ease to use, portability, and safety. On the other hand,   interpretation imposes a significance overhead. Just­in­ Time (JIT)   compilation is a popular approach to improving the runtime   performance of languages such as Java. We compare the performance of   a JIT compiler with a traditional compiler and with an emulator. We   show that the compilation overhead from using JIT is negligible, and   that the JIT compiler achieves better overall performance,   suggesting the case for aggresive compilation in JIT   compilers.               Keywords: compiler optimizations, dynamic compilation, just-in-time compiler               Categories: C.4, D.3.4  
11|7||Signals and Comonads|  Tarmo Uustalu (Institute of Cybernetics at Tallinn University of Technology, Estonia)   Tarmo Vene (Department of Computer Science, University of Tartu, Estonia)  Abstract: We propose a novel discipline for programming   stream functions and for the semantic description of stream   manipulation languages based on the observation that both general   and causal stream functions can be characterized as coKleisli arrows   of comonads. This seems to be a promising application for the old,   but very little exploited idea that if monads abstract notions of   computation of a value, comonads ought to be useable as an   abstraction of notions of value in a context. We also show that   causal partial-stream functions can be described in terms of a   combination of a comonad and a monad.               Keywords: comonads, dataflow computation, distributive laws, stream functions               Categories: D.3.1, F.3.2  
11|7||An Equational Specification for the Scheme Language|  Marcelo d'Amorim (Formal Systems Laboratory, Department of Computer Science, University of Illinois Urbana­Champaign, USA)   Grigore Rosu (Formal Systems Laboratory, Department of Computer Science, University of Illinois Urbana­Champaign, USA)  Abstract: This work describes the formal semantics of   Scheme 3 as an equational theory in the Maude rewriting system. The   semantics is based on continuations and is highly modular. We   briefly investigate the relationship between our methodology for   defining programming languages and other semantic formalisms. We   conclude by showing some performance results of the interpreter   obtained for free from the executable specification.               Keywords: equational specification, formal and executable semantics, program analysis               Categories: D.3.1, D.3.4  
11|8|http://www.jucs.org/jucs_11_8|Data Streams|
11|8||Learning Decision Trees from Dynamic Data Streams|  João Gama (LIACC, FEP - University of Porto, Portugal)   Pedro Medas (LIACC - University of Porto, Portugal)  Abstract: This paper presents a system for induction of forest of functional trees from data streams able to detect concept drift. The Ultra Fast Forest of Trees (UFFT) is an incremental algorithm, which works online, processing each example in constant time, and performing a single scan over the training examples. It uses analytical techniques to choose the splitting criteria, and the information gain to estimate the merit of each possible splitting-test. For multi-class problems the algorithm builds a binary tree for each possible pair of classes, leading to a forest of trees. Decision nodes and leaves contain naive-Bayes classifiers playing different roles during the induction process. Naive-Bayes in leaves are used to classify test examples. Naive-Bayes in inner nodes play two different roles. They can be used as multivariate splitting-tests if chosen by the splitting criteria, and used to detect changes in the class-distribution of the examples that traverse the node. When a change in the class-distribution is detected, all the sub-tree rooted at that node will be pruned. The use of naive­Bayes classifiers at leaves to classify test examples, the use of splitting-tests based on the outcome of naive-Bayes, and the use of naive-Bayes classifiers at decision nodes to detect changes in the distribution of the examples are directly obtained from the sufficient statistics required to compute the splitting criteria, without no additional computations. This aspect is a main advantage in the context of high-speed data streams. This methodology was tested with artificial and real-world data sets. The experimental results show a very good performance in comparison to a batch decision tree learner, and high capacity to detect drift in the distribution of the examples.               Keywords: concept drift, data streams, incremental decision trees               Categories: H.2.8, I.2.6, I.5.2  
11|8||Network Attack Scenarios Extraction and Categorization by Mining IDS Alert Streams|  Wei Yan (New Jersey Institute of Technology, USA)  Abstract: The past few years have witnessed significant   increase in DDoS attacks on Internet, prompting network security as   a great concern. With the attacks getting more sophisticated,   automatically reasoning the attack scenarios in real time and   categorizing those scenarios become a critical   challenge. However,the overwhelming flow of events generated by   Intrusion Detection System (IDS) sensors make it hard for security   administrators to uncover hidden attack plans. This paper presents a   semantic vector space model to extract and categorize attack   scenarios based on First-order Logics (FOL) and linguistics. The   modified Case Grammar is introduced to formalize the heterogeneous   IDS alerts into uniform structured alert streams. The attack   resolution is then used to generate attack semantic   network. Afterwards, mutual information is used to determine the   alert semantic context range. Based on the attack ontology and alert   contexts, attack scenarios are extracted and the alerts are   represented as attack semantic space vectors. Finally text   categorization technique are used to categorize the intrusion   stages. The preliminary results show our model has better   performance than the traditional alert correlations.               Keywords: first-order logics, intrusion detection, network security,, resolution               Categories: I.2.4  
11|8||Semantic Preprocessing of Web Request Streams for Web Usage Mining|  Jason J. Jung (School of Computer and Information Engineering,Inha University, Korea)  Abstract: Efficient data preparation needs to discover the   underlying knowledge from complicated Web usage data. In this paper,   we have focused on two main tasks, semantic outlier detection from   online Web request streams and segmentation (or sessionization) of   them. We thereby exploit semantic technologies to infer the   relationships among Web requests. Web ontologies such as taxonomies   and directories can label each Web request as all the corresponding   hierarchical topic paths. Our algorithm consists of two steps. The   first step is the nested repetition of top-down partitioning for   establishing a set of candidates of session boundaries, and the next   step is evaluation process of bottom-up merging for reconstructing   segmented sequences. In addition, we propose the hybrid approach of   this method, as combining with the existing heuristics.  Using   synthesized dataset and real­world dataset of the access log files   of IRCache, we conducted experiments and showed   that semantic preprocessing method improves the performance of rule   discovery algorithms. It means that we can conceptually track the   behavior of users tending to easily change their intentions and   interests, or simultaneously try to search various kinds of   information on the Web.               Keywords: Web usage mining, browsing patterns, semantic analysis               Categories: H.3.3, I.5.3  
11|8||Evaluating Trigger Conditions on Streaming Time Series with User-given Quality Requirements|  Like Gao (CS Dept., University of Vermont, USA)   Min Wang (IBM T.J. Watson Research Center, USA)   X. Sean Wang (CS Dept., University of Vermont, USA)  Abstract: For many applications, it is important to   evaluate trigger conditions on streaming time series. In a resource   constrained environment, users' needs should ultimately decide how   the evaluation system balances the competing factors such as   evaluation speed, result precision, and load shedding level. This   paper presents a basic framework for evaluation algorithms that   takes user-specified quality requirements into consideration. Three   optimization algorithms, each under a different set of user-defined   probabilistic quality requirements, are provided in the framework:   (1) minimize the response time given accuracy requirements and   without load shedding; (2) minimize the load shedding given a   response time limit and accuracy requirements; and (3) minimize one   type of accuracy errors given a response time limit and without load   shedding. Experiments show that these optimization algorithms   effectively achieve their optimization goals while satisfying the   corresponding quality requirements.               Keywords: QoS (Quality of Service), prediction model, streaming time series, trigger               Categories: H.2  
11|8||Online Mining Changes of Items over Continuous Append-only and Dynamic Data Streams|  Hua-Fu Li (Department of Computer Science and Information Engineering,National Chiao-Tung University, Taiwan)   Suh-Yin Lee (Department of Computer Science and Information Engineering,National Chiao-Tung University, Taiwan)   Man-Kwan Shan (Department of Computer Science,National Chengchi University, Taiwan)  Abstract: Online mining changes over data streams has been   recognized to be an important task in data mining. Mining changes   over data streams is both compelling and challenging. In this paper,   we propose a new, single-pass algorithm, called   MFC-append (Mining   Frequency Changes of   append-only data streams), for discovering the   frequent frequency-changed items, vibrated frequency changed items,   and stable frequency changed items over continuous append-only data   streams. A new summary data structure, called   Change-Sketch, is developed to compute the   frequency changes between two continuous data streams as fast as   possible.s Moreover, a MFC-append-based algorithm, called   MFC-dynamic (Mining   Frequency Changes of   dynamic data streams), is proposed to find the   frequency changes over dynamic data streams. Theoretical analysis   and experimental results show that our algorithms meet the major   performance requirements, namely single-pass, bounded space   requirement, and real-time computing, in mining data   streams.               Keywords: change mining, data streams, single-pass algorithm               Categories: H.2.8  
11|8||Incremental Rule Learning and Border Examples Selection from Numerical Data Streams|  Francisco J. Ferrer-Troyano (Computer Science Department, University of Seville, Spain)   Jesús S. Aguilar-Ruiz (Computer Science Department, University of Seville, Spain)   José C. Riquelme (Computer Science Department, University of Seville, Spain)  Abstract: Mining data streams is a challenging task that   requires online systems based on incremental learning   approaches. This paper describes a classification system based on   decision rules that may store up-to-date border examples to avoid   unnecessary revisions when virtual drifts are present in   data. Consistent rules classify new test examples by covering and   inconsistent rules classify them by distance as the nearest   neighbour algorithm. In addition, the system provides an implicit   forgetting heuristic so that positive and negative examples are   removed from a rule when they are not near one another.               Keywords: classification, concept drift, data streams, decision rules, incremental learning               Categories: H.2.8, I.2.6, I.5.2  
11|8||Resource-aware Mining of Data Streams|  Mohamed Medhat Gaber (Centre for Distributed Systems and Software Engineering,Monash University, Australia)   Shonali Krishnaswamy (Centre for Distributed Systems and Software Engineering,Monash University, Australia)   Arkady Zaslavsky (Centre for Distributed Systems and Software Engineering,Monash University, Australia)  Abstract: Mining data streams has raised a number of research challenges for the data mining community. These challenges include the limitations of computational resources, especially because mining streams of data most likely be done on a mobile device with limited resources. Also due to the continuality of data streams, the algorithm should have only one pass or less over the incoming data records. In this article, our Algorithm Output Granularity (AOG) approach in mining data streams is discussed. AOG is a novel adaptable approach that can cope with the challenging inherent features of data streams. We also show the results for AOG based clustering in a resource constrained environment.               Keywords: clustering, data mining, data stream, resource-aware computing               Categories: H  
11|9|http://www.jucs.org/jucs_11_9|Computers and Education: Research and Experiences in eLearning Technology|
11|9||From Contents to Activities: Modelling Units of Learning|  Manuel Caeiro-Rodríguez (University of Vigo, Spain)   Martín Llamas-Nistal (University of Vigo, Spain)   Luis Anido-Rifón (University of Vigo, Spain)    Keywords: collaborative learning, e-learning, educational modelling language, learning object, unit of learning               Categories: H.1, K.3.1, K.3.2  
11|9||Semantic Web Technologies Applied to e-learning Personalization in <e-aula>|  Pilar Sancho (Universidad Complutense de Madrid, Spain)   Iván Martínez (CES Felipe II, Aranjuez, Spain)   Baltasar Fernández-Manjón (Universidad Complutense de Madrid, Spain)  Abstract: Despite the increasing importance gained by   e-learning standards in the past few years, and the unquestionable   goals reached (mainly regarding interoperability among e-learning   contents) current e-learning standards are yet not sufficiently   aware of the context of the learner. This means that only a limited   support for adaptation regarding individual characteristics is   currently being provided. In this article, we propose the use of   semantic metadata for Learning Object (LO) contextualization in   order to adapt instruction to the learner's cognitive requirements   in three different ways: background knowledge, knowledge objectives   and the most suitable learning style. In our pilot e-learning   platform () the context for LOs is addressed in two   different ways: knowledge domain and instructional design. We   propose the use of ontologies as the knowledge representation   mechanism to allow the delivery of learning material that is   relevant to the current situation of the learner.               Keywords: XML, hypermedia systems, multimedia, semantic web, web-based services               Categories: H.3.1, H.3.2, H.3.3, H.3.7, H.5.1  
11|9||A Tool for the Reinforcement of Conceptual Learning: Description and Use Experiences|  Roberto Moriyón (Escuela Politécnica Superior, Universidad Autónoma de Madrid, Spain)   Francisco Saiz (Escuela Politécnica Superior, Universidad Autónoma de Madrid, Spain)  Abstract: In this paper we describe the DeepTest tool, which is intended to reinforce the conceptual learning of any subject by means of interactive exercises for the detection of incorrect texts. DeepTest can be used through Internet. The generic aspects of the tool are analyzed, and a first report on conclusions from the use of the tool by a group of students and teachers is presented. The main conclusion is that DeepTest can be used effectively in assessment tasks and its use is very simple and intuitive.               Keywords: authoring tool, conceptual learning, interactive exercise               Categories: K.3.1  
11|9||Ubiquitous Computing in the Classroom: An Approach through Identification Process|  José Bravo (Castilla-La Mancha University, Spain)   Ramón Hervás (Castilla-La Mancha University, Spain)   Gabriel Chavira (Autonomous University of Tamaulipas, Mexico)  Abstract: In recent years, there have been many efforts at   research towards obtaining the simple and natural use of computers,   with interfaces closer to the user. New visions such as that of the   Ubiquitous Computing paradigm emerge. In Ubiquitous Computing the   computer is distributed in a series of devices with reduced   functionality, spread over the user's environment and communicating   wirelessly. With these, context-aware applications are obtained. In   this paper we present an approach to the classroom context by   identification process using RFID technology, as an implicit input   to the system. The main goal is to acquire natural interaction,   because the only requirement for the user (teacher or student) is to   carry a device (smart label), identifying and obtaining context   services. Some of these services and the mechanisms that make them   available are described here, together with a scenario of their use   in the classroom.               Keywords: RFID, context aware, implicit interaction, ubiquitous computing               Categories: F.1.2, H.5.2, I.2.6, K.3.1, K.3.2  
11|9||Integrating Educational Tools for Collaborative Computer Programming Learning|  Crescencio Bravo (Escuela Superior de Informática, Universidad de Castilla - La Mancha, Spain)   Maria Jose Marcelino (Centro de Informática e Sistemas da Universidade de Coimbra, Portugal)   Anabela Gomes (Instituto Superior de Engenharia de Coimbra, Portugal)   Micaela Esteves (Escola Superior de Tecnologia e Gestão de Leiria, Portugal)   Antonio Jose Mendes (Centro de Informática e Sistemas da Universidade de Coimbra, Portugal)  Abstract: Computer Programming learning is a difficult process. Experience has demonstrated that many students find it difficult to use programming languages to write programs that solve problems. In this paper we describe several educational computer tools used successfully to support Programming learning and we present a global environment which integrates them, allowing a broader approach to Programming teaching and learning. This environment uses program animation and the Computer-Supported Collaborative Learning (CSCL) paradigm.               Keywords: collaborative programming, computer programming learning, computer programming teaching, program animation, program simulation               Categories: K.3.2  
11|9||From Chasqui to Chasqui II: an Evolution in the Conceptualization of Virtual Objects|  Antonio Navarro (Departamento de Sistemas Informáticos y Programación, UCM, Spain)   José Luis Sierra (Departamento de Sistemas Informáticos y Programación, UCM, Spain)   Alfredo Fernández-Valmayor (Departamento de Sistemas Informáticos y Programación, UCM, Spain)   Héctor Hernanz (Telefonica I+D, Spain)  Abstract: This paper describes the evolution experienced   by the concept of virtual object. This concept   has evolved in the context of several e-learning projects developed   by the Software Engineering and Artificial   Intelligence (ISIA) group at the Complutense   University of Madrid (UCM). The initial goal of the first   of these projects, the Chasqui Project, was to   facilitate the didactic and scientific use of real objects belonging   to the Archaeology Museum of the   Department of American History II at this   University. As a concept intended for organizing learning and   scientific information, the concept of virtual object has undergone   an important transformation as it has been applied to two other   projects: the virtualization of the Museum of the History   of Computing at the School of Computer   Science at the same university, and the Chasqui   II project, an improved version of the first   Chasqui, which is now under development by the   ISIA group and the Telefónica I+D   corporation.               Keywords: IMS, LCMS, LOM, SCORM, authoring tool, e-learning, learning object, virtual campus, virtual museum, virtual object, web services               Categories: K.3.0, K.3.1, K.3.2  
11|9||Authoring and Diagnosis of Learning Activities with  the KADD  ET Environment|  Begoña Ferrero (University of the Basque Country, Spain)   Maite Martín (University of the Basque Country, Spain)   Ainhoa Alvarez (University of the Basque Country, Spain)   Maite Urretavizcaya (University of the Basque Country, Spain)   Isabel Fernández-Castro (University of the Basque Country, Spain)  Abstract: This paper describes KADD ET, a cognitive   diagnostic environment created to assess the conceptual and   procedural learning activities of students. It is composed of a   diagnostic engine, DETECTive, and a knowledge acquisition tool   developed to fulfil its knowledge representation needs, KADI. Both   of them share a Model of Learning Tasks (MLT) as a diagnostic   basis. One of the main goals of this environment is to provide   teachers with easy-to-use tools that facilitate the construction of   learning environments with diagnosis capabilities customized to   their particular subject domains and adaptation styles.               Keywords: authoring tools, cognitive diagnosis, error libraries, learning environments, model tracing               Categories: K.3, K.3.1  
11|9||A System to Support Asynchronous Collaborative Learning Tasks Using PDAs|  Ana I. Molina (Escuela Superior de Informática, Castilla - La Mancha University, Spain)   Miguel A. Redondo (Escuela Superior de Informática, Castilla - La Mancha University, Spain)   Manuel Ortega (Escuela Superior de Informática, Castilla - La Mancha University, Spain)  Abstract: Some tasks supported by educative and   collaborative tools can be more realistic and accessible if they are   tackled using mobile devices. This approach allows students to   benefit from the mobility features of this kind of devices, which   are expected to revolutionize teaching in the next decade. In this   paper we present an application called DomoSim-Mob to carry out   practical activities of domotical design using PDAs. We introduce   the task of collaborative planning of design which is supported by   DomoSim-Mob and describe its materialization starting from the user   tasks supported by the previous desktop computer version.               Keywords: PDA, computer-supported collaborative learning, domotics, mobile computing               Categories: J.4, K.3.1, K.3.2, K.3.m  
11|9||Case Studies in Tele-Education: Research and Projects|  Miguel A. Vega-Rodríguez (Dept. Informatica, Universidad de Extremadura, Spain)   Juan A. Gómez-Pulido (Dept. Informatica, Universidad de Extremadura, Spain)   Juan Manuel Sánchez-Pérez (Spain, Dept. Informatica, Universidad de Extremadura)  Abstract: ICT (Information and Communication Technologies)   are a very important educational resource at the present time   because they allow place and time limitations to be overcome and   therefore reduce costs. In addition, multimedia applications offer a   set of characteristics in order to improve learning by means of   interactive activities. For these reasons, we believe it is   important to devote efforts to the development of proposals and   prototypes for teaching via Internet. Since 1998, our research group   has been focused on this objective and working on diverse projects   such as SD2I, TEDA or PDIWeb. In this paper we overview all these   projects, presenting a general description of each web platform, as   well as the tools and methods used for their implementation. This   paper also includes the results obtained after the use of each   platform and the feedback from surveys. In this way, several   conclusions are presented in the last section of this   paper.               Keywords: Internet, computer uses in education, hypertext/hypermedia, multimedia, web-based services               Categories: C.2.5, H.3.5, H.5.1, H.5.4, K.3.1  
11|9||Integrating Ontologies into the Collaborative Authoring of Learning Objects|  Juan Manuel Dodero (Universidad Carlos III de Madrid, Spain)   Paloma Díaz (Universidad Carlos III de Madrid, Spain)   Antonio Sarasa (Universidad Complutense de Madrid, Spain)   Ignacio Sarasa ((Universidad Carlos III de Madrid, Spain)  Abstract: Authoring learning material is a multi-disciplinary undertaking where different people can play their role. Any support that can be provided for the collaboration of instructional designers, pedagogues, media designers, and students, among others, is welcome. In particular, metadata annotation of learning objects is an important task within the whole authoring process. This work presents the first resulting products and approaches from the MD2 project, consisting of a service-oriented framework and a tool to support the integrated, ontology-based collaborative annotation of learning objects.               Keywords: collaborative annotation, learning objects, metadata, ontologies               Categories: K.3.1, K.3.2  
volume|issue|url|title|abstract
12|1|http://www.jucs.org/jucs_12_1|Pervasive Health Management:  New Challenges for Health Informatics|
12|1||Pervasive Health Management and Health Management Utilizing Pervasive Technologies : Synergy and Issues|  Jean Roberts (Health Informatics Unit, University of Central Lancashire, United Kingdom)  Abstract: Much development work is ongoing addressing technologies and their application in the health domain, in order to achieve solutions that are non-invasive to every day life and work. As with many previous phases of informatics to support health, currently the developments are in islands and there is considerable untapped potential for synergy. Much research development is happening in other domains and show potential for health reversioning and deployment once proven. This paper explores some of the technological, societal and domain-specific issues surrounding this emerging concept of pervasiveness. It concludes that pervasive support to care is emerging but further work on minimizing risk and marketing the concept to professionals and laypeople is necessary to ensure an effective deployment.               Keywords: expert systems, health, human information processing, pervasive technology, portable devices, societal issues               Categories: C.5.3, H.1.2, I.1.2, J.3, K.4.m  
12|1||Health Monitoring and Assistance to Support Aging in Place|  Diane J. Cook (The University of Texas at Arlington, USA)  Abstract: To many people, home is a sanctuary. For those people who need special medical care, they may need to be pulled out of their home to meet their medical needs. As the population ages, the percentage of people in this group is increasing and the effects are expensive as well as unsatisfying. We hypothesize that many people with disabilities can lead independent lives in their own homes with the aid of at-home automated assistance and health monitoring. In order to accomplish this, robust methods must be developed to collect relevant data and process it dynamically and adaptively to detect and/or predict threatening long-term trends or immediate crises.  The main objective of this paper is to investigate techniques for using agent-based smart home technologies to provide this at-home health monitoring and assistance. To this end, we have developed novel inhabitant modeling and automation algorithms that provide remote health monitoring for caregivers. Specifically, we address the following technological challenges: 1) identifying lifestyle trends, 2) detecting anomalies in current data, and 3) designing a reminder assistance system. Our solution approaches are being tested in simulation and with volunteers at the UTA's MavHome site, an agent-based smart home project.               Keywords: artificial intelligence, multiagent systems, smart environments               Categories: I.2.11, I.2.6, M.3  
12|1||A New System Dedicated to Real-time Cardiac Arrhythmias Tele-assistance and Monitoring|  Haiying Zhou (Laboratoire LIMOS, UMR 6158 CNRS, ISIMA, University of Blaise Pascal, France)   Kun Mean Hou (Laboratoire LIMOS, UMR 6158 CNRS, ISIMA, University of Blaise Pascal, France)   Laurent Gineste (Laboratoire LIMOS, UMR 6158 CNRS, ISIMA, University of Blaise Pascal, France)   Christophe De Vaulx (Laboratoire LIMOS, UMR 6158 CNRS, ISIMA, University of Blaise Pascal, France)   Jean Ponsonnaille   Abstract: More than 60,000 people die suddenly each year in France due to cardiac arrhythmias. The current techniques used to diagnose cardiac arrhythmias such as HOLTER, R.TEST and telemetry system are partially efficient owing to the limitation of the duration of monitoring. This paper presents a new system dedicated to real-time cardiac arrhythmias tele-assistance and monitoring. This system is generally composed of 4 main configurable elements: wireless ECG sensor, local access unit, remote centre server, and remote surveillance terminal. The main technical challenges of this system include three aspects: a real-time automatic ECG diagnostic algorithm, an embedded real-time multi-task operating system, and a real-time reliable telemedicine communication protocol. This paper gives our solutions to these problems and specifies the technical details. Currently, this system has been evaluated on thirty patients at the CHRU of Gabriel Montpied hospital (Clermont-Ferrand, France) and also been used to test the athletes' cardiac status during the physical exercises. The performance results show that this system meets fully the requirements of real-time cardiac monitoring and diagnosing application and can be used as a long-term cardiac healthcare equipment.               Keywords: automatic ECG diagnosis, cardiac arrhythmias, embedded micro-kernel, real-time telemedicine, wireless ECG sensor               Categories: C.2.0, C.3, H.4.3, J.3  
12|1||CAMMD: Context-Aware Mobile Medical Devices|  Timothy O'Sullivan (Computer Science Department, University College Cork, Ireland)   John O'Donoghue (Computer Science Department, University College Cork, Ireland)   John Herbert (Computer Science Department, University College Cork, Ireland)   Richard Studdert (Computer Science Department, University College Cork, Ireland)  Abstract: Telemedicine applications on a medical practitioner's mobile device should be context-aware. This can vastly improve the effectiveness of mobile applications and is a step towards realising the vision of a ubiquitous telemedicine environment. The nomadic nature of a medical practitioner emphasises location, activity and time as key context-aware elements. An intelligent middleware is needed to effectively interpret and exploit these contextual elements. This paper proposes an agent-based architectural solution called Context-Aware Mobile Medical Devices (CAMMD). This framework can proactively communicate patient records to a portable device based upon the active context of its medical practitioner. An expert system is utilised to cross-reference the context-aware data of location and time against a practitioner's work schedule. This proactive distribution of medical data enhances the usability and portability of mobile medical devices.  The proposed methodology alleviates constraints on memory storage and enhances user interaction with the handheld device. The framework also improves utilisation of network bandwidth resources. An experimental prototype is presented highlighting the potential of this approach.               Keywords: agent technology, context-aware computing, mobile devices, telemedicine               Categories:  I.2.1, H.3.0, H.3.4, H.4.3  
12|1||The Impact of Behavioral Monitoring Technology on the Provision of Health Care in the Home|  Anthony P. Glascock (Drexel University, USA)   David M. Kutzik (Drexel University, USA)  Abstract: The lack of appropriate and accurate information on the ability of a frail individual to accomplish specific task oriented activities can place the individual at risk or result in the allocation of costly and unnecessary care. Although there have been previous attempts to use computer technology to obtain this information, they have proved to be costly and complex and therefore not widely used. However, a behavioral monitoring technology, based on smart-home and telemedicine applications, has been developed that obtains more accurate and timely information on the ability of frail individuals to accomplish specific tasks in their own residences than any other existing method. During a twelve month pilot study, this system has been used by care providers to assess the status of their clients, respond to immediate needs and alter overall care plans, thus resulting in better care and greater peace of mind for the individual.               Keywords: behavioral monitoring, care provision, smart-home technology, telemedicine, web-based services               Categories: J.3, J.4, K.4.1, K.4.2, M.0, M.7  
12|1||A Collaborative Biomedical Research System|"  Adel Taweel (University of Manchester, United Kingdom)   Alan Rector (University of Manchester, United Kingdom)   Jeremy Rogers (University of Manchester, United Kingdom)  Abstract: The convergence of need between improved clinical care and post genomics research presents a unique challenge to restructuring information flow so that it benefits both without compromising patient safety or confidentiality. The CLEF project aims to link-up heath care with bioinformatics to build a collaborative research platform that enables a more effective biomedical research. In that, it addresses various barriers and issues, including privacy both by policy and by technical means, towards establishing its eventual system. It makes extensive use of language technology for information extraction and presentation, and its shared repository is based around coherent ""chronicles"" of patients' histories that go beyond traditional health record structure. It makes use of a collaborative research workbench that encompasses several technologies and uses many tools providing a rich platform for clinical researcher.               Keywords: bioinformatics, cancer, computerized patient records, confidentiality, electronichealth records, natural languageprocessing, privacy, security               Categories: H.3.1, H.3.3, H.3.4, H.3.5, H.5.2, I.2.7, I.5.0, I.7.0, J.3, K.4.1, K.6.5, M.0, M.6  "
12|1||A Pervasive Multimodal Tele-Home Healthcare System|  Zhenjiang Miao (Institute of Information Science, School of Computer and Information Technology, Beijing Jiaotong University, P.R.China)   Baozong Yuan (Institute of Information Science, School of Computer and Information Technology, Beijing Jiaotong University, P.R.China)   Mengsun Yu (Institute of Information Science, School of Computer and Information Technology, Beijing Jiaotong University, P.R.China)  Abstract: This paper proposes a Human-centered Pervasive Computing System Model (HPC), a Layered Architectural Analysis and Design Method (LAAD) and a Waterfall Prototyping Process Model (WPP). Based on the HPC model and the LAAD method, a pervasive computing based multimodal tele-home healthcare system is designed and partly implemented using the Waterfall Prototyping Process. The design and implementation issues are discussed in more detail. Some testing results are presented.               Keywords: Jini, agent, home healthcare, pervasive computing               Categories: H.4.3, H.5.1, J.3, J.7  
12|1||A Web-Based Decision Support System for Chronic Diseases|  Chi-Chang Chang (Yuan Ze University, Taiwan, ROC)   Chuen-Sheng Cheng (Yuan Ze University, Taiwan, ROC)   Yeu-Shiang Huang (National Cheng Kung University, Taiwan, ROC)  Abstract: Individuals vary in survival chances due to   differences in genetics, environmental exposures, and   gene-environment interactions. These chances, as well as the   contribution of each factor to mortality, change as individuals get   older. In general, human physiological systems are constructed by   collecting more than one part to perform either single or multiple   functions. In addition, the successive times between failures are   not necessarily identically distributed. More generally, they can   become smaller (an indication of deterioration). However, if any   critical deterioration is detected, then the decision of when to   take the intervention, given the costs of diagnosis and   therapeutics, is of fundamental importance. At the time of the   decision, the degree of future physiological system deterioration,   which is likely to be uncertain, is of primary interest for the   decision maker. This paper develops a possible Web-based decision   support system by considering the sensitivity analysis as well as   the optimal prior and posterior decisions for aging chronic   diseases. The proposed design of Bayesian decision support systems   facilitates the effective use of the computing capability of   computers and provides a systematic way to integrate the expert's   opinions and the sampling information which will furnish decision   makers with valuable support for quality decision making.               Keywords: Bayesian Decision Theory, chronic diseases, decision support system, nonhomogeneous Poisson process (NHPP)               Categories: ...  
12|10|http://www.jucs.org/jucs_12_10|Managing Editor's Column|
12|10||Proving Properties for Behavioural Specifications with Term Observation|"  Narjes Berregeb (Institut National des Sciences Appliquées et deTechnologie, Tunisia)  Abstract: Behavioural specifications allow to focus only on the""observable"" behaviour of objects. These observations are made through ""observable contexts"" which are particular terms with a hole to be filled in with an object. We consider behavioural specifications based on the observation of a specified set of linear terms. The set of observable contexts is often infinite; therefore, we give an algorithm for computing some special contexts that we call ""covering contexts"", and show that they are sufficient for proving that two terms are behaviourally equal.               Keywords: behavioural specifications, covering contexts, observable contexts, term observation               Categories: F.3.1, F.4.1  "
12|10||Ridge Orientation Estimation and Verification Algorithm for Fingerprint Enhancement|  Limin Liu (Chung Yuan Christian University, Taiwan, ROC)   Tian-Shyr Dai (National Chiao-Tung University, Taiwan, ROC)  Abstract: Fingerprint image enhancement is a common and critical step in fingerprint recognition systems. To enhance the images, most of the existing enhancement algorithms use filtering techniques that can be categorized into isotropic and anisotropic according to the filter kernel. Isotropic filtering can properly preserve features on the input images but can hardly improve the quality of the images. On the other hand, anisotropic filtering can effectively remove noise from the image but only when a reliable orientation is provided. In this paper, we propose a ridge orientation estimation and verification algorithm which can not only generate an orientation of ridge flows, but also verify its reliability. Experimental results show that, on average, over 51 percent of an image in the NIST-4 database has reliable orientations. Based on this algorithm, a hybrid fingerprint enhancement algorithm is developed which applies isotropic filtering on regions without reliable orientations and anisotropic filtering on regions with reliable orientations. Experimental results show the proposed algorithm can combine advantages of both isotropic and anisotropic filtering techniques and generally improve the quality of fingerprint images.               Keywords: Gabor filter, enhancement, fingerprint, orientation estimation               Categories: I.4.3, I.4.9, I.5.4  
12|10||Fault Tolerant Neural Predictors for Compression of Sensor Telemetry Data|  Rajasvaran Logeswaran (Multimedia University, Malaysia)  Abstract: When dealing with remote systems, it is desirable that these systems are capable of operation within acceptable levels with minimal control and maintenance. In terms or transmission of telemetry information, a prediction-based compression scheme has been introduced. This paper studies the influence of some typical transmission and network errors on the encoded residue stream produced by a number of predictors used in the scheme, with the intention of identifying the more fault tolerant architecture that may be preferred as predictors. Classical linear predictors such as FIR and lattice filters, as well as a variety of feedforward and recurrent neural networks are studied. The residue streams produced by these predictors are subjected to two types of commonly occurring transmission noise, namely gaussian and burst. The noisy signal is decoded at the receiver and the magnitude of error, in terms or MSE and MAE are compared. Hardware failures in the input receptor and multiplier are also simulated and the performance of various predictors is compared. Overall, it is found that even small low-complexity neural networks are more resilient to faults due to the characteristics of their parallel architecture and distributed storage/processing characteristics.               Keywords: data compression, error tolerance, neural networks, predictors               Categories: E.2, H.4.3, I.5.4  
12|10||Time-varying H Systems Revisited|  Remco Loos (Rovira i Virgili University, Spain)  Abstract: We cast a new look on time-varying distributed H systems. In their original definition, where only new strings are passed to the next component, this language definition in itself is already enough to obtain computational completeness. Here, we consider two types of time-varying H systems with weaker language definitions, based on the usual definition of splicing systems: The next generation of strings consists of the union of all existing strings and the newly created strings. We show that if all strings, both old and new, are passed to the next component these systems are regular in power. If however, the new strings pass to the next component and the existing ones remain accessible to the current one, we prove that systems with 4 components are already computationally complete.               Keywords: DNA computing, molecular computing, splicing systems               Categories: F.1.1, F.4.2  
12|11|http://www.jucs.org/jucs_12_11|Programming and Languages|
12|11||An Interval Constraint Branching Scheme for Lattice Domains|  Antonio J. Fernández (University of Málaga, Spain)   Patricia M. Hill (University of Leeds, United Kingdom)  Abstract: Abstract This paper presents a branching schema for the solving of a wide range of interval constraint satisfaction problems defined on any domain of computation, finite or infinite, provided the domain forms a lattice. After a formal definition of the branching schema, useful and interesting properties, satisfied by all instances of the schema, are presented. Examples are then used to illustrate how a range of operational behaviors can be modelled by means of different schema instantiations. It is shown how the operational procedures of many constraint systems (including cooperative systems) can be viewed as instances of this branching schema. Basic directives to adapt this schema to solving constraint optimization problems are also provided.               Keywords: constraint branching, constraint optimization, constraint propagation, constraint solving, interval constraint               Categories: D.3.3, I.1.2  
12|11||Constraint Based Methods for Biological Sequence Analysis|  Maryam Bavarian (Simon Fraser University, USA)   Veronica Dahl (Simon Fraser University, USA)  Abstract: The need for processing biological information is rapidly growing, owing to the masses of new information in digital form being produced at this time. Old methodologies for processing it can no longer keep up with this rate of growth. The methods of Artificial Intelligence (AI) in general and of language processing in particular can offer much towards solving this problem. However, interdisciplinary research between language processing and molecular biology is not yet widespread, partly because of the effort needed for each specialist to understand the other one's jargon. We argue that by looking at the problems of molecular biology from a language processing perspective, and using constraint based logic methodologies we can shorten the gap and make interdisciplinary collaborations more effective. We shall discuss several sequence analysis problems in terms of constraint based formalisms such Concept Formation Rules, Constraint Handling Rules (CHR) and their grammatical counterpart, CHRG. We postulate that genetic structure analysis can also benefit from these methods, for instance to reconstruct from a given RNA secondary structure, a nucleotide sequence that folds into it. Our proposed methodologies lend direct executability to high level descriptions of the problems at hand and thus contribute to rapid while efficient prototyping.               Keywords: RNA secondary structure, concept formation, constraint handling rule grammars, constraint handling rules, gene prediction, protein structure               Categories: D.3.2, D.3.3, I.2.1  
12|11||Process Equivalences as Global Bisimulations|  David de Frutos Escrig (Universídad Complutense de Madrid, Spain)   Carlos Gregorio Rodríguez (Universídad Complutense de Madrid, Spain)  Abstract: Bisimulation can be defined in a simple way using coinductive methods, and has rather pleasant properties. Ready similarity was proposed by Meyer et al. as a way to weakening the bisimulation equivalence thus getting a semantics defined in a similar way, but supported for more reasonable (weaker) observational properties.  Global bisimulations were introduced by Frutos et al. in order to study different variants of non-determinism getting, in particular, a semantics under which the internal choice operator becomes associative. Global bisimulations are defined as plain bisimulations but allowing the use of new moves, called global transitions, that can change the processes not only locally in its head, but anywhere.  Now we are continuing the study of global bisimulation but focusing on the way different semantics can be characterised as global bisimulation semantics. In particular, we have studied ready similarity, on the one hand because it was proposed as the strongest reasonable semantics weaker than bisimulation; on the other hand, because ready similarity was not directly defined as an equivalence relation but as the nucleus of an order relation, and this open the question whether it is also possible to define it as a symmetric bisimulation-like semantics.  We have got a simple and elegant characterisation of ready similarity as a global bisimulation semantics, that provides a direct symmetric characterisation of it as an equivalence relation, without using any order as intermediate concept. Besides, we have found that it is not necessary to start from a simulation based semantics to get an equivalent global bisimulation. What has proved to be very useful is the axiomatic characterisation of the semantics. Following these ideas we have got also global bisimulation for several semantics, including refusals and traces. That provides a general framework that allows to relate both intensional and extensional semantics.               Keywords: bisimulation, comparative semantics, concurrentprocess equivalences and preorders,, ready simulation, refusal, traces               Categories: D.3.1, F.1.2, F.3.2  
12|11||Verifying Real-Time Properties of tccp Programs|  María Alpuente (Technical University of Valencia, Spain)   María del Mar Gallardo (University of Malaga, Spain)   Ernesto Pimentel (University of Malaga, Spain)   Alicia Villanueva (Technical University of Valencia, Spain)  Abstract: The size and complexity of software systems are   continuously increasing, which makes them difficult and   labor-intensive to develop, test and evolve. Since concurrent   systems are particularly hard to verify by hand, achieving effective   and automated verification tools for concurrent software has become   an important topic of research. Model checking is   a popular automated verification technology which allows us to   determine the properties of a software system and enables more   thorough and less costly testing. In this work, we improve the   model-checking methodology previously developed   for the timed concurrent constraint programming   language tccp so that more   sophisticated, real-time properties can be verified by the   model-checking tools. The contributions of the paper are twofold. On   the one hand, we define a timed extension of the   tccp semantics which considers an explicit,   discrete notion of the passing of time. On the other hand, we   consistently define a real-time extension of the linear-time   temporal logic that is used to specify and analyze the software   properties in tccp. Both extensions fit into   the tccp framework perfectly in such a way that   with minor modifications any tccp model checker   can be reused to analyze real-time properties. Finally, by means of   an example, we illustrate the improved ability to check real-time   properties.               Keywords: model checking, temporal logic, timed concurrent constraint paradigm               Categories: D.2.4, D.3.2  
12|11||Constructive Failure in Functional-Logic Programming: From Theory to Implementation|  Jaime Sánchez-Hernández (Universidad Complutense de Madrid, Spain)  Abstract: Functional-logic programming amalgamates some of   the main features of both functional and logic styles into a single   paradigm. Nevertheless, negation is a widely investigated feature in   logic programming that has not received much attention in such   programming style. It is not difficult to incorporate some kind of   negation as finite failure for ground goals, but   we are interested in a constructive version able   to deal with non-ground goals. With this aim, in previous works we   have built a formal framework for checking (finite) failure   of reduction. In this paper we adapt it for implementing a   prototype for a functional-logic language with constructive   failure as the natural counterpart to negation in logic   programming.               Keywords: constructive failure, functional-logic programming, narrowing, negation               Categories: D.1.1, D.1.6, F.3.2  
12|11||Verification of CRWL Programs with Rewriting Logic|  José Miguel Cleva (Universidad Complutense de Madrid, Spain)   Isabel Pita (Universidad Complutense de Madrid, Spain)  Abstract: We present a novel approach to the verification of functional-logic programs. For our verification purposes, equational reasoning is not valid due to the presence of non-deterministic and partial functions. Our approach transforms functionallogic programs into Maude theories and then uses the Rewriting Logic logical framework to verify properties of the transformed programs. We propose an inductive proving method based on the length of the computation on the Rewriting Logic framework to cope with the non-deterministic and non-terminating aspects of the programs. We illustrate the application of the method on various examples, where we analyze the sequence of steps to be performed by the proof in order to get expertise for the automatization of the process. Then, since the proposed transformation process is also amenable of automatization, we will obtain a tool for proving properties of CRWL programs. Another advantage of our methodology, that distinguish it from other approaches, is that it does not confuse the original functional-logic program with the subjects we want to talk about in the properties, but it allows the equational definition of observations on top of the transformed programs which simplifies the obtained proofs.               Keywords: Maude, functional logic programming, rewriting logic, verification               Categories: D.1.1, D.1.6, F.3.1  
12|11||Introducing the ITP Tool: a Tutorial|  Manuel Clavel (Universidad Complutense de Madrid, Spain)   Miguel Palomino (Universidad Complutense de Madrid, Spain)   Adrián Riesco (Universidad Complutense de Madrid, Spain)  Abstract: We present a tutorial of the ITP tool, a rewriting-based theorem prover that can be used to prove inductive properties of membership equational specifications. We also introduce membership equational logic as a formal language particularly adequate for specifying and verifying semantic data structures, such as ordered lists, binary search trees, priority queues, and powerlists. The ITP tool is a Maude program that makes extensive use of the reflective capabilities of this system. In fact, rewritingbased proof simplification steps are directly executed by the powerful underlying Maude rewriting engine. The ITP tool is currently available as a web-based application that includes a module editor, a formula editor, and a command editor. These editors allow users to create and modify their specifications, to formalize properties about them, and to guide their proofs by filling and submitting web forms.               Keywords: ITP, inductive theorem proving, membership equational logic, semantic data structures               Categories: F.3.1, F.4.2  
12|11||Magic Sets for the XPath Language|  Jesús M. Almendros-Jiménez (Universidad de Almería, Spain)   Antonio Becerra-Terón (Universidad de Almería, Spain)   Francisco J. Enciso-Baños (Universidad de Almería, Spain)  Abstract: The eXtensible Markup Language (XML) is considered as the format of choice for the exchange of information among various applications on the Internet. Since XML is emerging as a standard for data exchange, it is natural that queries among applications should be expressed as queries against data in XML format. This use gives rise to a requirement for a query language expressly designed for XML resources. World Wide Web Consortium (W3C) convened to create the XQuery language, concretely, a typed functional language for querying XML documents. One key aspect of the XQuery language is the use of the XPath language as basis for handling the structure of an XML document. In this paper, we present a proposal for the representation of XML documents by means of a logic program. Rules and facts can be used for representing the document schema and the XML document itself. In addition, we study how to query by means of the XPath language against a logic program representing an XML document. It evolves the specialization of the logic program with regard to the XPath expression. This specialization technique is based on the well-known transformation technique called Magic Sets and studied for deductive databases. The bottom-up evaluation of the speciali               Keywords: XPath language, logic programming, magic sets               Categories: D.1.6, H.2.3  
12|11||Operational/Interpretive Unfolding of Multi-adjoint Logic Programs|  Pascual Julián (University of Castilla-La Mancha, Spain)   Ginés Moreno (University of Castilla-La Mancha, Spain)   Jaime Penabad (University of Castilla-La Mancha, Spain)  Abstract: Multi-adjoint logic programming represents a   very recent, extremely flexible attempt for introducing fuzzy logic   into logic programming. In this setting, the execution of a goal   w.r.t. a given program is done in two separate phases. During the   operational one, admissible steps are   systematically applied in a similar way to classical resolution   steps in pure logic programming, thus returning a computed   substitution together with an expression where all atoms have been   exploited. This last expression is then interpreted under a given   lattice during the so called interpretive phase, hence returning a   value which represents the fuzzy component (truth   degree) of the computed answer.  On the other hand, unfolding is a well known transformation rule widely used in declarative programming for optimizing and specializing programs, among other applications. In essence, it is usually based on the application of operational steps on the body of program rules. The novelty of this paper consists in showing that this process can also be made in terms of interpretive steps. We present two strongly related kinds of unfolding (operational and interpretive), which, apart from exhibiting strong correctness properties (i.e. they preserve the semantics of computed substitutions and truth degrees) they are able to significantly simplify the two execution phases when solving goals.               Keywords: fuzzy logic programming, program transformation, unfolding               Categories: D.1.6, I.2.2, I.2.3  
12|12|http://www.jucs.org/jucs_12_12|Managing Editor's Column|
12|12||Modeling Inheritance as Coercion in the Kenzo System|"  César Domínguez (Universidad de La Rioja, Spain)   Julio Rubio (Universidad de La Rioja, Spain)   Francis Sergeraert (Universite Grénoble, France)  Abstract: In this paper the analysis of the data structures used in a symbolic computation system, called Kenzo, is undertaken. We deal with the specification of the inheritance relationship since Kenzo is an object-oriented system, written in CLOS, the Common Lisp Object System. We show how the order-sorted algebraic specification formalism can be adapted, through the ""inheritance as coercion"" metaphor, in order to model the simple inheritance between structures in Kenzo.               Keywords: algebraic specification, coercion, inheritance, symbolic computation               Categories: F.3.1  "
12|12||Restricting the View and Connecting the Dots — Dangers of a Web Search Engine Monopoly|"  Narayanan Kulathuramaiyer (University Malaysia Sarawak, Malaysia)   Wolf-Tilo Balke (L3S Research Center and University of Hannover, Germany)  Abstract: Everyone realizes how powerful the few big Web search engine companies have become, both in terms of financial resources due to soaring stock quotes and in terms of the still hidden value of the wealth of information available to them. Following the common belief that ""information is power"" the implications of what the data collection of a de-facto monopolist in the field like Google could be used for should be obvious. However, user studies show that the real implications of what a company like Google can do, is already doing, and might do in a not too distant future, are not explicitly clear to most people.  Based on billions of daily queries and an estimated share of about     49% of the total Web queries [Colburn, 2007], allows predicting     with astonishing accuracy what is going to happen in a number of     areas of economic importance. Hence, based on a broad information     base and having the means to shift public awareness such a company     could for instance predict and influence the success of products     in the market place beyond conventional advertising or play the     stock market in an unprecedented way far beyond mere time series     analysis. But not only the mining of information is an interesting     feature; with additional services such as Google Mail and on-line     communities, user behavior can be analyzed on a very personal     level. Thus, individual persons can be targeted for scrutiny and     manipulation with high accuracy resulting in severe privacy     concerns.  All this is compounded by two facts: First, Google's initial     strategy of ranking documents in a fair and objective way     (depending on IR techniques and link structures) has been replaced     by deliberatively supporting or ignoring sites as economic or     political issues are demanding [Google Policy: Censor,     2007]. Second, Google's acquisition of technologies and     communities together with its massive digitization projects such     as [Burright, 2006] [Google Books Library, Project, 2006] enable     it to combine information on issues and persons in a still more     dramatic way. Note that search engines companies are not breaking     any laws, but are just acting on the powers they have to increase     shareholder value. The reason for this is that there are currently     no laws to constrain data mining in any way. We contend that     suitable internationally accepted laws are necessary. In their     absence, mechanisms are necessary to explicitly ensure web content     neutrality (which goes beyond the net neutrality of [Berners-Lee,     2006]) and a balanced distribution of symbolic power [see Couldry,     2003]. In this paper we point to a few of the most sensitive     issues and present concrete case studies to support our point. We     need to raise awareness to the threat that a Web search engine     monopoly poses and as a community start to discuss the     implications and possible remedies to the complex problem.               Keywords: Web mining, search engines and information retrieval, social issues               Categories: H.3.0, I.2.6, K.4.2, K.5.2  "
12|12||A Formal Architectural Description Language based on Symbolic Transition Systems and Temporal Logic|  Pascal Poizat (IBISC FRE 2873 CNRS - Université d'Évry Val d'Essonne and ARLES team - INRIA, France)   Jean-Claude Royer (Ecole des Mines de Nantes - INRIA, LINA, France)  Abstract: Component Based Software Engineering has now   emerged as a discipline for system development. After years of   battle between component platforms, the need for means to abstract   away from specific implementation details is now recognized. This   paves the way for model driven approaches (such as the OMG MDA) but   also for the more older Architectural Description Language (ADL)   paradigm. In this paper we present Korrigan, a true ADL (in the   [MT00] sense), which provides interesting features: fully formal   behaviours and data types, expressive component gluing mechanisms   through the use of temporal logic, yet ensuring the specification   readability thanks to graphical notations.               Keywords: abstract data types, architectural description language, component basedsoftware engineering, graphical notations, mixed formal specifications, symbolic transitionsystem, temporal logic glue               Categories: D.2, D.2.1, D.2.10, D.2.11, D.2.13, D.2.2  
12|12||Persian/Arabic Baffletext CAPTCHA|  Mohammad Hassan Shirali-Shahreza (Yazd University, Iran)   Mohammad Shirali-Shahreza (Sharif University of Technology, Iran)  Abstract: Nowadays, many daily human activities such as education, trade, talks, etc are done by using the Internet. In such things as registration on Internet web sites, hackers write programs to make automatic false registration that waste the resources of the web sites while it may also stop it from functioning. Therefore, human users should be distinguished from computer programs. To this end, this paper presents a method for distinction of Persian and Arabic-language users from computer programs based on Persian and Arabic texts. Our proposed algorithm is based on adding a background to the image of a meaningless Persian/Arabic randomly generated word. This method relies on the difficulty of automatic separation of background from Persian/Arabic writing, due to the presence of many diacritical dots and signs.In this method, the image of a random meaningless Persian or Arabic word is shown to the user and he is asked to type it. Considering that the presently available Persian and Arabic OCR programs cannot identify these words, the word can be identified only by a Persian or Arabic-language user. This method also can be used to prevent program attacks, resource waste and performance reduction. The proposed method has been implemented by the Java language. The generated words are tested, using ReadIris and Omnipage OCR systems. These OCR systems were unable to recognize these words.               Keywords: BaffleText, Persian and Arabic text, completely automated public Turing test to tell computersand human apart (CAPTCHA), internet security, optical character recognition (OCR)               Categories: I.4.0, I.4.5  
12|2|http://www.jucs.org/jucs_12_2|Managing Editor's Column|
12|2||Multiple Explanations Driven Naïve Bayes Classifier|  Ahmad Almonayyes (Kuwait University, Kuwait)  Abstract: Exploratory data analysis over foreign language   text presents virtually untapped opportunity. This work incorporates   Naïve Bayes classifier with Case-Based Reasoning in order to   classify and analyze Arabic texts related to fanaticism. The Arabic   vocabularies are converted to equivalent English words using   conceptual hierarchy structure. The understanding process operates   at two phases. At the first phase, a discrimination network of   multiple questions is used to retrieve explanatory knowledge   structures each of which gives an interpretation of a text according   to a particular aspect of fanaticism. Explanation structures   organize past documents of fanatic content. Similar documents are   retrieved to generate additional valuable information about the new   document.  In the second phase, the document classification process   based on Naïve Bayes is used to classify documents into their   fanatic class. The results show that the classification accuracy is   improved by incorporating the explanation patterns with the Naïve   Bayes classifier.               Keywords: Naïve Bayes, case-based reasoning, data mining, explanation patterns, text classification               Categories: I.1.2, I.1.7, I.2.1, I.2.6  
12|2||An O(√n) Distributed Mutual Exclusion Algorithm  Using Queue Migration|  Pranay Chaudhuri (University of the West Indies, Cave Hill Campus, Barbados)   Thomas Edward (University of the West Indies, Cave Hill Campus, Barbados)  Abstract: In this paper a distributed algorithm is   proposed that realises mutual exclusion among n nodes in a computer   network.  There is no common or global memory shared by the nodes   and there is no global controller.  The nodes of the network   communicate among themselves by exchanging messages only.  The   proposed algorithm is based on queue migration and achieves a   message complexity of O(√n) per mutual exclusion invocation.  Under   heavy load, the number of required messages approaches 2 per mutual   exclusion.               Keywords: computer network, critical section, distributed algorithm, message complexity, mutual exclusion, queue migration               Categories: C.2.4, F.2.2, I.1.2  
12|2||POCA : A User Distributions Algorithm in Enterprise Systems with Clustering|  Ping-Yu Hsu (Department of Business Administration, National Central University,, Taiwan)   Ping-Ho Ting (Department of Hospitality Management, Tunghai University)  Abstract: As enterprises worldwide race to improve real-time management to improve productivity, customer services and flexibility, huge resources have been invested into enterprise systems (ESs). All modern ESs adopt an n-tier client-server architecture, which includes several application servers to hold users and applications. As in any other multi-server environment, the load distributions, and user distributions in particular, become a critical issue in tuning system performance.  In stateful ESs, a user who logs onto an application server and stays connected to the server for an entire working session, which can last for days, evokes each application.  Therefore, admitting a user onto an application server affects not only current but also future performance of that server. Although the n-tier architecture may involve web servers, there is little in the literature in Distributed Web Server Architectures that considers the effects of distributing users instead of individual requests to servers.  The algorithm proposed in this paper gives specific suggestions in user distributions and the minimal number of servers required based on the application reusability threshold.  A heuristic version of the algorithm is also presented to improve the performance. The paper also discusses how to apply association rules to predict new user behavior when distributing users in the run-time. The distributions recommended by the algorithms are compared against the Round-Robin distributions on a set of real data derived from a mid size company. The result shows that the user distributions suggested have better performance than Round Robin distributions.               Keywords: clustering, enterprise systems, load balancing, profile, user distribution               Categories: H.1.2, H.2.4, H.2.8, H.3.3, H.3.4, K.6.4  
12|2||The Transformation of the Web: How Emerging Communities Shape the Information we Consume|  Josef Kolbitsch (Graz University of Technology, Austria)   Hermann Maurer (Institute for Information Systems and Computer Media,Graz University of Technology, Austria)  Abstract: To date, one of the main aims of the World Wide   Web has been to provide users with information. In addition to   private homepages, large professional information providers,   including news services, companies, and other organisations have set   up web-sites. With the development and advance of recent   technologies such as wikis, blogs, podcasting and file sharing this   model is challenged and community-driven services are gaining   influence rapidly. These new paradigms obliterate the clear   distinction between information providers and consumers. The lines   between producers and consumers are blurred even more by services   such as Wikipedia, where every reader can become an author,   instantly.   This paper presents an overview of a broad selection of current technologies and services: blogs, wikis including Wikipedia and Wikinews, social networks such as Friendster and Orkut as well as related social services like del.icio.us, file sharing tools such as Flickr, and podcasting. These services enable user participation on the Web and manage to recruit a large number of users as authors of new content. It is argued that the transformations the Web is subject to are not driven by new technologies but by a fundamental mind shift that encourages individuals to take part in developing new structures and content. The evolving services and technologies encourage ordinary users to make their knowledge explicit and help a collective intelligence to develop.               Keywords: blogs, collaborative work, community building, emergence, file sharing, information systems, podcasting, self-organisation, social networks, web-based applications, wikis               Categories: H.3.4, H.3.5, H.3.7, H.4.3, H.5.1  
12|2||A Structure Causality Relation  for Liveness Characterisation in Petri Nets|  Belhassen Zouari (LIP2 laboratory , University ElManar, Tunisia)  Abstract: Characterising liveness using a structure based approach is a key issue in theory of Petri nets. In this paper, we introduce a structure causality relation from which a topological characterisation of liveness in Petri nets is defined. This characterisation relies on a controllability property of siphons and allows to determine the borders of the largest abstract class of Petri nets for which equivalence between liveness and deadlock-freeness holds. Hence, interesting subclasses of P/T systems, for which membership can be easily determined, are presented. Moreover, this paper resumes, from a new point of view, similar results related to this issue and, provides a unified interpretation of the causes of the non-equivalence between liveness and deadlock-freeness.               Keywords: Petri nets, deadlock-freeness, liveness, siphons, structural analysis               Categories: D.0, F.1.1, F.3.1, F.4, G.2  
12|3|http://www.jucs.org/jucs_12_3|Ubiquitous Computing and Ambient Intelligence:  New Challenges for Computing|
12|3||Development of Ambient Intelligence Applications using Components and Aspects|  Lidia Fuentes (Universidad de Málaga, Spain)   Daniel Jiménez (Universidad de Málaga, Spain)   Mónica Pinto (Universidad de Málaga, Spain)  Abstract: In recent times, interest in Ambient Intelligence (or AmI) has increased considerably. One of the main challenges in the development of these systems is to improve their modularization in order to achieve a high degree of reusability, adaptability and extensibility. This will help us to deal with the heterogeneity and evolution of the environments in which AmI devices exit. An example would be to easily adapt existing applications when new communication technologies appear. Current approaches apply component technologies to achieve these goals, but more should be done. Our research focuses on applying aspect technologies to components in order to improve AmI application modularization. We present the benefits of aspect technologies with regard to reusability and adaptability, by showing the limitations of PCOM, a component-based AmI middleware platform. We will show a study comparing DAOPAmI, our own component and aspect-based AmI middleware platform and PCOM.               Keywords: ambient intelligence, aspects, components, middleware, pervasive computing               Categories: D.2, D.2.11, D.2.12, D.2.13, D.2.2, D.2.4, D.2.6  
12|3||Quality of Privacy (QoP) for the Design of Ubiquitous Healthcare Applications|  Mónica Tentori (Department of Computer Science, CICESE, Mexico)   Jésus Favela (Department of Computer Science, CICESE, Mexico)   Victor M. González (Department of Informatics, University of California at Irvine, USA)  Abstract: Privacy is a complex social process that will persist in one form or another as a fundamental feature of the substrate into which ubiquitous computing (ubicomp) is threaded. Hospitals are natural candidates for the deployment of ubicomp technology while at the same time face significant privacy requirements. To better understand the privacy issues related to the use of ubicomp we place our efforts in understanding the contextual information relevant to privacy and how its interplay shapes the perception of privacy in a hospital. The results indicate that hospital workers tend to manage privacy by assessing the value of the services provided by a ubicomp application and the amount of privacy they are willing to concede. For ubicomp applications to better deal with this issue we introduce the concept of Quality of Privacy (QoP) which allows balancing this trade-off in a similar way as that of Quality of Service (QoS) does for networking applications. We propose an architecture that allows designers to identify different levels of QoP based on the user's context. Finally, we identify the main privacy risks of a location-aware application and we extend its architecture exemplifying the use of QoP to manage those risks.               Keywords: privacy-aware computing, quality of privacy, ubiquitous computing, ubiquitous healthcare               Categories: H.5.2, K.4.1  
12|3||Visualization Services in a Conference Context:  An Approach by RFID Technology|"  José Bravo (Castilla-La Mancha University, Spain)   Ramón Hervás (Castilla-La Mancha University, Spain)   Inocente Sánchez (Castilla-La Mancha University, Spain)   Gabriel Chavira (Autonomous University of Tamaulipas, Mexico)   Salvador Nava (Autonomous University of Tamaulipas, Mexico)  Abstract: Ambient Intelligent (AmI) vision is a new concept materialized by the Six Framework Program of the European Community. It involves three key technologies: Ubiquitous Computing, Ubiquitous Communications and Natural Interfaces. With the increase in context aware applications it is important to keep these technologies in mind. In this paper we present a context aware application in a conference site based on the identification process using RFID. Furthermore the highlights of this proposal are based on the ""ws"" concepts. Three environments are modelled applying the ""who"" to the ""when"" and ""where"" to reach the ""what"". In this sense certain services are offered to the conference attendees, some of which are characteristics of this technology and others are the result of a context aware application, the visualization services named ""Mosaics of Information"".               Keywords: RFID, context aware, implicit interaction, information mosaics, ubiquitous computing, visualization               Categories: F.1.1, H.1, H.1.1, H.1.2, H.5, H.5.2  "
12|3||A Mechanism for Solving Conflicts in Ambient Intelligent Environments|  Pablo A. Haya (Dept. de Ingeniería Informática UAM - EPS, Spain)   Germán Montoro (Dept. de Ingeniería Informática UAM - EPS, Spain)   Abraham Esquivel (Dept. de Ingeniería Informática UAM - EPS, Spain)   Manuel García-Herranz (Dept. de Ingeniería Informática UAM - EPS, Spain)   Xavier Alamán (Dept. de Ingeniería Informática UAM - EPS, Spain)  Abstract: Ambient Intelligence   scenarios describe situations in which multitude of devices and   agents live together. In this kind of scenarios is frequent to see   the appearance of conflicts when modifying the state of a device as   for example a lamp. Those problems are not as much of sharing of   resources as of conflict of orders coming from different   agents. This coexistence must deal also with the desire of privacy   of the different users over their personal information such as where   they are, what their preferences are or to whom this information   should be available.  When facing incompatible orders over the state   of a device it turns necessary to make a decision. In this paper we   propose a centralised mechanism based on prioritized FIFO queues to   decide the order in which the control of a device is granted. The   priority of the commands is calculated following a policy that   considers issues such as the commander's role, command's type,   context's state and commander-context and commander-resource   relations.  Finally we propose a set of particular policies for   those resources that do not adjust to the general policy. In   addition we present a model pretending to integrate privacy through   limiting and protecting contextual information.               Keywords: ambience intelligence, context awareness, intelligent environments, privacy               Categories: H.3.1, H.3.2, H.3.3, H.3.7, H.5.1  
12|3||EMI²lets: A Reflective   Framework for Enabling AmI|  Diego López de Ipiña (University of Deusto, Spain)   Juan Ignacio Vázquez (University of Deusto, Spain)   Daniel García (University of Deusto, Spain)   Javier Fernández (University of Deusto, Spain)   Iván García (University of Deusto, Spain)   David Sainz (University of Deusto, Spain)   Aitor Almeida (University of Deusto, Spain)  Abstract: An interesting new application domain for handheld devices may be represented by Ambient Intelligence (AmI), where they can be used as intermediaries between us and our surrounding environment. Thus, the devices, which always accompany us, will behave as electronic butlers who assist us in our daily tasks, by interacting with the smart objects (everyday objects augmented with computational services) in our whereabouts. In order to achieve such goal, this paper proposes an AmI-enabling framework providing two main functions: a) facilitate the development and deployment of smart objects and b) transform mobile devices into universal remote controllers of those smart objects.               Keywords: ambient intelligence, middleware, pervasive computing, smart spaces               Categories: C.2.4, C.2.6, D.2.11, D.2.12, D.2.2, D.2.6  
12|3||Context-Aware QoS Provision for Mobile Ad-hoc Network -based Ambient Intelligent Environments|  Felix Jesus Villanueva (University of Castilla-La Mancha, Spain)   David Villa (University of Castilla-La Mancha, Spain)   Francisco Moya (University of Castilla-La Mancha, Spain)   Jesus Barba (University of Castilla-La Mancha, Spain)   Fernando Rincón (University of Castilla-La Mancha, Spain)   Juan Carlos López (University of Castilla-La Mancha, Spain)  Abstract: Lately, wireless networks have gained acceptance for home networking. Low cost installation, flexibility and no fixed infrastructures have made it possible home environments rapidly to adopt this technology. In this paper we introduce the use of mobile ad-hoc networks (MANETs) for large in-home environments, such as hospitals, government buildings, office and industrial buildings, etc. Thus, we define an information gathering mechanism in order to provide a context aware QoS framework, relaxing some restrictions that are inherited from traditional ad-hoc networks scenarios (battlefield, catastrophic disaster, etc.) to better fit the specific characteristics of this new application field. In particular, we propose an adaptative QoS architecture oriented to provide context-aware quality of service to the traffic generated in a smart-building network.               Keywords: context-aware services, mobile ad-hoc networks, quality of services                
12|3||A Modular Architecture for Nodes in Wireless  Sensor Networks|  Jorge Portilla (Universidad Politécnica de Madrid, Spain)   Angel de Castro (Universidad Politécnica de Madrid)   Eduardo de la Torre (Universidad Politécnica de Madrid, Spain)   Teresa Riesgo (Universidad Politécnica de Madrid, Spain)  Abstract: The growth of sensor networks during the last years is a fact and within this field, wireless sensor networks are growing particularly as there are many applications that demand the use of many nodes, even hundreds or thousands. More and more applications are emerging to solve several problems in data acquisition and control in different environments, taking advantage of this technology. In this context, hardware design of the sensor network node becomes critical to satisfy the hard constraints imposed by wireless sensor networks, like low power consumption, low size and low cost. Moreover, these nodes must be capable of sensing, processing and communicating physical parameters, becoming true smart sensors in a network. With this goal in mind, we propose a modular architecture for the nodes, composed of four layers: communication, processing, power supply and sensing. The purpose is to minimize the redesign effort as well as to make the node flexible and adaptable to many different applications. In a first prototype of the node, we present a node with a mixed design based on a microcontroller and an FPGA for the processing layer and Bluetooth technology for communications.               Keywords: hardware node design, modular architecture, sensor network node, wireless sensor networks               Categories: B.5.1, B.6.0, B.7.0.  
12|3||Secure Service Discovery based on Trust Management for ad-hoc Networks|  Celeste Campo (University Carlos III of Madrid, Spain)   Florina Almenárez (University Carlos III of Madrid, Spain)   Daniel Díaz (University Carlos III of Madrid, Spain)   Carlos García-Rubio (University Carlos III of Madrid, Spain)   Andrés Marín López (University Carlos III of Madrid, Spain)  Abstract: In ad-hoc networks, mobile devices communicate via wireless links without the aid of any fixed networking infrastructure. These devices must be able to discover services dynamically and share them safely, taking into account ad-hoc net-works requirements such as limited processing and communication power, decentralised management, and dynamic network topology, among others. Legacy solutions fail in addressing these requirements.   In this paper, we propose a service discovery protocol with security features, the Secure Pervasive Discovery Protocol. SPDP is a fully distributed protocol in which services offered by devices can be discovered by others, without a central server. It is based on an anarchy trust model, which provides location of trusted services, as well as protection of confidential information, secure communications, or access control.  Keywords: ad-hoc networks, security, service discovery protocol, trust               Categories: C.2.2, C.4  
12|3||Information and Hybrid Architecture Model of the OCP Contextual Information Management System|  Ignacio Nieto (University of Murcia, Spain)   Juan A. Botía (University of Murcia, Spain)   Antonio F. Gómez-Skarmeta (University of Murcia, Spain)  Abstract: This paper describes OCP (Open Context Platform), a middleware which provides support for management of contextual information and merging of information from different sources. The host system is thus endowed with proactive capacities which, in turn, provide a certain environmental intelligence [8]. The approach consists of a modelling of contextual information which is based on Semantic Web derived technologies and a description of the structured merging in the form of decision rules. The latter serve to classify situations of interest and subsequently to trigger off the relevant actions at each moment. Elsewhere, the underlying architecture in OCP is designed so that it can function both by centralizing all the contextual information from a central server and by distributing it among consumers and producers of this type of information.               Keywords: context-awareness, decision rules, hybrid architecture, information merging, semantic web               Categories: C.2.4, H.3.3, I.2.11, J.4, K.4.2  
12|4|http://www.jucs.org/jucs_12_4|Evolvable Hardware|
12|4||A Multi-objective          Genetic Approach to Mapping Problem on Network-on-Chip|  Giuseppe Ascia (Università di Catania, Italy)   Vincenzo Catania (Università di Catania, Italy)   Maurizio Palesi (Università di Catania, Italy)  Abstract: Advances in technology now make it possible to integrate hundreds of cores (e.g. general or special purpose processors, embedded memories, application specific components, mixed-signal I/O cores) in a single silicon die. The large number of resources that have to communicate makes the use of interconnection systems based on shared buses inefficient. One way to solve the problem of on-chip communications is to use a Network-on-Chip (NoC)-based communication infrastructure. Such interconnection systems offer new degrees of freedom, exploration of which may reveal significant optimization possibilities: the possibility of arranging the computing and storage resources in an NoC, for example, has a great impact on various performance indexes.  The paper addresses the problem of topological mapping of intellectual properties (IPs) on the tiles of a mesh-based NoC architecture. The aim is to obtain the Pareto mappings that maximize performance and minimize power dissipation. We propose a heuristic technique based on evolutionary computing to obtain an optimal approximation of the Pareto-optimal front in an efficient and accurate way. At the same time, two of the most widely-known approaches to mapping in mesh­based NoC architectures are extended in order to explore the mapping space in a multi-criteria mode. The approaches are then evaluated and compared, in terms of both accuracy and efficiency, on a platform based on an event-driven trace-based simulator which makes it possible to take account of important dynamic effects that have a great impact on mapping. The evaluation performed on both synthesized traffic and real applications (an MPEG-4 codec) confirms the efficiency, accuracy and scalability of the proposed approach.               Keywords: evolutionary algorithm, mapping, multi-objective optimization, network-on-chip, simulation, system-on-chip               Categories: B.4.3, D.4.7, G.1.6, I.6  
12|4||Pareto-Optimal Hardware for Substitution Boxes|  Nadia Nedjah (State University of Rio de Janeiro, Brazil)   Luiza de Macedo Mourelle (State University of Rio de Janeiro, Brazil)  Abstract: In this paper, we propose a methodology based on genetic programming to automatically generate hardware designs of substitution boxes necessary for many cryptosystems such as DES encryption system. We aim at evolving minimal hardware specifications, which minimise both space (i.e. required gate number), response time (i.e. encryption and decryption time) and dissipated power. We compare our results against existing and well-known designs, which were produced by human designers using conventional methods.               Keywords: S-box, cryptography, evolvable hardware, genetic algorithms, multi-objective optimisation               Categories: B.5.2, C.3, E.3, I.2.2  
12|4||Automatic Programming Methodologies for Electronic Hardware Fault Monitoring|  Ajith Abraham (Chung-Ang University, South Korea)   Crina Grosan (Babes-Bolyai University, Romania)  Abstract: This paper presents three variants of Genetic Programming (GP) approaches for intelligent online performance monitoring of electronic circuits and systems. Reliability modeling of electronic circuits can be best performed by the stressor — susceptibility interaction model. A circuit or a system is considered to be failed once the stressor has exceeded the susceptibility limits. For on-line prediction, validated stressor vectors may be obtained by direct measurements or sensors, which after pre-processing and standardization are fed into the GP models. Empirical results are compared with artificial neural networks trained using backpropagation algorithm and classification and regression trees. The performance of the proposed method is evaluated by comparing the experiment results with the actual failure model values. The developed model reveals that GP could play an important role for future fault monitoring systems.               Keywords: computational intelligence, decision trees, electronic hardware, fault monitoring, genetic programming, neural networks               Categories: B.8.1, B.8.2, I.2.2, I.2.6  
12|4||Multi-Objective Evolutionary Algorithms           and Pattern Search Methods for Circuit Design Problems|  Tonio Biondi (STMicroeletronics, Italy)   Angelo Ciccazzo (STMicroeletronics, Italy)   Vincenzo Cutello (University of Catania, Italy)   Santo D'Antona (University of Catania, Italy)   Giuseppe Nicosia (University of Catania, Italy)   Salvatore Spinella (University of Calabria, Italy)  Abstract: The paper concerns the design of evolutionary   algorithms and pattern search methods on two circuit design   problems: the multi-objective optimization of an Operational   Transconductance Amplifier and of a fifth-order leapfrog filter. The   experimental results obtained show that evolutionary algorithms are   more robust and effective in terms of the quality of the solutions   and computational effort than classical methods. In particular, the   observed Pareto fronts determined by evolutionary algorithms has a   better spread of solutions with a larger number of nondominated   solutions when compared to the classical multi-objective   techniques.               Keywords: circuit design problems, classical optimization methods, evolutionary algorithms, evolutionary electronics, genetic algorithms, leapfrog filter, multi-objective optimization, operational transconductance amplifier, pattern search methods               Categories: B.7.1, B.7.2, I.2.8, J.2  
12|4||DS/CDMA Multiuser Detection with Evolutionary Algorithms|  Fernando Ciriaco (State University of Londrina - UEL, Brazil)   Taufik Abrão (State University of Londrina - UEL, Brazil)   Paul Jean E. Jeszensky (Polytechnic School of São Paulo University - EPUSP, Brazil)  Abstract: This work analyses two heuristic algorithms based on the genetic evolution theory applied to direct sequence code division multiple access (DS/CDMA) com­ munication systems. For different phases of an evolutionary algorithm new biological processes are analyzed, specially adapted to the multiuser detection (MuD) problem in multipath fading channels. Monte Carlo simulation results show that the detection based on evolutionary heuristic algorithms is a viable option when compared with the optimum solution (ML ­ maximum likelihood), even for hostile channel conditions and severe system operation. Additionally, a comparative table is presented considering the relation between bit error rate (BER) and complexity as the main analyzed figure of merit. Each algorithm complexity is determined and compared with others based on the required number of computational operations to reach de optimum performance and also the spent computational time.               Keywords: code division multiple access, evolutionary computation, genetic algorithm, multiuser detection               Categories: D.2.2, J.2  
12|5|http://www.jucs.org/jucs_12_5|Managing Editor's Column|
12|5||On-line Monitoring of Metric Temporal Logic with Time-Series Constraints Using Alternating Finite Automata|  Doron Drusinsky (Naval Postgraduate School, USA)  Abstract: In this paper we describe a technique for   monitoring and checking temporal logic assertions augmented with   real-time and time-series constraints, or Metric Temporal Logic   Series (MTLS). The method is based on Remote Execution and   Monitoring (REM) of temporal logic assertions. We describe the   syntax and semantics of MTLS and a monitoring technique based on   alternating finite automata that is efficient for a large set of   frequently used formulae and is also an on-line technique. We   investigate the run-time data-structure size for several interesting   assertions taken from the Kansas State specification   patterns.               Keywords: alternating automata, assertions, formal specification, reactive systems, run-time monitoring, run-time verification, temporal logic, time series               Categories: D.2.4, F.1.1, F.4.1  
12|5||Reversible Karatsuba's Algorithm|  Luis Antonio Brasil Kowada (Universidade Federal do Rio de Janeiro - UFRJ, Brazil)   Renato Portugal (Laboratório Nacional de Computação Científica - LNCC, Brazil)   Celina Miraglia Herrera de Figueiredo (Universidade Federal do Rio de Janeiro - UFRJ, Brazil)  Abstract: Karatsuba discovered the first algorithm that accomplishes multiprecision integer multiplication with complexity below that of the grade-school method. This algorithm is implemented nowadays in computer algebra systems using irreversible logic. In this paper we describe reversible circuits for the Karatsuba's algorithm and analyze their computational complexity. We discuss garbage disposal methods and compare with the well known Bennett's schemes. These circuits can be used in reversible computers which have the advantage of being very efficient in terms of energy consumption. The algorithm can also be used in quantum computers and is an improvement of previous circuits for the same purpose described in the literature.               Keywords: arithmetic operations, multiplier, reversible circuit, reversible computing,               Categories: B.2, B.6, F.1, F.2  
12|5||About an Algorithmic Approach to Tilings {p,q} of the          Hyperbolic Plane|  Maurice Margenstern (Université de Metz, France)  Abstract: In this paper, we remind previous results about   the tilings {p,q} of the hyperbolic plane. As   proved in [Margenstern and Skordev 2003a], these tilings are   combinatoric, a notion which we recall in the introduction. It   turned out that in this case, most of these tilings also have the   interesting property that the language of the splitting associated   to the tiling is regular. In this paper, we investigate the   consequence of the regularity of the language by providing   algorithms to compute the path from a tile to the root of the   spanning tree as well as to compute the coordinates of the   neighbouring tiles. These algorithms are linear in the coordinate of   the given node.               Keywords: combinatorial approach, tilings, discrete hyperbolic geometry, tilings               Categories: F.2.2  
12|5||Completeness in the Boolean Hierarchy: Exact-Four-Colorability, Minimal Graph Uncolorability, and Exact Domatic Number Problems - a Survey|  Tobias Riege (Heinrich-Heine-University Düsseldorf, Germany)   Jörg Rothe (Heinrich-Heine-University Düsseldorf, Germany)  Abstract: This paper surveys some of the work that was   inspired by Wagner's general technique to prove completeness in the   levels of the boolean hierarchy over NP and some related results. In   particular, we show that it is DP-complete to decide whether or not   a given graph can be colored with exactly four colors, where DP is   the second level of the boolean hierarchy. This result solves a   question raised by Wagner in 1987, and its proof uses a clever   reduction due to Guruswami and Khanna. Another result covered is due   to Cai and Meyer: The graph minimal uncolorability problem is also   DP-complete. Finally, similar results on various versions of the   exact domatic number problem are discussed.               Keywords: Boolean hierarchy, completeness, exact colorability, exact domatic number, minimal uncolorability               Categories: F.1.2, F.1.3, F.2.2, F.2.3  
12|6|http://www.jucs.org/jucs_12_6|Computational Challenges of Massive Data Sets and  Randomness in Computation  J.UCS Special Issue on the First and Second Japanese-German Frontiers of  Science Symposia|
12|6||The Berlin Brain-Computer          Interface:Machine Learning Based Detection of User          Specific Brain States|  Benjamin Blankertz (Fraunhofer FIRST (IDA), Germany)   Guido Dornhege (Fraunhofer FIRST (IDA), Germany)   Steven Lemm (Fraunhofer FIRST (IDA), Germany)   Matthias Krauledat (Technical University Berlin, Germany)   Gabriel Curio (Charite University Medicine Berlin, Germany)   Klaus-Robert Müller (Fraunhofer FIRST (IDA) and University of Potsdam, Germany)  Abstract: We outline the Berlin Brain-Computer Interface   (BBCI), a system which enables us to translate brain signals from   movements or movement intentions into control commands. The main   contribution of the BBCI, which is a non-invasive EEG-based BCI   system, is the use of advanced machine learning techniques that   allow to adapt to the specific brain signatures of each user with   literally no training. In BBCI a calibration session of about 20min   is necessary to provide a data basis from which the individualized   brain signatures are inferred. This is very much in contrast to   conventional BCI approaches that rely on operand conditioning and   need extensive subject training of the order 50-100 hours. Our   machine learning concept thus allows to achieve high quality   feedback already after the very first session. This work reviews a   broad range of investigations and experiments that have been   performed within the BBCI project. In addition to these general   paradigmatic BCI results, this work provides a condensed outline of   the underlying machine learning and signal processing techniques   that make the BBCI succeed. In the first experimental paradgm we   analyze the predictability of limb movement long before the actual   movement takes place using only the movement intention measured from   the pre-movement (readiness) EEG potentials. The experiments include   both off-line studies and an online feedback paradigm. The limits   with respect to the spatial resolution of the somatotopy are   explored by contrasting brain patterns of movements of left   vs. right hand rsp. foot. In a second conplementary paradigm   voluntary modulations of sensorimotor rhythms caused by motor   imagery (left hand vs. right hand vs. foot) are translated into a   continuous feedback signal. Here we report results of a recent   feedback study with 6 healthy subjects with no or very little   experience with BCI control: half of the subjects achieved an   information transfer rate above 35 bits per minute   (bmp). Furthermore one subject used the BBCI to operate a mental   typewriter in free spelling mode. The overall spelling speed was   4.5-8 letters per minute including the time needed for the   correction errors.               Keywords: Brain-Computer Interface, EEG, ERD, Information Transfer Rate, Machine Learning, RP, Readiness Potential, Single-Trial Analysis, classification, common spatial patterns, event-related desynchronization, feedback               Categories: G.1.6, H.1.1, H.1.2, I.2.1, I.2.6, I.5, J.2, J.3, J.7  
12|6||Sequential Data Assimilation: Information Fusion of a Numerical Simulation and Large Scale Observation Data|  Kazuyuki Nakamura (The Graduate University for Advanced Studies, JSTCREST, Japan)   Tomoyuki Higuchi (The Institute of Statistical Mathematics, JST CREST, Japan)   Naoki Hirose (Kyushu University, Japan)  Abstract: Data assimilation is a method of combining an imperfect simulation model and a number of incomplete observation data. Sequential data assimilation is a data assimilation in which simulation variables are corrected at every time step of observation. The ensemble Kalman filter is developed for a sequential data assimilation and frequently used in geophysics. On the other hand, the particle filter developed and used in statistics is similar in view of ensemble-based method, but it has different properties. In this paper, these two ensemble based filters are compared and characterized through matrix representation. An application of sequential data assimilation to tsunami simulation model with a numerical experiment is also shown. The particle filter is employed for this application. An erroneous bottom topography is corrected in the numerical experiment, which demonstrates that the particle filter is useful tool as the sequential data assimilation method.               Keywords: data fusion, particle filter, simulation science               Categories: G.1.0, I.6.0, I.6.4, J.2  
12|6||Data Mining Methods for Discovering Interesting Exceptions from an Unsupervised Table|  Einoshin Suzuki (Kyushu University, Japan)  Abstract: In this paper, we survey efforts devoted to discovering interesting exceptions from data in data mining. An exception differs from the rest of data and thus is interesting and can be a clue for further discoveries. We classify methods into exception instance discovery, exception rule discovery, and exception structured-rules discovery and give a condensed and comprehensive introduction.               Keywords: data mining, exception, instance, interestingness, pattern, rule, unexpectedness               Categories: I.2.6  
12|6||Randomness and Secrecy - A Brief Introduction|  Johannes Blõmer (Paderborn University, Germany)  Abstract: We give a brief introduction to probabilistic encryptions. This serves as an example how randomness plays a pivotal role in cryptographic systems that satisfy advanced security concepts.               Keywords: cryptography, randomness, security               Categories: E.3, F.1.2  
12|6||Pseudorandom Number Generation: Impossibility and Compromise|  Makoto Matsumoto (Hiroshima University, Japan)   Mutsuo Saito (Hiroshima University, Japan)   Hiroshi Haramoto (Hiroshima University, Japan)   Takuji Nishimura (Yamagata University, Japan)  Abstract: Pseudorandom number generators are widely used in the area of simulation. Defective generators are still widely used in standard library programs, although better pseudorandom number generators such as the Mersenne Twister are freely available.  This manuscript gives a brief explanation on pseudorandom number generators for Monte Carlo simulation. The existing definitions of pseudorandomness are not satisfactorially practical, since the generation of sequences satisfying the definitions is sometimes impossible, somtimes rather slow. As a compromise, to design a fast and reliable generator, some mathematical indices are used as measures of pseudorandomness, such as the period and the higher-dimensional equidistribution property. There is no rigorous justification for the use of these indices as measures of pseudorandomness, but experiences show their usefulness in choosing pseudorandom number generators.               Keywords: Mersenne Twister, Monte Carlo methods, pseudorandom number generation, random number generation, simulation               Categories: G.3  
12|6||Progress in Quantum Computational Cryptography|  Akinori Kawachi (Tokyo Institute of Technology, Japan)   Takeshi Koshiba (Saitama University, Japan)  Abstract: Shor's algorithms for the integer factorization and the discrete logarithm problems can be regarded as a negative effect of the quantum mechanism on publickey cryptography. From the computational point of view, his algorithms illustrate that quantum computation could be more powerful. It is natural to consider that the power of quantum computation could be exploited to withstand even quantum adversaries. Over the last decade, quantum cryptography has been discussed and developed even from the computational complexity-theoretic point of view. In this paper, we will survey what has been studied in quantum computational cryptography.               Keywords: computational cryptography, quantum computing, quantum cryptography               Categories: E.3, F.1.1  
12|6||Testing Membership in Formal          Languages Implicitly Represented by Boolean Functions|  Beate Bollig (University Dortmund, Germany)  Abstract: Combinatorial property testing, initiated   formally by Goldreich, Goldwasser, and Ron in [Goldreich et   al. (1998)] and inspired by Rubinfeld and Sudan in [Rubinfeld and   Sudan 1996], deals with the relaxation of decision problems. Given a   property P the aim is to decide whether a given   input satisfies the property P or is   far from having the property. A property   P can be described as a language, i.e., a   nonempty family of binary words. The associated property to a family   of boolean functions f =   (fn) is the set of   1-inputs of f. By an attempt to correlate the   notion of testing to other notions of low complexity property   testing has been considered in the context of formal   languages. Here, a brief summary of results on testing properties   defined by formal languages and by languages implicitly represented   by small restricted branching programs is provided.               Keywords: binary decision diagrams (BDDs), boolean functions, branching programs (BPs), computational complexity, formal languages, property testing, randomness, sublinear algorithms               Categories: F.1.3, F.2.2, G.3  
12|6||Improving Deterministic and Randomized          Exponential-Time Algorithms for the Satisfiability, the Colorability, and the Domatic Number Problem|  Tobias Riege (Heinrich-Heine-University Düsseldorf, Germany)   Jörg Rothe (Heinrich-Heine-University Düsseldorf, Germany)  Abstract: NP-complete problems cannot have efficient algorithms unless P = NP. Due to their importance in practice, however, it is useful to improve the known exponential-time algorithms for NP-complete problems. We survey some of the recent results on such improved exponential-time algorithms for the NP-complete problems satisfiability, graph colorability, and the domatic number problem. The deterministic time bounds are compared with the corresponding time bounds of randomized algorithms, which often run faster but only at the cost of having a certain error probability.               Keywords: deterministic algorithms, exact computation, exponential-time algorithms, randomized algorithms               Categories: F.1.2, F.1.3, F.2.2, F.2.3  
12|6||Randomized Algorithms and Complexity Theory|  Harald Hempel (Friedrich-Schiller-Universität Jena, Germany)  Abstract: In this paper we give an introduction to the connection between complexity theory and the study of randomized algorithms. In particular, we will define and study probabilistic complexity classes, survey the basic results, and show how they relate to the notion of randomized algorithms.               Keywords: randomized algorithms, randomized complexity classes               Categories: F.1.2, F.1.3, F.2.2, F.2.3  
12|7|http://www.jucs.org/jucs_12_7|Selected Papers from SBLP 2006: The 10th          Brazilian Symposium on Programming Languages|
12|7||The Design of the YAP Compiler: An Optimizing Compiler for Logic Programming Languages|  Anderson Faustino da Silva (Federal University of Rio de Janeiro, Brazil)   Vitor Santos Costa (Federal University of Rio de Janeiro, Brazil)  Abstract: Several techniques for implementing Prolog in a efficient manner have been devised since the original interpreter, many of them aimed at achieving more speed. There are two main approaches to efficient Prolog implementation: (1) compilers to bytecode and then interpreting it (emulators) or (2) compilers to native code. Emulators have smaller load/compilation time and are a good solution for their simplicity when speed is not a priority. Compilers are more complex than emulators, and the difference is much more acute if some form of code analysis is performed as part of the compilation, which impacts development time. Generation of low level code promises faster programs at the expense of using more resources during the compilation phase. In our work besides using an mixed execution mode, we design an optimizing compiler that using type feedback profiling, dynamic compilation and dynamic deoptimization for improving the performance of logic programming languages.               Keywords: Just-in-Time compiler, compiler optimizations, dynamic compilation               Categories: C.4, D.3.4  
12|7||Our Experiences with Optimizations in Sun's Java Just-In-Time Compilers|  Anderson Faustino da Silva (Federal University of Rio de Janeiro, Brazil)   Vitor Santos Costa (Federal University of Rio de Janeiro, Brazil)  Abstract: Modern Java Compilers, such as Sun's HotSpot compilers, implement a number of optimizations, ranging from high-level program transformations to low-level architecure dependent operations such as instruction scheduling. In a Just-in-Time (JIT) environment, the impact of each optimization must be weighed against its cost in terms of total runtime. Towards better understanding the usefulness of individual optimizations, we study the main optimizations available on Sun HotSpot compilers for a wide range of scientific and non-scientific benchmarks, weighing their cost and benefits in total runtime. We chose the HotSpot technology because it is state of the art and its source code is available.               Keywords: Dynamic compilation, Just-in-Time compiler, compiler optimizations               Categories: C.4, D.3.4  
12|7||Detecting Bad Smells in AspectJ|  Eduardo Kessler Piveta (Universidade Federal do Rio Grande do Sul, Brazil)   Marcelo Hecht (Universidade Federal do Rio Grande do Sul, Brazil)   Marcelo Soares Pimenta (Universidade Federal do Rio Grande do Sul, Brazil)   Roberto Tom Price (Universidade Federal do Rio Grande do Sul, Brazil)  Abstract: This paper defines algorithms to automatically detect five types of bad smells that occur in aspect-oriented systems, more specifically those written using the AspectJ language. We provide a prototype implementation to evaluate the detection algorithms in a case study, where bad smells are detected in three well-known AspectJ systems.               Keywords: AspectJ language,, aspect oriented software development, refactoring               Categories: D.1.5  
12|7||Program Slicing by Calculation|  Nuno F. Rodrigues (Universidade do Minho, Portugal)   Luís S. Barbosa (Universidade do Minho, Portugal)  Abstract: Program slicing is a well known family of techniques used to identify code fragments which depend on or are depended upon specific program entities. They are particularly useful in the areas of reverse engineering, program understanding, testing and software maintenance. Most slicing methods, usually oriented towards the imperative or object paradigms, are based on some sort of graph structure representing program dependencies. Slicing techniques amount, therefore, to (sophisticated) graph transversal algorithms. This paper proposes a completely different approach to the slicing problem for functional programs. Instead of extracting program information to build an underlying dependencies' structure, we resort to standard program calculation strategies, based on the so-called Bird-Meertens formalism. The slicing criterion is specified either as a projection or a hiding function which, once composed with the original program, leads to the identification of the intended slice. Going through a number of examples, the paper suggests this approach may be an interesting, even if not completely general, alternative to slicing functional programs.               Keywords: functional programming, program analysis, program slicing               Categories: D.1.1, I.2.2, I.2.4  
12|7||The Language of the Visitor Design Pattern|  Markus Schordan (Vienna University of Technology, Austria)  Abstract: Design patterns have been developed to cope with the vast space of possible different designs within object-oriented systems. One of those classic patterns is the Visitor Pattern, used for representing an operation to be performed on the elements of an object structure. In general, the order in which the objects are visited is crucial. We present a mapping from the Visitor Pattern to a context free grammar that defines the set of all such visit sequences, a given Visitor can perform. The language defined by this grammar is the language of the Visitor Design Pattern and the mapping encodes knowledge about the class hierarchy and the implementation of the accept methods of a Visitor Design Pattern. It is general enough to model complications that occur when traversing arbitrary object structures, and also properly represents cases such as lack of a common base class, multiple inheritance, and inheritance from concrete classes. Due to its particular design, the grammar can also be used as precise documentation for a Visitor Design Pattern.               Keywords: context free grammar, essential aspect, method invocation sequence, visitor language, visitor pattern               Categories: D.1.5, D.3.1, F.4.2  
12|7||Strong Mobility in Mobile Haskell|  André Rauber Du Bois (Universidade Católica de Pelotas, Brazil)   Phil Trinder (Heriot-Watt University, United Kingdom)   Hans-Wolf Loidl (Ludwig-Maximilians-Universität München, Germany)  Abstract: In a mobile language, computations can move   between locations in a network to better utilise resources, e.g., as   in a computational GRID. Mobile Haskell, or   mHaskell, is a small extension of Concurrent Haskell that enables   the construction of distributed mobile software by introducing   higher order communication channels called Moble   Channels (MChannels). mHaskell only provides weak   mobility, i.e. the ability to start new computations on   remote locations. This paper shows how strong   mobility, i.e. the ability to migrate running threads   between locations, can be implemented in a language like mHaskell   with weak mobility, higher-order channels and first-class   continuations. Using Haskell's high level features, such as   higher-order functions, type classes and support for monadic   programming, strong mobility is achieved without any changes to the   runtime system, or built-in support for continuations. Strong   mobility is illustrated with examples and a mobile agent case   study.               Keywords: Haskell, functional programming, mobile computation, strong mobility               Categories: D.3.3  
12|7||An Object Model for Interoperable Systems|  Alcides Calsavara (Pontifícia Universidade Católica do Paraná, Brazil)   Aron Borges (Pontifícia Universidade Católica do Paraná, Brazil)   Leonardo Nunes (Sumersoft Tecnologia, Brazil)   Diogo Variani (Global Village Telecom, Brazil)   Carlos Kolb (Companhia Paranaense de Energia, Brazil)  Abstract: Most modern computer applications should run on heterogeneous platforms and, moreover, objects and respective code should be easily interchangeable between distinct platforms at runtime. This paper describes a runtime platform based on distributed and cooperating virtual machines named Virtuosi. A unified object model permits easy inter-operation between applications written on different languages. All applications must be compiled to a standard runtime code format so they all can run on any platform where an implementation of the virtual machine exists. A novel code format which is entirely based on instances of the classes that define the object model itself is employed. A proper programming language has been defined, a corresponding compiler implemented, a virtual machine that includes a class loader, a code interpreter, a single-threaded execution control and a distributed object store implemented and tested through example applications.               Keywords: interoperability, object model, virtual machine               Categories: C.2.4, D.1.5  
12|7||Expressing Workflow Patterns for Web Services: The Case of PEWS|  Martin A. Musicante (Federal University of Rio Grande do Norte, Brazil)   Edinardo Potrich (Federal University of Paraná, Brazil)  Abstract: PEWS is a language for the implementation of web service interfaces. PEWS programs can be used for the description of both individual and composed web services. Individual web services can be built up from Java programs. Composed web services are built from simpler services. PEWS operators describe the allowed workflow of the web service, i.e.the order in which the operations of the web service will be executed. In this paper we analyze the expressiveness of PEWS programs. This is done by the systematic evaluation of the language. Our evaluation is based on a framework composed by workflow patterns. We also compare PEWS with other interface description languages. This comparison is based on the workflow behavior of the languages.               Keywords: programming languages, web services, workflow patterns               Categories: C.2.4, D.3.m.  
12|7||Generic Process Algebra: A Programming Challenge|  Paula R. Ribeiro (Universidade do Minho, Portugal)   Marco Antonio Barbosa (Universidade do Minho, Portugal)   Luís Soares Barbosa (Universidade do Minho, Portugal)  Abstract: Emerging interaction paradigms, such as service-oriented computing, and new technological challenges, such as exogenous component coordination, suggest new roles and application areas for process algebras. This, however, entails the need for more generic and adaptable approaches to their design. For example, some applications may require similar programming constructs coexisting with different interaction disciplines. In such a context, this paper pursues a research programme on a coinductive rephrasal of classic process algebra, proposing a clear separation between structural aspects and interaction disciplines. A particular emphasis is put on the study of interruption combinators defined by natural co-recursion. The paper also illustrates the verification of their properties in an equational and pointfree reasoning style as well as their direct encoding in Haskell.               Keywords: Process Algebra, coalgebra, coinduction               Categories: D.3.1, F.3.1  
12|7||Type-safe Versioned Object Query Language|  Rodrigo Machado (Universidade Federal do Rio Grande do Sul, Brazil)   Álvaro Freitas Moreira (Universidade Federal do Rio Grande do Sul, Brazil)   Renata de Matos Galante (Universidade Federal do Rio Grande do Sul, Brazil)   Mirella Moura Moro (University of California Riverside (UCR), USA)  Abstract: The concept of versioning was initially proposed for controlling design evolution on computer aided design and software engineering. On the context of database systems, versioning is applied for managing the evolution of different elements of the data. Modern database systems provide not only powerful data models but also complex query languages that have evolved to include several features from complex programming languages. While most related work focuses on different aspects of the concepts, designing models, and processing of versions efficiently, there is yet to be a formal definition of a query language for database systems with versions control. In this work we propose a query language, named Versioned Object Query Language (VOQL), that extends ODMG Object Query Language (OQL) with new features to recover object versions. We provide a precise definition of VOQL through a type system and we prove it safe in relation to a small-step operational semantics. Finally, we validate the proposed definition by implementing an interpreter for VOQL.               Keywords: object-oriented database managementsystems, operational semantics, query languages, type systems               Categories: F.3.2, H.2.3  
12|7||Defining Atomic Composition in UML Behavioral Diagrams|"  Júlio Pereira Machado (Pontifícia Universidade Católica do Rio Grande do Sul, Brazil)   Paulo Blauth Menezes (Universidade Federal do Rio Grande do Sul, Brazil)  Abstract: UML may be used to describe both the structure and behavior of objectoriented systems using a combination of notations. For the modeling of the dynamic behavior, a number of different models are offered such as interaction, state and activity diagrams. Although compositional techniques for modeling computational processes demand means of composing elements both in non-atomic or atomic ways, UML seems to lack compositional constructs for defining atomic composites. We discuss proper extensions for diagrams that are able to cope with the concept of atomic composition as the basic element for describing transactions (in our settings the term ""transaction"" denotes a certain operation of a system that might be atomically composed by many, possibly concurrent, operations). Atomic compositions are then formally defined through a special morphism between automata in a domain called Nonsequential Automata.               Keywords: UML, nonsequential automata, semantics               Categories: D.1.5, D.2.0, F.1.1, F.3.2  "
12|8|http://www.jucs.org/jucs_12_8|Managing Editor's Column|
12|8||Variations on Itai-Rodeh Leader Election for Anonymous Rings and their Analysis in PRISM|  Wan Fokkink (Vrije Universiteit, The Netherlands)   Jun Pang (Universitat Oldenburg, Germany)  Abstract: We present two probabilistic leader election algorithms for anonymous unidirectional rings with FIFO channels, based on an algorithm from Itai and Rodeh [Itai and Rodeh 1981]. In contrast to the Itai-Rodeh algorithm, our algorithms are finite-state. So they can be analyzed using explicit state space exploration; we used the probabilistic model checker PRISM to verify, for rings up to size four, that eventually a unique leader is elected with probability one. Furthermore, we give a manual correctness proof for each algorithm.               Keywords: anonymous networks, distributed computing, formal verification, leader election, model checking, probabilistic algorithms               Categories: C.2.4, D.2.4, F.3.1  
12|8||Eliminating Redundant Join-Set Computations in Static Single Assignment|  Angela French (University of Alberta, Canada)   José Nelson Amaral (University of Alberta, Canada)  Abstract: The seminal algorithm developed by Ron Cytron,   Jeanne Ferrante and colleagues in 1989 for the placement of   φ-nodes in a control flow graph is still widely used   in commercial compilers. Placing φ-nodes is necessary when   converting a program representation to Static Single Assignment   (SSA) form. This paper shows that if a variable x is defined in   a set of basic blocks A(x), then the iterated   join set of A(x) can be decomposed into the   computation of the iterated join set of a disjoint collection of   subsets of A(x). We use this result to show that   some join set computations are redundant. We measured the number of   redundant computations in the Open Research Compiler (ORC) in a   selection of SPEC 2000 benchmarks.               Keywords: SSA, compiler optimization               Categories: D.1.3, D.3.4, I.1.2  
12|8||Behavioral Institutions and Refinements in Generalized Hidden Logics|  Manuel A. Martins (Aveiro University, Portugal)  Abstract: We investigate behavioral institutions and   refinements in the context of the object oriented paradigm. The   novelty of our approach is the application of generalized abstract   algebraic logic theory of hidden heterogeneous deductive systems   (called hidden k-logics) to the algebraic   specification of object oriented programs. This is achieved through   the Leibniz congruence relation and its   combinatorial properties.  We reformulate the notion of hidden k-logic as well as the behavioral logic of a hidden k-logic as institutions. We define refinements as hidden signature morphisms having the extra property of preserving logical consequence. A stricter class of refinements, the ones that preserve behavioral consequence, is studied. We establish sufficient conditions for an ordinary signature morphism to be a behavioral refinement.               Keywords: Leibniz congruence, behavioral equivalence relation, behavioral logic, behavioral refinements, hidden logics, institutions, refinements               Categories: F.3.1, F.3.2, F.4.1  
12|8||Plagiarism - A Survey|"  Hermann Maurer (Graz University of Technology, Austria)   Frank Kappe (Graz University of Technology, Austria)   Bilal Zaka (Graz University of Technology, Austria)  Abstract: Plagiarism in the sense of ""theft of intellectual property"" has been around for as long as humans have produced work of art and research. However, easy access to the Web, large databases, and telecommunication in general, has turned plagiarism into a serious problem for publishers, researchers and educational institutions. In this paper, we concentrate on textual plagiarism (as opposed to plagiarism in music, paintings, pictures, maps, technical drawings, etc.). We first discuss the complex general setting, then report on some results of plagiarism detection software and finally draw attention to the fact that any serious investigation in plagiarism turns up rather unexpected side-effects. We believe that this paper is of value to all researchers, educators and students and should be considered as seminal work that hopefully will encourage many still deeper investigations.               Keywords: IPR, cheating, plagiarism, similarity detection               Categories: K.0, K.3, K.4, K.5  "
12|9|http://www.jucs.org/jucs_12_9|Informatics in Higher Education|
12|9||Creation and Evaluation of Fuzzy Knowledge-base|  Ágnes Achs (University of Pécs, Hungary)  Abstract: In this paper we give a possible model for handling uncertain information. The concept of fuzzy knowledge-base will be defined as a quadruple of any background knowledge, defined by the proximity of predicates and terms; a deduction mechanism: a fuzzy Datalog program; a connecting algorithm, which connects the background knowledge with the program and a decoding set of the program, which help us to determine the uncertainty level of the results. Evaluation strategies will also be presented.               Keywords: evaluation strategies, fuzzy Datalog, fuzzy knowledge-base, proximity               Categories: I.2.3  
12|9||UML-Based Modeling of Data-oriented WEB Applications|  Attila Adamkó (University of Debrecen, Hungary)  Abstract: Recently a growing demand has arisen for methods for the development of small- and medium scale Web Information Systems (WIS). Web applications are being built in a rapidly changing environment where requirements are usually unstable. Short-time design and implementation are needed in response to the new technologies. Our work focuses rather on the design and construction of Web applications, than management. Flexibility is a major requirement in such applications, and also in a database-backed environment for the structure and presentation of the sites.  We propose a systematic design method for Web applications which takes into account the data-oriented aspects of the application. The method is based on a UML profile adapted to the problem domain by means of stereotypes as well as a strategy for generating code templates from such models. We provide a method to derive the navigation model from the structural model of a Web application. We will also show guidelines for the development of the Data Layer of data-oriented Web application. Moreover, why to divide the business logic layer into two parts: the pure application logic for managing the workflow of the application and the storage logic responsible for the data structures.  Rapid development is enabled by providing roundtrip engineering capabilities with support for automatic code generation. We will show the role of XML: why to use XML to support both the reuse of content and context-dependent delivery.    An advantage of the proposed methodology is that several steps can be performed is a semi-automatic way providing rapid development and prototyping.               Keywords: MVC design pattern, UML, Web application,, Web modeling techniques, XMI, XML, XSLT, data models               Categories: D.2.10, D.2.2, D.2.3, H.4.3  
12|9||The mobiDIÁK Educational Portal|  Péter Antal (University of Debrecen, Hungary)   Norbert Bátfai (University of Debrecen, Hungary)   Istvá Fazekas (University of Debrecen, Hungary)   Péter Jeszenszky (University of Debrecen, Hungary)  Abstract: In this paper we present our aims in the mobiDIÁAK (i.e. mobile STUDENT) portal that we have been developed and are running. Our essential goal was to create a portal engine, that is: (1) self-organizing, i.e. it has built in mechanisms by means of that it is able to exploit the power of the user community around the portal on behalf of its continuous growth; (2) for educational purposes; (3) mobile, i.e. its main services are also accessible from mobile devices.  We have developed the portal engine ourselves that serves the basis to the portal. We are running the portal hourly at the Faculty of Informatics at the University of Debrecen, Hungary.  We give an overview of the main portal services and also of the content offered by the running portal.               Keywords: portal engine, server-side Java technology, web development               Categories: H.3.5  
12|9||Design and Implementation  of Enum-Based Services|  Balázs Benyó (Széchenyi István University, Hungary)   Miklós F. Hatwágner (Széchenyi István University, Hungary)   Tamás Heckenast (Széchenyi István University, Hungary)   Katalin Kovács (Széchenyi István University, Hungary)   Ágnes Varga (Széchenyi István University, Hungary)   Norbert Varjasi (Széchenyi István University, Hungary)  Abstract: ENUM is a technology based on a procedure that assigns a sequence of traditional telephone numbers to Internet domain names. It specifies a rule that makes it possible to relate a domain to a telephone number without any risk of ambiguity. This domain can then be used to identify various communication services like fax, mobile phone numbers, voice-mail systems, e-mail addresses, IP telephone addresses, web pages, GPS coordinates, call diverts or unified messaging. In our paper we deal with three main problem areas in connection with the business model of the ENUM service and with the introduction of new services, i.e. the questions of tariffs, legal regulations and financial return. For the ENUM procedure to spread out in use specific services have to be implemented that can exploit the advantages of the ENUM and efficient methods have to be elaborated to base existing services on ENUM. We will outline the two new services invented by our group and that we have implemented in our project.               Keywords: Domain Name System (DNS), E.164 telephone number, ENUM, ENUM client, ENUM procedure, ENUM-based service               Categories: C.2.2, C.3, H.4.3  
12|9||Performance Modeling of Proxy Cache Servers|  Tamás Bérczes (University of Debrecen, Hungary)   János Sztrik (University of Debrecen, Hungary)  Abstract: The primary aim of the present paper is to modify the performance model of Boseand Cheng [1] to a more realistic case when external visits are also allowed to the remote Web servers and the Web servers have limited buffer. We analyze how many parameters affect theperformance of a Proxy Cache Server. Numerical results are obtained for the overall response time with and without a PCS. These results show that the benefit of a PCS depends on variousfactors. Several numerical examples illustrate the effect of visit rates, visit rates for the external users , and the cache hit rate probability on the mean response times.               Keywords: performance models, proxy cache server, queueing network               Categories: H.1.1, H.3.3  
12|9||Developing on Exact Quality and Classification System for Plant Improvement|  József Berke (University of Veszprém, Hungary)   Zsolt Polgár (University of Veszprém, Hungary)   Zoltán Horváth (University of Veszprém, Hungary)   Tamás Nagy (Hexium Ltd., Hungary)  Abstract: On the field of potato research and breeding, there are several possibilities for the application of modern digital image processing and data collection/analysing techniques. One of the most obvious methods is the multi/hyper spectral analysis. In our experiments research were done in the visible as well as in the infra, near infra and thermal wavelength. For more advanced analysis we developed a multi/hyper-spectral analysis method (spectral fractal dimension measurement and application). In the following we summarize its basic elements and the developed integrated information system of potato research and breeding.               Keywords: fractal dimension, image classification, plant improvement, potato breeding and qualification, thermovision               Categories: I.4.8, J.3  
12|9||Extension of CQL over Dynamic Databases|  Antal Buza (College of Dunaújváros, Hungary)  Abstract: CQL, Continuous Query Language is suitable for data stream queries. Sometimes it is better if the queries operate on relational databases and data streams simultaneously. The execution of a CQL query takes a long time (several hours, days or even more). It is not clear what kind of semantics is suitable for the user when the database is updated during the execution of a CQL query. In this paper we give a short description of CQL, a characterization of update-problems, and we offer possible suggestions for the semantic extension of CQL. After the expansion, the CQL would be suitable for solving much more practical problems. The parallel usage of continuous data streams and updatable databases would be settled.               Keywords: data-flow languages, database, query languages               Categories: D.3.2, H.2.1, H.2.3  
12|9||Japlo: Rule-based Programming on Java|  Miklós Espák (University of Debrecen, Hungary)  Abstract: Imperative programming languages (such as Java) are the most widespread programming languages recently. Besides being quite easy to get familiar with them, they are also perfectly suitable for business software development. Although the productivity of imperative languages is much acclaimed, some problems are much easier to solve in a logical language. The paper introduces a Java language extension called Japlo, which fits the Prolog language constructs into Java harmonically. Blurring the borders between the representatives of these two paradigms, the author aims at making the logical programming tools more easily available for Java programmers. Japlo does not only provide a foreign language interface to Prolog programs, but you can write Prolog rules within the language relying on some basic concepts (static typing, expression orientation) and the grammatic structure of Java.               Keywords: Japlo, Java, Prolog               Categories: D.1.5, D.1.6, D.3.3  
12|9||Analysing Data of Childhood Acute Lymphoid Leukaemia by Seasonal Time Series Methods|  Maria Fazekas (University of Debrecen, Hungary)  Abstract: We examined the periodicity of the childhood leukaemia in Hungary using seasonal decomposition time series. Between 1988 and 2000 the number of annually diagnosed leukaemia (incidence) was analysed. The time series of the number of patients between the age of 0 and 18 years and the data series divided at the median were analysed. From the time series the seasonal components, trends, the seasonally adjusted series, the moving averages and the data series of the random components were examined. The seasonal components of the dates of diagnosis revealed that a higher percent of the peaks fell within the winter months than in the other seasons. This proves the seasonal occurrence of the childhood leukaemia in Hungary. These data seem to highlight the role of the environmental effects (viral infections, epidemics, etc.) on the onset of the disease.We examined the periodicity of the childhood leukaemia in Hungary using seasonal decomposition time series. Between 1988 and 2000 the number of annually diagnosed leukaemia (incidence) was analysed. The time series of the number of patients between the age of 0 and 18 years and the data series divided at the median were analysed. From the time series the seasonal components, trends, the seasonally adjusted series, the moving averages and the data series of the random components were examined. The seasonal components of the dates of diagnosis revealed that a higher percent of the peaks fell within the winter months than in the other seasons. This proves the seasonal occurrence of the childhood leukaemia in Hungary. These data seem to highlight the role of the environmental effects (viral infections, epidemics, etc.) on the onset of the disease.               Keywords: acute childhood lymphoid leukaemia, seasonal decomposition time series method, time series analysis               Categories: G  
12|9||4M — Software for Modelling and Analysing Cropping Systems|  Nándor Fodor (RISSAC of HAS, Hungary)  Abstract: Models have played an important role in scientific research for a long time. The crop models try to simulate the functioning of the atmosphere-soil-plant system with the help of computers. These models can be effective tools in research, education and solving agricultural and environmental protection related problems. The 4M package includes a crop model and several accessories that help to operate the model. The 4M crop model is a daily-step, deterministic model that simulates the water and nutrient balance of the soil, the soil-plant interactions and the plant development and growth. To mention some examples: (1) The package can be used in education to carry out 'zero-cost' virtual agricultural experiments and to challenge and enhance the system oriented thinking of the students. (2) In research it can be used for designing experiments and estimating the present and future characteristics of the investigated system. (3) In practical applications the package can be used to prepare agro-technological advise (fertilization, irrigation, etc.) for farmers, and to carry out economical analyses on farm level.               Keywords: crop model, education, estimation method               Categories: H.5.2, J.2, J.3  
12|9||Modern Technologies in Client-Server Architecture for Geo-based Interactive Web Portals|  Pawel Gocek (Technical University of Lodz, Poland)   Michael Hartmann (OTA Private University of Applied Sciences Berlin, Germany)   Heinz Schleusener (Technische Universität Berlin, Germany)  Abstract: The internet is an unlimited growing and most comfortable information and communication base. In this context, web portals on the internet play an important role created for combining communication facilities and information data bases. An increasing number of portals involve web-based map applications to integrate geographic information for the representation of economical and other records. Web-based map applications are typically designed in a client-server architecture. Different solutions exist using especially HTML and JavaScript, Flash or Java applets. We discuss these possibilities and point out an alternative solution. Particularly, we show how to use Java Applet Technology and Asynchronous JavaScript and XML (Ajax) in this field.  Finally, we report about our results as a complete, flexible map service solution which is available on the internet. An adapted kind of solution will be used by a geo-based marketing portal for offering information about the economic situation, social and cultural aspects and natural facts of regions to support joint-ventures inside the European Union.               Keywords: Ajax, Java, Web-based services, XML, geo-base, map services, marketing, portal               Categories: H.3.3, H.3.5, H.4.3, H.5.2, H.5.4  
12|9||The Number of the Modulo n Roots of the Polynomial          xv — xv and the RSA|  János Gonda (Eötvös University Budapest, Hungary)  Abstract: RSA is one of the oldest and until now one of the most widely used public key cryptographic systems, which is based on the modular raising to power. In this article it is pointed out that most of the essential properties of the RSA can be read out from the number of the modulo n roots of the polynomial mentioned in the title of this article. The results explain almost all of the properties taken into account at the choice of the parameters of the RSA. By the help of the polynomial it is pointed out how the modulus and the exponent must be chosen so that the modular raising to power realizes a secure cryptosystem. The article investigates also the role of the choice of the parameters related to the success of the cycling attack. The article conveys a unified point of view for the examination of a lot of the number theoretic problems arising with respect to the RSA.               Keywords: RSA, cycling attack, modulo  n  roots               Categories: E.3  
12|9||"The ""MEDIP-Platform Independent Software System for Medical Image Processing"" Project"|  András Hajdu (University of Debrecen,, Hungary)   János Kormos (University of Debrecen,, Hungary)   Zsolt Lencse (University of Debrecen, Hungary)   Lajos Trón (PET Center, University of Debrecen, Hungary)   Miklós Emri (PET Center, University of Debrecen, Hungary)  Abstract: In this paper we present the structure and the achieved results of the R&D project IKTA-4, 6/2001 MEDIP - Platform independent software system for medical image processing supported by the Hungarian Ministry of Education. The aim of the project was to develop a software background for our basic and applied research in the field of medical imaging that can be used in clinical routine, as well. Realization was based on the experience of information technology and medical imaging research university teams and a company specialized on software and hardware developing for nuclear medicine. The aims also reflect some former research and development activities of the participants. Thus some of them are well experienced in registration, segmentation and image fusion techniques. These experiences were also considered in the determination of the main purposes. The capabilities of the provided software library were demonstrated through test applications from the fields of orthopedics, oncology and nuclear medicine.               Keywords: medical image processing, multimodal image analysis, surface rendering, virtual surgery, visualization, volume rendering               Categories: D.1.5, G.2.3, I.3.7, I.4.0, J.3  
12|9||Applications          of Neighborhood Sequence in Image Processing and Database Retrieval|  Andás Hajdu (University of Debrecen, Hungary)   János Kormos (University of Debrecen, Hungary)   Tamás Tóth (University of Debrecen, Hungary)   Krisztián Veréb (University of Debrecen, Hungary)  Abstract: In this paper we show how the distance functions generated by neighborhood sequences provides flexibility in image processing algorithms and image database retrieval. Accordingly, we present methods for indexing and segmenting color images, where we use digital distance functions generated by neighborhood sequences to measure distance between colors. Moreover, we explain the usability of neighborhood sequences within the field of image database retrieval, to find similar images from a database for a given query image. Our approach considers special distance functions to measure the distance between feature vectors extracted from the images, which allows more flexible queries for the users.               Keywords: database retrieval, image database, image processing, segmentation               Categories: H.2.8 , H.3.3, I.4.6, I.5.3  
12|9||Course Modeling for Student Profile Based Flexible Higher Education on the Internet|  László Horváth (John von Neumann Faculty of Informatics,Budapest Tech, Hungary)   Imre Rudas (John von Neumann Faculty of Informatics,Budapest Tech, Hungary)  Abstract: Higher education courses are increasingly created as student organized collections of interrelated modules. At the same time, frequent change of subject matter and knowledge in its background must be handled. Above and other factors created and recognized a need for efficient computer based course management. Conventional computer aided teaching methods are not suitable to organize, manage, and communicate the comprehensive course information any more. The authors considered an analogy with well- organized computer descriptions of interrelated objects in the form of comprehensive integrated models in product engineering. Modeling and management of information serve engineering activities during lifecycle of product. Relevant advanced characteristics of integrated product descriptions are process orientation, definition of application oriented building elements called as features, and assistance of decisions by knowledge representations. The authors considered higher education course as one kind of product and proposed a course model. They focused to integrating student, teacher, and institute demand driven characteristics of modeling. Model is developed for application by course procedures. While conventional virtual education systems concentrate to computer mediated distance education, the authors considered arbitrary mix of campus and distance styles of education. In this paper, the authors first give an introduction in their approach to classroom modeling by a comparison of conventional distance education, conventional virtual classroom, and the proposed model based virtual classroom. Next, functional elements of the proposed course modeling and components of virtual classroom are explained. Conflicts as consequences of inappropriate capability or breaking of human intent are analyzed. Following this, initial conditions for definition of course module and construction of course module using modification by features are detailed. Finally, future work for implementation of the modeling in an experimental system composed by professional product lifecycle management (PLM) system, configurable virtual teaching environment, its virtual classroom extension and virtual classroom extension to the engineering modeling system is concluded.               Keywords: conflicts at course definition, featuredriven model construction, model of higher education course, virtual classroom               Categories: J.6, J.7  
12|9||Mathematical Models of Endocrine Systems|  István Koós (UD Health Faculty College, Hungary)  Abstract: A mathematical model is proposed to allow expressive representation of endocrine systems by graphic means. The differential equations exactly describing the system can be formulated easily and automatically by the graphic model. Different kinds of software are supposed to solve these equations easily. Chaotic operational range can be found by fitting the parameters of equations. The results can account for some endocrine diseases and would be able to help the therapy.               Keywords: chaos, endocrine, graphic, nonlinear differential equation               Categories: G.1.7, J.3  
12|9||Construction of Wavelets and Applications|  Ildikó László (Eöotvös Lóránd University Budapest, Hungary)   Ferenc Schipp (Eötvöos Lóránd University Budapest, Hungary)   Samuel P. Kozaitis (FIT, USA)  Abstract: A sequence of increasing translation invariant   subspaces can be defined by the Haar-system (or generally by   wavelets). The orthogonal projection to the subspaces generates a   decomposition (multiresolution) of a signal. Regarding the rate of   convergence and the number of operations, this kind of decomposition   is much more favorable then the conventional Fourier   expansion.  In this paper, starting from Haar-like   systems we will introduce a new type of multiresolution. The   transition to higher levels in this case, instead of dilation will   be realized by a two-fold map. Starting from a convenient scaling   function and two-fold map, we will introduce a large class of   Haar-like systems. Besides others, the original Haar system and   Haar-like systems of trigonometric polynomials, and rational   functions can be constructed in this way. We will show that the   restriction of Haar-like systems to an appropriate set can be   identified by the original Haar-system.  Haar-like rational functions are used for the approximation of rational transfer functions which play an important role in signal processing [Bokor1 1998, Schipp01 2003, Bokor3 2003, Schipp 2002].               Keywords: Haar-like systems, image processing, multiresolution, signal processing, wavelets               Categories: F.2.1, G.1, I.4  
12|9||Resource Efficient Maintenance of Wireless Network Topologies|  Tamás Lukovszki (Eötvös Lóránd University, Hungary)   Christian Schindelhauer (Albert-Ludwig University, Freiburg, Germany)   Klaus Volbert (Paderborn University, Germany)  Abstract: Multiple hop routing in mobile ad hoc networks can minimize energy consumption and increase data throughput. Yet, the problem of radio interferences remain. However if the routes are restricted to a basic network based on local neighborhoods, these interferences can be reduced such that standard routing algorithms can be applied.  We compare different network topologies for these basic networks, i.e. the Yao-graph (aka. Θ-graph) and some also known related models, which will be called the SymmY-graph (aka. YS-graph), the SparsY-graph (aka. YY-graph) and the BoundY-graph. Further, we present a promising network topology called the HL-graph (based on Hierarchical Layers).  We compare these topologies regarding degree, spanner-properties, and communication features. We investigate how these network topologies bound the number of (uni- and bidirectional) interferences and whether these basic networks provide energy-optimal or congestion-minimal routing. Then, we compare the ability of these topologies to handle dynamic changes of the network when radio stations appear and disappear. For this we measure the number of involved radio stations and present distributed algorithms for repairing the network structure.               Keywords: ad hoc networks, distributed algorithms, topology control               Categories: F.2, G.2.3, I.3.5  
12|9||Membrane Computing and Graphical Operating Systems|  Benedek Nagy (Rovira i VirgiliUniversity, Tarragona, Spain, University of Debrecen, Hungary)   László Szegedi (University of Debrecen, Hungary)  Abstract: In this paper a comparison is provided between the membrane computing systems and the graphical interfaces of operating systems. A membrane computing system is a computing model using massive parallelism inspired by the functioning of living cells. The graphical schemes of these computing devices look like the windows of a graphical operating system representing programs running parallel on the computer. Both similarities and differences of membrane-systems and graphical operating systems are detailed as well as some possible simulation methods.               Keywords: graphical interfaces, graphical operating systems, membrane computing, operating systems, parallel computing               Categories: D.4, F.1.1, F.4.2, H.5.2, I.6  
12|9||Parameter Estimation of the Cauchy Distribution in Information Theory Approach|  Ferenc Nagy (University of Miskolc, Hungary)  Abstract: As we know the Cauchy distribution plays an important role in Probability Theory and Statistics. In this paper, we investigate the estimation of the location and the scale parameter. Both the one-dimensional problem and the multidimensional problem are studied for large sample. In the one-dimensional case, we give two algorithms for the estimation. The first one is an iterative method for which we prove the convergence and we show that the rate of convergence is geometric. The second algorithm provides an exact solution to the problem. In the multidimensional case, we give an algorithm analogous to the one-dimensional case. Computer experiments show that the rate of convergence is similar to the one-dimensional iterative algorithm.               Keywords: Cauchy distribution, discrimination information, inaccuracy, parameter estimation               Categories: G.3  
12|9||Phasetransition-like Changes in Human Visual Information Processing|  Péter Nagy (Kecskemét College Faculty of Mechanical Engineering and Automation, Hungary)   Istvan Pintér (Kecskemét College Faculty of Mechanical Engineering and Automation, Hungary)   Mihály Bagány (Kecskemét College Faculty of Mechanical Engineering and Automation, Hungary)  Abstract: For exact examination of human information processing ability we elaborated an information-theory-based model and a new measuring method. Starting from the theoretical background of the well-known Hick-Hyman law and analysing the data acquired during the Soyuz-Salyut space missions, an important fact was derived. When examining the model by reducing the H(X) input entropy of the stimulus signals (symbols) and approaching to the 0 bit there was an interesting effect: through the reduction of H(X) input entropy towards zero the ratio of (processed information)/(input entropy) was increasing and its value approached to 1, while at non-zero entropy this ratio was less than 1. Therefore a phase-change-like effect occurred below H(X) = 1 bit. Consequently the zero bit measurement could not be involved into the determination of Information Processing Ability (IPA) while the traditional measurements were performed only at two distinct values of entropy: at 0 bit and at a not too high H(X) value (e.g. 2 bits/symbol).               Keywords: artificial neural networks, associative memory, information processing ability, phase transition, visual information processing               Categories: H.1.0, H.1.1, J.2, J.3, J.7  
12|9||Primary School Teachers in the Information Society|  Robert Sinka (Szent István University College of Jászberény, Hungary)  Abstract: This study represents a survey approach in order to analyse the information society in a regional setting. The first part deals with a current problematic issue: the human resources of the information society, which is a neglected research area of the information society.  The second part of the paper will point out the main characteristics of the human adaptation of the information society. My aim is to accentuate the importance of the 'human-interface gap. These days the accessibility is strongly connected to the education and to the fact that several jobs do not require competence in digital or information literacy. Focusing on the human aspect has become a central issue of the higher education, and one of its prominent tasks, besides others, is to prepare the next generation for the challenges of the information society.               Keywords: competence of digital literacy, information society, school, teachers               Categories: J.4, K.3.2, K.4, K.4.1, K.4.3  
12|9||The Additional Examination of the Kudo-Mathuria Time-Release Protocol|  Péter Takács (University Debrecen, Hungary)  Abstract: The purpose of the present paper is to give an   expansion of the results of Michiharu Kudo and Anish Mathuria. We   present the base-protocol and formulate three properties of the   protocol with modal logic tools. After that we expand the   baseprotocol and prove four new properties. We prove that the third   trusted partner can not read the message of the sender until a   predetermined time.               Keywords: Kudo-Mathuria protocol, formal verification of cryptographic protocols, time capsule, time-release cryptography               Categories: C.2.2  
12|9||Synthesis of Optimal Workflow Structure|  József Tick (Budapest Tech, Hungary)   Zoltán Kovacs (University of Szeged, Hungary)   Ferenc Friedler (Budapest Tech, Hungary)  Abstract: Optimal synthesis of workflow structures, the formerly undefined problem, has been introduced. Mathematical programming model is presented for determining the cost optimal workflow system of a given workflow problem. On the basis of a methodology developed for process network synthesis, effective solvers are available for the systematic synthesis of workflow systems.               Keywords: P-graph, network synthesis, workflow               Categories: F.4.1, G.1.6, H.1.0  
12|9||Systems Engineering: A New Approach to Complex IT-based Technological Systems in Engineering Education|  Tibor Tóth (University of Miskolc, Hungary)   Ferenc Erdélyi (University of Miskolc, Hungary)  Abstract: Introduction of the multi-degree linear   education system consisting of BSc, MSc and PhD programs in the   Hungarian higher education, according to the goals and requirements   of the Bologna Process, necessitates reviewing, enhancing and   changing the three-level subject-structures consisting of   fundamental, foundation enlarging and special subjects. In the   course of the last 50 years the quantity of the number of subject   areas and the number of engineering branches have been increasing in   technological faculties around the world and they have already   reached the limits of rationality. Recently there is an increasing   demand for integrated and interdisciplinary special branches such as   Systems Engineering. After having surveyed the paradigm changes in   the progress of engineering sciences, the paper gives a brief   summary on the concept, formation and significance of Systems   Engineering. The paper also deals with Production Information   Engineering as a characteristic field of Systems Engineering, which   offers important application possibilities for IT-based system   integration.               Keywords: higher education, production information engineering, system integration, systems engineering               Categories: H.4.2, J.0, J.6  
12|9||Computer Science, Logic, Informatics Education|  Katalin Pásztor Varga (Eötvös Loránd University, Hungary)   Magda Várterész (varteres@inf.unideb.hu, Hungary)  Abstract: Our aim is to discuss what, when and, how deep   logic should be taught in the computer science education in   connection with the so called Bologna   process. We survey the spread of logic in the computer   science education. We draw special attention to the process   resulting by 1987 in a comprehensive school in the international   logic research called Computer Science   Logic. It includes the investigation of research   problems arising among others on such fields as programming theory,   data- and knowledge base theory and, artificial intelligence as   well. New directions have emerged during the problem solving, the   earlier disciplines of classical logic like lambda calculus, type   theory, model theory, modal logic, temporal logic has come back into   the main scope. The results of these researches have a great impact   on the development of computer science. The research results and the   ever increasing role of logic should be obviously reflected by the   education. We explain our conception concerning this issue as   well.               Keywords: computer science, education, logic               Categories:  F.4.1, F.4.0  
volume|issue|url|title|abstract
13|1|http://www.jucs.org/jucs_13_1|Selected Papers from the 1st ACIS International Workshop on Self-Assembling Wireless Networks|
13|1||Duplicate Address Detection and Autoconfiguration in OLSR|  Saadi Boudjit (GET/ENST, France)   Cédric Adjih (INRIA, France)   Paul Mühlethaler (INRIA, France)   Anis Laouiti (GET/INT, France)  Abstract: Mobile Ad hoc NETworks (MANETs) are   infrastructure-free, highly dynamic wireless networks, where central   administration or configuration by the user is very difficult. In   hardwired networks nodes usually rely on a centralized server and   use a dynamic host configuration protocol, like DHCP [Droms et   al. 2003], to acquire an IP address. Such a solution cannot be   deployed in MANETs due to the unavailability of any centralized DHCP   server. For small scale MANETs, it may be possible to allocate free   IP addresses manually. However, the procedure becomes impractical   for a large-scale or open system where mobile nodes are free to join   and leave. Most of the autoconfiguration algorithms proposed for ad   hoc networks are independent of the routing protocols and therefore,   generate a significant overhead. Using the genuine optimization of   the underlying routing protocol can significantly reduce the   autoconfiguration overhead. One of the MANET protocols which have   been promoted to experimental RFC is the OLSR routing protocol   [Jacquet et al. 2003], on which this article focuses. This article   aims at complementing the OLSR routing protocol specifications to   handle autoconfiguration. The corner stone of this autoconfiguration   protocol is an advanced duplicate address detection   algorithm.               Keywords: MANET, OLSR, autoconfiguration               Categories: C.2.0, C.2.1, C.2.2  
13|1||An Adaptive Hierarchical Extension of DSR: The Cluster Source Routing|  Farid Jaddi (IRIT-ENSEEIHT, France)   Béatrice Paillassa (IRIT-ENSEEIHT, France)  Abstract: Numerous studies have shown the difficulty for a   single routing protocol to scale with respect to mobility and   network size in wireless ad hoc networks. This paper presents a   cluster-based extension of the DSR protocol called Cluster Source   Routing (CSR)1. The proposed approach improves the scalability of   DSR in high-density and low-mobility networks. The originality of   our proposal is an adaptive use of DSR and CSR routing modes   according to network density and node mobility in order to produce   less overhead and perform efficient routing. Indeed, adaptation is a   key feature for a routing protocol since network dynamics can   suddenly and widely change in wireless ad hoc networks. Thus, the   DSR-CSR protocol achieves enhanced performance over a broader   {network density, node mobility} domain as shown by simulations.               Keywords: ad hoc routing, adaptation, clustering, scalability, wireless networks               Categories: H.3.7, H.5.4  
13|1||Quality of Service Routing in a MANET with OLSR|  Dang-Quan Nguyen (INRIA Rocquencourt, France)   Pascale Minet (INRIA Rocquencourt, France)  Abstract: Ad hoc wireless networks have enormous commercial and military potential becauseof their self-organizing capacity and mobility support. However, some specificities of these networks such as radio interferences and limited resources make more complex the quality of service(QoS) support. Indeed, on the one hand, the bandwidth offered to users is strongly affected by radio interferences. On the other hand, flooding information in such a network must be optimizedin order to save resources. Therefore, we propose in this paper, a solution taking into account radio interferences in mobile ad hoc network routing and optimizing flooding. This solution isbased on a modified version of the OLSR routing protocol that considers bandwidth requests and radio interferences in the route selection process while providing a very efficient flooding.A comparative performance evaluation based on NS simulations shows that despite the overhead due to QoS management, this solution outperforms classical OLSR in terms of QoS perceivedby the users (e.g. bandwidth amount granted to a flow and delivery rate). The efficiency of the optimized flooding is equal to that provided by the native version of OLSR.               Keywords: OLSR, QoS routing, ad hoc network, admission control, interference, local available bandwidth, multi-point relay (MPR), optimized flooding, quality of service               Categories: C.2.0, C.2.1, C.2.2  
13|1||VCA: An Energy-Efficient Voting-Based Clustering Algorithm for Sensor Networks|  Min Qin (University of Southern California, USA)   Roger Zimmermann (University of Southern California, USA)  Abstract: Clustering provides an effective mechanism for   energy-efficient data delivery in wireless sensor networks. To   reduce communication cost, most clustering algorithms rely on a   sensor's local properties in electing cluster heads. They often   result in unsatisfactory cluster formations, which may cause the   network to suffer from load imbalance or extra energy   consumption. In this paper, we propose a novel Voting-based   Clustering Algorithm (VCA) for energy-efficient data dissemination   in wireless sensor networks. This new approach lets sensors vote for   their neighbors to elect suitable cluster heads. VCA is completely   distributed, location-unaware and independent of network size and   topology. It combines load balancing, energy and topology   information together by using very simple voting   mechanisms. Simulation results show that VCA can reduce the number   of clusters by 5-25% and prolong the lifetime of a sensor network by   10-30% over that of existing energy-efficient clustering   protocols.               Keywords: cluster head, clustering, data aggregation, energy-efficient, sensor network, voting               Categories: C.2.2, C.2.4  
13|1||Energy Efficient Node Caching and Load Balancing Enhancement of Reactive Ad Hoc Routing Protocols|  Nisar Hundewale (Georgia State University, USA)   Sunsook Jung (Georgia State University, USA)   Alex Zelikovsky (Georgia State University, USA)  Abstract: Enhancing route request broadcasting protocols   constitutes a substantial part of recent research in mobile ad-hoc   network (MANET) routing. We suggest a novel approach to modify route   request broadcast based on node caching. The intuition behind node   caching is that the nodes involved in recent data packet forwarding   have more reliable information about its neighbors and have better   locations (e.g., on the intersection of several data routes) than   other nodes. We cache nodes which are recently involved in data   packet forwarding, and use only them to forward route   requests. Stopping forwarding route requests from the other nodes   considerably reduces routing overhead at the expense of possible   destination missing. The suggested node caching techniques can be   also viewed as a dynamic implementation of a connected dominating   set (CDS). We overcome the known drawback of CDS - overuse of   dominating (cached) nodes - by a new load-balancing scheme. Our contributions include: (i) a new energy-efficient node caching enhancement of route request broadcast for reactive ad hoc routing protocols; (ii) an extensive simulation study in NS2 of the novel node caching enhancement of AODV (AODV-NC) showing drastic reduction in overhead, significant improvement of the packet delivery ratio and the end-to-end delay and overhead; (iii) an analysis of the forwarding load distribution and energy consumption, and (iv) an extensive simulation study in NS2 of the novel AODV-NC based routing protocol with adaptive workload balancing (AODVNC-WLB) showing considerable improvement in throughput, overhead, delivery ratio and delay over the standard AODV for stressed MANETs.               Keywords: Ad-hoc On-demandDistance Vector, energy efficiency, mobile ad hoc networks, node caching, performance evaluation, routing load balancing, routing protocols               Categories: C.2.2  
13|10|http://www.jucs.org/jucs_13_10|Managing Editor's Column|
13|10||Constant Size Ciphertext HIBE in the Augmented Selective-ID Model and its Extensions|  Sanjit Chatterjee (University of Waterloo, Canada)   Palash Sarkar (Indian Statistical Institute, India)  Abstract: At Eurocrypt 2005, Boneh, Boyen and Goh   presented a constant-size ciphertext hierarchical identity-based   encryption (HIBE) protocol. Our main contribution is to present a   variant of the BBG-HIBE. The new HIBE is proved to be secure   (without any degradation) in an extension of the s-ID model (denoted   the s+-ID model) and the components of the   identities are from ℤ p, where   p is a suitable large prime. The BBG-HIBE is   proved to be secure in the selective-ID (s-ID) security model and   the components of the identities are from   ℤ *p. In the   s+-ID model the adversary is allowed to vary   the length of the challenge identity whereas this is not allowed in   the s-ID model. The new HIBE shares all the good features of the   BBG-HIBE. The drawback is that the public parameters and the private   key are longer than that of the BBG-HIBE. We also provide two more   extensions of the basic constant-size ciphertext HIBE. The first is   a constant-size ciphertext HIBE secure in the generalised   selective-ID model ℳ 2. The second one is   a product construction composed of two HIBEs and a trade-offis   possible between the private key size and the ciphertext   size.               Keywords: bilinear pairing, hierarchical identity-based encryption, standard model               Categories: E.3  
13|10||Pedagogical Natural Deduction Systems: the Propositional Case|  Loïc Colson (L.I.T.A. University of Metz, France)   David Michel (L.I.T.A. University of Metz, France)  Abstract: This paper introduces the notion of   pedagogical natural deduction systems, which are   natural deduction systems with the following additional constraint:   all hypotheses made in a proof must be motivated by some example. It   is established that such systems are negationless. The expressive   power of the pedagogical version of some propositional calculi are   studied.               Keywords: constructive mathematics, mathematical logic, natural deduction, negationless mathematics, typed λ-calculus               Categories: F.1.1, F.4.1  
13|10||Efficient Access Methods for Temporal Interval Queries of Video Metadata|  Spyros Sioutas (Ionian University, Greece)   Kostas Tsichlas (Aristotle University of Thessaloniki, Greece)   Bill Vassiliadis (Hellenic Open University, Greece)   Dimitrios Tsolis (University of Patras, Greece)  Abstract: Indexing video content is one of the most   important problems in video databases. In this paper we present   linear time and space algorithms for handling video metadata that   represent objects or events present in various frames of the video   sequence. To accomplish this, we make a straightforward reduction of   this problem to the intersection problem in Computational   Geometry. Our first result is an improvement over the one of   V. S. Subrahmanian [Subramanian, 1998] by a logarithmic factor in   storage. This is achieved by using different basic data   structures. Then, we present two other interesting time-efficient   approaches. Finally a reduction to a special geometric problem is   considered according to which we can achieve two optimal in time and   space solutions in main and external memory model of computation   respectively. We also present an extended experimental evaluation.               Keywords: computational geometry, data structures, video databases               Categories: E.1, E.5, H.3.1, H.3.3, M.9  
13|10||Mobile Sensemaking: Exploring Proximity and Mobile Applications in the Classroom|  Gustavo Zurita (University of Chile, Chile)   Pedro Antunes (University of Lisboan, Portugal)   Nelson Baloian (University of Chile, Chile)   Felipe Baytelman (University of Chile, Chile)  Abstract: We propose mobile sensemaking as a   collaborative mechanism to explore and understand information in   highly mobile and fluid situations, where people engage in multiple   parallel, rapid and ad-hoc interactions, rather than participating   in large highly-structured decision processes. Mobile sensemaking is   explored in the classroom context, where it has been recognized that   the traditional lectures should be reconstructed as active processes   centered on collaborative activities. Mobile sensemaking relies on   mobile computing devices and a proximity model, both organizing   collaborative activities according to the domain context and   physical proximity. The paper describes in detail the proposed   proximity model and the developed mobile application.               Keywords: collaborative learning, computer supported learning, mobile computing, proximity.               Categories: H.4.0, H.5.3, M.0  
13|10||An Approach to Polygonal Approximation of Digital Curves Based on Discrete Particle Swarm Algorithm|  Fangmin Dong (Huazhong University of Science and Technology, China)   Renbin Xiao (Huazhong University of Science and Technology, China)   Yifang Zhong (Huazhong University of Science and Technology, China)   Yong Liu (Three Gorges University, China)  Abstract: An approach to polygonal approximation of   regular digital curves based on PSO algorithm is presented. In this   paper, each particle corresponds to a candidate solution to the   polygonal approximation problem, which is represented as a binary   vector. The offset error of centroid between the original curve and   the approximation polygon, and the variance of distance error for   each approximation segment are adopted in the fitness function to   evaluate the feasibility degree of the candidate solution. The   sigmoid function of iteration times is used as the acceleration   factors instead of the constant factors to improve the global   searching characteristics. Experimental results show that the   proposed approach can get suitable approximation results for   preserving the features of original curves.               Keywords: PSO, centroid, polygonal approximation, sigmoid function               Categories: I.2.8, I.3.5  
13|10||An Improved SVM Based on Similarity Metric|  Chaoyong Wang (Jilin University, China)   Yanfeng Sun (Jilin University, China)   Yanchun Liang (Jilin University, China)  Abstract: A novel support vector machine method for   classification is presented in this paper. A modified kernel   function based on the similarity metric and Riemannian metric is   applied to the support vector machine. In general, it is believed   that the similarity of homogeneous samples is higher than that of   inhomogeneous samples. Therefore, in Riemannian geometry, Riemannian   metric can be used to reflect local property of a curve. In order to   enlarge the similarity metric of the homogeneous samples or reduce   that of the inhomogeneous samples in the feature space, Riemannian   metric is used in the kernel function of the SVM. Simulated   experiments are performed using the databases including an   artificial and the UCI real data. Simulation results show the   effectiveness of the proposed algorithm through the comparison with   four typical kernel functions without similarity metric.               Keywords: Riemannian metric, similarity metric, support vector machine               Categories: H.3.7, H.5.4  
13|10||Machine Learning-Based Keywords Extraction for Scientific Literature|  Chunguo Wu (Jilin University and Beijing Jiaotong University, China)   Maurizio Marchese (University of Trento, Italy)   Jingqing Jiang (Jilin University, China)   Alexander Ivanyukovich (University of Trento, Italy)   Yanchun Liang (Jilin University, China)  Abstract: With the currently growing interest in the Semantic Web, keywords/metadata extraction is coming to play an increasingly important role. Keywords extraction from documents is a complex task in natural languages processing. Ideally this task concerns sophisticated semantic analysis. However, the complexity of the problem makes current semantic analysis techniques insufficient. Machine learning methods can support the initial phases of keywords extraction and can thus improve the input to further semantic analysis phases. In this paper we propose a machine learning-based keywords extraction for given documents domain, namely scientific literature. More specifically, the least square support vector machine is used as a machine learning method. The proposed method takes the advantages of machine learning techniques and moves the complexity of the task to the process of learning from appropriate samples obtained within a domain. Preliminary experiments show that the proposed method is capable to extract keywords from the domain of scientific literature with promising results.               Keywords: keywords extraction, machine learning, metadata extraction, support vector machine               Categories: H.3.7, H.5.4, M.0, M.7, M.9  
13|10||A Model of Immune Gene Expression Programming for Rule Mining|"  Tao Zeng (Sichuan University, China)   Changjie Tang (Sichuan University, China)   Yong Xiang (Chengdu Electromechanical College, China)   Peng Chen (Sichuan University, China)   Yintian Liu (Sichuan University, China)  Abstract: Rule mining is an important issue in data   mining. To address it, a novel Immune   Gene Expression   Programming (IGEP) model was proposed. Concepts   of rule, gene, immune cell, and antibody were formalized. The   dynamic evolution models and the corresponding recursive equations   of immune cell, self, immune-tolerance were built. The novel key   techniques of IGEP were presented. Experiment results showed that   the new method has good stability, scalability and flexibility. It   can discover traditional association rule, non-traditional rule   including connective ""OR"" or ""NOT"", and meta-rule of strong   rule. Furthermore, it can perform well in constrained pattern   mining.               Keywords: artifical immune system, data mining, evolutionary algorithm, gene expression programming, meta-rule, rule               Categories: F.2.2, H.2.8, I.2.6, I.5.2, I.6.5, M.7  "
13|11|http://www.jucs.org/jucs_13_11|Combinatorics and Related Areas A Collection of Papers in Honour of the 65th Birthday of  Ioan Tomescu|
13|11||Spectral Densest Subgraph           and Independence Number of a Graph|  Reid Andersen (Microsoft Research, USA)   Sebastian M. Cioabă (University of California, USA)  Abstract: In this paper, we study spectral versions of the densest subgraph problem and the largest    independence subset problem. In the first part, we give an algorithm for identifying small subgraphs with     large spectral radius. We also prove a Hoffman-type ratio bound for the order of an induced subgraph whose      spectral radius is bounded from above.               Keywords: densest subgraph, eigenvalues, graphs, independence number               Categories: F.4.1  
13|11||Perfect Matchings in Polyhexes,           or Recent Graph-theoretical Contributions to Benzenoids|  Alexandru T. Balaban (Texas A&M University at Galveston, USA)   Milan Randić (National Institute of Chemistry, Slovenia)  Abstract: After an introduction on the history of   polycyclic aromatic compounds, recent advances in the theory of   benzenoids are briefly reviewed. Then using systems with 4, 5, or 6   benzenoid rings for illustration, the partition of the P   π-electrons among the rings of the benzenoid is presented,   followed by a different way of examining the distribution of these   π-electrons which is called the signature of the benzenoid,   consisting in six integers from   s6 to   s1. The P π-electrons   are divided between the two sums   s6 +   s5 +   s2 +   s1 and   s4 +   s3 characterizing thereby   the closeness of benzenoids to all-resonant structures according to   Clars theory.               Keywords: Clar structures, isoarithmic benzenoids, perfect matchings (1-factors, resonance  structures, or Kekul'e structures), polycyclic aromatic hydrocarbons (polyhexes or  benzenoids)               Categories: G.2.2, J.2  
13|11||Equivalent           Transformations of Automata by Using Behavioural Automata|  Gabriel Ciobanu (gabriel@info.uaic.ro, Romania)   Sergiu Rudeanu (University of Bucharest, Romania)  Abstract: This paper uses category theory to emphasize the   relationships between Mealy, Moore and Rabin-Scott automata, and the   behavioural automata are used as a unifying framework. Some of the   known links between Mealy, Moore and RabinScott automata are   translated into isomorphisms of categories, and we also show how   behavioural automata connect to these automata. Considering the   distinction between final and sequential behaviours of an automaton,   we define a sequential version of Mealy automata and study its   relationship to behavioural automata.               Keywords: Mealy, Moore and Rabin-Scott automata, behavioural automata, category theory, final and sequential behaviours of automata, semiautomata               Categories: F.1, F.1.1  
13|11||On the Forcing Semantics for Monoidal t-norm Based Logic|"  Denisa Diaconescu (University of Bucharest, Romania)   George Georgescu (University of Bucharest, Romania)  Abstract: MTL-algebras are algebraic   structures for the Esteva-Godo monoidal t-norm   based logic (MTL), a many-valued propositional   calculus that formalizes the structure of the real interval [0, 1],   induced by a left-continuous t-norm. Given a   complete MTL-algebra Χ, we define the weak   forcing value |φ|χ and the forcing value [φ]χ,   for any formula φ of MTL in Χ. We   establish some arithmetical properties of|.|χ and [.]χ,   and prove the equality [φ]χ=||φ||χ, where   ||φ||χ is the truth value of φ in Χ.               Keywords: MTL logic, MTL-algebras, forcing semantics               Categories: F.4.1  "
13|11||The Gray Code|  Robert W. Doran (The University of Auckland, New Zealand)  Abstract: Here we summarise the properties and algorithms   of the Gray code. Descriptions are given of the Gray code   definition, algorithms and circuits for generating the code and for   conversion between binary and Gray code, for incrementing, counting,   and adding Gray code words. Some interesting applications of the   code are also treated. Java implementations of the algorithms in   this paper are available at: http://www.jucs.org/jucs_13_11/the_gray_code/data/DoranGrayPrograms.zip  Keywords: Gray code, single-distance code               Categories: E.4  
13|11||Accepting Networks of Evolutionary Processors with Filtered Connections|  Cezara Drăgoi (University of Bucharest, Romania)   Florin Manea (University of Bucharest, Romania)   Victor Mitrana (University of Bucharest, Romania)  Abstract: In this paper we simplify a recent model of   computation considered in [Margenstern et al. 2005], namely   accepting network of evolutionary processors, by moving the filters   from the nodes to the edges. Each edge is viewed as a two-way   channel such that input and output filters, respectively, of the two   nodes connected by the edge coincide. Thus, the possibility of   controlling the computation in such networks seems to be   diminished. In spite of this observation these simplified networks   have the same computational power as accepting networks of   evolutionary processors, that is they are computationally   complete. As a consequence, we propose characterizations of two   complexity classes, namely NP and   PSPACE, in terms of accepting networks of   evolutionary processors with filtered connections.               Keywords: Turing machine, complexity class, evolutionary processor, network of evolutionary processors               Categories: F.1.1, F.1.3, F.4.3  
13|11||Analysis of two Sweep-line Algorithms for Constructing Spanning Trees and Steiner Trees|  Adrian Dumitrescu (University of Wisconsin-Milwaukee, USA)   Csaba D. Tóth (Massachusetts Institute of Technology, USA)  Abstract: We give a tight analysis of an old and popular   sweep-line heuristic for constructing a spanning tree of a set of   n points in the plane. The algorithm sweeps a   vertical line across the input points from left to right, and each   point is connected by a straight line segment to the closest point   left of (or on) the sweep-line. If W denotes the   weight the Euclidean minimum spanning tree (EMST), the spanning tree   constructed by the sweep-line algorithm has weight   O(W log n),   and this bound is asymptotically tight. We then analyze a sweep-line   heuristic for constructing a Steiner tree, in which a vertical line   is swept across the input points from left to right, and each point   is connected by a straight line segment to the closest point on   edges or vertices of the current tree (on the left of the sweep   line). We show that this algorithm achieves an approximation ratio   of O(log n), and describe a   class of instances where this ratio is Ω(log n / log log n). Our results   give almost complete answers to two old open questions from the   1970s.               Keywords: approximation ratio, heuristic, minimum Steiner tree, minimum spanning tree, sweep-line               Categories: F.2.2, G.2.2  
13|11||On BCK Algebras - Part I.a: An Attempt to Treat Unitarily the Algebras of Logic. New Algebras|"  Afrodita Iorgulescu (Academy of Economic Studies, Romania)  Abstract: Since all the algebras connected to logic have,   more or less explicitely, an associated order relation, it follows   that they have two presentations, dual to each other. We classify   these dual presentations in ""left"" and ""right"" ones and we consider   that, when dealing with several algebras in the same research, it is   useful to present them unitarily, either as ""left"" algebras or as   ""right"" algebras. In some circumstances, this choice is essential,   for instance if we want to build the ordinal sum (product) between a   BL algebra and an MV algebra. We have chosen the ""left"" presentation   and several algebras of logic have been redefined as particular   cases of BCK algebras.  We introduce several new properties of algebras of logic, besides those usually existing in the literature, which generate a more refined classification, depending on the properties satisfied. In this work (Parts I-V) we make an exhaustive study of these algebras - with two bounds and with one bound - and we present classes of finite examples, in bounded case.  In this Part I, divided in two because of its length, after surveying chronologically several algebras related to logic, as residuated lattices, Hilbert algebras, MV algebras, divisible residuated lattices, BCK algebras, Wajsberg algebras, BL algebras, MTL algebras, WNM algebras, IMTL algebras, NM algebras, we propose a methodology in two steps for the simultaneous work with them (the first part of Part I).  We then apply the methodology, redefining those algebras as particular cases of reversed left-BCK algebras. We analyse among others the properties Weak Nilpotent Minimum and Double Negation of a bounded BCK(P) lattice, we introduce new corresponding algebras and we establish hierarchies (the subsequent part of Part I).               Keywords: BCK algebra, BCK(P) lattice, BL algebra, Hertz algebra, Heyting algebra, Hilbert algebra, Hájek(P) algebra, IMTL algebra, MTL algebra, MV algebra, NM algebra, R0 algebra, WNM algebra, Wajsberg algebra, divisible BCK(P) lattice, generalized Wajsberg algebra, generalized-BL algebra, generalized-MV algebra, pocrim, residuated lattice, t-norm, weak-BL algebra               Categories: F.4.1  "
13|11||Satisfying Assignments of Random Boolean Constraint Satisfaction Problems: Clusters and Overlaps|  Gabriel Istrate (eAustria Research Institute, Romania)  Abstract: The distribution of overlaps of solutions of a   random constraint satisfaction problem (CSP) is an indicator of the   overall geometry of its solution space. For random   k-SAT, nonrigorous methods from Statistical   Physics support the validity of the one step replica symmetry   breaking approach. Some of these predictions were rigorously   confirmed in [Mézard et al. 2005a] [Mézard et   al. 2005b]. There it is proved that the overlap distribution of   random k-SAT, k ≥ 9,   has discontinuous support. Furthermore, Achlioptas and   Ricci-Tersenghi [Achlioptas and Ricci-Tersenghi 2006] proved that,   for random k-SAT, k ≥ 8,   and constraint densities close enough to the phase   transition:  - there exists an exponential number of clusters of satisfying assignments.  - the distance between satisfying assignments in different clusters is linear.   We aim to understand the structural properties of random CSP that lead to solution clustering. To this end, we prove two results on the cluster structure of solutions for binary CSP under the random model from [Molloy 2002]:  1. For all constraint sets S (described in [Creignou and Daudé 2004, Istrate 2005]) such that SAT (S) has a sharp threshold and all q ∈ (0, 1], q-overlap-SAT (S) has a sharp threshold. In other words the first step of the approach in [Mézard et al. 2005a] works in all nontrivial cases.  2. For any constraint density value c q ∈ (0, 1] such an instance has with high probability two satisfying assignment of overlap ~ q. Thus, as expected from Statistical Physics predictions, the second step of the approach in [Mézard et al. 2005a] fails for 2-SAT.               Keywords: overlaps, random constraint satisfaction, sharp thresholds               Categories: G.2.1, G.3  
13|11||Graded Sparse Graphs and Matroids|  Audrey Lee (University of Massachusetts, USA)   Ileana Streinu (Smith College, USA)   Louis Theran (University of Massachusetts, USA)  Abstract: Sparse graphs and their associated matroids play an important role in rigidity theory, where they capture the combinatorics of some families of generic minimally rigid structures. We define a new family called graded sparse graphs, arising from generically pinned bar-and-joint frameworks, and prove that they also form matroids. We also address several algorithmic problems on graded sparse graphs: Decision, Spanning, Extraction, Components, Optimization, and Extension. We sketch variations on pebble game algorithms to solve them.               Keywords: computational geometry, hypergraph, matroid, pebble game, rigidity theory               Categories: F.2.2, G.2.2  
13|11||Rates of Asymptotic Regularity for Halpern Iterations of Nonexpansive Mappings|  Laurentiu Leustean (Technische Universität Darmstadt, Germany)  Abstract: In this paper we obtain new effective results on   the Halpern iterations of nonexpansive mappings using methods from   mathematical logic or, more specifically, proof-theoretic   techniques. We give effective rates of asymptotic regularity for the   Halpern iterations of nonexpansive self-mappings of nonempty convex   sets in normed spaces. The paper presents another case study in the   project of proof mining, which is concerned with   the extraction of effective uniform bounds from (prima-facie)   ineffective proofs.               Keywords: Halpern iterations, asymptotic regularity, metric fixed point theory, nonexpansive functions, proof mining               Categories: F.4.1, G.1  
13|11||Matrices and α-Stable Bipartite Graphs|  Vadim E. Levit (Ariel University Center of Samaria, Israel)   Eugen Mandrescu (Holon Institute of Technology, Israel)  Abstract: A square (0, 1)-matrix X of   order n ≥ 1 is called fully   indecomposable if there exists no integer   k with 1 ≤ k ≤   n - 1, such that X has a   k by n - k   zero submatrix. The reduced adjacency matrix of a   bipartite graph G = (A, B, E)   (having A ∪ B =   {a1, ...,   am} ∪   {b1, ...,   bn} as a vertex set, and   E as an edge set), is X =   [xij], 1 ≤   i ≤ m, 1 ≤   j ≤ n, where   xij = 1 if   aibj   ∈ E and   xij = 0 otherwise. A   stable set of a graph G is a   subset of pairwise nonadjacent vertices. The stability   number of G, denoted by   α(G), is the cardinality of a maximum stable   set in G. A graph is called   α-stable if its stability number remains the   same upon both the deletion and the addition of any edge. We show   that a connected bipartite graph has exactly two maximum stable sets   that partition its vertex set if and only if its reduced adjacency   matrix is fully indecomposable. We also describe a decomposition   structure of α-stable bipartite graphs in terms of their   reduced adjacency matrices. On the base of these findings, we obtain   both new proofs for a number of well-known theorems on the structure   of matrices due to Brualdi (1966), Marcus and Minc (1963), Dulmage   and Mendelsohn (1958), and some generalizations of these   statements. Two kinds of matrix product are also considered (namely,   Boolean product and Kronecker product), and their corresponding   graph operations. As a consequence, we obtain a new proof of one   Lewin's theorem claiming that the product of two fully   indecomposable matrices is a fully indecomposable matrix.               Keywords: Boolean product, Kronecker product, adjacency matrix, bistable bipartite graph, cover irreducible matrix, elementary graph, fully indecomposable matrix, perfect matching, stable set, total support               Categories: G.2.1, G.2.2  
13|11||Spiking Neural P Systems with Astrocyte-Like Control|  Gheorghe Păun (Institute of Mathematics of the Romanian Academy, Romania)  Abstract: Spiking neural P systems are computing models   inspired from the way the neurons communicate by means of spikes,   electrical impulses of identical shapes. In this note we consider a   further important ingredient related to brain functioning, the   astrocyte cells which fed neurons with nutrients, implicitly   controlling their functioning. Specifically, we introduce in our   models only one feature of astrocytes, formulated as a control of   spikes traffic along axons. A normal form is proved (for systems   without forgetting rules) and decidability issues are   discussed.               Keywords: astrocyte, membrane computing, neural computing, spiking neural P system               Categories: F.1.1, F.4.2, F.4.3, G.2.2  
13|11||High-level Structured Interactive Programs with Registers and Voices|"  Alexandru Popa (University of Bucharest, Romania)   Alexandru Sofronia (University of Bucharest, Romania)   Gheorghe Stefanescu (University of Bucharest, Romania)  Abstract: A model (consisting of rv-systems), a core programming language (for developing rv-programs), several specification and analysis techniques appropriate for modeling, programming and reasoning about interactive computing systems have been introduced by Stefanescu in 2004 using register machines and space-time duality, see [Stefanescu 2006, Stefanescu 2006b]. Later on, Dragoi and Stefanescu have introduced structured programming techniques for programming rv-systems and have presented a kernel programming language AGAPIA v0.1 for interactive computing systems, see [Dragoi and Stefanescu 2006a, Dragoi and Stefanescu 2006b].  AGAPIA v0.1 has a restricted format for program construction, using a ""3-level"" grammar for their definition: the procedure starts with simple while programs, then modules are defined, and finally AGAPIA v0.1 programs are obtained applying structured rvprogramming statements on top of modules.  In the current paper the above restriction is completely removed. By an appropriate reshaping interface technique, general programs may be encapsulated into modules, allowing to reiterate the above ""3-level"" construction of programs, now starting with arbitrary AGAPIA programs, not with simple while programs. This way, high-level interactive programs are obtained. The extended version is called AGAPIA v0.2.  As a case study we consider a cluster of computers, each having a dynamic set of running processes. We present a protocol for the communication and termination detection in this system and implement the protocol in our AGAPIA v0.2 language. We also describe the operational semantics of the program using high-level scenarios, i.e., scenarios where, recursively, the cells may themselves contain scenarios, at a lower, refined level.               Keywords: AGAPIA programming, distributed termination protocols, interactive systems, programming languages, registers and voices, rv-systems, typing systems               Categories: D.1, D.3  "
13|11||Balance in Systems of Finite Sets with Applications|"  Dragoş-Radu Popescu (University of Bucharest, Romania)  Abstract: An extension of balance notion from the theory   of signed graphs to the case of finite sets systems is   presented. For a finite set T, a subset   S ⊆ T and a family   F of subsets of T we denote by   δm   (S|F) respectively   δM   (S|F) the minimum/maximum   number of changes (addition or deletion of elements), without   repetition, which transforms S into a set from   F.  We are especially interested in the particular case in which F is the group X1,..., Xn> generated by a family of subsets X1,..., Xn ⊆ T with symmetric difference operation. The obtained results are applied to the theory of signed graphs.               Keywords: balancing signed graphs               Categories: G.2.2  "
13|11||Metric-Entropy Pairs on Lattices|  Dan Simovici (University of Massachusetts Boston, USA)  Abstract: We introduce the notion of ∧- and   ∨-pairs of functions on lattices as an abstraction of the   notions of metric and its related entropy for probability   distributions. This approach allows us to highlight the   relationships that exist between various properties of metrics and   entropies and opens the possibility of extending these concepts to   other algebraic structures.               Keywords: entropy, metric, modular lattice               Categories: H.1.1, H.2.8  
13|11||Connectivity and Reachability in Signed Networks|  Monica Tătărâm (Faculty of Mathematics and Informatics, Romania)  Abstract: For modeling real-life situations where not only   the intensity of the relation existing between elements but also its   polarity is important, we have proposed (see [Marcus and Tataram   1987a]) a new type of graphs: the signed networks. In the present   paper we study two of thier most important properties: connectivity   and reachability, and try to use them in order to offer a strategy   to improve communication in social or professional   groups.               Keywords: connectivity, geodesics, graph theory               Categories: G.2.2, G.2.3  
13|11||Hamiltonicity of Topological Grid Graphs|  Christina Zamfirescu (City University of New York, USA)   Tudor Zamfirescu (Universität Dortmund, Germany)  Abstract: In this paper we study connectivity and hamiltonicity properties of the topological grid graphs, which are a natural type of planar graphs associated with finite subgraphs of the usual square lattice graph of the plane. The main results are as follows. The shortness coefficient of the family of all topological grid graphs is at most 16/17. Every 3-connected topological grid graph is hamiltonian.               Keywords: 3-connectedness, grid graph, hamiltonian graph, shortness coefficient, topological grid graph               Categories: G.2.2  
13|12|http://www.jucs.org/jucs_13_12|Ontologies and their Applications|
13|12||ODEDialect: a Set of Declarative Languages for Implementing Ontology Translation Systems|  Oscar Corcho (Universidad Politécnica de Madrid, Spain)   Asunción Gómez-Pérez (Universidad Politécnica de Madrid, Spain)  Abstract: Implementing ontology translation systems is a   complex task that requires taking many types of translation   decisions, which are usually hidden inside their source code. In   order to ease building, maintaining and understanding ontology   translation systems, we propose ODEDialect, a set of languages to   express translation decisions declaratively and at different layers:   lexical, syntax, semantics, and pragmatics. This paper describes the   three languages that comprise ODEDialect: ODELex, which allows   expressing transformations in the lexical layer; ODESyntax, which   allows expressing transformations in the syntax layer; and ODESem,   which allows expressing transformations in the semantic and   pragmatic layers.               Keywords: ODEDialect, ontology language, translation               Categories: I.2.4, M.2, M.8  
13|12||An Adaptable Framework for Ontology-based Content Creation on the Semantic Web|  Onni Valkeapää (Helsinki University of Technology (TKK), Finland)   Olli Alm (Helsinki University of Technology (TKK), Finland)   Eero Hyvönen (Helsinki University of Technology (TKK), Finland)  Abstract: Creation of rich, ontology-based metadata is one of the major challenges in developing the Semantic Web. Emerging applications utilizing semantic web techniques, such as semantic portals, cannot be realized if there are no proper tools to provide metadata for them. This paper discusses how to make provision of metadata easier and cost-effective by an annotation framework comprising of annotation editor combined with shared ontology services. We have developed an annotation system Saha supporting distributed collaboration in creating annotations, and hiding the complexity of the annotation schema and the domain ontologies from the annotators. Saha adapts flexibly to different metadata schemas, which makes it suitable for different applications. Support for using ontologies is based on ontology services, such as concept searching and browsing, concept URI fetching, semantic autocompletion and linguistic concept extraction. The system is being tested in various practical semantic portal projects.               Keywords: annotation, information extraction, metadata, ontologies, semantic Web               Categories: H.3.1, H.3.2, H.3.4  
13|12||On Ranking RDF Schema Elements (and its Application in Visualization)|  Yannis Tzitzikas (University of Crete, Greece)   Dimitris Kotzinos (University of Crete, Greece)   Yannis Theoharis (University of Crete, Greece)  Abstract: Ranking is a ubiquitous requirement whenever we   confront a large collection of atomic or interrelated   artifacts. This paper elaborates on this issue for the case of RDF   schemas. Specifically, several metrics for evaluating automatic   methods for ranking schema elements are proposed and   discussed. Subsequently the creation of a test collection for   evaluating such methods is described, upon which several ranking   methods (from simple to more sophisticated) for RDF schemas are   evaluated. This formal way for evaluating ranking methods, apart   from yielding credible and repeatable results, gave us some   interesting insights to the problem. Finally, our experiences from   exploiting these ranking methods for visualizing RDF schemas,   specifically for deriving and visualizing top-k schema subgraphs,   are reported.               Keywords: schema ranking, schema visualization, semantic web               Categories: H.0, H.5  
13|12||An Ontology-based Approach to Support Text Mining and Information Retrieval in the Biological Domain|  Khaled Khelif (INRIA Sophia Antipolis, France)   Rose Dieng-Kuntz (INRIA Sophia Antipolis, France)   Pascal Barbry (IPMC, Sophia Antipolis, France)  Abstract: This paper describes an ontology-based approach aiming at helping biologists to annotate their documents and at facilitating their information retrieval task. Our approach, based on semantic web technologies, relies on formalised ontologies, semantic annotations of scientific articles and knowledge extraction from texts. We propose a method/system for the generation of ontology-based semantic annotations (MeatAnnot) and a system allowing biologists to draw advanced inferences on these annotations (MeatSearch). This approach was proposed to support biologists working on DNA microarray experiments in the validation and the interpretation of their results, but it can probably be extended to other massive analyses of biological events (as provided by proteomics, metabolomics...).               Keywords: Corese, NLP, life science, ontologies, semantic annotation, semantic web               Categories: H.3.1, H.3.3, M.0, M.7  
13|12||Discovering the Semantics of User Keywords|  Raquel Trillo (University of Zaragoza, Spain)   Jorge Gracia (University of Zaragoza, Spain)   Mauricio Espinoza (University of Zaragoza, Spain)   Eduardo Mena (University of Zaragoza, Spain)  Abstract: The technology in the field of digital media generates huge amounts of textual information every day, so mechanisms to retrieve relevant information are needed. Under these circumstances, many times current web search engines do not provide users with the information they seek, because these search tools mainly use syntax based techniques. However, search engines based on semantic and context information can help overcome some of the limitations of current alternatives.  In this paper, we propose a system that takes as input a list of plain keywords provided by a user and translates them into a query expressed in a formal language without ambiguity. Our system discovers the semantics of user keywords by consulting the knowledge represented by many (heterogeneous and distributed) ontologies. Then, context information is used to remove ambiguity and build the most probable query. Our experiments indicate that our system discovers the user's information need better than traditional search engines when the semantics of the request is not the most popular on the Web.  Keywords: information retrieval, querying the semantic Web, semantic interoperability               Categories: H.3.3, H.3.5  
13|12||The SEWASIE Network of Mediator Agents for Semantic Search|  Domenico Beneventano (University of Modena and Reggio Emilia, Italy)   Sonia Bergamaschi (University of Modena and Reggio Emilia, Italy)   Francesco Guerra (University of Modena and Reggio Emilia, Italy)   Maurizio Vincini (University of Modena and Reggio Emilia, Italy)  Abstract: Integration of heterogeneous information in the   context of Internet becomes a key activity to enable a more   organized and semantically meaningful access to data sources. As   Internet can be viewed as a data-sharing network where sites are   data sources, the challenge is twofold. Firstly, sources present   information according to their particular view of the matter,   i.e. each of them assumes a specific ontology. Then, data sources   are usually isolated, i.e. they do not share any topological   information concerning the content or the structure of other   sources. The classical approach to solve these issues is provided by   mediator systems which aim at creating a unified virtual view of the   underlying data sources in order to hide the heterogeneity of data   and give users a transparent access to the integrated information.  In this paper we propose to use a multi-agent architecture to build and manage a mediators network. While a single peer (i.e. a mediator agent) independently carries out data integration activities, it exchanges knowledge with other peers by means of specialized agents (i.e. brokers) which provide a coherent access plan to access information in the peer network. This defines two layers in the system: at local level, peers maintain an integrated view of local sources, while at network level agents maintain mappings among the different peers. The result is the definition of a new networked mediator system intended to operate in web economies, which we realized in the SEWASIE (SEmantic Webs and AgentS in Integrated Economies) project. SEWASIE is a RDT project supported by the 5th Framework IST program of the European Community successfully ended on September 2005.               Keywords: distributed applications, distributed databases, internet, knowledge management, mediator, ontologies, query language               Categories: C.2, C.2.4, H.2, H.2.3, M.0, M.1  
13|13|http://www.jucs.org/jucs_13_13|Applications of Formal Methods to System Design and Verification|
13|13||Hardware/Software Co-design and Verification Methodology from System Level Based on System Dependence Graph|  Shunsuke Sasaki (University of Tokyo, Japan)   Tasuku Nishihara (University of Tokyo, Japan)   Daisuke Ando (University of Tokyo, Japan)   Masahiro Fujita (University of Tokyo, Japan)  Abstract: System Dependence Graph (SDG) is a graph   representation which shows dependencies among statements /   expressions in a design. In this paper, we propose a new HW/SW   co-design methodology based on SDG. In our method, any combination   of C / C++ / SpecC descriptions is acceptable as input designs so   that design functions can be specified flexibly. First, the input   descriptions are analyzed and verified with static but partially   dynamic program checking methods by traversing SDG. With those   methods, large descriptions can be processed. Next, those designs   are divided into HW and SW parts. In this step, SDGs are fully   utilized to insert parallelism into the designs, and it enables   flexible HW/SW partitioning. The HW parts are further optimized and   then converted into RTL descriptions by existing behavioral   synthesis tools. Finally, the generated RTL descriptions together   with the SW parts are compared to the original descriptions in order   to make sure that they are logically equivalent. Also,   designerspecified properties may be model checked with these final   design descriptions. Such formal verifications can be realized by   translating those descriptions into Finite State Machine (FSM) type   representations and existing formal verifiers. We show two case   studies with practical examples to demonstrate the usefulness of our   approach.               Keywords: hardware software co-design, hardware software coverification, program slicing               Categories: B.7.2, D.2.2, D.2.4  
13|13||Self-Evolving Petri Nets|  Lorenzo Capra (Università degli Studi di Milano, Italy)   Walter Cazzola (Università degli Studi di Milano, Italy)  Abstract: Nowadays, software evolution is a very hot   topic. It is particularly complex when it regards critical and   nonstopping systems. Usually, these situations are tackled by   hard-coding all the foreseeable evolutions in the application design   and code.    Neglecting the obvious difficulties in pursuing this   approach, we also get the application code and design polluted with   details that do not regard the current system functionality, and   that hamper design analysis, code reuse and application maintenance   in general. Petri Nets (PN), as a formalism for modeling and   designing distributed/concurrent software systems, are not exempt   from this issue.    The goal of this work is to propose a PN based   reflective framework that lets everyone model a system able to   evolve, keeping separated functional aspects from evolutionary ones   and applying evolution to the model only if necessary. Such an   approach tries to keep system's model as simple as possible,   preserving (and exploiting) ability of formally verifying system   properties typical of PN, granting at the same time   adaptability.               Keywords: Petri Nets, reflection, software evolution               Categories: D.1, D.1.5, D.2, D.2.2  
13|13||From Theoretical e-Barter Models to Two Alternative Implementations Based on Web Sevices|  Mario Bravetti (Universita di Bologna, Italy)   Adalberto Casalboni (Universita di Bologna, Italy)   Manuel Núñez (Universidad Complutense Madrid, Spain)   Ismael Rodriguez (Universidad Complutense Madrid, Spain)  Abstract: An e-barter system is an e-commerce environment where transactions do not necessarily involve money. They are multi-agent systems where agents perform exchanges of rewources on behlaf of their respective users. Besides, their strucutre is based on a tree of markets. In this paper we show how to develop suitable designs for this kind of systems by means of web services by using WS-BPEL. Since the formal specification abstracts most practical details, the development of such design definition requires to face several challenges. We present two alternative designs that both comply with the formal specification.               Keywords: e-barter, formal methods, web services               Categories: D.2.1, F.3.1, K.4.4  
13|13||Integrating Module Checking and Deduction in a Formal Proof for the Perlman Spanning Tree Protocol (STP)|  Hossein Hojjat (University of Tehran, Iran)   Hootan Nakhost (Sharif University of Technology, Iran)   Marjan Sirjani (University of Tehran, Iran)  Abstract: In the IEEE 802.1D standard for the Media Access Control layer (MAC layer) bridges, there is an STP (Spanning Tree Protocol) definition, based on the algorithm that was proposed by Radia Perlman. In this paper, we give a formal proof for correctness of the STP algorithm by showing that finally a single node is selected as the root of the tree and the loops are eliminated correctly. We use formal inductive reasoning to establish these requirements. In order to ensure that the bridges behave correctly regardless of the topology of the surrounding bridges and LANs, the Rebeca modular verification techniques are applied. These techniques are shown to be efficiently applicable in model checking of open systems.               Keywords: Rebeca, formal methods, formal verification, modular verification, network protocols               Categories: C.2.2, D.2.4  
13|2|http://www.jucs.org/jucs_13_2|Communicative Intelligence|
13|2||Sustainable Memory System Using Global and Conical Spaces|  Hidekazu Kubota (Kyoto University, Japan)   Satoshi Nomura (Kyoto University, Japan)   Yasuyuki Sumi (Kyoto University, Japan)   Toyoaki Nishida (Kyoto University, Japan)  Abstract: We present a concept and implementation of a   computational support for spatial memory management and describe its   temporal evolution. Our essential idea is to use an immersible globe   that consists of a global space and a conical space, thereby   providing arbitrary memory space for humans. We developed a   sustainable knowledge globe (SKG) for constructing a memory space,   and proposed a system called Contents Garden to expand the SKG into   immersive space. We carried out the user study of SKG to evaluate   its effectiveness. We also proposed and discussed three perceptual   operations on Contents Garden to improve the operativity of the   SKG.               Keywords: SKG, contents management, information visualization, sustainable knowledge globe               Categories: H.3.7, H.5.1, H.5.2, M.6  
13|2||Building Immersive Conversation Environment  Using Locomotive Interactive Character|  Rai Chan (University of Tsukuba, Japan)   Junichi Hoshino (University of Tsukuba,, Japan)  Abstract: Generating composite human motion such as   locomotion and gestures is important for interactive applications,   such as interactive storytelling and computer games. In interactive   story environments, CG characters do not merely stand in one   position. Rather, they should be able to compose gestures and   locomotion based on the discourse of the story and the locations of   objects in the scene. Thus, in the present paper, we propose a   conversational locomotion model for CG character. We constructed a   conversational locomotion network for a virtual environment. A   multi-path searching algorithm calculates the optimal walking path,   which uses node activation from the story locations and conversation   units. The CG character also locally adjusts its position so that it   does not block the referenced object from the users sight. We have   applied the proposed technique to an interactive 3D movie system and   have demonstrated composite motion of the locomotion and   conversation of a CG character, which improves the immersion of the   viewer in the story environment.               Keywords: conversational locomotion, conversational locomotion network, panorama               Categories: D.1.0, D.1.1, D.2.1  
13|2||Real-time Human Proxy: An Avatar-based Communication System|  Daisaku Arita (Institute of Systems and Information Technologies/KYUSHU, Japan)   Rin-Ichiro Taniguchi (Kyushu University, Japan)  Abstract: We propose a concept of real-time human proxy   for avatar-based communication systems, which virtualizes a human in   the real world in real-time and which lets the virtualized human   behave as if he/she was present at a distant place.  For estimating   RHP, we apply it to a simple game and a virtual classroom system.   The experimental results shows us that RHP is useful for   avatar-based communication.               Keywords: avatar-based communication, motion capture, motion generation, virtual reality               Categories: H.5.1, H.5.2, H.5.3, I.3.7  
13|2||Analysis of Conversation Quanta  for Conversational Knowledge Circulation|  Ken Saito (Kyoto University, Japan)   Hidekazu Kubota (Kyoto University, Japan)   Yasuyuki Sumi (Kyoto University, Japan)   Toyoaki Nishida (Kyoto University, Japan)  Abstract: In this paper, we present a computational approach to understanding and augmenting the conversational knowledge process. We introduce the concept of the conversation quantization, a technique of approximating a continuous flow of conversation by a series of conversation quanta that represent points of the discourse. To investigate what the nature of conversation quanta is, we attempt to extract conversation quanta from two types of the meeting videos by hand. As a result, we have obtained some profitable suggestions about conversation quanta.               Keywords: conversation, conversation quantization, knowledge acquisition               Categories: H.3.1, H.3.3, H.5.1, M.0  
13|2||Entrainment in the   Rate of Utterances in Speech Dialogs between Users and an Auto   Response System|"  Takanori Komatsu (Future University-Hakodate, Japan)   Koji Morikawa (Matsushita Electric Industrial Co, Japan)  Abstract: Entrainment, a physical phenomenon in which one   individual's expressed information synchronizes with another's and   vice versa, can be observed between two communicators who are   interacting naturally. In this study, we focused on the ""rate of   utterances"" as communicators' expressed information and then   conducted an experiment to observe whether or not entrainment   naturally occurs in the rate of utterances in speech dialogs between   users and an auto response system. Specifically, participants were   asked to read given dialog scripts with an auto response system that   replied with different rates of utterances. The results revealed   that 1) when the system's rate of utterances increased, the   participants produced faster rates of utterances, 2) when the   system's rates decreased, participants spoke at slower rates. These   results suggest entrainment in the rate of utterances naturally   occurs in speech dialogs between participants and an auto response   system.               Keywords: entrainment, rate of utterances, speech interface               Categories: H.1.3, H.5.2  "
13|2||Parameter Estimation of Systems Described by the  Relation with Noisy Observations|  Jerzy Świątek (Wroclaw University of Technology, Poland)  Abstract: In this paper the problem of parameter estimation of an input-output system is discussed. It is assumed that the system is described by the relation known with accuracy to some parameters. The possible noisy observations of system are described. The estimation algorithm based on maximum likelihood method is proposed. The presented approach is illustrated by analytical examples.               Keywords: input-output system, knowledge representation, parameter estimation, relational systems, system identification               Categories: H.2.1, I.2.11, I.2.4  
13|2||An OWL Ontology of Set of Experience Knowledge Structure|  Cesar Sanin (University of Newcastle, Australia)   Edward Szczerbicki (University of Newcastle, Australia)   Carlos Toro (VICOMTech Research Centre, Spain)  Abstract: Collecting, distributing and sharing knowledge   in a knowledge-explicit way is a significant task for any company.   However, collecting decisional knowledge in the form of formal   decision events as the fingerprints of a company is an utmost   advance.  Such decisional fingerprint is called decisional DNA.  Set   of experience knowledge structure can assist on accomplishing this   purpose.  In addition, Ontology-based technology applied to set of   experience knowledge structure would facilitate distributing and   sharing companies' decisional DNA.  Such possibility would assist in   the development of an e-decisional community,   which will support decision-makers on their overwhelming job.  The   purpose of this paper is to explain the development of .an OWL   decisional Ontology built upon set of experience, which would make   decisional DNA, that is, explicit knowledge of formal decision   events, a useful element in multiple systems and technologies, as   well as in the construction of the e-decisional community.               Keywords: artificial intelligence, information_systems_applications, knowledge acquisition, knowledge representation formalismand method, semantic networks               Categories: H.4, H.5.2, I.2, I.2.4, I.2.6, M.0, M.3, M.4, M.6  
13|2||Using Place Invariants and Test Point Placement to Isolate Faults in Discrete Event Systems|  Iwan Georgiew Tabakow (Wroclaw University of Technology, Poland)  Abstract: This paper describes a method of using Petri net   P-invariants in system diagnosis. To model this process a net   oriented fault classification is presented. Hence, the considered   discrete event system is modelled by a live, bounded, and reversible   place-transition Petri net. The notions of D-partition of the set   of places P of a given place-transition net N and net   k-distinguishability are first introduced. Next these two notions   are extended to the set of all vertices, i.e. places and transitions   of N. So the problem of fault identification of the vertices of N   is transformed as a problem of fault identification of the places of   a new net N´ called a net simulator of N. Any transition in N´ is   assumed to be fault-free. Then the corresponding net place   invariants are computed. The system k-distinguishability measure is   obtained in a unique way from the place-invariant matrix. For a   large value of k, the system model is extended by using some set of   additional places called test points and at the same time preserving   the original net properties. To obtain a 1-distinguishable net the   notion of a marked graph component is used. It is shown a sufficient   condition for 1-distinguishability of an arbitrary place-transition   net and a corresponding algorithm is presented. Next two different   diagnosis test strategies are discussed, i.e. combinational and   sequential fault diagnosis. Corresponding (single) place and   transition fault models are introduced. The complexity of the   proposed method depends on the effectivity of the existing   algorithms for computation of the P-cover, i.e. the set of   P-invariants covering N. The proposed approach can be extended for   higher level Petri nets, e.g such as coloured nets or also to design   self-diagnosable circuit realisations of Boolean interpreted Petri   nets. Several examples are given.               Keywords: D-partition, P-invariant, discrete event system, fault diagnosis, k-distinguishability, place-transition net, test point               Categories: C.3, D.2.2, G.2.3, H.1.1, J.6, J.7  
13|2||Implementing Rule-Based Automated Price Negotiation in an Agent System|  Costin Bădică (University of Craiova, Romania)   Maria Ganzha (Polish Academy of Science Warsaw, Poland)   Marcin Paprzycki (Polish Academy of Science Warsaw, Poland)  Abstract: The idea of automating e-commerce transactions   attracts a lot of interest among researchers and IT practitioners,   and multi-agent systems are claimed to be one of promising software   technologies for achieving this goal. Since price negotiations are   one of crucial aspects of e-commerce transactions, in this paper we   present a rule-based implementation of automated price negotiations   utilized in a multi-agent system that models an e-commerce   environment. We start by summarizing state-of-the-art in rule-based   approaches to automated negotiations. We follow with a brief   description of the conceptual architecture of our system and a   simplified scenario that involves multiple buyer agents   participating in multiple English auctions performed in parallel.  A   detailed discussion of the design and implementation of price   negotiations, using JADE and JESS, and presentation of sample   experiments complete the paper.               Keywords: electronic commerce transaction, multiagent system, rule-based representation               Categories: I.2.11, I.2.4, K.4.4  
13|2||Using Recommendation to Improve Negotiations in Agent-based Systems|  Mateusz Lenar (Wroclaw University of Technology)   Janusz Sobecki (Wroclaw University of Technology, Poland)  Abstract: In this paper we present research works on   non-intuitive and low-efficient negotiations between agents in agent   based system. We find recommendation techniques as a suitable method   of making negotiation smarter and more efficient. We have introduced   into the negotiation thread the improvements in the form of hybrid   recommendation. Hybrid recommendation is composed of three basic   elements: demographic, collaborative and content-based. On the base   of a negotiation algorithm we have studied how recommendation   methods can improve the whole process of finding mutually acceptable   agreements between agents. The proposed methodology is presented   using a travel agency and its client negotiation.               Keywords: Petri Nets, agent-based systems, hybrid recommendation, negotiation thread                
13|2||Internet Path Behavior Prediction via Data Mining: Conceptual Framework and Case Study|  Leszek Borzemski (Wroclaw University of Technology, Poland)  Abstract: In this paper we propose an application of data mining methods in the prediction of the availability and performance of Internet paths. We deploy a general decision-making method for advising the users in further usage of Internet path at particular time and date. The method is based on the clustering and tree classification data mining techniques. The usefulness of our method for prediction the Internet path behavior has been confirmed in real-life experiment. The active Internet measurements were performed to gather the end-to-end latency and packet routing information. The knowledge gathered has been analyzed using a professional data mining package via neural clustering and decision tree algorithms. The results show that the data mining can be efficiently used for the purpose of the forecasting the network behavior. We propose to build a network performance monitoring and prediction service based on proposed data mining procedure. We address our approach especially to the non-networkers of such networking frameworks as Grid and overlay networks who want to schedule their network activity but who want to be left free from networking issues to concentrate on their work.               Keywords: Internet performance, Knowledge Management, data mining, end-to-end-performance, grids, network behavior prediction               Categories: C.2.3, C.4, H.1.2, H.2.8, M.0, M.1, M.7  
13|2||Deriving Consensus for Hierarchical Incomplete Ordered Partitions and Coverings|  Marcin Hernes (Wroclaw University of Technology, Poland)   Ngoc Thanh Nguyen (Wroclaw University of Technology, Poland)  Abstract: A method for determining consensus of hierarchical incomplete ordered partitions and coverings of sets is presented in this chapter. Incomplete ordered partitions and coverings are often used in expert information analysis. These structures should be useful when an expert has to classify elements of a set into given classes, but referring to several elements he does not know to which classes they should belong. The hierarchical ordered partition is a more general structure than incomplete ordered partition. In this chapter we present definitions of the notion of hierarchical incomplete ordered partitions and coverings of sets. The distance functions between hierarchical incomplete ordered partitions and coverings are defined. We present also algorithms of consensus determining for a finite set of hierarchical incomplete ordered partitions and coverings.               Keywords: consensus methods, hierarchical incomplete ordered partition and covering               Categories: E.1, H.2.1, I.2.11, I.2.4  
13|2||Consensus Determining with Dependencies of Attributes with Interval Values|  Michal Zgrzywa (Technical University of Wroclaw, Poland)  Abstract: In this paper the author considers some problems   related to attribute dependencies in consensus determining. These   problems concern the dependencies of attributes representing the   content of conflicts, which cause that one may not treat the   attributes independently in consensus determining. It is assumed   that attribute values are represented by intervals. In the paper the   author considers the choice of proper distance function. Next, the   limitations guarantying determining a correct consensus despite   treating the attributes independently are presented. Additionally,   the algorithm of calculating the proper consensus in cases when   these limitation are not met is introduced.               Keywords: agent, attribute dependency, conflict, consensus theory, distributed system               Categories: E.1, H.2.1, I.2.11, I.2.4  
13|3|http://www.jucs.org/jucs_13_3|New Advances in Reconfigurable Computing and its Applications|
13|3||The Use of Runtime Reconfiguration on FPGA Circuits to Increase the Performance of the AES Algorithm Implementation|  Oscar Pérez (Université Henri Poincaré I, France)   Yves Berviller (Université Henri Poincaré I, France)   Camel Tanougast (Université Henri Poincaré I, France)   Serge Weber (Université Henri Poincaré I, France)  Abstract: This article presents an architecture that   encrypts data with the AES algorithm. This architecture can be   implemented on the Xilinx Virtex II FPGA family, by applying   pipelining and dynamic total reconfiguration (DTR). The originality   of our implementation is that it computes sequentially in the FPGA   the Key and Cipher part of the AES algorithm. This dynamic   reconfiguration implementation allows a good optimization of logic   resources with a high throughput. This architecture employs only   11619 slices allowing a considerable economy of the resources and   reaching a maximum throughput of 44 Gbps.               Keywords: AES, FPGA, dynamic total reconfiguration, iterative looping, latency, pipeline, reconfiguration controller, reconfiguration time, registers, throughput, unrolling looping               Categories: B.2.2, B.3.3, B.4.4, D.4.8, E.3, E.4  
13|3||Real-time Architecture for Robust Motion Estimation under Varying Illumination Conditions|  Javier Díaz (University of Granada, Spain)   Eduardo Ros (University of Granada, Spain)   Rafael Rodriguez-Gomez (University of Granada, Spain)   Begoña del Pino (University of Granada, Spain)  Abstract: Motion estimation from image sequences is a   complex problem which requires high computing resources and is   highly affected by changes in the illumination conditions in most of   the existing approaches. In this contribution we present a high   performance system that deals with this limitation. Robustness to   varying illumination conditions is achieved by a novel technique   that combines a gradient-based optical flow method with a   non-parametric image transformation based on the Rank transform. The   paper describes this method and quantitatively evaluates its   robustness to different illumination changing patterns. This   technique has been successfully implemented in a real-time system   using reconfigurable hardware. Our contribution presents the   computing architecture, including the resources consumption and the   obtained performance. The final system is a real-time device capable   to computing motion sequences in real-time even in conditions with   significant illumination changes. The robustness of the proposed   system facilitates its use in multiple potential application   fields.               Keywords: optical flow, real-time image processing, reconfigurable devices (FPGAs), robust illumination systems               Categories: C.1.3, C.3, I.4.8, I.5.4  
13|3||Design and Implementation of the AMCC Self-Timed Microprocessor in FPGAs|  Susana Ortega-Cisneros (Universidad de Guadalajara, Mexico)   Juan Jóse Raygoza-Panduro (Universidad de Guadalajara, Mexico)   Alberto de la Mora Gálvez (Universidad de Guadalajara, Mexico)  Abstract: The development of processors with full custom technology has some disadvantages, such as the time used to design the processors and the cost of the implementation. In this article we used the programmable circuits FPGA such as an option of low cost for the development and implementation of Self-Timed (ST) systems. In addition it describes the architecture and the modules that compose the Asynchronous Microprocessor of Centralized Control (AMCC), and reviews the results of the occupation in the implementation of the FPGA.  The operation of this processor only requires of an external pulse to the input of the first asynchronous control block, and with this pulse the sequence of request-recognition of the control unit begins, that it activates the cycle search and it begins the process of execution of the instructions, without the need of having a clock feeding the system. Once concluded the program, the microprocessor stops and include inherently the stoppable clock feature; i.e., circuit is stopped if it is not required (minimal dynamic consumption). Until it is activated again by an external request signal.               Keywords: 4 phase protocol, FPGA, Virtex II, asynchronous microprocessor, self-timed               Categories: B.1.0, B.2.1, B.6.0, C.1.1  
13|3||Hardware Implementation of an Efficient Correlator for Interleaved Complementary Sets of Sequences|  María del Carmen Peréz (University of Alcala, Spain)   Jesús Ureña (University of Alcala, Spain)   Álvaro Hernández (University of Alcala, Spain)   Carlos De Marziani (University of Alcala, Spain)   Ana Jiménez (University of Alcala, Spain)   William P. Marnane (University College Cork, Ireland)  Abstract: Some sensor systems are characterized by multiple simultaneous aperiodic emissions, with low signal-to-noise ratio and asynchronous detection. In these systems, complementary sets of sequences can be used to encode emissions, due to their suitable auto-correlation and cross-correlation properties. The transmission of a complementary set can be accomplished by interleaving the sequences of the set, generating a macro-sequence which is easily transmitted by a BPSK modulation. The detection of the macrosequence can be performed by means of efficient correlation algorithms with a notably decreased computational load and hardware complexity. This work presents a new hardware design in configurable logic of an efficient correlator for macrosequences generated from complementary sets of sequences. A generic implementation has been achieved, so the configuration can be changed according to the requirements of the application. The developed correlator has been tested in an ultrasonic pulse compression system in which real-time is needed. However, it is applicable in any multi-sensor or communication system where the goal is to make simultaneous emissions from different independent sources, minimizing mutual interference.               Keywords: FPGA-based implementation, complementary sets of sequences, compression techniques, efficient correlation, ultrasonics               Categories: B.4.0, B.5.1, B.5.2  
13|3||A Dynamically and Partially Reconfigurable Implementation of the IDEA Algorithm Using FPGAs and Handel-C|  José M. Granado-Criado (University of Extremadura, Spain)   Miguel A. Vega-Rodríguez (University of Extremadura, Spain)   Juan M. Sánchez-Pérez (University of Extremadura, Spain)   Juan A. Gómez-Pulido (University of Extremadura, Spain)  Abstract: Nowadays, the information security has achieved a great importance, both when information is sent through a non-secure network (as the Internet) and when data are stored in massive storage devices. The cryptographic algorithms are used in order to guarantee the security of data sent or stored. A lot of research is being done in order to improve the performance of the current cryptographic algorithms, including the use of FPGAs. In this work we present an implementation of the IDEA cryptographic algorithm using reconfigurable hardware (FPGAs). In addition, in order to improve the performance of the algorithm, partial and dynamic reconfiguration has been used to implement our final circuit. This fact allows us to obtain a very high encryption speed (14.757 Gb/s), getting better results than those found in the literature.               Keywords: FPGA, IDEA, cryptography, partial and dynamic reconfiguration               Categories: C.4, E.3  
13|3||On Pipelining Sequences of Data-Dependent Loops|  Rui M. M. Rodrigues (INESC-ID/IST, Portugal)   João M. P. Cardoso (INESC-ID/IST, Portugal)  Abstract: Sequences of data-dependent tasks, each one   traversing large data sets, exist in many applications (such as   video, image and signal processing applications). Those tasks   usually perform computations (with loop intensive behavior) and   produce new data to be consumed by subsequent tasks. This paper   shows a scheme to pipeline sequences of data-dependent loops, in   such a way that subsequent loops can start execution before the   completion of the previous ones, which achieves performance   improvements. It uses a hardware scheme with decoupled and   concurrent data-path and control units that start execution at the   same time. The communication of array elements between two loops in   sequence is performed by special buffers with a data-driven,   fine-grained scheme. Buffer elements are responsible to flag the   availability of each array element requested by a subsequent loop   (i.e., a ready protocol is used to trigger the execution of   operations in the succeeding loop). Thus, the control execution of   following loops is also orchestrated by data availability (in this   case at the array element grain) and out-of-order produced-consumed   pairs are permitted. The concept has been applied using Nau, a   compiler infrastructure to map algorithms described in Java onto   FPGAs. This paper presents very encouraging results showing   important performance improvements and buffer size reductions for a   number of benchmarks.               Keywords: FPGAs, compilation,, hardware schemes, loop pipelining               Categories: B.1.2, B.5.2, B.7.2, C.1.2,, C.1.4, C.5.4, D.3.4  
13|3||Performance Evaluation and Limitations of a Vision   System on a Reconfigurable/Programmable Chip|  José Fernández-Pérez (Consejo Superior de Investigaciones Científicas (CSIC) and Universidad de Sevilla, Spain)   Francisco J. Sánchez-Fernández (Consejo Superior de Investigaciones Científicas (CSIC) and Universidad de Sevilla, Spain)   Ricardo Carmona-Galán (Consejo Superior de Investigaciones Científicas (CSIC) and Universidad de Sevilla, Spain)  Abstract: This paper presents a survey of the   characteristics of a vision system implemented in a   reconfigurable/programmable chip (FPGA). System limitations and   performance have been evaluated in order to derive specifications   and constraints for further vision system synthesis. The system   hereby reported has a conventional architecture. It consists in a   central microprocessor (CPU) and the necessary peripheral elements   for data acquisition, data storage and communications. It has been   designed to stand alone, but a link to the programming and debugging   tools running in a digital host (PC) is provided. In order to   alleviate the computational load of the central microprocessor, we   have designed a visual co-processor in charge of the low-level image   processing tasks. It operates autonomously, commanded by the CPU, as   another system peripheral. The complete system, without the sensor,   has been implemented in a single reconfigurable chip as a SOPC. The   incorporation of a dedicated visual co-processor, with specific   circuitry for low-level image processing acceleration, enhances the   system throughput outperforming conventional processing   schemes. However, time-multiplexing of the dedicated hardware   remains a limiting factor for the achievable peak computing   power. We have quantified this effect and sketched possible   solutions, like replication of the specific image processing   hardware.               Keywords: algorithms implemented in hardware, hardware architecture, image processing, implementation, system-on-a-programmable-chip               Categories: B.7.1, C.1.4, C.4, C.5.4, I.3.1, I.4.9  
13|4|http://www.jucs.org/jucs_13_4|Managing Editor's Column|
13|4||A Comparison of Various Methods for Computing Bounds for Positive Roots of Polynomials|  Alkiviadis G. Akritas (University of Thessaly, Greece)   Panagiotis S. Vigklas (University of Thessaly, Greece)  Abstract: The recent interest in isolating real roots of   polynomials has revived interest in computing sharp upper bounds on   the values of the positive roots of polynomials. Until now Cauchy's   method was the only one widely used in this   process. Ştefănescu's recently published theorem offers an   alternative, but unfortunately is of limited applicability as it   works only when there is an   even number of sign variations (or changes) in   the sequence of coefficients of the polynomial under   consideration. In this paper we present a more general theorem that   works for any number of sign variations provided   a certain condition is met. We compare the method derived from our   theorem with the corresponding methods by Cauchy and by Lagrange for   computing bounds on the positive roots of polynomials. From the   experimental results we conclude that it would be advantageous to   extend our theorem so that it works without any restrictive   conditions.               Keywords: positive roots, real root isolation, upper bounds               Categories: F.2.1, G.1.5  
13|4||Compile-time Computation of Polytime Functions|  Emanuele Covino (Università di Bari, Italy)   Giovanni Pani (Università di Bari, Italy)   Daniele Scrimieri (Università di Bari, Italy)  Abstract: We investigate the computational power of C++   compilers. In particular, it is known that any partial recursive   function can be computed at compile time, using the template   mechanism to de¯ne primitive recursion, composition, and   minimalization.  We show that polynomial time computable functions   can be computed at compile-time using the same mechanism, together   with template specialization.               Keywords: C++ templates, polytime computable functions, static computation               Categories: D.3, F.1.3  
13|4||Internet Payment System:  A New Payment System for Internet Transactions|  Zoran Đurić (University of Banjaluka, Bosnia and Herzegovina)   Ognjen Marić (University of Banjaluka, Bosnia and Herzegovina)   Dragan Gašević (Athabasca University, Canada)  Abstract: Payment systems need to address a number of   security issues in order to be an effective and secure means of   transferring payments across the Internet. To be accessible to a   wider audience, they also need to be easy to use for their end-users   (customers and merchants).  Trying to address these issues, we created the Internet Payment System (IPS). IPS tries to combine the advantages of several existing payment systems. While strong emphasis is made on the mobility and ease of use for its customers, IPS still retains strong security properties. It achieves privacy, integrity, authentication and non-repudiation by using different cryptographic algorithms and techniques. To demonstrate that the protocol satisfies the desired security properties, we use a recently proposed tool for formal verification, called AVISPA.               Keywords: cryptography, e-commerce, formal verification, payment systems, security               Categories: C.2.2, C.2.4, D.4.6, K.4.4, K.6.5  
13|4||Formal Representations of Learning Scenarios: A Methodology to Configure E-Learning Systems|  Denis Helic (Graz University of Technology, Austria)  Abstract: Nowadays, advanced E-Learning systems are generally pedagogy-aware. Commonly, these systems include facilities for defining so-called learning scenarios that reflect sophisticated pedagogical approaches such as collaborative writing or project-oriented learning. To support different learning activities from such scenarios the technological infrastructure of these systems must be appropriately adjusted and configured. Usually, this configuration process is laced with a number of difficulties. Most of these difficulties are caused by the fact that scenario capturing is achieved through informal user-developer dialogues. Typically, the result of such informal dialogues contains inconsistent and incomplete information because of misunderstandings and the complexity of the interactions within a scenario. Consequently, the configuration of the system is suboptimal and a number of iterations are required in order to achieve better results. In this paper an approach to improve this situation is presented. This approach is based on a general formal representation model for describing learning scenarios. A particular formal description of a concrete learning scenario is obtained through a user dialogue with a wizard tool. At the next step, this formal description might be automatically processed to facilitate configuration process. The paper is concluded with some experiences gained by applying this approach in two E-Learning projects.               Keywords: configuration, e-learning system, e-learning,, formal representation, learning scenario               Categories: H.1.0, H.4.0, M.0, M.3, M.7  
13|4||Mashups: Emerging Application Development Paradigm for a Digital Journal|  Narayanan Kulathuramaiyer (Graz University of Technology, Austria)  Abstract: The WWW is currently experiencing a   revolutionary growth due to its increasing participative community   software applications. This paper highlights an emerging application   development paradigm on the WWW, called mashup. As blogs have   enabled anyone to become a publisher, mashups stimulate web   development by allowing anyone to combine existing data to develop   web applications. Current applications of mashups include tracking   of events such as crime, hurricanes, earthquakes, meta-search   integration of data and media feeds, interactive games, and as an   organizer for web resources. The implications of this emerging web   integration and structuring paradigm remains yet to be explored   fully. This paper describes mashups from a number of angles,   highlighting current developments while providing sufficient   illustrations to indicate its potential implications. It also   highlights the role of mashups in complementing and enhancing   digital journals by providing insights into the quality academic   content, extent of coverage, and the enabling of expanded   services. We present pioneering initiatives for the Journal of   Universal Computer Science in our efforts to harness the collective   intelligence of a collaborative scholarly network.               Keywords: Web 2.0, mashups, visualisation               Categories: H.3.4, H.3.5, H.3.7, H.4.3, H.5.1, M.1, M.7, M.8  
13|4||A Cultural Information System Providing e-commerce Web Services, Digital Rights Management and Copyright Protection|  Dimitrios K. Tsolis (University of Patras, Greece)   Spyros Sioutas (Ionian University, Greece)   Lambros Drossos (Technological Institute of Messolongi, Greece)   Theodore S. Papatheodorou (University of Patras, Greece)  Abstract: The issue addressed in this paper focuses on the   design and implementation of an advanced information system for   Cultural Organizations, which serves as a platform for the   exploitation through e-Commerce web services and, in parallel, the   protection of copyright and digital rights management of the   cultural content. The main components of the information system are:   (a) Digital Image Library, which offers specialized services, (b)   copyright protection and digital rights management of digitized   material and (c) the E-Commerce web services, supported by advanced   technologies, for the proper exploitation of the digital cultural   content. The work described in this contribution focuses on   digitized material of Cultural Heritage and is deployed at several   cultural organizations.               Keywords: copyright protection, digital rights management, e-commerce applications, integrated information system, licensing, metadata, usable user interfaces, watermarking, web services               Categories: H.4.0, H.5.0, H.5.1  
13|4||Random k-GD-Sat Model and its Phase Transition|  Milena Vujošević-Janičić (University of Belgrade, Serbia)   Jelena Tomašević (University of Belgrade, Serbia)   Predrag Janičić (University of Belgrade, Serbia)  Abstract: We present a new type of sat problem called the   k-GD-SAT, which generalizes   k-sat and GD-sat. In k-GD-SAT,   clause lengths have geometric distribution, controlled by a   probability parameter p; for p   = 1, a k-GD-SAT problem is a   k-SAT problem. We report on the phase transition   between satisfiability and unsatisfiability for randomly generated   instances of k-GD-SAT. We provide theoretical   analysis and experimental results suggesting that there is an   intriguing relationship (linear in the parameter   1/p) between crossover points for different   parameters of k-GD-SAT. We also consider a   relationship between crossover points for k-SAT   and k-GD-SAT and provide links between these   values.               Keywords: npcomplete problems, phase transition, propositional satisfiability, random sat problems               Categories: F.2.2, F.4.1, I.6.4  
13|5|http://www.jucs.org/jucs_13_5|Managing Editor's Column|
13|5||Formal MethodsGuest Editorial|  Richard Banach (University of Manchester, United Kingdom)  Abstract: This introductory paper gives some historical   background to the emergence of formalmethods, overviews what   subsequently happened, and surveys prospects for the future. Brief   introductions to the remaining papers in the Special Issue are   given.               Keywords: formal methods               Categories: B.2, D.2.4, F.3.1  
13|5||Software Is More Than Code|  Sriram K. Rajamani (Microsoft Research, India)  Abstract: This paper reviews the current practice of   software engineering and outlines someprospects for developing a   more holistic and formally grounded approach.               Keywords: formal methods, software engineering               Categories: D.2.4, F.3.1  
13|5||Formal Methods for Specifying, Validating, and Verifying Requirements|  Constance L. Heitmeyer (Naval Research Laboratory, USA)  Abstract: This paper describes the specification, validation and verification of system and soft-ware requirements using the SCR tabular method and tools. An example is presented to illustrate the SCR tabular notation, and an overview of each of the ten tools in the SCR toolset is presented.               Keywords: SCR toolset, formal methods, requirements               Categories: D.2.4, F.3.1  
13|5||Formal Methods: Theory Becoming Practice|  Jean-Raymond Abrial (ETHZ, Switzerland)  Abstract: This paper gives a tutorial introduction to the   ideas behind system development usingthe B-Method. Properly handled,   the crucial relationship between requirements and formal model leads   to systems that are correct by construction. Some industrial   successes are outlined.               Keywords: B-method, formal methods               Categories: D.2.4, F.3.1  
13|5||Floating-Point Verification|  John Harrison (Intel Corporation, USA)  Abstract: This paper overviews the application of formal   verification techniques to hardware ingeneral, and to floating-point   hardware in particular. A specific challenge is to connect the usual   mathematical view of continuous arithmetic operations with the   discrete world, in a credible andverifiable way.               Keywords: formal methods, hardware verification               Categories: B.2, F.3.1  
13|5||Model Checking: Software and Beyond|  Edmund M. Clarke (Carnegie Mellon University, USA)   Flavio Lerda (Carnegie Mellon University, USA)  Abstract: This paper introduces model checking, originally   conceived for checking finite statesystems. It surveys its evolution   to encompass finitely checkable properties of systems with unbounded   state spaces, and its application to software and other   systems.               Keywords: formal methods, model checking               Categories: B.2, D.2.4, F.3.1  
13|5||Automated Formal Methods Enter the Mainstream|  John Rushby (SRI International, USA)  Abstract: This paper outlines the emergence of formal   techniques, explaining why they wereslow to take on an industrially   acceptable form. The contemporary scene, in which formal techniques   are increasingly packaged within tools usable by a wide variety of   engineers, is reviewed,as are the promising prospects for the   future.               Keywords: formal methods               Categories: B.2, D.2.4, F.3.1  
13|5||The Verification Grand Challenge|  Jim Woodcock (University of York, United Kingdom)   Richard Banach (University of Manchester, United Kingdom)  Abstract: This paper overviews the Verification Grand Challenge, a large scale multinationalintiative designed to significantly increase the interoperability, applicability and uptake of formal development techniques. Results to date are reviewed, and next steps are outlined.               Keywords: Verification Grand Challenge, formal methods               Categories: B.2, D.2.4, F.3.1  
13|5||Realising the Benefits of Formal Methods|  Anthony Hall (Independent Consultant, United Kingdom)  Abstract: This paper surveys the whys, and the wherefores of using formal methods in an industrial context. Evidence is presented that the benefits of using formal techniques, though not an automatic consequence of their adoption, can be considerable.               Keywords: correctness by construction, formal methods               Categories: D.2.4, F.3.1  
13|6|http://www.jucs.org/jucs_13_6|Selected Papers from SBLP 2007: The 11th Brazilian  Symposium on Programming Languages|
13|6||CML: C Modeling Language|  Frederico de Oliveira Jr. (Pernambuco State University, Brazil)   Ricardo Lima (Pernambuco State University, Brazil)   Marcio Cornelio (Pernambuco State University, Brazil)   Sergio Soares (Pernambuco State University, Brazil)   Paulo Maciel (Federal University of Pernambuco, Brazil)   Raimundo Barreto (Federal University of Pernambuco, Brazil)   Meuse Oliveira Jr. (Federal University of Pernambuco, Brazil)   Eduardo Tavares (Federal University of Pernambuco, Brazil)  Abstract: Non-functional requirements such as performance,   program size, and energy consumption significantly affect the   quality of software systems. Small devices like PDAs and mobile   phones have little memory, slow processors, and energy   constraints. The C programming language has been the choice of many   programmers when developing application for small devices. On the   other hand, the need for functional software correctness has derived   several specification languages that adopt the Design by Contract   (DBC) technique. In this work we propose a specification language   for C, called CML (C Modeling Language), focused on non-functional   requirements. CML is inspired on the Design By Contract   technique. An additional contribution is a verification tool for   hard real-time systems. The tool is the first application developed   for CML. The practical usage of CML is presented through a case   study, which is a real application for a vehicle monitoring   system.               Keywords: c programming language, non-functional requirements, specification language               Categories: D.2.1, D.2.4, D.3.3  
13|6||Constraint Programming Architectures: Review and a New Proposal|  Jacques Robin (Universidade Federal de Pernambuco (CIn-UFPE), Brazil)   Jairson Vitorino (Universidade Federal de Pernambuco (CIn-UFPE), Brazil)   Armin Wolf (Fraunhofer Institut, Germany)  Abstract: Most automated reasoning tasks with prac tical   applications can be automatically reformulated into a constraint   solving task. A constraint programming platform can thus act as a   unique, underlying engine to be reused for mu ltiple automated   reasoning tasks in intelligent agents and systems. We identify six   key requirements for such platform: expressive task modeling   language, rapid solving method custom ization and combination,   adaptive solving method, user-friendly solution explanation,   efficient execution, and seamless integration within larger systems   and practical applications. We then propose a novel, model-driven,   component and rule-based architecture for such a platform that   better satisfies as a whole this set of requirements than those of   currently available platforms.               Keywords: constraint programming, model-driven architecture, software reuse               Categories:  D.2.11, D.1.6, D.2.13, I.2.3, I.2.4, I.2.5, I.2.8  
13|6||Logic Programming for Verification of Object-Oriented Programming Law Conditions|  Leandro de Freitas (Universidade de Pernambuco, Brazil)   Marcel Caraciolo (Universidade de Pernambuco, Brazil)   Márcio Cornélio (Universidade de Pernambuco, Brazil)  Abstract: Programming laws are a means of stating properties of programming con-structs and resoning about programs. Also, they can be viewed as a program transformation tool, being useful to restructure object-oriented programs. Usually the appli-cation of a programming law is only allowed under the satisfaction of side-conditions. In this work, we present how the conditions associated to object-oriented program-ming laws are checked by using Prolog. This is a step towards a tool that allows user definable refactorings based on the application of programming laws.               Keywords: logic programming, programming law conditions, refactoring               Categories: D.1.5,, D.1.6, D.2.6  
13|6||A Methodology for Removing LALR(k) Conflicts|  Leonardo Teixeira Passos (Federal University of Minas Gerais, Brazil)   Mariza A. S. Bigonha (Federal University of Minas Gerais, Brazil)   Roberto S. Bigonha (Federal University of Minas Gerais, Brazil)  Abstract: Despite all the advances brought by LALR parsing   method by DeRemer in the late 60's, conflicts reported by LALR   parser generators are still removed in an old fashion and primitive   manner, based on analysis of a huge amount of textual and low-level   data stored on a single log file. For the purpose of minimizing the   effort and time consumed in LALR conflict removal, which is   definitely a laborious task, a methodology is proposed, along with   the set of operations necessary to its realization. We also present   a tool and the ideas behind it to support the methodology, plus its   plugin facility, which permits the interpretation of virtually any   syntax specification, regardless of the specification language   used.               Keywords: conflicts, lalr parsing,, methodology               Categories: D.3.4, F.4.2  
13|6||Optimized Compilation of Around Advice for Aspect Oriented Programs|  Eduardo S. Cordeiro (Universidade Federal de Minas Gerais, Brazil)   Roberto S. Bigonha (Universidade Federal de Minas Gerais, Brazil)   Mariza A. S. Bigonha (Universidade Federal de Minas Gerais, Brazil)   Fabio Tirelo (Universidade Federal de Minas Gerais, Brazil)  Abstract: The technology that supports Aspect-Oriented   Programming (AOP) tools is inherently intrusive, since it changes   the behavior of base application code. Advice weaving performed by   AspectJ compilers must introduce crosscutting behavior defined in   advice into Java programs without causing great performance   overhead. This papershows the techniques applied by the   ajc and abc AspectJ compilers   for around advice weaving, and identifies problems in code they   produce. The problems analyzed are advice and shadow   implementation repetition and context variable   repetition. Performance gain provided by solving these   problems is discussed, showing that bytecodesize, running time and   memory consumption can be reduced by these optimizations. It is   assumed that the reader is familiar with AOP and AspectJ   constructs.               Keywords: advice weaving, aspect-oriented programming, optimized compilation               Categories: D.3.4  
13|6||A Visual Language for Animated Simulation|"  Vladimir O. Di Iorio (Universidade Federal de Viçosa, Brazil)   Débora P. Coura (Centro Universitário do Leste de Minas Gerais, Brazil)   Leonardo V.S. Reis (Universidade Federal de Viçosa, Brazil)   Marcelo Oikawa (Universidade Federal de Viçosa, Brazil)   Carlos R.M. Junior (Universidade Federal de Viçosa, Brazil)  Abstract: This paper presents a visual language for   producing animated simulations. The language is implemented on a   tool called Tabajara Animator, using principles   of Programming By Demonstration (PBD), which is a   technique for teaching the computer new behaviour by demonstrating   actions on concrete examples. The language is based on a formal   model for concurrent update of agents, which represent the animated   characters. The visual rules follow the ""before-after"" style,   adopted by the most important similar tools. New features discussed   by this work may produce a significant reduction on the number of   required rules for producing animated simulations. This paper shows   how these new features are implemented on a visual user-friendly   interface, and how they are translated into structures of the formal   model adopted.               Keywords: programming by demonstration, visual programming               Categories: D.1.7  "
13|6||RE-AspectLua - Achieving Reuse in AspectLua|  Thaís Batista (Federal University of Rio Grande do Norte, Brazil)   Maurício Vieira (Federal University of Rio Grande do Norte, Brazil)  Abstract: AspectLua is a Lua-based dynamic aspect-oriented   language that follows the original AspectJ concepts. It suffers from   the same problem of AspectJ-like languages with regard to   limitations in terms of aspect reusability, modularity and   heterogeneous interaction. In this paper we propose RE-AspectLua, a   new version of AspectLua that combines aspect interfaces with   abstract joinpoints and the use of a connection language, the Lua   language, to instantiate, at application composition time, the   abstract joinpoints. Thus, the connection language defines the   composition of reusable aspects with base code. Using these concepts   RE-AspectLua intends to break away from the syntactically manifest   coding of aspects in which joinpoints are hard-coded into aspects,   thereby promoting general reusability and the heterogeneous   composition of an aspect with different base codes. In order to   illustrate RE-AspectLua concepts we present two case studies.               Keywords: AOP, Lua, dynamic aspects, heterogeneity, reusability               Categories: D.2.3, D.3.3  
13|6||Programming through Spreadsheets and Tabular Abstractions|  Carlos Henrique Q. Forster (Instituto Tecnológico de Aeronáutica, Brazil)  Abstract: The spreadsheet metaphor has, over the years,   proved itself valuable for the definition and use of computations by   non-programmers. However, the computation model adopted in   commercial spreadsheets is still limited to non-recursive   computations and lacks abstraction mechanisms that would provide   modularization and better reuse (beyond copy and paste). We   investigate these problems by identifying a minimal set of   requirements for recursive computations, designing a   spreadsheet-based language with an abstraction definition mechanism,   prototyping an interpreter and evaluating it with   examples.               Keywords: abstraction, call-by-need, end-user programming, lazy structures, recursion, spreadsheet languages               Categories: D.1.1, D.1.7, D.2.6, D.3.3, F.1.1, H.1.2  
13|6||A New Architecture for Concurrent Lazy Cyclic Reference Counting on Multi-Processor Systems|  Andrei de Araújo Formiga (Universidade Federal de Pernambuco, Brazil)   Rafael Dueire Lins (Universidade Federal de Pernambuco, Brazil)  Abstract: Multi-processor systems have become the standard   in current computer architectures. Software developers have the   possibility to take advantage of the additional computing power   available to concurrent programs. This paper presents a way to   automatically use additional processors, by performing memory   management concurrently. A new architecture with little explicit   synchronization for concurrent lazy cyclic reference counting is   described. This architecture was implemented and preliminary   performance tests point at significant efficiency improvements over   the sequential counterpart.               Keywords: concurrent garbage collection, garbage collection, memory management, reference counting               Categories: D.1.3, D.3.4  
13|6||Cyclic Reference Counting with Permanent Objects|  Rafael Dueire Lins (Universidade Federal de Pernambuco, Brazil)   Francisco Heron de Carvalho Junior (Universidade Federal do Ceará, Brazil)   Zanoni Dueire Lins (Universidade Federal de Pernambuco, Brazil)  Abstract: Reference Counting is the memory management   technique of most widespread use today. Very often applications   handle objects that are either permanent or get tenured. This paper   uses this information to make cyclic reference counting more   efficient.               Keywords: cyclic graphs, garbage collection, memory management, permanent objects, reference counting, tenured objects               Categories: D.4.2  
13|6||C APIs in Extension and Extensible Languages|  Hisham Muhammad (Pontifícia Universidade Católica do Rio de Janeiro (PUC-RIO), Brazil)   Roberto Ierusalimschy (Pontifícia Universidade Católica do Rio de Janeiro (PUC-RIO), Brazil)  Abstract: Scripting languages are used in conjuction with   C code in two ways: as extension languages, where the interpreter is   embedded as a library into an application; or as extensible   languages, where the interpreter loads C code as add-on   modules. These two scenarios share many similarities, as in both of   them two-way communication of code and data needs to take   place. However, the differences between them impose design tradeoffs   that affect the C API that bridges the two languages, often making a   scripting language more suitable for extending than embedding, or   vice-versa. This paper discusses how these tradeoffs are handled in   the APIs of popular scripting languages, and the impact on their use   as embedded or extensible languages.               Keywords: application programming interfaces, programming languages               Categories: D.3.2, D.3.4  
13|6||Higher-Order Lazy Functional Slicing|  Nuno F. Rodrigues (Universidade do Minho, Portugal)   Luís S. Barbosa (Universidade do Minho, Portugal)  Abstract: Program slicing is a well known family of techniques intended to identify and isolate code fragments which depend on, or are depended upon, specific program entities. This is particularly useful in the areas of reverse engineering, program understanding, testing and software maintenance. Most slicing methods, and corresponding tools, target either the imperative or the object oriented paradigms, where program slices are computed with respect to a variable or a program statement.Taking a complementary point of view, this paper focuses on the slicing of higher-order functional programs under a lazy evaluation strategy. A prototype of a Haskell slicer, built as proof-of-concept for these ideas, is also introduced.               Keywords: functional programming, program analysis, program slicing               Categories: D.1.1, I.2.2, I.2.4  
13|6||Open and Closed Worlds for Overloading: a Definition and Support for Coexistence|  Carlos Camarão (Universidade Federal de Minas Gerais, Brazil)   Cristiano Vasconcellos (Universidade Federal de Ouro Preto, Brazil)   Lucília Figueiredo (Universidade Federal de Ouro Preto, Brazil)   João Nicola (Universidade Federal de Minas Gerais, Brazil)  Abstract: The type system of Haskell and some related   systems are based on an open world approach for overloading. In an   open world, the principal type of each overloaded symbol must be   explicitly annotated (in Haskell, annotations occur in type class   declarations) and a definition of an overloaded symbol is required   to exist only when overloading is resolved. In a closed world, on   the other hand, each principal type is determined according to the   types of definitions that exist in the relevant context and,   furthermore, overloading resolution for an expression considers only   the context of the definition of its constituent symbols. In this   paper we formally characterize open and closed worlds, and discuss   their relative advantages. We present a type system that supports   both approaches together, and compare the defined system with   Haskell type classes extended with multi-parameter type classes and   functional dependencies. We show in particular that functional   dependencies are not necessary in order to support multi-parameter   type classes, and present an alternative route.               Keywords: closed and open world approaches for overloading, constrained polymorphism, type inference, type system               Categories: D.3.1, D.3.3  
13|6||Using Visitor Patterns in Object-Oriented Action Semantics|  André Murbach Maidl (Federal University of Paraná, Brazil)   Cláudio Carvilhe (Federal University of Paraná, Brazil)   Martin A. Musicante (Federal University of Rio Grande do Norte, Brazil)  Abstract: Object-Oriented Action Semantics is a semantic   framework for the definition of programming languages. The framework   incorporates some object-oriented concepts to the Action Semantics   formalism. Its main goal is to obtain more readable and reusable   semantic specifications. ObjectOriented Action Semantics provides   support for the definition of syntax-independent specifications, due   to the way its classes are written. In a previous work, a library of   classes (called LFL) was developed to improve specification reuse   and to provide a way to describe semantic concepts, independent from   the syntax of the programming language. This paper aims to address   some problematic aspects of LFL, and presents a case study, where a   specification is built by using the Visitor Pattern technique. The   use of this pattern allows a clear separation between the syntax of   a programming language and its different semantic   aspects.               Keywords: action semantics, formal semantics, object-oriented               Categories: D.1.5, F.3.2  
13|7|http://www.jucs.org/jucs_13_7|Computers in Education: New Developments in  e-Learning Technology|
13|7||A First Step Mapping IMS Learning Design and Moodle|  Daniel Burgos (Open University of the Netherlands, The Netherlands)   Colin Tattersall (Open University of the Netherlands, The Netherlands)   Martin Dougiamas (Open University of the Netherlands, The Netherlands)   Hubert Vogten (Open University of the Netherlands, The Netherlands)   Rob Koper (Open University of the Netherlands, The Netherlands)  Abstract: Mapping the specification IMS Learning Design   and the Course Management System Moodle is a logical step forward on   interoperability between eLearning systems and specifications in   order to increase the best acceptance of the specifications into the   widespread world of the eLearning systems and to ensure the   standardization of the outputs from the systems to be used in   others. IMS Learning Design and Moodle look for a common   understanding focused on the integration of information packages   modelled by each part in the other. The final goal aims at Moodle   playing an IMS LD package. A second step will map a Moodle course to   be used in any IMS LD complaint tool. The Unit of Learning in IMS LD   and the course in Moodle become the perfect couple where to find   several elements that should match each other. This paper shows how   to make this understanding, mapping related elements in both to get   a list of pairs easy to translate from one to another, and to define   also a list of requirements for this protocol.               Keywords: IMS Learning Design, Integration, Mapping, Moodle               Categories: D.2.1, D.2.12, H.4.2, M.0, M.4  
13|7||A WebQuest Framework to Improve the Study of Deadlock and Process Synchronization|  Luis Panizo (Universidad de León, Spain)   Ramón-Ángel Fernández (Universidad de León, Spain)   Lidia Sánchez (Universidad de León, Spain)  Abstract: The impact of the Internet on Society also   affects learning at University. Students use not only printed books   and their own notes, but also the information available on the   Net. WebQuests are learning tools that help the students use the   Internet, but under the supervision of the lecturer, who has   previously selected the most interesting sites to visit. An   experience of using WebQuests with first year Computer Science   students is shown, as well as the good results obtained both in the   improvement of examination results and in the positive attitude of   the students when using WebQuests.               Keywords: WebQuests, e-learning, education technologies               Categories: H.3.5, K.3.1, K.3.2  
13|7||Supporting the Authoring and Operationalization of Educational Modelling Languages|  Iván Martínez-Ortiz (Complutense University of Madrid, Spain)   Pablo Moreno-Ger (Complutense University of Madrid, Spain)   José Luis Sierra-Rodríguez (Complutense University of Madrid, Spain)   Baltasar Fernández-Manjón (Complutense University of Madrid, Spain)  Abstract: The modelling of educational processes and their   operational support is a key aspect in the construction of more   effective e-learning applications. Instructional models are usually   described by means of an educational modelling language (EML). The   EML used can be one of the available standards (e.g. IMS Learning   Design), the customization of a standard to meet a specific   application profile, or even a domain-specific EML specifically   designed to better fit the very particular needs of a learning   scenario. In this paper we present , a general authoring and   operationalization architecture capable of dealing with all these   possibilities in a highly modular and flexible way. We also outline   a specific implementation of  based on standard XML   technologies and workflow management systems, and we describe how   this implementation can be used to support IMS Learning   Design.               Keywords: IMS LD, authoring, graphical notation, learning design, units of learning               Categories: K.3.1, K.3.2, M.4  
13|7||Collaborative Composition in a Foreign Language with Handheld Computing and Web Tools|  Maximiliano Paredes (Rey Juan Carlos University, Spain)   Pedro Pablo Sánchez-Villalón (University of Castilla - La Mancha, Spain)   Manuel Ortega (University of Castilla - La Mancha, Spain)   J. Ángel Velázquez-Iturbide (Rey Juan Carlos University, Spain)  Abstract: Writing applications are currently designed for   desktop personal computers. Mobile devices like PDAs or smart phones   are increasingly being used for mobile applications such as access   to information sources or local work on the device, but they are   seldom used for collaborative tasks.  Here we present AULA and AWLA,   two applications that put mobile devices and collaborative   educational environments together inside and outside the   classroom. They are designed under the paradigm of collaborative   composition writing in language learning courses, in particular   English as a Foreign Language (EFL).               Keywords: collaborative learning, mobile computing, pervasive computing, synchronous interaction               Categories: H.5.2, H.5.3, K.3.1, M.0, M.1, M.6  
13|7||Pipeline-scheduling Simulator for Educational Purpose|  José M. Chaves-González (University of Extremadura, Spain)   Miguel A. Vega-Rodríguez (University of Extremadura, Spain)   Juan A. Gómez-Pulido (University of Extremadura, Spain)   Juan M. Sánchez-Pérez (University of Extremadura, Spain)  Abstract: This paper presents a project that provides both, to professors and to students, a tool that is useful for studying, teaching and learning how pipelines work and how they can be scheduled in an easy and widespread way. The project is called PipeSim, and features static and dynamic pipelines with a very attractive, dynamic and intuitive interface. It is well known that pipeline and pipeline-scheduling are very relevant concepts in computer science studies and it is very important that students can learn these in an easy and reliable way. The simulator makes easy both working in depth about pipeline scheduling and working slowly paying attention in the different stages of the scheduling. However, we designed the simulator knowing that principal users would be students with no experience, so both the execution and the presentation of the results have been carefully developed. In addition to this, to check the success of PipeSim, a survey has been made among some students that used the simulator. Results reveal that this kind of applications has a great acceptance among students, thought they consider that simulators are complements to the lessons given by the professor and never a substitute for them.               Keywords: collision vector, delay insertion, educational simulator, forbidden latency list, pipeline, pipeline scheduling, reservation table, state diagram               Categories: B.2.1, B.2.2, B.4.4, C.1.1, C.1.2, H.5.2, K.3.1, M.0  
13|7||Improving LO Quality through Instructional Design Based on an Ontological Model and Metadata|  Erla M. Morales (University of Salamanca, Spain)   Francisco J. García-Peñalvo (University of Salamanca, Spain)   Ángela Barrón (University of Salamanca, Spain)  Abstract: The activities developed in this paper were aimed at providing an awareness of the elements that should be considered in quality learning objects instructional design for e-learning systems. We thus propose our own LO definition taking into account aggregation level number 2. On this basis, we analyze cognitive theories for promoting learning and we explain issues relating to the LO characteristics that help to improve their quality for suitable management. To achieve this we propose an instructional design based on an ontological model which explains the relationship between the instructional design elements and a specific classification to improve their management.               Keywords: instructional design, learning objects, ontology, quality               Categories: H.1.1, H.3.1, H.3.3, J.1, M.4  
13|7||Supporting the Modeling of Flexible Educational Units PoEML: A Separation of Concerns Approach|  Manuel Caeiro-Rodríguez (University of Vigo, Spain)   Maria José Marcelino (University of Coimbra, Portugal)   Martín Llamas-Nistal (University of Vigo, Spain)   Luis Anido-Rifón (University of Vigo, Spain)   António José Mendes (University of Coimbra, Portugal)  Abstract: Educational Modeling   Languages (EMLs) have been proposed to support the   modeling of educational units. Currently, there are some EML   proposals devoted to provide a computational base, enabling the   software processing and execution of educational units' models. In   this context, flexibility is a key requirement in order to support   alternatives and changes . This paper presents a   Perspective-oriented Educational Modeling Language (PoEML)   that simplifies and facilitates the modeling of alternatives and the   performance of changes. The key point of the proposal is the   separation of the modeling in several concerns that can be managed   almost independently. As a result, changes at each concern can be   performed without affecting to other concerns, or affecting in   controlled ways.               Keywords: educational modeling language, flexibility, separation of concerns               Categories: D.3.2, K.3.1, M.4  
13|7||"A Framework for the Conceptualization of Approaches to ""Create-by-Reuse"" of Learning Design Solutions"|  Davinia Hernández-Leo (University of Valladolid, Spain)   Andreas Harrer (University of Duisburg-Essen, Germany)   Juan Manuel Dodero (University Carlos III of Madrid, Spain)   Juan I. Asensio-Pérez (University of Valladolid, Spain)   Daniel Burgos (Open University of the Netherlands, The Netherlands)  Abstract: IMS Learning Design (IMS LD) is an interoperable   and standardized language that enables the computational   representation of Units of Learning (UoLs). However, its adoption   and extensive use in real practice largely depends on the extent to   which teachers can design and author their own UoLs according to the   requirements of their educational situations. Many of the proposed   design processes for facilitating the creation of UoLs are based on   the reuse of complete or non-complete learning design solutions at   different levels of granularity. This paper introduces a comparison   framework that conceptually analyzes and classifies reusable   learning design solutions and processes that drive the creation of   ready-to-run UoLs. The framework provides a comprehensible   representation of such processes and units of reuse over two   dimensions, namely granularity and completeness. It also offers a   frame for discussing issues, such as the proper level of reuse, of   existing and forthcoming proposals. Finally, it opens the path to   other strands for future research such as providing language   independence of learning designs or proposing approaches for the   selection of the reusable solutions.               Keywords: conceptual framework, educational modelling languages, interoperability, learning design processes, reusable units of learning               Categories: D.2.12, D.2.13, H.1.0, K.3.1, M.4, M.8  
13|7||Creating Online Graduate Engineering Degrees at the University of New Mexico|  Gregory L. Heileman (University of New Mexico, USA)   Chaouki T. Abdallah (University of New Mexico, USA)   Wei Shu (University of New Mexico, USA)   Christos G. Christodoulou (University of New Mexico, USA)   Debby Knotts (New Media & Extended Learning University of New Mexico, USA)  Abstract: This paper describes the motivation, strategies,   and implementation details that lead to the creation of online   graduate-level degree programs in the Department of Electrical &   Computer Engineering at the University of New Mexico. It also   presents some of the benefits as well as the challenges encountered   when designing and implementing these programs. The paper concludes   with a discussion of lessons learned and the future directions of   the program.               Keywords: WebCT, graduate education, online degree               Categories: H.4.3, K.3.1  
13|7||HME: a Handheld Model Editor for Educational Contexts|  Maria José Marcelino (Universidade de Coimbra, Portugal)  Abstract: Handheld devices are becoming more and more popular in education. Educational simulation and modelling are not new soil, but for handhelds they are still much under explored. Due to the difficulties teachers usually face in developing computer models and simulations and the lack of adequate tools for building them, we developed an authoring-tool for handheld educational simulation and modelling, called Sim-H (SIMulation for Handhelds). Sim-H is made by several modules each one relating to a type of simulation application that can be used in an educational context. One of these modules, that we describe thoroughly herein, is the Handheld Model Editor, a modelling tool for handheld devices that can be used to build models to use as such or as the core of educational handheld simulations.               Keywords: authoring-tools, handheld devices, modelling, simulation               Categories: K.3  
13|7||Designing Collaborative Learning Environments Using Digital Games|  César A. Collazos (Universidad del Cauca, Colombia)   Luis A. Guerrero (Universidad de Chile, Chile)   José A. Pino (Universidad de Chile, Chile)   Sergio F. Ochoa (Universidad de Chile, Chile)   Gerry Stahl (Drexel University, USA)  Abstract: Collaborative learning environments require carefully crafted designs — both technical and social. This paper presents a model describing how to design socio-technical environments that will promote collaboration in group activities. A game was developed based on this model. This tool was used to conduct experiments for studying the collaborative learning process. Testing with this system revealed some strengths and weaknesses, which are being addressed in the on-going research.               Keywords: CSCL, collaborative games, collaborative learning, model design               Categories: K.3, K.3.1, K.3.2  
13|7||Mapping Academic Collaboration Networks: Perspectives from the First Year of the Reusable Learning Objects CETL|  Raquel Morales (University of Cambridge, United Kingdom)   Patrick Carmichael (University of Cambridge, United Kingdom)  Abstract: The 'Reusable Learning Objects' Centre   for Excellence in Teaching and Learning (RLO-CETL) is a five-year   project (2005-2010) involving staff from three universities (London   Metropolitan, Cambridge University and the University of Nottingham)   in a collaborative programme of development, deployment and   evaluation of a range of multimedia learning objects that can be   stored in repositories, accessed over the Web, and integrated into   course delivery. One of the goals of the RLO-CETL is to provide   sustainable and reproducible processes that will allow sector-wide   collaboration, so as part of the internal formative evaluation of   the RLO-CETL, we are concerned to analyse its character, boundaries   and evolution, and how this develops in relation to individual and   institutional contexts, priorities, structures. In this paper, we   present some of the results of 'mapping' tasks in which   twenty-eight participants (who included lecturers, tutors, students,   multimedia developers, administrators, evaluators and managers)   represented and talked about the networks of people with whom they   communicated. There are aspects of the maps that indicate how the   network of the RLO-CETL interacts and overlaps with institutional   and individual networks.               Keywords: evaluation/methodology, human factors, network communications               Categories: K.3, K.3.m, M.4, M.8  
13|8|http://www.jucs.org/jucs_13_8|Atomicity: A Unifying Concept in Computer Science|
13|8||Dedication to Jim Gray|
13|8||Improving Program Correctness with Atomic Exception Handling|  Christof Fetzer (TU Dresden, Germany)   Pascal Felber (University of Neuchâtel, Switzerland)  Abstract: Exception handling is a powerful mechanisms for   dealing with failures at runtime. It simplifies the development of   robust programs by allowing the programmer to implement recovery   actions and tolerate non-fatal errors. Yet, exception handling is   difficult to get right!  The complexity of correct exception   handling is a major cause for incorrect exception handling. It is   therefore important to reduce the complexity of writing exception   handling code while, at the same time, making sure it is   correct. Our approach is to use atomic blocks for exception handling   combined with optional compensation actions.               Keywords: exception handling, transactional memory               Categories: D.2.m, D.3.3  
13|8||Specification and Refinement of Access Control|  Dominique Méry (Nancy University & LORIA, France)   Stephan Merz (INRIA Nancy & LORIA, France)  Abstract: We consider the extension of fair event system   specifications by concepts of access control (prohibitions, user   rights, and obligations). We give proof rules for verifying that an   access control policy is correctly implemented in a system, and   consider preservation of access control by refinement of event   systems. Prohibitions and obligations are expressed as properties of   traces and are preserved by standard refinement notions of event   systems. Preservation of user rights is not guaranteed by   construction; we propose to combine implementation-level user rights   and obligations to implement high-level user rights.               Keywords: access control, event systems, refinement               Categories: D.2.4, F.3.1  
13|8||Achieving Atomicity for Web Services Using Commutativity of Actions|  P. Michael Melliar-Smith (University of California, USA)   Louise E. Moser (University of California, USA)  Abstract: Web Services enable the creation of complex business activities through the cooperation of independently developed software programs. However, Web Services incur the risk of long delays and locked data when using the classical distributed transaction strategy, and the risk of inconsistency when using the compensating transactions strategy. If the benefits of Web Services are to be fully realized, a better strategy must be employed. In this paper we describe an extended transactions strategy that can be used in conjunction with existing Web Services infrastructures, and that is compatible with existing business practices. The strategy exploits local transactions and commutativity of local actions at each data item to achieve global atomicity for business activities.               Keywords: atomicity, commutativity, concurrency control, distributed transactions, web services               Categories: H.2.1  
13|8||On the Use of a Reflective Architecture to Augment Database Management Systems|  Nuno Carvalho (Universidade de Lisboa, Portugal)   Alfranio Correia Jr. (Universidade do Minho, Portugal)   José Pereira (Universidade do Minho, Portugal)   Luís Rodrigues (Instituto Superior Técnico/INESC-ID, Portugal)   Rui Oliveira (Universidade do Minho, Portugal)   Susana Guedes (Universidade de Lisboa, Portugal)  Abstract: The Database Management System (DBMS) used to be   a commodity software component, with well known standard interfaces   and semantics. However, the performance and reliability expectations   being placed on DBMSs have increased the demand for a variety   add-ons, that augment the functionality of the database in a wide   range of deployment scenarios, offering support for features such as   clustering, replication, and self-management, among others. A well   known software engineering approach to systems with such   requirements is reflection. Unfortunately, standard reflective   interfaces in DBMSs are very limited. Some of these limitations may   be circumvented by implementing reflective features as a wrapper to   the DBMS server. Unfortunately, these solutions comes at the expense   of a large development effort and significant performance   penalty.  In this paper we propose a general purpose DBMS reflection architecture and interface, that supports multiple extensions while, at the same time, admitting efficient implementations. We illustrate the usefulness of our proposal with concrete examples, and evaluate its cost and performance under different implementation strategies.               Keywords: databases, performance, reflection               Categories: H.2.1, H.2.5, H.2.8  
13|9|http://www.jucs.org/jucs_13_9|Managing Editor's Column|
13|9||Web Service Selection based on QoS Knowledge Management|  Poulia Adamopoulou (University of Patras, Greece)   Evangelos Sakkopoulos (University of Patras, Greece)   Athanasios Tsakalidis (University of Patras, Greece)   Miltiadis Lytras (University of Patras, Greece)  Abstract: The Semantic Web vision is among others to allow   automatic identification and selection of Web documents and services   to meet the requirements of users. In this work we provide a novel   solution that supports organizational knowledge flow utilizing   non-functional qualitative criteria for web service consumption. A   knowledge management web service selection mediator is presented   based on the Web Services resource framework (WSRF). It enhances   organizational best practices and promotes reusability of successful   services during the process of online Web Service selection. Apart   from meeting functionality requirements, the mediator utilizes   previous domain knowledge to base its decision upon Quality of Web   Service (QoWS) ontology knowledge. The proposed solution is open and   able to host a number of different selection policies and business   logic implementations. We present and experimentally evaluate and   compare four such selection policies. The design of the proposed   mechanism is analyzed and implementation details are   discussed. Evaluation results have shown that the solution is able   to satisfy cases and scenarios that have been derived while studying   and working on web services selection business processes for   different enterprises.               Keywords: WS resources, Web service selection algorithm, knowledge management for quality of Web service               Categories: C.2.4, H.3.4, H.3.5, M.1, M.8  
13|9||Ontology and Grammar of the SOPHIE Choreography Conceptual Framework - An Ontological Model for Knowledge Management|  Sinuhé Arroyo (University of Alcalá de Henares, Spain)  Abstract: Ontologies have been recognized as a fundamental   infrastructure for advanced approaches to Knowledge Management (KM)   automation in SOA. Building services communicate with each other by   exchanging self-contained messages. Depending on the specific   requirements of the business model they serve and the application   domain for which services were deployed, a number of mismatches   (i.e. sequence and cardinality of messages exchanges, structure and   format of messages and content semantics), can occur which prevent   interoperation among a prior compatible services. Existing   choreography technologies attempt to model such external visible   behavior. However, they lack the consistent semantic support   required to fully meet the necessities of heterogeneous KM   environments. This paper describes the ontology and grammar of   SOPHIE, a semantic service-based choreography framework for   overcoming conversational pattern mismatches in knowledge intensive   environments. Consequently, the paper provides an overview of the   framework that depicts its main building blocks, so a good   understantind of the ontology and grammar that summarize the   conceptual model is gained. Such ontology allows the desing and   description of fully fledged choreographies that can be used, as a   result of a mediation task, to produce the mediating structures that   in fact allow dynamic service-to-service interoperation. Finally, a   use case centred in the telcomunications field serves as proof of   concept of how SOPHIE is being applied.               Keywords: choreography, semantic services               Categories: H.3.1, H.3.2, H.3.3, H.3.7, H.5.1, M.4, M.7, M.9  
13|9||Semantic-based Skill Management for Automated Task Assignment and Courseware Composition|  Simona Colucci (Politecnico di Bari, Italy)   Tommaso Di Noia (Politecnico di Bari, Italy)   Eugenio Di Sciascio (Politecnico di Bari, Italy)   Francesco M. Donini (Politecnico di Bari, Italy)   Azzurra Ragone (Politecnico di Bari, Italy)  Abstract: Knowledge management is characterized by many   different activities ranging from the elicitation of knowledge to   its storing, sharing, maintenance, usage and creation. Skill   management is one of such activities, with its own peculiarities, as   it focuses on full exploitation of knowledge individuals in an   organization have, in order to carry out at best given tasks. In   this paper a semantic-based automated Skill Management System is   proposed, which supports competences search and creation. The system   implements an approach exploiting the formalism and the reasoning   services provided by Description Logics. The approach embeds also   non standard Description Logics reasoning services to extend the set   of provided features. Here we present main characteristics of our   system and focus on a novel algorithm exploiting advanced inference   services for the one-to-one assignment of a set of individuals to a   set of tasks, endowed of logical explanation features for   missing/conflicting skills.               Keywords: competence creation, description logics, e-learning, knowledge representation, skill management               Categories: I.2.1, I.2.4, K.6.1, M.2, M.9  
13|9||Generative Instructional Engineering of Competence Development Programmes|  Juan Manuel Dodero (Universidad Carlos III de Madrid, Spain)   Salvador Sánchez-Alonso (University of Alcala, Spain)   Dirk Frosch-Wilke (University of Applied Sciences, Germany)  Abstract: Competence development programmes are   collections of units of learning and learning activities used to   increase the overall effective performance of a learner within a   certain task. The definition of a competence development programme   is fairly complex and subject to variability, depending on the   available learning units and components. Some instructional   engineering approaches have been successfully used to create   courseware by the combination of existing learning resources within   a systematic and iterative method. In this work, a generative,   model-driven engineering approach is used to create and adapt   competence development programmes from families of available   learning components, such as units of learning, learning designs,   and learning services. The process begins from the statement of the   learning goals as feature models, and carries out a number of   transformations from the analysis model down to learning designs and   implementation components. However, shared definitions for   competence-related terms and computational semantics are essential   in this effort. In this paper, ontologies are proposed as a means to   that end. In particular, the transformations between models are   defined with the help of a general competence ontology.               Keywords: competence development programmes, instructional engineering, learning design               Categories: D.2.2, I.2.4, K.3.0, M.0, M.1, M.3, M.4  
13|9||Creating Links into the Future|"  Muhammad Tanvir Afzal (Graz University of Technology, Austria)   Narayanan Kulathuramaiyer (Graz University of Technology, Austria)   Hermann Maurer (Graz University of Technology, Austria)  Abstract: We are approaching an era where research   materials will be stored more and more as digital resources on the   World Wide Web. This of course will enable easier access to online   publications. As the number of electronic publications expands, it   will, however, become a challenge for individuals to find related or   relevant papers. Related papers could be papers written by the same   team of authors or by one of the authors, or even papers that deal   with the same topic but were written by other authors. This, of   course, raises the issue of linking to papers forward in time, or as   we call it ""links into the future"". To be concrete, while reading a   paper written in the year 1980, it would be nice to know if the same   author has written another related paper in 1990s or if the same   author has written a paper earlier, all this without making an   explicit search. Based on the ascertained interest of a person   reading a particular paper from a digital repository, an   auto-suggestion facility could be useful to indicate papers in the   same area, category and subject that might potentially be of   interest to the reader. One is typically interested in finding   related papers by the same author or by one of the authors of a   paper. This feature can be implemented in two ways. The first is by   creating links from this paper to all the relevant papers and   updating it periodically for new papers appearing on the World Wide   Web. Another way is by going through the references of all papers   appearing on the WWW. Based on the references, one can create mutual   links to the papers that are referred to.In this paper, we focus on offering personalised services beyond standard global access. We explore means of identifying the relevance (or relatedness) of papers. A related paper can mean different things to different people as explained above. Ideally, related papers are found and made accessible using links into the future that could be customised to suit the needs of individual users. In this paper, we will focus on a subset of the problem. We explore links into the future in the context of a particular journal which has existed for the past 13 years with over 1500 published papers. We discuss problems that arise in this restricted context while providing details of partial implementations. We plan to pursue our ideas in a more general setting in future implementations.               Keywords: annotations, citation, citation index, links into the future, similarity, typed-link               Categories: H.1, H.3, H.4, H.m, K.6, K.m, M.0, M.6, M.7, M.8, M.9  "
13|9||Focus of Attention in Reinforcement Learning|  Lihong Li (Rutgers University, USA)   Vadim Bulitko (University of Alberta, Canada)   Russell Greiner (University of Alberta, Canada)  Abstract: Classification-based reinforcement learning (RL)   methods have recently been pro-posed as an alternative to the   traditional value-function based methods. These methods use a   classifier to represent a policy, where the input (features) to the   classifier is the state and theoutput (class label) for that state   is the desired action. The reinforcement-learning community knows   that focusing on more important states can lead to improved   performance. In this paper,we investigate the idea of focused   learning in the context of classification-based RL. Specifically, we   define a useful notation of state importance, which we use to prove   rigorous bounds on policyloss. Furthermore, we show that a   classification-based RL agent may behave arbitrarily poorly if it   treats all states as equally important.               Keywords: attention, function approximation, generalization, reinforcement learning               Categories: I.2.6, M.0, M.1  
13|9||Distance Learning and Student Satisfaction in Java Programming Courses|  Amber Settle (DePaul University, United States)   Chad Settle (University of Tulsa, United States)  Abstract: Student satisfaction with distance learning is   impacted by a variety of factors, including interaction with the   instructor and the structure of the course.  Satisfaction with   distance-learning courses also has a strong impact on retention.  In   an earlier article, we determined that student satisfaction as   measured by course evaluation scores in an online discrete   mathematics course taught by the first author was not statistically   significantly different from that of students in traditional   versions of the same course, supporting some previous studies on   distance-learning student satisfaction.  However, the model of   distance-learning studied in our initial work is not the dominant   model used for distance learning at the institution in question.  In   this article we obtain statistically significant results different   from the earlier article when a distance-learning course that uses   the dominant model is considered. In particular, the course   evaluations for online and traditional sections of introductory Java   programming courses varied in some notable ways.               Keywords: computer and information science education               Categories: K.3.2, M.0, M.1  
13|9||Improving the Performance of a Tagger Generator in an Information Extraction Application|  José A. Troyano (University of Seville, Spain)   Fernando Enríquez (University of Seville, Spain)   Fermín Cruz (University of Seville, Spain)   José M. Cañete-Valdeón (University of Seville, Spain)   F. Javier Ortega (University of Seville, Spain)  Abstract: In this paper we present an experience in the   extraction of named entities from Spanish texts using   stacking. Named Entity Extraction (NEE) is a subtask of Information   Extraction that involves the identification of groups of words that   make up the name of an entity, and the classification of these names   into a set of predefined categories. Our approach is corpus-based,   we use a re-trainable tagger generator to obtain a named entity   extractor from a set of tagged examples. The main contribution of   our work is that we obtain the systems needed in a stacking scheme   without making use of any additional training material or tagger   generators. Instead of it, we have generated the variability needed   in stacking by applying corpus transformation to the original   training corpus. Once we have several versions of the training   corpus we generate several extractors and combine them by means of a   machine learning algorithm. Experiments show that the combination of   corpus transformation and stacking improve the performance of the   tagger generator in this kind of natural language processing   applications. The best of our experiments achieves an improvement of   more than six percentual points respect to the predefined   baseline.               Keywords: corpus transformation, named entity extraction, stacking, system combination               Categories: I.2.6, I.2.7, M.8, M.9  
13|9||Co-evolution for Communication: An EHW Approach|  Yasser Baleghi Damavandi (Iran University of Science and Technology, Iran)   Karim Mohammadi (Iran University of Science and Technology, Iran)  Abstract: Evolvable Hardware (EHW) is a new concept that   aims the application of evolutionary algorithms to hardware   design. EHW can adapt itself to unknown environment based on   features of the reconfigurable hardware. This paper presents   outlines of the idea of using some EHW agents in a distributed   system. These agents need to set up a self-organized communication   to achieve the predesigned goal. The experiment that is demonstrated   during the presentation, is to distribute a serial adder into two   EHW parts, where good results has been shown in a co-evolutionary   process.               Keywords: co-evolution, emergent communication, evolvable hardware, genetic algorithm               Categories: I.1.2, I.2.3  
13|9||An Hybrid Fuzzy Variable Neighborhood Particle Swarm Optimization Algorithm for Solving Quadratic Assignment Problems|  Hongbo Liu (Dalian Maritime University, China)   Ajith Abraham (Norwegian University of Science and Technology, Norway)  Abstract: Recently, Particle Swarm Optimization (PSO)   algorithm has exhibited good performance across a wide range of   application problems. A quick review of the literature reveals that   research for solving the Quadratic Assignment Problem (QAP) using   PSO approach has not much been investigated. In this paper, we   design a hybrid meta-heuristic fuzzy scheme, called as variable   neighborhood fuzzy particle swarm algorithm (VNPSO), based on fuzzy   particle swarm optimization and variable neighborhood search to   solve the QAP. In the hybrid fuzzy scheme, the representations of   the position and velocity of the particles in the conventional PSO   is extended from the real vectors to fuzzy matrices. A new mapping   is introduced between the particles in the swarm and the problem   space in an efficient way. We also attempt to theoretically prove   that the variable neighborhood particle swarm algorithm converges   with a probability of 1 towards the global optimal. The performance   of the proposed approach is evaluated and compared with other four   different algorithms. Empirical results illustrate that the approach   can be applied for solving quadratic assignment problems   effectively.               Keywords: particle swarm optimization, quadratic assignment problem, variable neighborhood search               Categories: I.2, I.2.2, I.2.8  
13|9||Genetic Algorithm Based Recurrent Fuzzy Neural Network Modeling of Chemical Processes|  Jili Tao (Zhejiang University, China)   Ning Wang (Zhejiang University, China)   Xuejun Wang (Central South University, China)  Abstract: A genetic algorithm (GA) based recurrent fuzzy   neural network modeling method for dynamic nonlinear chemical   process is presented. The dynamic recurrent fuzzy neural network   (RFNN) is constructed in terms of Takagi-Sugeno fuzzy model. The   consequent part is comprised of the dynamic neurons with output   feedback. The number and the parameters of membership functions in   the premise part are optimized by the GA considering both the   approximation capability and structure complexity of RFNN. The   proposed dynamic model is applied to a PH neutralization process and   the advantages of the resulting model are demonstrated.               Keywords: PH neutralization process, genetic algorithm, modeling, recurrent fuzzy neural network               Categories: H.3.3  
13|9||The Architecture and Circuital Implementation Scheme of a New Cell Neural Network for Analog Signal Processing|  Youren Wang (Nanjing University of Aeronautics and Astronautics, China)   Zhiqiang Zhang (Nanjing University of Aeronautics and Astronautics, China)   Jiang Cui (Nanjing University of Aeronautics and Astronautics, China)  Abstract: It is a difficult problem that using cellular   neural network to make up of analog signal processing circuit. This   paper presented the architecture of new cellular neural network   SCCNN for analog signal processing circuits, designed the neural   cell circuit, and developed the evolutionary design method of the   SCCNN based on selfadapting genetic algorithm. In the architecture   of new cellular neural network SCCNN, each neural cell connects with   four neighborhood neural cells, the neural cell circuit and signal   transfer line between neural cells are controlled by programmable   switches. The validity of the SCCNN architecture and the   evolutionary design method are verified through digital   simulation. The experimental results indicate that the SCCNN   hardware is a universal cellular neural network for analog signal   processing circuit, which can be used to make up of the analog   signal amplifier, analog signal filter,  digit logic circuit, DAC   circuit and so on.               Keywords: DAC circuit, analog signal processing circuit, cellular neural network, evolutionary design               Categories: B.2.3, B.7.3, C.5.4  
13|9||Computer Forensics System Based on Artificial Immune Systems|  Jin Yang (Sichuan University, China)   Tao Li (Sichuan University, China)   Sunjun Liu (Sichuan University, China)   Tiefang Wang (Sichuan University, China)   Diangang Wang (Sichuan University, China)   Gang Liang (Sichuan University, China)  Abstract: The current computer forensics approaches mainly   focus on the network actions capture and analysis the evidences   after attacks, which always result in the static methods. Inspired   by the theory of artificial immune systems (AIS ), a novel model of   Computer Forensics System is presented. The concepts and formal   definitions of immune cells are given, and dynamically evaluative   equations for self, antigen, immune tolerance, mature-lymphocyte   lifecycle and immune memory are presented, and the hierarchical and   distributed management framework of the proposed model are   built. Furthermore, the idea of biology immunity is applied for   enhancing the self-adapting and self-learning ability to adapt   continuously variety environments. The experimental results show   that the proposed model has the features of real-time processing,   selfadaptively, thus providing a promising solution for computer   forensics.               Keywords: artificial immune systems, computer forensics, network security               Categories: H.3.7, H.5.4  
volume|issue|url|title|abstract
14|1|http://www.jucs.org/jucs_14_1|Groupware: Issues and Applications|
14|1||The Trade-Offs of Blending Synchronous and Asynchronous Communication Services to Support Contextual Collaboration|  Werner Geyer (IBM T.J. Watson Research, USA)   Roberto S. Silva Filho (University of California Irvine, USA)   Beth Brownholtz (IBM T.J. Watson Research, USA)   David F. Redmiles (University of California Irvine, USA)  Abstract: Contextual collaboration seamlessly integrates existing groupware technologies into a uniform user experience that combines synchronous and asynchronous interactions. This user experience is usually supported by a collaboration infrastructure that needs to efficiently cope with the fast switching and integration of different modes of interaction. In this paper, we study a model for contextual collaboration that supports multiple modalities of collaboration. Our model is based on generic shared objects that provide building blocks for supporting contextual collaboration applications. We describe a native implementation of this model and evaluate its behavior under different media traffic conditions. We compare the native implementation with an alternative implementation that integrates existing notification and meeting servers to deliver the same model behavior. We discuss trade-offs and limitations of those two implementations.               Keywords: CSCW, architecture, asynchronous collaboration, groupware, notification, simulation, synchronous collaboration               Categories: H.3.4, H.4.3, H.5.3, I.6.0  
14|1||Ontoolcole: Supporting Educators in the Semantic Search of CSCL Tools|  Guillermo Vega-Gorgojo    Miguel L. Bote-Lorenzo (University of Valladolid, Spain)   Eduardo Gómez-Sánchez (University of Valladolid, Spain)   Juan I. Asensio-Pérez (University of Valladolid, Spain)   Yannis A. Dimitriadis (University of Valladolid, Spain)   Iván M. Jorrín-Abellán (University of Valladolid, Spain)  Abstract: Collaborative learning systems can be   constructed following the serviceoriented computing paradigm. This   allows educators to integrate external tools, offered as services by   software providers, in order to support the realization of   collaborative learning situations. Discovering appropriate services   is a challenging task that requires the description of their   capabilities. This can be accomplished with Ontoolcole, an ontology   of collaborative learning tools designed with the aim of supporting   educators in the search of CSCL tools. Ontoolcole is depicted here   and some new, relevant features are discussed. Namely, Ontoolcole   incorporates an artifact module, a task-level coordination module   and the description of static information resources, further   improving the capabilities to describe complex CSCL tools. As a   proof of concept, we also present a preliminary prototype of the   intended target application of Ontoolcole, an interactive system for   the search of CSCL tools, named Ontoolsearch. A case study with   practitioners has been carried out to evaluate whether Ontoolcole   can be employed by educators to search CSCL tools. Evaluation   results show that Ontoolcole abstractions fit educators' questions   based on their real practice while retrieving useful tools for their   educational needs.               Keywords: CSCL tools, collaborative learning systems, ontologies, semantic web services, service discovery               Categories: H.3.3, H.4.3, I.2.4, K.3.1  
14|1||Seamless Transition between Connected and Disconnected Collaborative Interaction|  Stephan Lukosch (FernUniversität in Hagen, Germany)  Abstract: Nowadays, more and more users make use of web-based collaborative systems. Users participate in communities or search for and provide information in webbased systems. They access shared resources which they need for their professional life or for learning. One of the major prerequisites of such web-based systems is that users have to be connected to the network. But life has become much more mobile over the last years. While traveling, e.g. to the office or the university, users often are disconnected from the network. This makes it difficult to interact with other users or to access shared resources. An application supporting a seamless transition between connected and disconnected phases would allow users to work at any time and place while maintaining the advantages of a web-based collaborative system once they are online again. In this article, we describe the requirements that a web-based collaborative system has to fulfill to enable a nomadic use. We show how we extended the web-based collaborative system CURE to fulfill these requirements and how our approach can be transferred to other web-based collaborative systems.               Keywords: collaborative working and learning, interactive situation model, nomadic working and learning, shared workspaces               Categories: H.1.2, H.5.1, H.5.3, J.7  
14|1||Integrating Service-Oriented Mobile Units to Support Collaboration in Ad-hoc Scenarios|  Andrés Neyem (Universidad de Chile, Chile)   Sergio F. Ochoa (Universidad de Chile, Chile)   José A. Pino (Universidad de Chile, Chile)  Abstract: Advances in wireless communication and mobile   computing extend collaboration scenarios. Mobile workers using   computing devices are currently able to collaborate in order to   carry out productive, educational or social activities. Typically,   collaborative applications intended to support mobile workers   involve some type of centralized data or services, because they are   designed to work on infrastructure supported wireless networks. This   centralization constrains the collaboration capabilities in ad-hoc   communication cases. This paper introduces the concept of   Service-Oriented Mobile Unit (SOMU) in order to reduce such   limitation. SOMU is an autonomous software infrastructure running on   a computing device; it is able to be integrated to ad-hoc networks   and it can interoperate with other mobile units in ad-hoc   collaboration scenarios. In addition, the paper presents the   challenges faced when designing and implementing the SOMU   platform. It also describes an application developed on   SOMU.               Keywords: Web services platform, ad-hoc collaboration scenarios, middleware for mobile groupware, service-oriented mobile units               Categories: C.3, C.5, J.7  
14|1||Using PDAs in Meetings: Patterns, Architecture and Components|  Gustavo Zurita (University of Chile, Chile)   Pedro Antunes (University of Lisboa, Portugal)   Nelson Baloian (University of Chile, Chile)   Luís Carriço (University of Lisboa, Portugal)   Felipe Baytelman (University of Chile, Chile)   Marco Sá (University of Lisboa, Portugal)  Abstract: This paper addresses the role of Personal   Digital Assistants (PDAs) in electronic meetings. Several real-world   scenarios of PDA usage in meetings are defined using a pattern   language. Anchored on these scenarios, we propose an upper-layer   meeting middleware which addresses three major goals: defining a   common architecture and set of components for meeting systems;   standardizing the meeting memory and process data structures   commonly managed by electronic meetings; and supporting XML-based   interoperability between these components. The patterns,   architecture and components were validated through their adoption in   three applications, developed by different teams and covering quite   different domains. The applications, encompassing several meeting   patterns and adopting multifaceted combinations of the upper-layer   components, demonstrate the high level of interoperability supported   by the proposed upper-layer middleware.               Keywords: electronic meetings, meeting patterns, upper-layer middleware               Categories: H.1  
14|1||The Remote Control Approach - An Architecture for Adaptive Scripting across Collaborative Learning Environments|  Andreas Harrer (University of Duisburg-Essen, Germany)   Nils Malzahn (University of Duisburg-Essen, Germany)   Astrid Wichmann (University of Duisburg-Essen, Germany)  Abstract: In this article we present an architecture for the integration of tutoring approaches and process scaffolds into existing collaborative applications. The architecture allows to combine existing research on explicit representations of collaborative learning processes with the availability of existing and tested collaborative learning environments. The architecture allows to control the learning environments either by a human or a pedagogic agent and thus enables adaptation of the tools to the current state of the learning process. Both types of tutors are using a so-called remote control component using the same set of control primitives. To prove the soundness of the architecture and the flexibility of its implementation two example scenarios are shown that use IMS LD learning process definitions with the Coppercore learning design engine controlling our collaborative environments.               Keywords: collaboration scripts, integration architecture, learning design               Categories: D.2.11, K.3.1, L.2.0, L.6.2  
14|10|http://www.jucs.org/jucs_14_10|Managing Editor's Column|
14|10||Feature Selection for the Classification of Large Document Collections|  Janez Brank (Jožef Stefan Institute, Slovenia)   Dunja Mladenić (Jožef Stefan Institute, Slovenia)   Marko Grobelnik (Jožef Stefan Institute, Slovenia)   Nataša Milić-Frayling (Microsoft Research, United Kingdom)  Abstract: Feature selection methods are often applied in the context of document classification. They are particularly important for processing large data sets that may contain millions of documents and are typically represented by a large number, possibly tens of thousands of features. Processing large data sets thus raises the issue of computational resources and we often have to find the right trade-off between the size of the feature set and the number of training data that we can taken into account. Furthermore, depending on the selected classification technique, different feature selection methods require different optimization approaches, raising the issue of compatibility between the two. We demonstrate an effective classifier training and feature selection method that is suitable for large data collections. We explore feature selection based on the weights obtained from linear classifiers themselves, trained on a subset of training documents. While most feature weighting schemes score individual features independently from each other, the weights of linear classifiers incorporate the relative importance of a feature for classification as observed for a given subset of documents thus taking the feature dependence into account. We investigate how these feature selection methods combine with various learning algorithms. Our experiments include a comparative analysis of three learning algorithms: Naïve Bayes, Perceptron, and Support Vector Machines (SVM) in combination with three feature weighting methods: Odds ratio, Information Gain, and weights from the linear SVM and Perceptron. We show that by regulating the size of the feature space (and thus the sparsity of the resulting vector representation of the documents) using an effective feature scoring, like linear SVM, we need only a half or even a quarter of the computer memory to train a classifier of almost the same quality as the one obtained from the complete data set. Feature selection using weights from the linear SVMs yields a better classification performance than other feature weighting methods when combined with the three learning algorithms. The results support the conjecture that it is the sophistication of the feature weighting method rather than its compatibility with the learning algorithm that improves the classification performance.               Keywords: data preprocessing, feature selection, information retrieval, knowledge representation, machine learning, support vector machines, text classification               Categories: H.3.3, I.2.4, I.2.6, M.4  
14|10||Guaranteeing Seamless Mobility with User Redials and Automatic Handover Retrials|  Jose Manuel Gimenez-Guzman (Universidad Politecnica de Valencia, Spain)   M. Jose Domenech-Benlloch (Universidad Politecnica de Valencia, Spain)   Vicent Pla (Universidad Politecnica de Valencia, Spain)   Vicente Casares-Giner (Universidad Politecnica de Valencia, Spain)   Jorge Martinez-Bauset (Universidad Politecnica de Valencia, Spain)  Abstract: In communication systems that guarantee seamless   mobility of users across service areas, repeated attempts occur as a   result of user behavior but also as au- tomatic retries of blocked   requests. Both phenomena play an important role in the system   performance and therefore should not be ignored in its analysis. On   the other hand, an exact Markovian model analysis of such systems   has proven to be infeasible and resorting to approximate techniques   is mandatory. We propose an approximate methodology which   substantially improves the accuracy of existing methods with a   negligible increase of the computational time from the human point   of view. A numer- ical evaluation of the model is carried out to   investigate the impact on performance of the parameters related to   the retry phenomena. As a result, some useful guidelines for setting   up the automatic retries are provided. Finally, we also show how our   model can be used to obtain a tight performance approximation in the   case where reattempts have a deterministic nature.               Keywords: Markovian model, finite truncated model, reattempt, seamless mobility               Categories: C.2.0, C.4  
14|10||Enhancements of Meeting Information Management and Application for Knowledge Access and Learning Activities|  Christian Gütl (Graz University of Technology, Austria)  Abstract: Communication processes have become increasingly   important in modern working life. Organizations invest a   surprisingly high amount of financial resources and employee work   time in both face-to-face and virtual meetings, yet this investment   often produces poor results. To overcome this problem, research on   technology-based support over a meetings life-cycle has been   increasingly conducted in recent decades. As a result of this   research, particular interest has emerged in meeting information   systems, which may include technology-enhanced meeting rooms as well   as tools for multi-modal meeting recording, automatic meeting   information extraction and annotation, in-meeting support, meeting   information archiving, indexing, retrieval and   visualization. Despite this great interest in and research activity   on meeting information systems, insufficient focus has been paid   into flexible architectures, interchangeability of meeting   information as well as the integration into business processes and   applications. This situation has motivated our research consortium   to direct the research activity within the MISTRAL project towards a   flexible and extendable system that can be easily integrated into   daily working environments for knowledge access and learning   activities. In this paper, we give an overview about electronic   meeting systems, introduce related work on meeting information   systems, outline the MISTRAL concept and its implementation, and   based on that we discuss findings and problems with our   research.               Keywords: electron meeting system, meeting information retrieval andvisualization, meeting information system, multimodal information extraction               Categories: H.3.3, H.4.0, H.5.1  
14|10||Expressibility in ∑11|  Walid Gomaa (Alexandria University, Egypt)  Abstract: Inspired by Fagin's result that   NP =   ∑11, we have   developed a partial framework to investigate expressibility inside   ∑11 so as to   have a finer look into NP. The framework uses   interesting combinatorics derived from second-order   Ehrenfeucht-Fraïssé games and the notion of game   types. Some of the results that have been proven within this   framework are: (1) for any k, divisibility by k is not expressible   by a ∑11   sentence where (1.i) each second-order variable has arity at most 2,   (1.ii) the first-order part has at most 2 first-order variables, and   (1.iii) the first-order part has quantifier depth at most 3, (2)   adding one more first-order variable makes the same problem   expressible, and (3) inside this last logic the parameter k creates   a proper hierarchy with varying the number of second-order   variables.               Keywords: Ehrenfeucht-Fraïssé games, divisibility, expressibility, first-order, second-order               Categories: F.1.3, F.4  
14|10||An IP Core and GUI for Implementing Multilayer Perceptron with a Fuzzy Activation Function on Configurable Logic Devices|  Alfredo Rosado-Muñoz (University of Valencia, Spain)   Luis Gomez-Chova (University of Valencia, Spain)   Luis Gomez-Chova (University of Valencia, Spain)   Joan Vila Francés (University of Valencia, Spain)  Abstract: This paper describes the development of an Intellectual Property (IP) core in VHDL able to implement a Multilayer Perceptron (MLP) artificial neural network (ANN) topology with up to 2 hidden layers, 128 neurons, and 31 inputs per neuron. Neural network models are usually developed by using programming languages, such as Matlab®. However, their implementation in configurable logic hardware requires the use of some other tools and hardware description languages, such as as VHDL. For easy migration, a Matlab Graphical User Interface (GUI) to automatically translate the ANN architecture to VHDL code has been developed. In addition, the use of an activation function based on fuzzy logic for the implementation of the MLP neural network simplifies the logic and improves the results. The environment was tested using a typical prediction problem, the Mackey-Glass series, where several ANN topologies were generated, tested and implemented in an FPGA. Results show the excellent agreement between the results provided by the software model and the hardware implementation.               Keywords: FPGA, IP core, VHDL, configurable hardware, fuzzy logic, multilayer perceptron, neural networks, programmable logic               Categories: B.6.3, B.7.1, C.1.3, I.2.3  
14|10||Applications of Mash-ups for a Digital Journal|  Muhammad Salman Khan (Graz University of Technology, Austria)   Narayanan Kulathuramaiyer (University of Malaysia Sarawak, Malaysia)   Hermann Maurer (Graz University of Technology, Austria)  Abstract: The WWW is currently experiencing a   revolutionary growth due to numerous emerging tools, techniques and   concepts. Digital journals thus need to transform themselves to cope   with this evolution of the web. With their growing information size   and access, conventional techniques for managing a journal and   supporting authors and readers are becoming insufficient. Journals   of the future need to provide innovative administrative tools in   helping its managers to ensure quality. They also need to provide   better facilities for assisting authors and readers in making   decisions regarding their submission of papers and in providing   novel navigational features for finding relevant publications and   collaborators in particular areas of interest. In this paper, we   explore an innovative solution to address these problems by using an   emerging Web 2.0 technology. We explore the application of mash-ups   for J.UCS - the Journal of Universal Computer Science and encourage   readers and authors to try out the applications (see section 11   Conclusions).  J.UCS can then serve as a model for contemporary   electronic journals.               Keywords: Web 2.0, annotations, decision making, mash-up, metadata, scholarly network               Categories: H.3.3, H.3.4, H.3.5, H.3.7, H.4.3, H.5.1  
14|10||Exposure and Support of Latent Social Networks among Learning Object Repository Users|  Peng Han (FernUniversität in Hagen, Germany)   Gerd Kortemeyer (Michigan State University, USA)   Bernd J. Krämer (FernUniversität in Hagen, Germany)   Christine von Prümmer (FernUniversität in Hagen, Germany)  Abstract: Although immense efforts have been invested in   the construction of hundreds of learning object repositories, the   degree of reuse of learning resources maintained in such   repositories is still disappointingly low. As the reasons for this   observation are not well understood, we carried out an empirical   investigation with the objectives to identify recurring patterns in   the retrieval and (re-) use of learning resources and to design and   test social networking functionality supporting communities of   practice. The outcomes of this project, which are reported here, aim   to affect the design of a new generation of learning object   repositories, like CampusContent, that tries to eliminate deficits   of current repositories and involve recent contributions in the area   of social software. Object of our investigation was LON-CAPA, a   crossinstitutional learning content management and assessment system   used since 2000. We analyzed hundreds of thousands of log data   collected over a period of three years and detected various kinds of   latent relationships among LON-CAPA users, such as the co-occurrence   of learning resources from independent authors in instructional   materials. To understand the rationale behind these findings, we   conducted a study with LON-CAPA users. One section of the   questionnaire asked for people's opinion about the expected benefit   of community support. Nearly 80% of the study participants said that   the formation of communities of practice (CoP) would be an asset to   LON-CAPA. More than 80% would be ready to provide their profiles for   matching up with CoPs and serve the community by spending time on   the evaluation of resources they had used. Finally we sketch a   faceted search functionality we designed to support CoPs among   LON-CAPA users. This functionality is currently tested with two   CoPs.               Keywords: community building, learning object, metadata, repository, sharing and reuse, structural computing               Categories: H.3.7, H.5.4  
14|10||Searching ... in a Web|"  Ian H. Witten (University of Waikato, New Zealand)  Abstract: Search engines—""web dragons""—are   the portals through which we access society's treasure trove of   information. They do not publish the algorithms they use to sort and   filter information, yet what they do and how they do it are amongst   the most important questions of our time. They deal not just with   information per se, but evaluate it in order to   prioritize it for the user. To do this they assess the prestige of   each web page in terms of who links to it. This article explains in   non-technical terms what is known about how web search engines   work. We describe the dominant way of measuring prestige, relating   it to the experience of a surfer condemned to click randomly around   the web forever—and also to standard techniques of bibliometric   evaluation. We review alternatives: some strive to identify   subcommunities of the web; others learn based on implicit user   feedback. We also takes a critical look at how people use search   engines, and identify issues of bias, privacy, and personalization   that crucially affect our world of information today.               Keywords: PageRank, information ethics, personalization, privacy, search bias, search engines, web search               Categories: H.3.3, K.4.0, K.4.1, K.4.2  "
14|10||Using Taxonomies to Support the Macro Design Process for the Production of Web Based Trainings|  Abdelhak Aqqal (Technische Universität Darmstadt, Germany)   Christoph Rensing (Technische Universität Darmstadt, Germany)   Ralf Steinmetz (Technische Universität Darmstadt, Germany)   Najib Elkamoun (Chouaib Doukkali University, Morocco)   Abdelghafour Berraissoul (Chouaib Doukkali University, Morocco)  Abstract: Recently Web Based Training (WBT) starts to be   widely used as a new way of teaching. Unfortunately, this mode of   teaching imposes new requirements and constraints. It has made the   creation of learning material a complex and demanding task for the   instructors as it takes much time and demands a multitude of skills,   in particular technical skills that must be developed and   continuously updated. Hence, we propose a collaborative authoring   methodology based on division of labour as a way to produce WBTs   where the processes of production are clearly separated to meet the   existing and needed skills of persons involved in WBT   production. This paper presents an efficient method to support   instructors guidance during the first phase of the WBT production   called the Macro Design using the Rhetorical Structure Theory (RST)   and the taxonomies we developed.               Keywords: E-learning, collaborative authoring, instructional design support tool, knowledge modelling, production of web based training, semantic design, taxonomies               Categories: H.4.0, H.5.4, I.6.5, K.3.1, M.1  
14|10||The Need for Formalizing Media Semantics in the Games and Entertainment Industry|  Tobias Bürger (Semantic Technology Institute Innsbruck, Austria)  Abstract: The digital media and games industry is one of   the biggest IT based indus-tries worldwide. Recent observations   therein showed that current production workflows may be potentially   improved as multimedia objects are mostly created from scratch due   to insu±cient reusability capacities of existing tools. In this   paper we provide reasons for that, provide a potential solution   based on semantic technologies, show the potential of ontologies,   and provide scenarios for the application of semantic technologies   in the digital media and games industry.               Keywords: digital entertainment, multimedia semantics, ontologies, semantic search               Categories: H.5.1  
14|10||Imagesemantics: User-Generated Metadata, Content Based Retrieval & Beyond|"  Marc Spaniol (RWTH Aachen University, Germany)   Ralf Klamma (RWTH Aachen University, Germany)   Mathias Lux (Klagenfurt University, Austria)  Abstract: With the advent of Web 2.0 technologies a new   attitude towards processing contents in the Internet has   emerged. Nowadays it is a lot easier to create, share and retrieve   multimedia contents on the Web. However, with the increasing amount   in contents retrieval becomes more challenging and often leads to   inadequate search results. One main reason is that image clustering   and retrieval approaches usually stick either solely to the images'   low-level features or their user-generated tags (high-level   features). However, this is frequently inappropriate since the   ""real"" semantics of an image can only be derived from the   combination of low-level and high-level features. Consequently, we   investigated a more holistic view on image semantics based on a   system called Imagesemantics. This system combines MPEG-7   descriptions for low-level content-based retrieval features and   MPEG-7 keywords by a machine learning approach producing joined OWL   rules. The rule base is used in Imagesemantics to improve retrieval   results.               Keywords: MPEG-7, Web 2.0, social media platform, user-generated content               Categories: H.3.3, H.3.4, H.3.5, H.5.1  "
14|11|http://www.jucs.org/jucs_14_11|Wrapping Web Data Islands|
14|11||Information Integration for the Masses|  Jim Blythe (USC Information Sciences Institute, USA)   Dipsy Kapoor (USC Information Sciences Institute, USA)   Craig A. Knoblock (USC Information Sciences Institute, USA)   Kristina Lerman (USC Information Sciences Institute, USA)   Steven Minton (Fetch Technologies, USA)  Abstract: Information integration applications combine   data from heterogeneous sources to assist the user in solving   repetitive data-intensive tasks. Currently, such applications   require a high level of expertise in information integration since   users need to know how to extract data from an on-line source,   describe its semantics, and build integration plans to answer   specific queries.  We have integrated three task learning   technologies within a single desktop application to assist users in   creating information integration applications. It includes a tool   for programmatic access to data in on-line information sources, a   tool to semantically model them by aligning their input and output   parameters with a common ontology, and a tool that enables the user   to create complex integration plans using simple text   instructions. Our system was integrated within the Calo Desktop   Assistant and evaluated independently on a range of problems. It   enabled non-expert users to construct integration plans for a   variety of problems in the office and travel domains.               Keywords: assistants, information extraction, web applications               Categories: D.2.11, H.3.5, H.3.6, H.3.7  
14|11||A Workflow Language for Web Automation|  Paula Montoto (University of A Coruña, Spain)   Alberto Pan (University of A Coruña, Spain)   Juan Raposo (University of A Coruña, Spain)   Jose Losada (University of A Coruña, Spain)   Fernando Bellas (University of A Coruña, Spain)   Víctor Carneiro (University of A Coruña, Spain)  Abstract: Most todays web sources do not provide suitable   interfaces for software programs to interact with them. Many   researchers have proposed highly effective techniques to address   this problem. Nevertheless, ad-hoc solutions are still frequent in   real-world web automation applications.  Arguably, one of the   reasons for this situation is that most proposals have focused on   query wrappers, which transform a web source into a special kind of   database in which some queries can be executed using a query form   and return resultsets that are composed of structured data   records. Although the query wrapper model is often useful, it is not   appropriate for applications that make decisions according to the   data retrieved or processes that use forms that can be modelled as   insert/update/delete operations. This article proposes a new   language for defining web automation processes that is based on a   wide range of real-world web automation tasks that are being used by   corporations from different business areas.               Keywords: data mining, web automation, web information systems, web wrappers               Categories: D.1.7, H.2.5, H.2.8, H.3.3  
14|11||Structure-Based Crawling in the Hidden Web|  Marcio Vidal (Federal University of Amazonas, Brazil)   Altigran S. da Silva (Federal University of Amazonas, Brazil)   Edleno S. de Moura (Federal University of Amazonas, Brazil)   João M.B. Cavalcanti (Federal University of Amazonas, Brazil)  Abstract: The number of applications that need to crawl the Web to gather data is growing at an ever increasing pace. In some cases, the criterion to determine what pages must be included in a collection is based on theirs contents; in others, it would be wiser to use a structure-based criterion. In this article, we present a proposal to build structure-based crawlers that just requires a few examples of the pages to be crawled and an entry point to the target web site. Our crawlers can deal with form-based web sites. Contrarily to other proposals, ours does not require a sample database to fill in the forms, and does not require the user to interact heavily. Our experiments prove that our precision is 100% in seventeen real-world web sites, with both static and dynamic content, and that our recall is 95% in the eleven static web sites examined.               Keywords: Web crawling, hidden web, tree-edit distance, web wrappers               Categories: H.3.3, H.3.4, H.3.5, H.3.7  
14|11||Structure and Semantics of Data-IntensiveWeb Pages: An Experimental Study on their Relationships|  Lorenzo Blanco (Università degli Studi Roma Tre, Italy)   Valter Crescenzi (Università degli Studi Roma Tre, Italy)   Paolo Merialdo (Università degli Studi Roma Tre, Italy)  Abstract: In data-intensive web sites pages are generated   by scripts that embed data from a backend database into HTML   templates. There is usually a relationship between the semantics of   the data in a page and its corresponding template. For example, in a   web site about sports events, it is likely that pages with data   about athletes are associated with a template that differs from the   template used to generate pages about coaches or referees. This   article presents a method to classify web pages according to the   associated template. Given a web page, the goal of our method is to   accurately find the pages that are about the same topic. Our method   leverages on a simple, yet effective model to abstract some   structural features of a web page. We present the results of an   extensive experimental analysis that show the performance of our   methods in terms of both recall and precision regarding a large   number of real-world web pages.               Keywords: clustering, data extraction, web page classification               Categories: H.3.3, I.2.6  
14|11||Recognising Informative Web Page Blocks Using Visual Segmentation for Efficient Information Extraction|  Jinbeom Kang (Hanyang University, Korea)   Joongmin Choi (Hanyang University, Korea)  Abstract: As web sites are getting more complicated, the   construction of web information extraction systems becomes more   troublesome and time-consuming. A common theme is the difficulty in   locating the segments of a page in which the target information is   contained, which we call the informative blocks. This article   reports on the Recognising Informative Page Blocks algorithm (RIPB),   which is able to identify the informative block in a web page so   that information extraction algorithms can work on it more   efficiently. RIPB relies on an existing algorithm for vision-based   page block segmentation to analyse and partition a web page into a   set of visual blocks, and then groups related blocks with similar   content structures into block clusters by using a tree edit distance   method. RIPB recognises the informative block cluster by using tree   alignment and tree matching. A series of experiments were performed,   and the conclusions were that RIPB was more than 95% accurate in   recognising informative block clusters, and improved the efficiency   of information extraction by 17%.               Keywords: information extraction, informative block, visual block               Categories: H.3.7, H.5.4  
14|11||Exploring Information Extraction Resilience|  Dawn G. Gregg (University of Colorado, USA)  Abstract: There are many challenges developers face when   attempting to reliably extract data from the Web. One of these   challenges is the resilience of the extraction system to changes in   the web pages information is being extracted from. This article   compares the resilience of information extraction systems that use   position based extraction with an ontology based extraction system   and a system that combines position based extraction with ontology   based extraction. The findings demonstrate the advantages of using a   system that combines multiple extraction techniques, especially in   environments where web sites change frequently and where data   collection is conducted over an extended period of time.               Keywords: information extraction, ontologies, semi-structured data               Categories: H.3.3, H.3.4, H.5.4  
14|12|http://www.jucs.org/jucs_14_12|Quo Vadis Abstract State Machines?|
14|12||ASM Refinement Preserving Invariants|"  Gerhard Schellhorn (University of Augsburg, Germany)  Abstract: This paper gives a definition of ASM refinement suitable for the verification that a protocol implements atomic transactions. We used this definition as the basis of the formal verification of the refinements of the Mondex case study with the interactive theorem prover KIV. The refinement definition we give differs from the one we gave in earlier work which preserves partial and total correctness assertions of ASM runs. The reason is that the main goal of the refinement of the Mondex protocol is to preserve a security invariant, while total correctness is not preserved. To preserve invariants, the definition of generalized forward simulation is limited to the use of ""small"" diagrams, which contain of a single protocol step. We show a technique that allows to use the natural ""big"" diagrams that consist of an atomic action being refined by a full protocol run.               Keywords: Abstract State Machines, Mondex, commuting diagrams, data refinement, dynamic logic, electronic purses, forward simulation, interactive theorem proving, refinement, security, weakest preconditions               Categories: D.2.1, D.2.4, D.3.1, D.4.6, F.3.1, F.4.1  "
14|12||A Metamodel-based Language and a Simulation Engine for Abstract State Machines|  Angelo Gargantini (Universitá di Bergamo, Italy)   Elvinia Riccobene (Universitá di Milano, Italy)   Patrizia Scandurra (Universitá di Milano, Italy)  Abstract: In this paper, we present a concrete textual notation, called AsmetaL, and a general-purpose simulation engine, called AsmetaS, for Abstract State Machine (ASM) specifications. They have been developed as part of the ASMETA (ASMs mETAmodelling) toolset, which is a set of tools for ASMs based on the metamodelling approach of the Model-driven Engineering. We briefly present the ASMETA framework, and we discuss how the language and the simulator have been developed exploiting the advantages offered by the metamodelling approach. We introduce the language AsmetaL used to write ASM specifications, and we provide the AsmetaL encoding of ASM specifications of increasing complexity. We explain the AsmetaS architecture, its kernel engine, and how the simulator works within the ASMETA tool set. We discuss the features currently supported by the simulator and how it has been validated.               Keywords: ASM language, ASM simulator, Abstract State Machines, metamodelling, model-driven engineering               Categories: B.2, D.2.1, D.2.6, F.3.1  
14|12||Simulation of Timed Abstract State Machines with Predicate Logic Model-Checking|  Anatol Slissenko (University Paris-East, France)   Pavel Vasilyev (University Paris-East, France)  Abstract: We describe a prototype of a simulator for   reactive timed abstract state machines (ASM) that checks whether the   generated runs verify a requirements specification represented as a   formula of a First Order Timed Logic (FOTL). The simulator deals   with ASM with continuous or discrete time. The time constraints are   linear inequalities. It can treat two semantics, one with   instantaneous actions and another one with delayed actions, the   delays being bounded and non-deterministic.               Keywords: abstract state machine, model-checking, predicate timed logic, real-time, simulation               Categories: D.2.1, D.2.4  
14|12||The Timed Abstract State Machine Language: Abstract State Machines for Real-Time System Engineering|  Martin Ouimet (Massachusetts Institute of Technology, USA)   Kristina Lundqvist (Massachusetts Institute of Technology, USA)  Abstract: In this paper, we present the Timed Abstract   State Machine (TASM) language, which is a language for the   specification of embedded real-time systems. In the engineering of   embedded real-time systems, the correctness of the system is defined   in terms of three aspects - function, time, and resource   consumption. The goal of the TASM language and its associated   toolset is to provide a basis for specification-based real-time   system engineering where these three aspects can be specified and   analyzed. The TASM language is built on top of Abstract State   Machines (ASM) by including facilities for compact and legible   specification of non-functional behavior, namely time and resource   consumption. The TASM language provides a notation which is   well-suited to the specification needs of embedded real-time   systems. We begin the presentation of the language with a historical   survey on the use of ASM in specifying real-time systems. The core   difference between the TASM language and ASM is that steps are   inherently durative instead of being instantaneous and steps consume   resources. These concepts capture the reality of physical systems in   a flexible abstract model. We present the syntax and semantics of   the language and illustrate the concepts using an extended version   of the production cell case study.               Keywords: Abstract State Machines, embedded systems, formal methods, real-time systems, specification, verification               Categories: D.2.1, D.2.2, D.4.7, I.6  
14|12||ASMs in Service Oriented Architectures|  Michael Altenhofen (CEC Karlsruhe, Germany)   Andreas Friesen (CEC Karlsruhe, Germany)   Jens Lemcke (CEC Karlsruhe, Germany)  Abstract: We give a survey on work we did in the past   where we have successfully applied the ASM methodology to provide   abstract models for a number of problem areas that are commonly   found in Service Oriented Architectures (SOA). In particular, we   summarize our work on (1) service behavior mediation, (2) service   discovery, and (3) service composition, showing that the   corresponding solutions can be described as variations of a   fundamental abstract processing model—the Virtual   Provider.               Keywords: process mediation, service discovery, workflow composition               Categories: D.2.1, H.4.3, I.6.5  
14|12||Modularizing Theorems for Software Product Lines: The Jbook Case Study|  Don Batory (University of Texas at Austin, USA)   Egon Börger (Università di Pisa, Italy)  Abstract: A goal of software product lines is the   economical assembly of programs in a family of programs. In this   paper, we explore how theorems about program properties may be   integrated into feature-based development of software product   lines. As a case study, we analyze an existing Java/JVM compilation   correctness proof for defining, interpreting, compiling, and   executing bytecode for the Java language. We show how features   modularize program source, theorem statements and their proofs. By   composing features, the source code, theorem statements and proofs   for a program are assembled. The investigation in this paper reveals   a striking similarity of the refinement concepts used in   Abstract State Machines (ASM) based system   development and Feature-Oriented Programming (FOP)   of software product lines. We suggest to exploit this observation   for a fruitful interaction of researchers in the two   communities.               Keywords: AHEAD, ASM, composition, features, verification               Categories: D.2.1, D.2.10, D.2.11, D.2.4  
14|12||What is Correctness of Security Protocols?|"  Giampaolo Bella (Università di Catania, Italy)  Abstract: As soon as major protocol flaws were discovered empirically - a good luck that is not older than the early 1990s -- this title question came up to the world. It was soon realised that some notion of formal correctness was necessary to substantiate the confidence derived from informal analyses. But protocol correctness was born in a decade when security in general was only beginning to ferment.    Security protocols aim at a large variety of goals. This is partly due to the increasing domains where the protocols are finding an application, such as secure access to localarea network services, secure e-mail, e-commerce, public-key registration at certification authorities and so on. Also, several interpretations are possible about each goal.    Clearly, it is impossible to study protocol correctness profitably without a universal and unambiguous interpretation of its goals. What may be typical of security problems is that it is at least as important to state a detailed and appropriate model of threats that a secure system is meant to withstand. This has been a second and significant source of perhaps useless debates around many protocols.    These are certain to be some of the reasons why dozens of papers appeared about one, now popular, protocol attack in just a few years of the second half of the last decade. One of the protocol designers firmly refused those ""findings"" because his protocol had been conceived within a different threat model -- and perhaps for different goals -- from the one that the publications had been constructed upon.    It seems obvious that an ant may survive under a single sheet of paper but certainly will not under a hard-back bulky book. It should be clarified what an ant and a bulky book precisely are. With particular attention to similar issues, this position paper discusses some findings of the author's in the area of protocol formal analysis. Their significance mostly is methodical rather than specific for particular protocols. The paper then outlines the author's favourite tool, the Inductive Method, and concludes with a few open problems.               Keywords: inductive method, protocol goal, protocol verification, threat model               Categories: D.2.4, F.3.1  "
14|13|http://www.jucs.org/jucs_14_13|Software Adaptation|
14|13||A Survey of Practical Software Adaptation Techniques|  Stephen Kell (University of Cambridge, United Kingdom)  Abstract: Software adaptation techniques appear in many   disparate areas of research literature, and under many guises. This   paper enables a clear and uniform understanding of the related   research, in three ways. Firstly, it surveys a broad range of   relevant research, describing and contrasting the approaches of each   using a uniform terminological and conceptual vocabulary. Secondly,   it identifies and discusses three commonly advocated principles   within this work: component models, first-class connection and loose   coupling. Thirdly, it identifies and compares the various   modularisation strategies employed by the surveyed work.               Keywords: adaptation, communication, coordination, coupling, modularity, reuse, software architecture, software composition, software measurement               Categories: D.2.11, D.2.12, D.2.13, D.2.6, D.2.7  
14|13||An Adaptation Logic Framework for Java-based Component Systems|  Enrico Oliva (Università di Bologna, Italy)   Antonio Natali (Università di Bologna, Italy)   Alessandro Ricci (Università di Bologna, Italy)   Mirko Viroli (Università di Bologna, Italy)  Abstract: This paper describes a Java-based framework for developing componentbased software systems supporting adaptation with logic laws and considering component interactions as a first-class aspect.  On the one side, the framework makes it possible to specify the logic of interaction at the component-level, in terms of input and output interfaces, the events generated and observed by a component, and related information about the management of the control flow. On the other side, it is possible to specify the logic of interaction at the inter-component level, providing a modelling and linguistic support for designing and (dynamically) programming the glue among the components, enabling general forms of adaptation, observation and construction of the interaction space.  As a result, the framework supports the adaptation of components at different levels: from interoperability among heterogeneous and unknown components, to the support for dynamic introduction, removal and update of components, to general coordination patterns, such as workflow.  The framework uses first-order logic as the reference computational model for describing and defining the logic of interaction: the modalities adopted by components to interact, the adaptation laws gluing the components and the interaction events occurring in the system are expressed as facts and rules. They compose the (evolving) logic theories describing and defining the interaction at the system level, and can be observed and controlled at runtime to allow dynamic re-configurability.               Keywords: logic programming, software adaptation, software component               Categories: D.1.5, D.1.6, D.2.11, D.2.2  
14|13||Composition and Run-time Adaptation of Mismatching Behavioural Interfaces|  Javier Cámara (University of Málaga, Spain)   Gwen Salaün (University of Málaga, Spain)   Carlos Canal (University of Málaga, Spain)  Abstract: Reuse of software entities such as components or Web services raise composition issues since, most of the time, they present mismatches in their interfaces. These mismatches may appear at different interoperability levels: signature, behaviour, quality of service and semantics. The behavioural level is crucial and behavioural mismatches must all be corrected, although this is a difficult task. So far, most adaptation approaches which deal with behavioural mismatches work on a fixed description of components where all ports involved in their interfaces are known at design-time. Here, we focus on systems in which composition is affected by run-time behaviour of the system. This is the case in pervasive systems where a client interacts with a specific service by using new communication channels dynamically created. These are of special interest to allow private interaction between several entities.  In this article, we define a behavioural model inspired by the ss-calculus to specify behavioural interfaces of components. Our model is particularly suitable for creating new channels dynamically, also taking concurrent behaviours into account. The dynamic nature of the systems we are dealing with obliges to apply adaptation at run-time, avoiding at the same time the costly generation of full descriptions of adaptors. The main contribution of this article is an adaptation engine that allows the dynamic creation of channels and applies at run-time a composition specification built at designtime. All the underlying formal foundations of our proposal have been implemented in a prototype tool that has been applied to system designs. Aspect-Oriented Programming has been studied as well, as a way to implement our engine for further application to real software components.               Keywords: aspect-oriented programming, behavioural interfaces, components, composition, mismatch, run-time adaptation, transition systems, validation               Categories: D.2, D.2.1, D.2.10, D.2.11, D.2.13, D.2.2  
14|13||A Safe Dynamic Adaptation Framework for Aspect-Oriented Software Development|  Miguel A. Pérez-Toledano (University of Extremadura, Spain)   Amparo Navasa (University of Extremadura, Spain)   Juan M. Murillo (University of Extremadura, Spain)   Carlos Canal (University of Málaga, Spain)  Abstract: One focus of current software development is the   re-use of components in the construction of systems. Software   Adaptation facilitates the consequent need to adapt these components   to the new environment by employing adaptors which are obtained   automatically and hence with a certain guarantee of suitability,   from formal descriptions of the interface behaviour. One appropriate   technique for Software Adaptation is Aspect-Oriented Programming   (AOP) which makes use of aspects to facilitate the dynamic   adaptation of components transparently and non-intrusively.   However, owing to the way that aspects are integrated, these can   unexpectedly modify the functionality of the system, and   consequently completely alter its semantics.  It is hence necessary   to study the final behaviour of the system to ensure its correctness   after adding aspects for its adaptation. This study must go beyond   just detecting problems at the protocol level, to analyze the   potential semantic problems.  This is the main focus of the present   communication.  We start from the Unified Modeling Language (UML   2.0) specification of both the initial system and the aspects.  This   specification is validated by generating an algebraic Calculus of   Communicating Systems (CCS) description of the system.  Next,   extended (finite) state machines are automatically generated to   verify, simulate, and test the modeled system's behaviour.  The   result of that process can also be compared with the behaviour of   the new running system.  To facilitate this task, we propose   grouping components so as to centre the study on the points actually   affected by the behaviour of the aspects.               Keywords: CCS, UML, aspect-oriented programming, extended state machines, interaction pattern specification, software adaptation               Categories: D.2.7, I.6.4, I.6.5  
14|13||Adapting Web 1.0 User Interfaces to Web 2.0 Multidevice User Interfaces using RUX-Method|  Juan Carlos Preciado (Universidad de Extremadura, Spain)   Marino Linaje (Universidad de Extremadura, Spain)   Fernando Sanchez-Figueroa (Universidad de Extremadura, Spain)  Abstract: The development of Web applications, both   functionality and Web User Interfaces (UIs), has been facilitated   over the last few years using Web models and methodologies. However,   new requirements that overcome traditional HTML-based Web 1.0 User   Interfaces limits have arisen. Developers and tool vendors have   answered these limits introducing Rich Internet Applications   (RIAs). RIA technologies provide Web 2.0 UI capabilities such as   high interactivity and native multimedia support among   others. Currently, numerous developers are adapting many of their   legacy Web 1.0 applications to Web 2.0 introducing Web 2.0 UI   capacities while maintaining the business logic. Nevertheless, there   is a lack of methodologies to support this adaptation process. In   this paper we show how to use a model driven method called   RUX-Method for the systematic adaptation of existing Web 1.0 UIs to   Web 2.0 multidevice UIs. This method focuses on new UI capabilities   provided by RIAs while taking advantage of functionality already   provided by existing Web models. The proposal follows a common UI   design for all the devices and an ad-hoc design approach for each   device attending to its specific features.               Keywords: adaptation techniques, web engineering               Categories: H.3.5, H.5.2, H.5.4  
14|14|http://www.jucs.org/jucs_14_14|Knowledge Processing in Intelligent Systems|
14|14||Intelligence Metasynthesis and Knowledge Processing in Intelligent Systems|  Longbing Cao (University of Technology, Australia)   Ngoc Thanh Nguyen (Wroclaw University of Technology, Poland)  Abstract: Intelligence and Knowledge play more and more important roles in building complex intelligent systems, for instance, intrusion detection systems, and operational analysis systems. Knowledge processing in complex intelligent systems faces new challenges from the increased number of applications and environment, such as the requirements of representing domain and human knowledge in intelligent systems, and discovering actionable knowledge on a large scale in distributed web applications. In this paper, we discuss the main challenges of, and promising approaches to, intelligence metasynthesis and knowledge processing in open complex intelligent systems. We believe (1) ubiquitous intelligence, including data intelligence, domain intelligence, human intelligence, network intelligence and social intelligence, is necessary for OCIS, which needs to be meta-synthesized; and (2) knowledge processing should pay more attention to developing innovative and workable methodologies, techniques, tools and systems for representing, modelling, transforming, discovering and servicing the uncertain, large-scale, deep, distributed, domain-oriented, human-involved, and actionable knowledge highly expected in constructing open complex intelligent systems. To this end, the meta-synthesis of ubiquitous intelligence is an appropriate way in designing complex intelligent systems. To support intelligence meta-synthesis, m-interaction can play as the working mechanism to form m-spaces as problem-solving systems. In building such m-spaces, advancement in knowledge processing is necessary.               Keywords: intelligence meta-synthesis, knowledge processing, m-interaction, m-space, open complex intelligent systems               Categories: I.2.11, I.2.4, M.4  
14|14||The APS Framework For Incremental Learning of Software Agents|"  Damian Dudek (The University of Information Technology and Management ""Copernicus"", Poland)  Abstract: Adaptive behavior and learning are required of   software agents in many application domains. At the same time agents   are often supposed to be resource-bounded systems, which do not   consume much CPU time, memory or disk space. In attempt to satisfy   both requirements, we propose a novel framework, called APS   (standing for Analysis of Past States), which provides agent with   learning capabilities with respect to saving system resources. The   new solution is based on incremental association rule mining and   maintenance. The APS process runs periodically in a cycle, in which   phases of agent's normal performance intertwine with learning   phases. During the former ones an agent stores observations in a   history. After a learning phase has been triggered, the history   facts are analyzed to yield new association rules, which are added   to the knowledge base by the maintenance algorithm. Then the old   observations are removed from the history, so that in the next   learning runs only recent facts are processed in search of new   association rules. Keeping the history small can save both   processing time and disk space as compared to batch learning   approaches.               Keywords: incremental methods, software agents, statistical learning, web browsing assistant               Categories: I.2.6, I.5.0, M.0, M.3  "
14|14||Market Microstructure Patterns Powering Trading and Surveillance Agents|  Longbing Cao (University of Technology, Australia)   Yuming Ou (University of Technology, Australia)  Abstract: Market Surveillance plays important mechanism   roles in constructing market models. From data analysis perspective,   we view it valuable for smart trading in designing legal and   profitable trading strategies and smart regulation in maintaining   market integrity, transparency and fairness. The existing trading   pattern analysis only focuses on interday data which discloses   explicit and high-level market dynamics. In the mean time, the   existing market surveillance systems available from large exchanges   are facing crucial challenges of diversified, dynamic, distributed   and cyber-based misuse, mis-disclosure and misdealing of   information, announcement and orders in one market or crossing   multiple markets. Therefore, there is a crucial need to develop   innovative and workable methods for smart trading and   surveillance. To deal with such issues, we propose the innovative   concept microstructure pattern analysis and corresponding approaches   in this paper. Microstructure pattern analysis studies trading   behaviour patterns of traders in market microstructure data by   utilizing market microstructure knowledge. The identified market   microstructure patterns are then used for powering market trading   and surveillance agents for automatically detecting/designing   profitable and legal trading strategies or monitoring abnormal   market dynamics and traders behaviour. Such trading/surveillance   agent-driven market trading/surveillance systems can greatly enhance   the analytical, discovery and decision-support capability of market   trading/surveillance than the current predefined rule/alert-based   systems.               Keywords: agents, data mining, market microstructure pattern, market surveillance               Categories: H.1.1, I.2.6, M.0, M.1  
14|14||Non-repudiation Mechanism of Agent-based Mobile Payment Systems: Perspectives on Wireless PKI|  Chung-Ming Ou (Kainan University, Taiwan)   Chung-Ren Ou (Hsiuping Institute of Technology, Taiwan)  Abstract: Non-repudiation of a mobile payment transaction ensures that when a buyer (B) sends some messages to a seller (S), neither B nor S can deny having participated in this transaction. An evidence of a transaction is generated by wireless PKI (WPKI) mechanism such that B and S cannot repudiate sending and receiving the purchase order respectively. Broker generates a mobile agent for B which carries encrypted purchase order to S. A trusted third party (TTP) acts as a lightweight notary for evidence generations. One advantage of this agent-based non-repudiation protocol is to reduce inconvenience for mobile clients such as connection time and search for suitable merchant servers, etc.; it provides necessary security mechanisms for fair mobile payment transactions.               Keywords: WPKI, mobile agent, non-repudiation, security, trusted third party               Categories: D.4.6, E.3, K.6.5  
14|14||An Optimization of CDN Using Efficient Load Distribution and RADS Caching Algorithm|  Yun Ji Na (Advanced Institute of Convergence Information Technology, South Korea)   Sarvar Abdullaev (Dongguk University, South Korea)   Franz I. S. Ko (Dongguk University, South Korea)  Abstract: Nowadays, while large-sized multimedia objects   are becoming very popular throughout the Internet, one of the   important issues appears to be the acceleration of content delivery   network (CDN) performance. CDN is a web system that delivers the web   cached objects to the client and accelerates the web   performance. Therefore the performance factor for any CDN is vital   factor in determining the quality of services. The performance   improvement can be achieved through load balancing technique, so the   server load could be distributed to several clustered groups of   machines and processed in parallel. Also the performance of CDN   heavily depends on caching algorithm which is used to cache the web   objects. This study investigates a method that improves the   performance of delivering multimedia content through CDN while using   RADS algorithm for caching large-sized objects separately from   small-sized ones. We will also consider the efficient distribution   of requests outgoing from local servers in order to balance the CDN   load. This method uses various types of factors such as CPU   processing time, I/O access time and Task Queue between nearby   servers. At the end of the paper, we will see the experimental   results derived from implementing the proposed optimization   technique and observe how it could contribute to the effectiveness   of CDN.               Keywords: caching algorithm, content delivery network, divided cache scope, load balancing               Categories: C.4, H.3  
14|14||Intelligent Resource Exchanges: Solutions and Pathways in a Workforce Allocation Problem|  Botond Virginas (Intelligent Systems Lab, British Telecom, United Kingdom)   Marian Ursu (University of London, United Kingdom)   Edward Tsang (University of Essex, United Kingdom)   Gilbert Owusu (Intelligent Systems Lab, British Telecom, United Kingdom)   Chris Voudouris (Intelligent Systems Lab, British Telecom, United Kingdom)  Abstract: This paper considers the problem of resource   allocation in the service industries approached from an agent-based   perspective. Agent technologies seem to be well suited to this   domain by providing a distributed environment, are network centric,   semi-autonomous and collaborative and can communicate with each   other to achieve better optimisation with little human   intervention. The paper describes the context of this solution, a   general power model and several pathways with corresponding example   implementations with results and discussion The novelty of the   solution resides in the fact that it is a natural and versatile   formulation that combines an agent-based model with various   artificial intelligence and operations research techniques such as   rule-based expressions of allocation strategies and multi-criteria   optimisation expressions of allocation objectives.               Keywords: case studies and reports on deployments, e-business agents, multi-agent planning               Categories: D.0, D.1.1, D.1.5, D.2.2, D.2.3, D.2.6, D.2.7  
14|14||Anti-Crisis Management of City Traffic Using Agent-Based Approach|  Jarosław Koźlak (AGH University of Science and Technology, Poland)   Grzegorz Dobrowolski (AGH University of Science and Technology, Poland)   Marek Kisiel-Dorohinicki (AGH University of Science and Technology, Poland)   Edward Nawarecki (AGH University of Science and Technology, Poland)  Abstract: The paper presents a multi-agent system for   modelling and optimising city traffic. Our attention is focused on the   prevention of crisis situations and detection of anomalies. Analysed   critical situations include traffic jams, whereas an anomaly is when   there is a decrease in average vehicle velocity in the whole city or   its part. The methods of crisis situation prevention are based on   the choice and configuration of the appropriate algorithms of city   light management or on modification of intersection and road network   topologies.               Keywords: city traffic modelling, multi-agent systems, traffic ligh optimization               Categories: I.2  
14|14||Implementation of a Prototype Positioning System for LBS on U-campus|  Jaegeol Yim (Dongguk University, Republic of Korea)   Ilseok Ko (Dongguk University, Republic of Korea)   Jaesu Do (Dongguk University, Republic of Korea)   Jaehun Joo (Dongguk University, Republic of Korea)   Seunghwan Jeong (Dongguk University, Republic of Korea)  Abstract: Location-based service is one of the most   popular buzzwords in the field of U-cities. Positioning a user is an   essential ingredient of a location-based system in a U-city. For   outdoor positioning, GPS based practical solutions have been   introduced. However, the measurement error of GPS is too big for it   to be used for U-campus services, because the size of a campus is   smaller than that of a city. We propose the Relative-Interpolation   Method to improve the accuracy of outdoor positioning. However,   indoor positioning is also necessary for a U-campus because the GPS   signal is not available inside buildings. For indoor positioning,   various systems including Cricket, Active Badge, and so on have been   introduced. These methods require special equipment dedicated to   positioning. Our method does not require such equipment because it   determines the users position based on the received signal strength   indicators (RSSIs) from access points (AP) which are already   installed for WLAN. The algorithm we use for indoor positioning is a   kind of fingerprinting method. However, our algorithm builds a   decision tree instead of a look-up table in the   off-line phase. Therefore, the proposed method is   faster than the existing indoor positioning methods in the   real-time phase. We integrated our indoor and   outdoor positioning methods and implemented a prototype   indoor-outdoor positioning system on a laptop. The experimental   results are discussed in this paper. In implementing the prototype,   we also implemented a C# library function which can be used to read   the RSSIs from the APs.               Keywords: LBS, decision tree, fingerprinting method, positioning, ubiquitous-campus               Categories: H.1.2, H.3.3, H.4.2, I.4.3, I.4.4  
14|14||An Application of Meta Search Agent System Based on Semantized  Tags for Enhanced Web Searching|  Chonggun Kim (Yeungnam University, Korea)   Jae-Youn Jung (Yeungnam University, Korea)   Hyeon-Cheol Zin (Yeungnam University, Korea)   Jason J. Jung (Yeungnam University, Korea)  Abstract: Web searching techniques have been investigated   and implemented in many aspects.Particularly, in case of   personalization, more important issue is how to manipulate the   results retrieved from search engines for better user   understandability and satisfaction. Such manipula-tion processes are   i) ranking the results in accordance with user   relevance, and ii) exchangingthe results between   users who have similar tastes. Thus, our work has been mainly   focusing on relevance-based ranking mechanism as well as sharing   schemes for the results retrieved from het-erogeneous web   information sources. In this paper, we propose a hybrid model for   meta search agent systems with three main functionalities, i.e.,   i) URL filtering method for preprocessing,   ii) tag-based information conceptualization   scheme for ranking, and iii) ontology-based   stan-dardization scheme for sharing. It means that the proposed meta   search agent model exploits semantized tags to formalize and share   heterogeneous information obtained from multiple searchengines and   to finally maintain the shared information. Within the tag-based   information space, a conceptual distance between retrieval interest   and search results can be efficiently computed. Byconducting some   experimentations, we have shown the semantized tag model can   conceptualize the retrieved results, and make them sharable. We also   compare performance of the proposedsystem with hyperlink-based   methodologies.               Keywords: information searching, meta searching, ontology, semantiization               Categories: H.1.1, H.3.5, I.2.11  
14|14||Tabu Search on GPU|  Adam Janiak (Wroclaw University of Technology, Poland)   Wladyslaw Janiak (Wroclaw University of Technology, Poland)   Maciej Lichtenstein (Wroclaw University of Technology, Poland)  Abstract: Nowadays Personal Computers (PCs) are often   equipped with powerful, multi-core CPU. However, the processing   power of the modern PC does not depend only of the processing power   of the CPU and can be increased by proper use of the GPGPU,   i.e. General-Purpose Computation Using Graphics Hardware. Modern   graphics hardware, initially developed for computer graphics   generation, appeared to be flexible enough for general-purpose   computations. In this paper we present the implementation of two   optimization algorithms based on the tabu search technique, namely   for the traveling salsesman problem and the flow shop scheduling   problem. Both algorithms are implemented in two versions and   utilize, respectively, multi-core CPU, and GPU. The extensive   numerical experiments confirm the high computation power of GPU and   show that tabu search algorithm run on modern GPU can be even 16   times faster than run on modern CPU.               Keywords: flow shop, graphics hardware, tabu search, traveling salesman               Categories: I.3.6, I.3.m  
14|14||A Novel Multi-Layer Level Set Method for Image Segmentation|  Xiao-Feng Wang (Chinese Academy of Sciences, China)   De-Shuang Huang (Chinese Academy of Sciences, China)  Abstract: In this paper, a new multi-layer level set   method is proposed for multi-phase image segmentation. The proposed   method is based on the conception of image layer and improved   numerical solution of bimodal Chan-Vese model. One level set   function is employed for curve evolution with a hierarchical form in   sequential image layers. In addition, new initialization method and   more efficient computational method for signed distance function are   introduced. Moreover, the evolving curve can automatically stop on   true boundaries in single image layer according to a termination   criterion which is based on the length change of evolving   curve. Specially, an adaptive improvement scheme is designed to   speed up curve evolution process in a queue of sequential image   layers, and the detection of background image layer is used to   confirm the termination of the whole multi-layer level set evolution   procedure. Finally, numerical experiments on some synthetic and real   images have demonstrated the efficiency and robustness of our   method. And the comparisons with multi-phase Chan-Vese method also   show that our method has a less time-consuming computation and much   faster convergence.               Keywords: curve evolution, image layer, level set, multi-layer, segmentation, termination criterion               Categories: G.1.8, I.4.6  
14|15|http://www.jucs.org/jucs_14_15|Evolutionary Optimization for Intelligent Systems Design|
14|15||Automatic Construction of Fuzzy Rule Bases: a further Investigation into two Alternative Inductive Approaches|  Marcos Evandro Cintra (Federal University of São Carlos, Brazil)   Heloisa Arruda Camargo (Federal University of São Carlos, Brazil)   Estevam R. Hruschka (Federal University of São Carlos, Brazil)   Maria do Carmo Nicoletti (Federal University of São Carlos, Brazil)  Abstract: The definition of the Fuzzy Rule Base is one of   the most important and difficult tasks when designing Fuzzy   Systems. This paper discusses the results of two different hybrid   methods, previously investigated, for the automatic generation of   fuzzy rules from numerical data. One of the methods, named   DoC-based, proposes the creation of Fuzzy Rule Bases using genetic   algorithms in association with a heuristic for preselecting   candidate rules based on the degree of coverage. The other, named   BayesFuzzy, induces a Bayesian Classifier using a dataset previously   granulated by fuzzy partitions and then translates it into a Fuzzy   Rule Base. A comparative analysis between both approaches focusing   on their main characteristics, strengths/weaknesses and easiness of   use is carried out. The reliability of both methods is also compared   by analyzing their results in a few knowledge domains.               Keywords: Bayesian classification, Bayesian networks, fuzzy logics, genetic fuzzy systems, machine learning               Categories: I.2, I.2.6  
14|15||Parallel Strategies for Stochastic Evolution|  Sadiq M. Sait (King Fahd University of Petroleum & Minerals, Saudi Arabia)   Khawar S. Khan (King Fahd University of Petroleum & Minerals, Saudi Arabia)   Mustafa I. Ali (King Fahd University of Petroleum & Minerals, Saudi Arabia)  Abstract: This paper discusses the parallelization of   Stochastic Evolution (StocE) metaheuristic, for a distributed   parallel environment. VLSI cell placement is used as an optimization   problem. A comprehensive set of parallelization approaches are   tested and an effective strategy is identified in terms of two   underlying factors: workload division and the effect of   parallelization on metaheuristic's search intelligence. The   strategies are compared with parallelization of another similar   evolutionary metaheuristic called Simulated Evolution (SimE). The   role of the two mentioned underlying factors is discussed in   parallelization of StocE.               Keywords: VLSI cell placement, cluster computing, combinatorial optimization, parallel metaheuristics, simulated evolution, stochastic evolution               Categories: F.1.2, I.2.11, I.2.8  
14|15||A Hybrid Transgenetic Algorithm for the Prize Collecting Steiner Tree Problem|  Elizabeth Ferreira Gouvêa Goldbarg (Federal University of Rio Grande do Norte, Brazil)   Marco César Goldbarg (Federal University of Rio Grande do Norte, Brazil)   Cristine Cunha Schmidt (Federal University of Rio Grande do Norte, Brazil)  Abstract: Evolutionary algorithms are effective search tools for tackling difficult optimization problems. In this paper an algorithm based on living processes where cooperation is the main evolutionary strategy is applied to the Prize Collecting Steiner Tree Problem, an NP-hard combinatorial optimization problem. The Transgenetic Algorithm presented here is hybridized with path-relinking. Computational results of an experiment performed with benchmark instances are reported. The results obtained for the Prize Collecting Steiner Tree Problem with the application of the hybrid Transgenetic Algorithm are compared with the results of three effective approaches presented previously. The computational experiment shows that the proposed approach is very competitive concerning both quality of solution and processing time.               Keywords: Prize Collecting Steiner Tree Problem, evolutionary algorithm, path-relinking, transgenetic algorithm               Categories: G.2.3, I.2.8  
14|15||Bus Network Optimization with a Time-Dependent Hybrid Algorithm|  Ana C. Olivera (Universidad Nacional del Sur, Argentina)   Mariano Frutos (Universidad Nacional del Sur, Argentina)   Jessica A. Carballido (Universidad Nacional del Sur, Argentina)   Nélida B. Brignole (Nacional del Sur, Argentina)  Abstract: This paper describes a new hybrid technique that   combines a Greedy Randomized Adaptive Search Procedure (GRASP) and a   genetic algorithm with simulation features in order to solve the   Bus-Network Scheduling Problem (BNSP). The GRASP is used as an   initialization method to find the routes between bus stops. T he   Genetic Algorithm is used to find the whole configuration of the bus   network, together with a simulation tool that finds the values of   the environmentally dependent dynamic variables. The new method was   tested with an academic case of study, and the results clearly   satisfy the requirements of both the transport user and the   transport operator.               Keywords: Bus Network Scheduling Problem, hybrid genetic algorithms, optimization               Categories: I.2.m, I.6.3  
14|15||Quantum-Inspired Evolutionary State Assignment for Synchronous Finite State Machines|  Marcos Paulo Mello Araujo (State University of Rio de Janeiro, Brazil)   Nadia Nedjah (State University of Rio de Janeiro, Brazil)   Luiza de Macedo Mourelle (State University of Rio de Janeiro, Brazil)  Abstract: Synchronous finite state machines are very important for digital sequential designs. Among other important aspects, they represent a powerful way for synchronizing hardware components so that these components may cooperate adequately in the fulfillment of the main objective of the hardware design. In this paper, we propose an evolutionary methodology to solve one of the problems related to the design of finite state machines. We optimally solve the state assignment NP -complete problem using a quantum inspired evolutionary algorithm. This is motivated by the fact that with an optimal state assignment one can physically implement the state machine using a minimal hardware area and response time.               Keywords: Quantum computation, finite state machine, state assignment problem               Categories: B.1.2, B.2.2, I.2.2  
14|15||Optimal Sensor Network Layout Using Multi-Objective Metaheuristics|  Guillermo Molina (University of Málaga, Spain)   Enrique Alba (University of Málaga, Spain)   El-Ghazali Talbi (University of Lille, France)  Abstract: Wireless Sensor Networks (WSN) allow, thanks to   the use of small wireless devices known as sensor nodes, the   monitorization of wide and remote areas with precision and liveness   unseen to the date without the intervention of a human operator. For   many WSN applications it is fundamental to achieve full coverage of   the terrain monitored, known as sensor field. The   next major concerns are the energetic efficiency of the network, in   order to increase its lifetime, and having the minimum possible   number of sensor nodes, in order to reduce the network cost. The   task of placing the sensor nodes while addressing these objectives   is known as WSN layout problem. In this paper we address a WSN   layout problem instance in which full coverage is treated as a   constraint while the other two objectives are optimized using a   multiobjective approach. We employ a set of multi-objective   optimization algorithms for this problem where we define the energy   efficiency and the number of nodes as the independent optimization   objectives. Our results prove the efficiency of multi-objective   metaheuristics to solve this kind of problem and encourage further   research on more realistic instances and more constrained scenarios.               Keywords: metaheuristics, multiobjective optimization, sensor networks               Categories: G.1.6, I.2.8  
14|15||GADYM - A Novel Genetic Algorithm in Mechanical Design Problems|  Khadiza Tahera (Monash University, Australia)   Raafat N. Ibrahim (Monash University, Australia)   Paul B. Lochert (Monash University, Australia)  Abstract: T his paper proposes a variant of genetic   algorithm - GADYM, Genetic Algorithm with Gender-Age   structure, DYnamic parameter tuning and Mandatory self perfection   scheme.  The motivation of this algorithm is to increase   the diversity throughout the search procedure and to ease the   difficulties associated with the tuning of GA parameters and   operators. To promote diversity , GADYM combines the concept of   gender and age in individuals of a traditional Genetic Algorithm and   implements the self perfection scheme through sharing. To ease the   parameter tuning process, the proposed algorithm uses dynamic   environment in which heterogeneous crossover and selection   techniques are used and parameters are updated based on   deterministic rules. Thus, GADYM uses a combination of genetic   operators and variable parameter values whereas a traditional GA   uses fixed values of those. The experim ental results of the   proposed algorithm based on a mechanical design problem show   promising result.               Keywords: genetic algorithm, optimization, search               Categories: F.2.0, G.1.6, I.2.8  
14|15||Two Step Swarm Intelligence to Solve the Feature Selection Problem|  Yudel Gómez (Universidad Central de Las Villas, Cuba)   Rafael Bello (Universidad Central de Las Villas, Cuba)   Amilkar Puris (Universidad Central de Las Villas, Cuba)   María M. García (Universidad Central de Las Villas, Cuba)   Ann Nowe (Vrije Universiteit Brussel, Belgium)  Abstract: In this paper we propose a new approach to Swarm   Intelligence called Two-Step Swarm Intelligence. The basic idea is   to split the heuristic search performed by agents into two   stages. In the first step the agents build partial solutions which,   are used as initial states in the second step. We have studied the   performance of this new approach for the Feature Selection Problem   by using Ant Colony Optimization and Particle Swarm   Optimization. The feature selection is based on the reduct concept   of the Rough Set Theory. Experimental results obtained show that   Two-step approach improves the performance of ACO and PSO   metaheuristics when calculating reducts in terms of computation time   cost and the quality of reducts.               Keywords: Ant Colony Optimization, Feature Selection Problem, Particle Swarm Optimization, Rough Set Theory, Swarm Intelligence, Two-Step Swarm Intelligence               Categories: I.2.6, I.2.8, I.5.1  
14|16|http://www.jucs.org/jucs_14_16|Human-Computer Interaction Research and Development Challenges|
14|16||The State of HCI in Ibero-American Countries|  Toni Granollers (University of Lleida, Spain)   César A. Collazos (University of Cauca, Spain)   María Paula González (University of Lleida, Spain)  Abstract: Human-Computer Interaction (HCI) is a   challenging discipline that is currently concerned with the design,   implementation and evaluation of interactive systems for human use,   as well as the study of major phenomena surrounding them. Indeed,   interdisciplinary communities formed by scientists, university   teachers and students, people coming from the industry and customers   related to HCI are emerging in different parts of the world. In   particular, this article overviews the HCI community in the   Ibero-American context, which involves hundreds of millions of   people working or studying in HCI, whose cultural background is   primarily associated with the Spanish and Portuguese languages and   cultures, regardless of ethnic and geographical differences. Our   final goal is to improve the visibility of this particular HCI   community, enhancing the self awareness of its members and their   individual motivation and future exchanges.               Keywords: human-computer interaction               Categories: A.1, H.5.2  
14|16||Cognitive Ergonomics in Interface Design - Discussion of a Moving Science|  Gerrit C. van der Veer (Open University, the Netherlands)  Abstract: Cognitive Ergonomics is discussed as a   systematic base for user interface design. The history of the   discipline, explicitly existing now for about 25 years, is   discussed, from participatory design, through various flavors of   user centered design, to contextual design. Several persistent   misunderstandings regarding the need for user interface design are   analyzed. The concept of activity centered design is proposed as   state of the art approach, and several techniques that support this   paradigm are mentioned and illustrated.               Keywords: cognitive ergonomics, user interface design               Categories: H.1.2, H.5.2, K.6.1  
14|16||Cognitive Ergonomics in Interface Development Evaluation|"  José Cañas (University of Granada, Spain)  Abstract: Cognitive Ergonomics is a discipline that   contributes with its knowledge to construct better machines in the   sense of being easier to use by human beings. Cognitive Ergonomists   perform a cognitive analysis of interaction to: (1) shorten the time   to accomplish interaction tasks; (2) reduce the number of mistakes   made by humans; (3) reduce learning time; and (4) improve peoples   satisfaction with a system. An appropriate methodology for   performing this cognitive analysis of interaction could be based on   what I call the ""Principle of Mutual Dependency"" [Cañas et al   2004]. This principle determines that: (1) The optimal interface   functions will be those that fit the human cognitive functions   involved in the task; (2) The human cognitive functions that are   involved in the task depend on the interface functions; (3) The   modification, replacement, or introduction of a new interface   function implies the adaptation of the human cognitive functions;   (4) The development (e.g., learning) or limitation (e.g., Elderly   users) of the human cognitive functions will imply limitations on   the possible interface functions. I will describe this principle   with examples from research projects in which our research group   participates.               Keywords: cognitive ergonomics, interface evaluation               Categories: H.1.2  "
14|16||Cultural Factors in a Mobile Phone Adoption and Usage Model|  Judy van Biljon (University of South Africa, South Africa)   Paula Kotzé (University of South Africa, South Africa)  Abstract: In human-computer interaction and computing, mobile phone usage is mostly addressed from a feature-driven perspective, i.e. which features do a certain user group use, and/or a usability perspective, i.e. how do they interact with these features. Although the feature driven and usability focus carry value, it is not the full picture. There is also an alternative or wider perspective: mobile phone use is influenced by demographic, social, cultural, and contextual factors that complicate the understanding of mobile phone usage. Drawing on concepts and models from sociology, computer-supported cooperative work, human-computer interaction and marketing, we researched the influence of culture on mobile phone adoption using interviews and two surveys. The contribution of this research is a model that includes culture as one of the factors that influence mobile phone adoption and usage. The proposed model represents the influence of mediating factors and determining factors on actual mobile phone use. The proposed model has been evaluated from both a qualitative and quantitative perspective.               Keywords: computer-supported cooperative work, determining factors, human-computer interaction, human-computer interaction marketing, mediating factors, mobile phone usage, sociology, usage intensity, usage variety and usage breath               Categories: H.1.2, J.4  
14|16||Designing Collaborative User Interfaces for Ubiquitous Applications Using CIAM: The AULA Case Study|  Maximiliano Paredes (Rey Juan Carlos University, Spain)   Ana I. Molina (University of Castilla, Spain)   Miguel A. Redondo (University of Castilla, Spain)   Manuel Ortega (University of Castilla, Spain)  Abstract: In this article we explain how we apply the CIAM   methodology based on the CIAN notation in order to generate user   interfaces in collaborative applications. CIAM has been applied   successfully in the development of desktop applications, such as   Domosim-TPC, demonstrating its effectiveness in the definition of   user interfaces for collaborative applications where a shared   context is required. We present the AULA system modeled by means of   CIAM. The results in the application of this Methodology show the   necessity to include those aspects closely related with context   modeling and the synchronization of contents; that is why we make an   outline of the way to take into account these characteristics as a   future work.               Keywords: CSCW, human - computer interaction, mobile computing, ubiquitous computing, user interfaces               Categories: H.5.2, H.5.3, K.3.1  
14|16||Supporting the Development of Accessible Web Applications|  Myriam Arrue (University of the Basque Country, Spain)   Markel Vigo (University of the Basque Country, Spain)   Julio Abascal (University of the Basque Country, Spain)  Abstract: The aim of this paper is to review the best   known methodologies for web applications development as well as the   existing supporting tools and techniques from an   accessibility-centric perspective. To this end, a number of   development methodologies with their respective characteristics are   described: model-based methodologies, user-centred processes,   usability engineering methodologies and accessibility engineering   methodologies. Some of these methodologies are provided with   specific supporting tools which facilitate the accomplishment of   specified tasks. However, there are methodologies which are not   supported by specific tools. Therefore, web developers must deal   with diverse tools in order to perform the corresponding   activities. In this context, the development of accessible web   applications is even more difficult. This paper concludes that there   is not currently a holistic development framework to be used   throughout the whole development process. Our contribution relies on   a set of tools that support the different phases of the   process. Since these tools are developed upon a common   methodological basis, a high rate of interoperability is   obtained. This cohesion allows their integration in a comprehensive   framework so that the development of accessible web applications is   facilitated.               Keywords: Web accessibility, Web applications, Web engineering, development process, development supporting tools               Categories: H.3.5, H.5.2, H.5.4  
14|16||Intelligent Decision Support in Medicine: back to Bayes?|  Gitte Lindgaard (Carleton University, Canada)   Peter Egan (S4Potential, Canada)   Colin Jones (S4Potential, Canada)   Catherine Pyper (Carleton University, Canada)   Monique Frize (Carleton University, Canada)   Robin Walker (IWK Health Centre, Canada)   Craig Boutilier (University of Toronto, Canada)   Bowen Hui (University of Toronto, Canada)   Sheila Narasimhan (Carleton University, Canada)   Janette Folkens (Carleton University, Canada)   Bill Winogron (S4Potential, Canada)  Abstract: Decision Support Systems are proliferating   rapidly in many areas of human endeavour including clinical medicine   and psychology. While these are typically based on rule-based   systems, decision trees, or Artificial Neural Networks, this paper   argues that Bayes Theorem can be applied fruitfully to support   expert decisions both in dynamically changing situations requiring   the system progressively to adapt, and when this is not the   case. One example of each of these two types is given. One provides   diagnostic support for human decision makers; the other, an e-health   mental intervention system provides decision rules enabling it to   respond and provide the most appropriate training modules to input   from clients with changing needs. The contributions of psychological   research underlying both systems is summarized.               Keywords: Bayes' Theorem, Decision Support Systems (DSS), base rates, diagnostic error, e-health intervention, individuating information               Categories: H.1.2, H.4.2, I.2.1  
14|16||Learner Course Recommendation in e-Learning Based on Swarm Intelligence|  Ana-Belén Gil (University of Salamanca, Spain)   Francisco J. García-Peñalvo (University of Salamanca, Spain)  Abstract: This paper analyses aspects about the   recommendation process in distributed information systems. It   extracts similarities and differences between recommendations in   e-stores and the recommendations applied to an e-learning   environment. It also explains the phenomena of self-organization and   cooperative emergence in complex systems coupled with bio-inspired   algorithms to improve knowledge discovery and association   rules. Finally, the present recommendation is applied to e-learning   by proposing recommendation by emergence in a Multi-Agent System   architecture.               Keywords: E-learning, Swarm Intelligence, emergence, multi-agent system, recommendation               Categories: E.4, H.3, H.4, I.2, J.7  
14|17|http://www.jucs.org/jucs_14_17|Authoring of Adaptive and Adaptable Hypermedia|
14|17||ITS Domain Modelling with Ontology|  Brent Martin (University of Canterbury, New Zealand)   Antonija Mitrovic (University of Canterbury, New Zealand)   Pramuditha Suraweera (Carnegie Learning Inc, USA)  Abstract: Authoring ITS domain models is a difficult task   requiring many skills. We explored whether modeling ontology reduces   the problem by giving the students of an e-learning summer school   the task of developing the model for a simple domain in under sixty   minutes using ontology. Some students also used our tool to develop   a complete tutor in around eight hours, which is much faster than   they could be expected to author the system without the tool. The   results suggest this style of authoring can lead to very rapid ITS   development. We further extend the ontological approach with domain   schema: high-level abstractions that describe the semantics of the   domain model for a class of domains. Using domain schema reduces the   authoring effort to one of describing only those aspects that are   unique to this particular domain, and enables the ontology-based   approach to model domains with different semantic   requirements.               Keywords: authoring systems, constraint-based modeling, domain models, intelligent tutoring systems, ontology               Categories: L.1.0, L.1.3, L.2.0, L.3.0  
14|17||Improving AEH Courses through Log Analysis|  César Vialardi (Universidad de Lima, Peru)   Javier Bravo (Universidad Autónoma de Madrid, Spain)   Alvaro Ortigosa (Universidad Autónoma de Madrid, Spain)  Abstract: Authoring in adaptive educational hypermedia   environment is complex activity. In order to promote a wider   application of this technology, the teachers and course designers   need specific methods and tools for supporting their work. In that   sense, data mining is a promising technology. In fact, data mining   techniques have already been used in E-learning systems, but most of   the times their application is oriented to provide better support to   students; little work has been done for assisting adaptive   hypermedia authors through data mining. In this paper we present a   proposal for using data mining for improving an adaptive hypermedia   system.  A tool implementing the proposed approach is also   presented, along with examples of how data mining technology can   assist teachers.               Keywords: adaptive educational hypermedia, authoring support, data mining applications               Categories: I.2.6, J.7, K.3  
14|17||A Spiral Model for Adding Automatic, Adaptive Authoring to Adaptive Hypermedia|  Maurice Hendrix (The University of Warwick, United Kingdom)   Alexandra Cristea (The University of Warwick, United Kingdom)  Abstract: At present a large amount of research exists   into the design and implementation of adaptive systems. However, not   many target the complex task of authoring in such systems, or their   evaluation. In order to tackle these problems, we have looked into   the causes of the complexity. Manual annotation has proven to be a   bottleneck for authoring of adaptive hypermedia. One such solution   is the reuse of automatically generated metadata. In our previous   work we have proposed the integration of the generic Adaptive   Hypermedia authoring environment, MOT (My Online Teacher), and a   semantic desktop environment, indexed by Beagle++. A prototype,   Sesame2MOT Enricher v1, was built based upon this integration   approach and evaluated. After the initial evaluations, a web-based   prototype was built (web-based Sesame2MOT Enricher v2 application)   and integrated in MOT v2, conforming with the findings of the first   set of evaluations. This new prototype underwent another   evaluation. This paper thus does a synthesis of the approach in   general, the initial prototype, with its first evaluations, the   improved prototype and the first results from the most recent   evaluation round, following the next implementation cycle of the   spiral model [Boehm, 88].               Keywords: Adaptive Educational Hypermedia, CAF, RDF, authoring, evaluation, metadata, semantic desktop, semi-automatic adding               Categories: M.5, M.6, M.7, M.8  
14|17||Authoring Courses with Rich Adaptive Sequencing for IMS Learning Design|  Sergio Gutierrez-Santos (London Knowledge Lab, Birkbeck College, United Kingdom)   Abelardo Pardo (Carlos III University of Madrid, Spain)   Carlos Delgado Kloos (Carlos III University of Madrid, Spain)  Abstract: This paper describes the process of translating   an adaptive sequencing strategy designed using Sequencing Graphs to   the semantics of IMS Learning Design. The relevance of this   contribution is twofold. First, it combines the expressive power and   flexibility of Sequencing Graphs, and the interoperability   capabilities of IMS. Second, it shows some important limitations of   IMS specifications (focusing on Learning Design) for the sequencing   of learning activities.               Keywords: IMS Learning Design, sequencing, sequencing graph, translation               Categories: L.2.0, L.2.1, L.3.5  
14|17||Authoring Social-aware Tasks on Active Spaces|  Roberto F. Arroyo (Universidad de Granada, Spain)   Miguel Gea (Universidad de Granada, Spain)   José Luis Garrido (Universidad de Granada, Spain)   Pablo A. Haya (Universidad Autónoma de Madrid, Spain)   Rosa M. Carro (Universidad Autónoma de Madrid, Spain)  Abstract: Social-aware computing is an emerging trend   based on ubiquitous computing technologies and collaborative work. A   successful design demands a better understanding of group tasks,   adaptation mechanisms and support for dynamic changes in a nomadic   computing paradigm. This paper proposes the use of a hypermedia   model to describe and support group activities in intelligent   environments. The resulting system integrates adaptive context-aware   information on the basis of user/group models in order to provide a   structured access to dynamic task scheduling. In particular, we   propose the use of the calendar metaphor as an ongoing connection   between active spaces and collaborative tasks. This proposal   provides the appropriate support for an easier human coordination to   achieve common objectives in blended learning scenarios, and thus,   extending authoring social tasks to physical spaces.               Keywords: Active Spaces, Ambient Intelligence, Collaboration, Hypermedia Authoring, Social-aware computing, Task Scheduling               Categories: H.5.1, H.5.2, H.5.3, H.5.4, K.3  
14|17||A Standards-based Modelling Approach for Dynamic Generation of Adaptive Learning Scenarios|  Jesus G. Boticario (aDeNu Group, UNED, Spain)   Olga C. Santos (aDeNu Group, UNED, Spain)  Abstract: One of the key problems in developing standard   based adaptive courses is the complexity involved in the design   phase, especially when establishing the hooks for the dynamic   modelling to be performed at runtime. This is particularly critical   when the courses are based on adaptation-oriented learning   scenarios, where the full eLearning cycle (design, publication, use   and auditing) is considered. Based on the problems we experienced in   developing such scenarios with a reusable, platform independent,   objective-based approach in the aLFanet project we have established   an alternative framework in the ADAPTAPlan project, which focuses on   dynamically generating learning design templates with the support of   user modelling, planning and machine learning techniques. In   particular, in this paper we describe the problems we are tackling   and how we are relaxing the design work by automatically building   the IMS learning design of the course from a simplified set of data   required from the course authors.               Keywords: Semantic Web, adaptive eLearning, design templates, educational standards, learning activities, learning design, learning objects, metadata and learning, pedagogy guidelines, user modelling               Categories: H.3.5, H.4.2, H.5.4, J.7  
14|17||Authoring & Culture in Online Education|  Craig Stewart (University of London, United Kingdom)  Abstract: The Cultural Artefacts in Education (CAE)   questionnaire is used to determine the educational values of   different cultures. In this paper I examine the results for ten   countries, specifically focussing on their attitudes towards   adaptive hypermedia in an educational setting. These results can   inform the authoring process for adaptive systems & content,   with Adaptive Hypermedia systems being able to employ stereotype   adaptation to deliver content pre-adjusted to a learners cultural   background.               Keywords: CAE, adaptive educational hypermedia, adaptive hypermedia, cultural education, culture, hypermedia systems               Categories: H.2.8, H.5.4  
14|17||Creating Adaptive e-Learning Board Games for School Settings Using the ELG Environment|"  Symeon Retalis (Piraeus University of Educational Technology and Digital Systems, Greece)  Abstract: The use of digital games in education is well   documented in the literature. They have been used in preschool,   K-12, the university. A specific type of digital games is board   games. Adding board games to the educational process can lead to an   interactive stimulating learning experience. With a board game,   players often learn from one another while at the same time having   fun in a competitive environment. In this paper we propose the   ""ELG"" game, an e-learning board game that adopts the basic   elements of a racing board game but fosters students creativity,   problem-solving skills, and imagination as students are trying to   reach the end by improving their performance in a variety of   learning activities. The innovative feature of the ELG is that it   offers an adaptive authoring tool that enables teachers to customize   their games according to the needs, interests and motives of   students. The teacher enters hierarchically categorized learning   activities according to the learning goals of a course, sets the   rules and assesses the learning progress easily and simply. Students   participate in a discovery or exploration trying to reach the   goals. After attaining them their level of activities is upgraded   and they are challenged to reach the next learning goal. The dice in   ELG is not randomized but controlled by the teachers in order that   they can customize adaptive learning rules. The educational benefits   of exploiting ELG in the learning process is that the teacher can   define the levels of difficulty according to the students needs and   interests, facilitate and monitor the learning rate of each student,   combine a variety of evaluation techniques, and address potential   learning problems in a timely manner.               Keywords: adaptive environments, authoring tools, e-learning, game based learning               Categories: L.2.0, L.2.1, L.2.2, L.3.0, L.3.4, L.5.1  "
14|18|http://www.jucs.org/jucs_14_18|Further Advances in Document Engineering|
14|18||A Generic Architecture for the Conversion of Document Collections into Semantically Annotated Digital Archives|  Josep Lladós (Universitat Autònoma de Barcelona, Spain)   Dimosthenis Karatzas (Universitat Autònoma de Barcelona, Spain)   Joan Mas (Universitat Autònoma de Barcelona, Spain)   Gemma Sánchez (Universitat Autònoma de Barcelona, Spain)  Abstract: Mass digitization of document collections with   further processing and semantic annotation is an increasing activity   among libraries and archives at large for preservation, browsing and   navigation, and search purposes. In this paper we propose a software   architecture for the process of converting high volumes of document   collections to semantically annotated digital libraries. The   proposed architecture recognizes two sources of knowledge in the   conversion pipeline, namely document images and humans. The Image   Analysis module and the Correction and Validation module cover the   initial conversion stages. In the former information is   automatically extracted from document images. The latter involves   human intervention at a technical level to define workflows and to   validate the image processing results. The second stage, represented   by the Knowledge Capture modules requires information specific to   the particular knowledge domain and generally calls for expert   practitioners. These two principal conversion stages are coupled   with a Knowledge Management module which provides the means to   organise the extracted and acquired knowledge. In terms of data   propagation, the architecture follows a bottom-up process, starting   with document image units, called terms, and   progressively building meaningful concepts and   their relationships. In the second part of the   paper we describe a real scenario with historical document archives   implemented according to the proposed architecture.               Keywords: digital libraries, document image analysis andunderstanding, document mining, software architectures               Categories: H.3.1, H.3.2, H.3.7, J.4, J.5, M.0, M.4  
14|18||Systematic Characterisation of Objects in Digital Preservation: The eXtensible Characterisation Languages|  Christoph Becker (Vienna University of Technology, Austria)   Andreas Rauber (Vienna University of Technology, Austria)   Volker Heydegger (University of Cologne, Germany)   Jan Schnasse (University of Cologne, Germany)   Manfred Thaller (University of Cologne, Germany)  Abstract: During the last decades, digital objects have become the primary medium to create, shape, and exchange information. However, in contrast to analog objects such as books that directly represent their content, digital objects are not usable without a corresponding technical environment. The fast changes in these environments and in formats and technologies mean that digital documents have a short lifespan before they become obsolete. Digital preservation, i.e. actions to ensure longevity of digital information, thus has become a pressing challenge. The dominant strategies prevailing today are migration and emulation; for each strategy, different tools are available. When converting an object to a different representation, a validation of the content is needed to verify that the transformed objects are still authentically representing the same intellectual content. This validation so far is largely done manually, which is infeasible for large collections.  Preservation planning supports decision makers in reaching accountable decisions by evaluating potential strategies against well-defined requirements. Especially the evaluation of different migration tools for digital preservation has to rely on validating the converted objects and thus on an analysis of the logical structure and the content of documents. Existing approaches for characterising and describing objects do not attempt to fully extract the informational content of digital objects and thus are not suffficient for an in-depth validation of transformed content.  This paper describes the eXtensible Characterisation Languages (XCL) that support the automatic validation of document conversions and the evaluation of migration quality by hierarchically decomposing a document and representing documents from different sources in an abstract XML language. The description language XCDL provides an abstract representation of digital content in XML, while the extraction language XCEL allows an extraction engine to create such an abstract description by mapping file format structures to XCDL concepts.  We present the context of the development of these languages and tools and describe the overall concept and features of the languages. We further give examples and show how the languages can be applied to the evaluation of digital preservation solutions in the context of preservation planning.               Keywords: XML languages, content characterisation, digital libraries, digital preservation, evaluation, file conversion, file formats, migration, preservation planning               Categories: H.3.7, I.7  
14|18||Crime Scene Representation (2D, 3D, Stereoscopic Projection) and Classification|  Ricardo O. Abu Hana (Catholic University of Paraná, Brazil)   Cinthia O.A. Freitas (Catholic University of Paraná, Brazil)   Luiz S. Oliveira (Catholic University of Paraná, Brazil)   Flávio Bortolozzi (OPET College, Brazil)  Abstract: In this paper we provide a study about crime   scenes and its features used in criminal investigations. We argue   that the crime scene provides a large set of features that can be   used to corroborate the conclusions emitted by the experts. We also   propose a set of features to classify the violent crime considering   two classes: attack from inside or outside of the scene. The   classification stage is based on conventional MLP (Multiple-Layer   Perceptron) Neural Network and SVM (Support Vector Machine). The   experimental results reveal an error rate of 30.3% (MLP), 22.8%   (SVM-linear), and 19.4% (SVM-polynomial) using a database composed   of 400 crime scenes. This paper presents an experiment based on a   stereoscopic projection that allows to experts analyze and take   decisions about the crime scene and its dynamic.               Keywords: SVM, classification, crime scenes, features, neural networks               Categories: I.5.2  
14|18||Using Conjunctions and Adverbs for Author Verification|  Daniel Pavelec (Pontifícia Universidade Católica do Paraná, Brazil)   Luiz S. Oliveira (Pontifícia Universidade Católica do Paraná, Brazil)   Edson Justino (Pontifícia Universidade Católica do Paraná, Brazil)   Leonardo V. Batista (Federal University of Paraíba, Brazil)  Abstract: Linguistics and stylistics have been   investigated for author identification for quite awhile, but   recently, we have testified a impressive growth in the volume with   which lawyers and courts have called upon the expertise of linguists   in cases of disputed authorship. This motivatescomputer science   researchers to look to the problem of author identification from a   different perspective. In this work, we propose a stylometric   feature set based on conjunctions and ad-verbs of the Portuguese   language to address the problem of author identification. Two   different approaches of classification were considered. The first   one is called writer-independent and it re-duces the pattern   recognition problem to a single model and two classes, hence, makes   it possible to build robust system even when few genuine samples per   writer are available. The second oneis called the personal model, or   writer-dependent, which very often performs better but needs a   bigger number of samples per writer. Experiments on a database   composed of short articlesfrom 30 different authors and Support   Vector Machine (SVM) as classifier demonstrate that the proposed   strategy can produced results comparable to the   literature.               Keywords: author verification, pattern recognition               Categories: H.3.7, H.5.4  
14|18||A Language-Independent, Open-Vocabulary System Based on HMMs for Recognition of Ultra Low Resolution Words|  Farshideh Einsele (University of Fribourg, Switzerland)   Rolf Ingold (University of Fribourg, Switzerland)   Jean Hennebert (University of Applied Sciences HES-SO, Switzerland)  Abstract: In this paper, we introduce and evaluate a   system capable of recognizing words extracted from ultra low   resolution images such as those frequently embedded on web   pages. The design of the system has been driven by the following   constraints. First, the system has to recognize small font sizes   between 6-12 points where anti-aliasing and resampling filters are   applied. Such procedures add noise between adjacent characters in   the words and complicate any a priori segmentation of the   characters. Second, the system has to be able to recognize any words   in an open vocabulary setting, potentially mixing different   languages in Latin alphabet. Finally, the training procedure must be   automatic, i.e. without requesting to extract, segment and label   manually a large set of data. These constraints led us to an   architecture based on ergodic HMMs where states are associated to   the characters. We also introduce several improvements of the   performance increasing the order of the emission probability   estimators, including minimum and maximum width constraints on the   character models and a training set consisting all possible   adjacency cases of Latin characters. The proposed system is   evaluated on different font sizes and families, showing good   robustness for sizes down to 6 points.               Keywords: HMMs, ultra low resolution text recognition, web document analysis, web image indexation and retrieval               Categories: H.2, H.3.7, H.5.4  
14|18||Stacked Dependency Networks for Layout Document Structuring|  Boris Chidlovskii (Xerox Research Centre Europe, France)   Loïc Lecerf (Xerox Research Centre Europe, France)  Abstract: We address the problems of structuring and   annotation of layout-oriented documents.We model the annotation   problems as the collective classification on graph-like structures   with typed instances and links that capture the domain-specific   knowledge. We use the relational de-pendency networks (RDNs) for the   collective inference on the multi-typed graphs. We then describe a   variant of RDNs where a stacked approximation replaces the Gibbs   sampling in orderto accelerate the inference. We report results of   evaluation tests for both the Gibbs sampling and stacking inference   on two document structuring examples.               Keywords: dependency networks, document structuring, stacking               Categories: H.2, H.3.7, H.5.4  
14|18||An Evaluation Technique for Binarization Algorithms|  Pavlos Stathis (Democritus University of Thrace, Greece)   Ergina Kavallieratou (University of the Aegean, Greece)   Nikos Papamarkos (Democritus University of Thrace, Greece)  Abstract: Document binarization is an active research area   for many years. The choice of the most appropriate binarization   algorithm for each case proved to be a very difficult procedure   itself. In this paper, we propose a new technique for the validation   of document binarization algorithms. Our method is simple in its   implementation and can be performed on any binarization algorithm   since it doesnt require anything more than the binarization   stage. As a demonstration of the proposed technique, we use the case   of degraded historical documents. Then we apply the proposed   technique to 30 binarization algorithms. Experimental results and   conclusions are presented.               Keywords: binarization, document image processing, evaluation               Categories: I.7.5  
14|18||Comparative Aspects between the  Cluster and Grid Implementations of BigBatch|  Giorgia de Oliveira Mattos (Federal University of Pernambuco, Brazil)   Andrei de Araújo (Federal University of Pernambuco, Brazil)   Rafael Dueire Lins (Federal University of Pernambuco, Brazil)   Francisco Heron de Carvalho Júnior (Universidade Federal do Ceará, Brazil)   Fernando Mário Junqueira Martins (Universidade do Minho, Portugal)  Abstract: BigBatch is an image processing environment   designed to process batches of thousands of monochromatic   documents. One of the flexibilities and pioneer aspects of BigBatch   is offering the possibility of working in distributed environments   such as clusters and grids. This paper presents an overview of   BigBatch image processing features and analyzes the results of a   number of experiments devised to compare its cluster and grid   configurations. Although preliminary results were published earlier   on, the new data shown here that sheds new lights onto this   aspect. The results obtained exhibit almost no difference in total   execution times for some grid and cluster configurations, but   significant differences for others, indicating that the choice   between such configurations must take into account a number of   details in order to reach peak performance. Besides those, there are   other qualitative aspects that may impact this choice. This paper   analyzes these aspects and provides a general picture of how to   successfully use BigBatch to process document images employing   computers in parallel for this task.               Keywords: cluster, grid, image processing, load-balancing               Categories: D.1.3  
14|19|http://www.jucs.org/jucs_14_19|New Trends in Human Computer Interaction|
14|19||Extending and Supporting Featured User Interface Models for the Development of Groupware Applications|  Víctor M.R. Penichet (University of Castilla-La Mancha, Spain)   María D. Lozano (University of Castilla-La Mancha, Spain)   José A. Gallud (University of Castilla-La Mancha, Spain)   Ricardo Tesoriero (University of Castilla-La Mancha, Spain)   María L. Rodríguez (Universidad de Granada, Spain)   José L. Garrido (Universidad de Granada, Spain)   Manuel Noguera (Universidad de Granada, Spain)   María V. Hurtado (Universidad de Granada, Spain)  Abstract: This paper presents a proposal to tackle the design and development of user interfaces for groupware applications. This proposal includes important design and implementation issues of special relevance for this kind of interfaces. In particular, group awareness requirements in the development of groupware applications are addressed, both in the sense of the basic manipulation actions of the interface widgets, as well as in the sense of other kinds of group awareness in relation to the presence of actors, the roles they play in a concrete moment, etc. The design proposal we present is part of a complete development process (called TOUCHE) which defines a set of facets to describe Abstract Interaction Objects. These objects, at design level, provide the basis for the definition of Concrete Interaction Objects at implementation level within a software platform intended to facilitate the development of user interfaces for groupware applications. This way, we get an integral approach to tackle the development of this kind of user interfaces, taking into account in an explicit way the perception of the joint activity of a group of users involved in a common task and thus achieving a more effective collaboration.               Keywords: group awareness, groupware, user interfaces               Categories: H.5.2, H.5.3  
14|19||A Model of Interaction for CVEs Based on the Model of Human Communication|  Diego Martínez (University of Castilla-La Mancha, Spain)   Arturo S. García (University of Castilla-La Mancha, Spain)   Jonatan Martínez (University of Castilla-La Mancha, Spain)   José P. Molina (University of Castilla-La Mancha, Spain)   Pascual Gonzalez (University of Castilla-La Mancha, Spain)  Abstract: This paper summarizes a model of interaction for   CVEs inspired by the process followed in human communication in the   real world, detailing both the main elements and the communication   process itself. The model proposed copies some properties of the   real world communication but also allows the easy integration of   Task Analysis to the design of CVEs, helping the developer in the   design of the application. Furthermore, some of the benefits that   the usage of this model brings to the user are also shown. Finally,   some implementation details of a prototype supporting the described   model are given. This prototype is used all along the paper to   illustrate the explanation of some parts of the model.               Keywords: collaborative virtual environments, human-computer interaction, virtual reality               Categories: I.3.7, L.3.1, L.6.2  
14|19||Gaze-based Interaction for Virtual Environments|  Jorge Jimenez (Universidad de Zaragoza, Spain)   Diego Gutierrez (Universidad de Zaragoza, Spain)   Pedro Latorre (Universidad de Zaragoza, Spain)  Abstract: Abstract We present an alternative interface   that allows users to perceive new sensations in virtual   environments. Gaze-based interaction in virtual environments creates   the feeling of controlling objects with the mind, arguably   translating into a more intense immersion sensation. Additionally,   it is also free of some of the most cumbersome aspects of   interacting in virtual worlds. By incorporating a real-time physics   engine, the sensation of moving something real is further   accentuated.  We also describe various simple yet effective techniques that allow eyetracking devices to enhance the three-dimensional visualization capabilities of current displays. Some of these techniques have the additional advantage of freeing the mouse from most navigation tasks.    This work focuses on the study of existing techniques, a detailed description of the implemented interface and the evaluation (both objective and subjective) of the interface. Given that appropriate filtering of the data from the eye tracker used is a key aspect for the correct functioning of the interface, we will also discuss that aspect in depth.               Keywords: eye tracking, human-computer interaction, input device, video games, virtual environments               Categories: H.5.2, I.3.3  
14|19||SHARP Online: An Adaptive Hypermedia System Applied to Mathematical Problem Solving|  Ana-Belén Gil (University of Salamanca, Spain)   Raquel Rodríguez (University of Salamanca, Spain)   Francisco J. García-Peñalvo (University of Salamanca, Spain)   Ricardo López (University of Salamanca, Spain)  Abstract: In this article we present the development of a   web application called SHARP Online: An Adaptive Hypermedia System   Applied to Mathematical Problem Solving. The pedagogical basis of   this application is found in the support techniques for heuristic   learning in mathematical problem solving developed according to the   Schoenfeld model. The adaptivity of this tool is achieved by way of   the utilization of an adaptive algorithm which has been developed   for it and is described in this article. This algorithm implements   mechanisms that make it possible for the user to construct   mathematical knowledge adaptively using training methods. This   application also provides the teacher with the following complete   set of tools for managing the entire process: the inclusion of   contents through a collaborative application with support; a shared   work space; the adaptivity of the algorithm variables; and the   supervision of the students progress, etc. through specific   modules. This application was originally developed for educational   contexts in the area of teaching mathematics, and therefore includes   a module for editing and visualizing mathematical formulas for a Web   environment.               Keywords: adaptive hypermedia, heuristic thought, interactive learning environments, teaching/learning strategies, user-computer interaction               Categories: G.4, L.0, L.2.0, L.3.0  
14|19||Displaying Pictures according to the Songs Being Played|  Jesús Ibáñez (Pompeu Fabra University, Spain)   David García (Pompeu Fabra University, Spain)   Oscar Serrano (Pompeu Fabra University, Spain)  Abstract: This paper presents Musimage, a novel system   which displays pictures according to the songs being played at the   same time. By using the interface the user selects the songs to be   played, but the pictures are automatically selected. For each song   to be played, the system selects a set of pictures, according to   various criteria corresponding to some features of the song. In this   sense, the pictures to be shown are, metaphorically, triggered by   the songs.               Keywords: ambient intelligence, indirection of information, intelligent user interface               Categories: H.1.2, H.5.1, H.5.2, H.5.5  
14|19||Using the Optical Flow to Implement a Relative Virtual Mouse Controlled by Head Movements|  Tomàs Pallejà (University of Lleida, Spain)   Edgar Rubión (University of Lleida, Spain)   Mercè Teixido (University of Lleida, Spain)   Marcel Tresanchez (University of Lleida, Spain)   Alicia Fernández del Viso (eInclusion Unit, Spain)   Carlos Rebate (eInclusion Unit, Spain)   Jordi Palacin (University of Lleida, Spain)  Abstract: The following paper introduces the work   conducted to create a relative virtual mouse based on the   interpretation of head movements and face gesture through a low cost   camera and the optical flow of the images. This virtual device is   designed specifically as an alternative non-contact pointer for   people with mobility impairments in the upper extremities and   reduced head control. The proposed virtual device was compared with   a conventional mouse, a touchpad and a digital joystick. Validation   results show performances close to a digital joystick but far away   from a conventional mouse.               Keywords: human computer interaction, optical flow, virtual mouse               Categories: D.2.2, D.2.3, D.2.5, H.5.2, J.5  
14|19||Taxonomy for Integrating Models in the Development of Interactive Groupware Systems|  William J. Giraldo (University of Quindío, Spain)   Ana I. Molina (La Mancha University, Spain)   Cesar A. Collazos (University of Cauca, Colombia)   Manuel Ortega (La Mancha University, Spain)   Miguel A. Redondo (La Mancha University, Spain)  Abstract: This paper describes the taxonomy for designing   interactive groupware systems. The taxonomy defines the objectives,   methods and principles for classifying models and facilitates their   integration. In particular, we show the integration process of   models in two notations such as CIAN, which considers collaboration   and human-computer interaction issues, and UML, which allows   specifying the functionality of groupware systems. The proposed   integration process is based on a software tool, called CIAT,   developed to put our proposal into practice.               Keywords: computer-human interaction, groupware, methodological proposal, model-based development, taxonomy               Categories: D.2.2, H.1.1, H.5.3  
14|19||Model-Driven Approach to Design User Interfaces for Workflow Information Systems|  Josefina Guerrero García (Université catholique de Louvain, Belgium)   Christophe Lemaigre (Université catholique de Louvain, Belgium)   Juan Manuel González Calleros (Université catholique de Louvain, Belgium)   Jean Vanderdonckt (Université catholique de Louvain, Belgium)  Abstract: Many methods in the area of Human-Computer   Interaction have been developed for deriving user interfaces   considering individual users. However, nowadays information systems   include more than single interaction, there is a need to explicitly   include multi user interaction during the design process of   information systems. One of this approaches are workflow   systems. Workflow information systems present the view of the   organization, while modelling their business process; workflow   systems define explicitly the role of each actor during the   performance of the different tasks. The introduction of aspects such   as: organizational units, agendas, Wok list, user stereotypes and   resources, allows the design of more robust systems, especially when   all of them are considered during the development of the User   Interfaces needed. In this paper, we present a model-driven approach   to derive user interfaces of a workflow information system from a   series of models. A graphical editor has been developed. It is   described and exemplified on a real-world case study for designing   the user interfaces of a workflow information system.               Keywords: collaboration, model-driven approach, user interfaces flow, userinterface development, workflow information systems               Categories: H.1.0, H.4.0, H.5.2, H.5.3  
14|19||Consequence of Two-handed Manipulation on Speed, Precision and Perception on Spatial Input Task in 3D Modelling Applications|  Manuel Veit (LSIIT, France)   Antonio Capobianco (LSIIT, France)   Dominique Bechmann (LSIIT, France)  Abstract: We developed a free form deformation application for an immersive environment in which users can interact freely using data gloves. To ensure better comfort and performances, we added the possibility of bi-manual interaction in our environment. To investigate the actual gain obtained by this interaction technique we designed an experimental protocol based on spatial input tasks. In our experiment, we asked our subjects to use only the dominant hand to achieve the different tasks or, on the contrary, to use both hands. Comparison of users' performances - i-e, time and precision - shows that, without proper training, executing a task using two hands can be more time consuming than using one hand. In fact, the degree of symmetry of the tasks performed with each hand seem to have a significant impact on whether or not users take advantage of bi-manual possibilities. Our results also show that bi-manual interaction can introduce proprioceptive cues that can be of help to achieve more precision in the placement or selection only when proper visual information are missing. In this study, we also wanted to investigate if bi-manual interaction can help users in their perception of the task. Even if there aren't statistically significant, our results shows that using symmetric bi-manual interaction, proprioception cues can improve user's perception.               Keywords: bi-manual interaction, user interfaces, virtual reality               Categories: H.5, H.5.1, H.5.2  
14|19||CTML: Domain and Task Modeling for Collaborative Environments|  Maik Wurdel (University of Rostock, Germany)   Daniel Sinnig (Concordia University, Canada)   Peter Forbrig (University of Rostock, Germany)  Abstract: A precise model of the behavioral dynamics is a   necessary precondition for the development of collaborative   environments. In this paper we present a specification framework for   collaborative environments. In particular we highlight the interplay   of task specifications and domain models. The framework consists of   two components: A formal specification language (called CTML) and   the tool CTML Editor and Simulator. CTML has a precisely defined   syntax and semantics and is designed to model actors, roles,   collaborative tasks and their dependency and impact on the   domain. The CTML Editor and Simulator is an Eclipse IDE for the   interactive creation and simulation of CTML   specifications.               Keywords: collaborative environments, domain modeling, task modeling               Categories: D.2.1, D.2.2   
14|19||Evaluation of Agent-based Interactive Systems: Proposal of an Electronic Informer Using Petri Nets|  Chi Dung Tran (University of Valenciennes and Hainaut Cambresis, France)   Houcine Ezzedine (University of Valenciennes and Hainaut Cambresis, France)   Christophe Kolski (University of Valenciennes and Hainaut Cambresis, France)  Abstract: The evaluation of interactive systems has been   an active subject of research for many years. Many methods and tools   have been proposed but most of them do not take architectural   specificities of agent-based interactive systems into account. In   addition, electronic informers are popular evaluation tools but   current ones have often some limits. In order to solve these   problems, we propose an electronic informer to evaluate agent-based   interactive systems. This tool captures interaction events occurred   in agent-based interactive systems and then, based on such captured   data, it realizes treatments such as calculations, statistics and   generates Petri Nets (PNs) to assist evaluators in evaluating three   aspects of the system: user interface, non-functional properties   (e.g. response time, reliability, etc.)  and users properties   (e.g. abilities, preferences, etc.). The approach has been validated   by applying it to evaluate an agent-based interactive system used   for the supervision of urban transport network.               Keywords: electronic informer (EI), evaluation, human-computer interaction, interactive systems, interface agents, software architecture, user interface (UI)               Categories: H.1.2, H.5.2  
14|19||Model-Based and Prototyping-Driven User Interface Specification to Support Collaboration and Creativity|  Thomas Memmel (University of Konstanz, Germany)   Harald Reiterer (University of Konstanz, Germany)  Abstract: When the user interface is specified, a picture   is worth a thousand words, and the worst thing one can do is write a   natural-language specification for it. Because this practice is   still common, it is a challenging task to move from text-based   requirements and problem-space concepts to a final UI design, and   then back again. However, this activity is required frequently and   is necessary to drive creative ideas. In our research we found that   advanced UI specifications should therefore be made up of   interconnected artefacts that have distinct levels of   abstraction. With regards to the transparency and traceability of   the rationale of the specification process, transitions and   dependencies must be visual and traversable. For this purpose, we   introduce a model-based user interface specification method and a   corresponding experimental tool that interactively integrates   interdisciplinary and informal models with different levels of   fidelity of user-interface prototyping. With innovative styles of   interaction and user input, our proposed tool supports the   collaboration required in a multidisciplinary context.               Keywords: model-based development, prototyping, specification, user interface design               Categories: H.5.2, H.5.3  
14|19||A Model-Driven Approach to Align Business Processes with User Interfaces|  Kenia Sousa (Université catholique de Louvain, Belgium)   Hildeberto Mendonça (Université catholique de Louvain, Belgium)   Jean Vanderdonckt (Université catholique de Louvain, Belgium)  Abstract: Information Technology (IT) has evolved over   time from its traditional use as administrative support towards a   more strategic role to enforce business processes (BP). But several   organizations that adopt BP modeling as a source to implement   enterprise systems struggle to maintain such a link. To solve this   problem, most researches are focused on software engineering to   specify the association between models from business and IT to   support propagating changes. But even though there are several   techniques to control the alignment of BP and their systems, there   lacks a solution that addresses a major aspect of systems: their   User Interfaces (UI). The negative impact of focusing only on   functional aspects is that many changes on business processes that   affect user interfaces are not carefully considered. Our solution   proposes a method for the alignment of business processes with user   interfaces of systems by adopting a model-driven approach. Such   support is targeted at large organizations in order to enable them   to be more capable of managing those links. The method along with   the tool guarantees that all the models used to develop enterprise   systems are internally mapped and that any attempt to make changes   in at least one of them is alerted with warnings about the possible   impacts. We propose a practical method, adaptable to specic   organizational structures, that enables professionals to focus on   achieving organizational goals, and still puts forward users' need   for a richer user interaction.               Keywords: business process modeling, model-driven engineering, user-centered design               Categories: H.1, H.5.2  
14|19||"""Fine Tuning"" Image Accessibility for Museum Web Sites"|  Barbara Leporini (ISTI - CNR, Italy)   Ivan Norscia (Università di Pisa, Italy)  Abstract: Accessibility and usability guidelines are   available to design web sites accessible to blind users. However,   the actual usability of accessible web pages varies depending on the   type of information the user is dealing with. Museum web sites,   including specimens and hall descriptions, need specific   requirements to allow vision-impaired users, who navigate using a   screen-reader, to access pieces of information that are mainly based   on visual perception. Here we address a methodology to be applied   for the proper creation and elaboration of alternative image   descriptions in museum web pages. Such methodology has been applied   to a gallery of the Museum of Natural History and Territory   (University of Pisa). Such indications allow the user: (1) to   address indexed contents and to link to information in more details,   (2) to calibrate image descriptions (with a command providing   alternative explanations for specimens), and (3) to access extra   information for the blind (via hidden labels). A multidisciplinary   approach is necessary to obtain effective and comprehensive   descriptions. In this perspective, a cooperative environment is   eventually proposed for team work facilitation.               Keywords: accessibility, cooperation, guidelines, museum, usability, virtual visit               Categories: H.5.2  
14|19||Integrating Dialog Modeling and Domain Modeling - the Case of Diamodl and the Eclipse Modeling Framework|  Hallvard Trætteberg (Norwegian University of Science and Technology, Norway)  Abstract: For most applications, data-intensive   applications in particular, dialog modeling makes little sense   without a domain model. Since domain models usually are developed   and used outside the dialog modeling activity, it is better to   integrate dialog modeling languages with existing domain modeling   languages and tools, than inventing your own. This paper describes   how the Diamodl language, editor and runtime have been integrated   with the Eclipse Modeling Framework.               Keywords: Eclipse Modeling Framework, dialog modeling, domain modeling, model-based user interface design               Categories: H.1.1, H.5.2   
14|2|http://www.jucs.org/jucs_14_2|Advances in Document Engineering|
14|2||Using an Evolving Thematic Clustering in a Text Segmentation Process|  Sylvain Lamprier (LERIA - University of Angers, France)   Tassadit Amghar (LERIA - University of Angers, France)   Bernard Levrat (LERIA - University of Angers, France)   Frederic Saubion (LERIA - University of Angers, France)  Abstract: The thematic text segmentation task consists in identifying the most important thematic breaks in a document in order to cut it into homogeneous passages. We propose in this paper an algorithm for linear text segmentation on general corpuses. It relies on an initial clustering of the sentences of the text. This preliminary partitioning provides a global view on the sentences relations existing in the text, considering the similarities in a group rather than individually. The method, so-called ClassStruggle, is based on the distribution of the occurrences of the members of each class. During the process, the clusters then evolve, by considering a notion of proximity and of layout in the text, in the aim to create groups that contain only sentences related to a same topic development. Finally, boundaries are created between sentences belonging to two different classes. First experimental results are promising, ClassStruggle appears to be very competitive compared with existing methods.               Keywords: clustering, text segmentation               Categories: I.2.7, I.7  
14|2||Informatics for Historians: Tools for Medieval Document XML Markup, and their Impact on the History-Sciences|  Benjamin Burkard (Universität zu Köln, Germany)   Georg Vogeler (Ludwig-Max.-Universität. München, Germany)   Stefan Gruner (University of Pretoria, South Africa)  Abstract: This article is a revised and extended version   of [VBG, 07]. We conjecture that the digitalization of historical   text documents as a basis of data mining and information retrieval   for the purpose of progress in the history sciences is urgently   needed. We present a novel, specialist XML tool-suite supporting the   working historian in the transcription of original medieval charters   into a machine-readable form, and we also address some latest   developments which can be found in the field since the publication   of [VBG, 07].               Keywords: XML tagging, digitalization and preparation ofmedieval documents for the Semantic Web, history-informatics, tool-support               Categories: H.1, H.1.m, H.3, H.3.1, H.3.5, H.3.7, H.3.m, H.5, H.5.m, I.7.1, I.7.2, J.5  
14|2||Metaclasses and Zoning Mechanism Applied to Handwriting Recognition|  Cinthia O.A. Freitas (Pontifical Catholic University of Paraná - PUCPR, Brazil)   Luiz S. Oliveira (Pontifical Catholic University of Paraná - PUCPR, Brazil)   Simone B. K. Aires (Technological Federal University of Paraná - UTFPR-PG, Brazil)   Flávio Bortolozzi (OPET College, Brazil)  Abstract: The contribution of this paper is twofold. First   we investigate the use of the confusion matrices in order to get   some insight to better define perceptual zoning for character   recognition. The features considered in this work are based on   concavities/convexities deficiencies, which are obtained by   labelling the background pixels of the input image. Four different   perceptual zoning (symmetrical and non-symmetrical) are   discussed. Experiments show that this mechanism of zoning could be   considered as a reasonable alternative to exhaustive search   algorithms. The second contribution is a methodology to define   metaclasses for the problem of handwritten character   recognition. The proposed approach is based on the disagreement   among the characters and it uses Euclidean distance computed between   the confusion matrices. Through comprehensive experiments we   demonstrate that the use of metaclasses can improve the performance   of the system.               Keywords: character recognition, confusion matrix, feature measurement, metaclasses, zoning mechanism               Categories: I.4.7, I.5.2  
14|2||A Progressive Learning Method for Symbol Recognition|  Sabine Barrat (University of Nancy 2 LORIA, France)   Salvatore Tabbone (University of Nancy 2 LORIA, France)  Abstract: This paper deals with a progressive learning method for symbol recognition which improves its own recognition rate when new symbols are recognized in graphic documents. We propose a discriminant analysis method which provides allocation rules from a training set of labelled data. However a discriminant analysis method is efficient only if the training set and the test data are defined in the same conditions but it is rare in real life. In order to overcome this problem, a conditional vector is added to each instance to take into account the parasitic effects between the test data and the training set. We also propose an adaptation to consider the user feedback.               Keywords: conditional discriminant analysis, symbol recognition               Categories: I.5.3  
14|2||Combining Classifiers in the ROC-space for Off-line Signature Verification|  Luiz S. Oliveira (Pontifícia Universidade Catolica do Paraná, Brazil)   Edson Justino (Pontifícia Universidade Catolica do Paraná, Brazil)   Robert Sabourin (École de Technologie Superieure, Canada)   Flávio Bortolozzi (Faculdades OPET, Brazil)  Abstract: In this work we present a strategy for off-line   signature verification. It takes intoaccount a writer-independent   model which reduces the pattern recognition problem to a 2-class   problem, hence, makes it possible to build robust signature   verification systems even when fewsignatures per writer are   available. Receiver Operating Characteristic (ROC) curves are used   to improve the performance of the proposed system . The contribution   of this paper is two-fold. First of all, we analyze the impacts of   choosing different fusion strategies to combine the partial   decisions yielded by the SVM classifiers. Then ROC produced by   different classifiers are combined using maximum likelihood   analysis, producingan ROC combined classifier. Through comprehensive   experiments on a database composed of 100 writers, we demonstrate   that the ROC combined classifier based on the   writer-independentapproach can reduce considerably false rejection   rate while keeping false acceptance rates at acceptable   levels.               Keywords: pattern recognition, signature verification               Categories: H.3.7, H.5.4  
14|2||Table-form Extraction with Artefact Removal|  Luiz Antônio Pereira Neves (PUCPR, Brazil)   João Marques de Carvalho (PUCPR, Brazil)   Jacques Facon (PUCPR, Brazil)   Flávio Bortolozzi (PUCPR, Brazil)  Abstract: In this paper we present a novel methodology to recognize the layout structure of handwritten filled table-forms. Recognition methodology includes locating line intersections, correcting wrong intersections produced by what we call artefacts (overlapping data, broken segments and smudges), extracting correct table-form cells and using as little previous table-form knowledge as possible. To improve layout structure recognition, a novel artefact identification and deletion method is also proposed. To evaluate the effectiveness of the methodology, a database composed of 350 handwritten filled table-form images damaged by different types of artefacts was used. Experiments show that the artefact identification method improves performance of the table-forms structure extractor that reached a success rate of 85%.               Keywords: document segmentation, handwritten data, table-form extraction, table-form recognition               Categories: I.4, I.4.6, I.7, I.7.m  
14|2||Detailing a Quantitative Method for Assessing Algorithms to Remove Back-to-Front Interference in Documents|"  Rafael Dueire Lins (Universidade Federal de Pernambuco, Brazil)   João Marcelo Monte da Silva (Universidade Federal de Pernambuco, Brazil)   Fernando Mário Junqueira Martins (Universidade do Minho, Portugal)  Abstract: Documents written on both sides on translucent   paper make visible the ink from one side on the other. This artefact   is called ""back-to-front interference"", ""bleeding"" or   ""show-through"". The direct binarization of documents with such   interference yields unreadable documents. The literature presents   several algorithms for suitably removing such artefact. This paper   presents a quantitative method to assess algorithms to remove   back-to-front interference.               Keywords: back-to-front interference, bleeding, document engineering, show-through               Categories: H.3.3  "
14|2||A Methodology for the Separation of Foreground/Background in Arabic Historical Manuscripts using Hybrid Methods|  Wafa Boussellaa (University of Sfax, REGIM, ENIS, Tunisia)   Abderrazak Zahour (University of Le Havre, France)   Adel Alimi (University of Sfax, REGIM, ENIS, Tunisia)  Abstract: This paper presents a new color document image   segmentation system suitable for historical Arabic manuscripts. Our   system is composed of a hybrid method which couple together   background light intensity normalization algorithm and k-means   clustering with maximum likelihood (ML) estimation, for foreground/   background separation.  Firstly, the background normalization algorithm performs separation between foreground and background. This foreground is used in later steps. Secondly, our algorithm proceeds on luminance and distort the contrast. These distortions are corrected with a gamma correction and contrast adjustment. Finally, the new enhanced foreground image is segmented to foreground/background on the basis of ML estimation.  The initial parameters for the ML method are estimated by k-means clustering algorithm. The segmented image is used to produce a final restored document image.  The techniques are tested on a set of Arabic historical manuscripts documents from the National Tunisian Library.  The performance of the algorithm is demonstrated on by real color manuscripts distorted with show-through effects, uneven background color and localized spot               Keywords: Arabic historical color manuscript image, foreground/background,, k-means, light intensity normalisation, maximum likelihood, restoration, segmentation               Categories: I.4.3, I.4.4, I.4.5, I.4.9  
14|2||A New and Efficient Algorithm to Binarize Document Images Removing Back-to-Front Interference|"  João Marcelo Monte da Silva (Universidade Federal de Pernambuco, Brazil)   Rafael Dueire Lins (Universidade Federal de Pernambuco, Brazil)   Fernando Mário Junqueira Martins (Universidade do Minho, Portugal)   Rosita Wachenchauzer (Universidad de Buenos Aires, Argentina)  Abstract: ""Back-to-front interference"",   ""bleeding"" and ""show-through""is the name given to   the phenomenon found whenever documents are written on both sides of   translucent paper and the print of one side is visible on the other   one. The binarization of documents with back-to-front interference   with standard algorithms yields unreadable documents. This paper   presents a fast entropy-based segmentation method for generating   high-quality binarized images of documents with back-to-front   interference.               Keywords: back-to-front interference, bleeding, document engineering, show through               Categories: H.3.3  "
14|20|http://www.jucs.org/jucs_14_20|Lisp: Research and Experience|
14|20||A Tool for Reasoning about Qualitative Temporal Information: the Theory of S-languages with a Lisp Implementation|  Irène A. Durand (Université de Bordeaux, France)   Sylviane R. Schwer (Université Paris-Nord, France)  Abstract: Reasoning about incomplete qualitative temporal   information is an essential topic inmany artificial intelligence and   natural language processing applications. In the domain of natural   language processing for instance, the temporal analysis of a text   yields a set of temporal relationsbetween events in a given   linguistic theory. The problem is first to express events and any   possible temporal relations between them, then to express the   qualitative temporal constraints (as subsetsof the set of all   possible temporal relations) and compute (or count) all possible   temporal relations that can be deduced. For this purpose, we propose   to use the formalism of S-languages, based onthe mathematical notion   of S-arrangements with repetitions [Schwer, 2002]. In this paper, we   present this formalism in detail and our implementation of it. We   explain why Lisp is adequateto implement this theory. Next we   describe a Common Lisp system SLS (for S-LanguageS)which implements   part of this formalism. A graphical interface written using McCLIM,   the free implementation of the CLIM specification, frees the   potential user of any Lisp knowledge. Fullydeveloped examples   illustrate both the theory and the implementation.               Keywords: Lisp, S-languages, relation algebras, temporal reasoning               Categories: F.4, I.1.1, I.2.4  
14|20||Context-Oriented Programming with the Ambient Object System|  Sebastián González (Université catholique de Louvain, Belgium)   Kim Mens (Université catholique de Louvain, Belgium)   Alfredo Cádiz (Université catholique de Louvain, Belgium)  Abstract: In this paper we present AmOS, the Ambient   Object System that underlies the Ambience programming language. AmOS   implements a computation model that supports highly dynamic   behaviour adaptation to changing contexts. Apart from being purely   object-based, AmOS features first-class closures, multimethods and   contexts. Dynamic method scoping through a subjective dispatch   mechanism is at the heart of our approach. These features make of   AmOS a very simple and elegant paradigm for context-oriented   programming.               Keywords: ambient intelligence, context-oriented programming, multiple dispatch, prototype-based programming, subjective dispatch               Categories: D.3.3  
14|20||UCL-GLORP - An ORM for Common Lisp|  António Menezes Leitão (Technical University of Lisbon, Portugal)  Abstract: UCL-GLORP is a Common Lisp implementation and   extension of GLORP (Generic Lightweight Object-Relational   Persistence), an Object-Relational Mapper for the Smalltalk   language. UCL-GLORP is now a mature framework that largely extends   GLORP and that takes advantage of some of Common Lisp unique   features. This paper illustrates UCL-GLORP and discusses some of the   challenges that we faced in order to find suitable replacements, in   Common Lisp, for some of the more esoteric features of Smalltalk   that were explored by GLORP.               Keywords: Common Lisp, Smalltalk, object-relational mapping               Categories: D.1.5, D.2.2, D.3.3, H.2  
14|20||An Implementation of CLIM Presentation Types|  Timothy Moore (Red Hat SARL, France)  Abstract: Presentation types are used in the CLIM   interface library to tag graphical output with a type and establish   an input type context in which the user may use the keyboard to type   input, accepted by a parser associated with that presentation type,   or click on the graphical representation of an object that has an   appropriate presentation type. Presentation types are defined using   a syntax reminiscent of the deftype syntax of Common Lisp; the input   and output actions of the types, as well as aspects of their   inheritance, are implemented using a system of generic functions and   methods directly based on CLOS. The presentation type system is   different enough from the Common Lisp type system that its types,   generic functions and methods do not map directly to those of Common   Lisp. We describe the presentation type implemention in McCLIM which   uses the CLOS Metaobject Protocol to implement presentation type   inheritance, method dispatch and method combination without   implementing an entire parallel object system next to CLOS. Our   implementation supports all types of method combination in the   presentation methods, including user-defined method   combination.               Keywords: CLIM, Common Lisp, metaobject protocol, presentation types               Categories: D.1.5, D.2.2, D.3.3  
14|20||Custom Specializers in Object-Oriented Lisp|  Jim Newton (Cadence Design Systems, Germany)   Christophe Rhodes (University of London New Cross, United Kingdom)  Abstract: We describe in this paper the implementation and   use of custom specializers in two current dialects of Lisp: Skill   and Common Lisp. We motivate the need for such specializers by   appealing to clarity of expression, referring to experience in   existing industrial applications. We discuss the implementation   details of such user-defined specializers in both dialects of Lisp,   detailing open problems with those implementations, and we sketch   ideas for solving them.               Keywords: Lisp, Metaobject Protocol, Specializer, generic function               Categories: D.1, D.3.3  
14|20||Binary Methods Programming: the Clos Perspective|  Didier Verna (Epita Research and Development Laboratory, France)  Abstract: Implementing binary methods in traditional   object-oriented languages isdifficult. Numerous problems arise   regarding the relationship between types and classes in the context   of inheritance, or the need for privileged access to the internal   repre-sentation of objects. Most of these problems occur in the   context of statically typed languages that lack multi-methods   (polymorphism on multiple arguments). The pur-pose of this paper is   twofold: to show why some of these problems are either non-issues,   or easily solved in Common Lisp, and to demonstrate how the Common   Lisp ObjectSystem (Clos) allows us to simply define, implement and   enforce type-safe binary methods. These last considerations involve   re-programming a binary method-specificobject system through the   Clos Meta-Object Protocol (Mop).               Keywords: Common Lisp, binary methods, meta-programming, object orientation               Categories: D.1.5, D.3.3  
14|21|http://www.jucs.org/jucs_14_21|SBLP 2008: XII Brazilian Symposium on Programming|
14|21||Beyond ASCII - Parsing Programs with Graphical Presentations|  Martijn M. Schrage (Utrecht University, The Netherlands)   S. Doaitse Swierstra (Utrecht University, The Netherlands)  Abstract: Proxima is a generic structure editor suitable for a wide range of structured document types. It allows edit operations on the document structure as well as on its screen representation (i.e. free-text editing), without the need to switch between the two modes. The system maintains a bidirectional mapping between the document structure and its presentation. Besides obvious applications, such as word-processor and spread-sheet editors, Proxima is especially well-suited for defining source editors for programming languages.    Presentation-oriented edit operations require that an edited presentation can be parsed to yield an updated document structure. However, conventional parsing techniques cannot readily be applied, since presentations in Proxima are not restricted to text but may also contain graphical elements. For example, an exponential may be presented as 32. Although this graphical presentation may not be directly edited at the presentation level, its components may. Hence, instead of simply parsing the changed representation, we have to take into account the existing structure.    This paper explains the scanning and parsing process for presentations that are a possibly nested combination of text and graphical elements. For textual parts of the presentation a Haskell combinator parser needs to be provided. The parser for graphical parts, on the other hand, is constructed by Proxima, based on information in the presentation. White space in the presentation can be handled automatically, if desired.               Keywords: Haskell, parsing, presentation-oriented editing               Categories: D.1.1, D.2.6  
14|21||Shortcut Fusion of Monadic Programs|  Cecilia Manzino (Universidad Nacional de Rosario, Argentina)   Alberto Pardo (Universidad de la República, Uruguay)  Abstract: Functional programs often combine separate parts   of the program using intermediate data structures for communicating   results. Programs so defined are easier to understand and maintain,   but suffer from inefficiency problems due to the generation of those   data structures. In response to this problematic, some program   transformation techniques have been studied with the aim to   eliminate the intermediate data structures that arise in function   compositions. One of these techniques is known as shortcut   fusion. This technique has usually been studied in the context of   purely functional programs. In this work we propose an extension of   shortcut fusion that is able to eliminate intermediate data   structures generated in the presence of monadic effects. The   extension to be presented can be uniformly defined for a wide class   of data types and monads.               Keywords: computational effects, functional programming, monads, shortcut fusion               Categories: D.1, D.1.1, D.3.3, F.3.3  
14|21||An LALR Parser Generator Supporting Conflict Resolution|  Leonardo Teixeira Passos (Federal University of Minas Gerais, Brazil)   Mariza A. S. Bigonha (Federal University of Minas Gerais, Brazil)   Roberto S. Bigonha (Federal University of Minas Gerais, Brazil)  Abstract: Despite all the advance brought by LALR parsing   method by DeRemer in the late 60's, conflicts continue to be removed   in a non-productive way, by means of analysis of a huge amount of   textual and low level data dumped by the parser generator tool. For   the purpose of changing this scenario, we present a parser generator   capable of automatically removing some types of conflicts, along   with a supported methodology that guides the process of manual   removal. We also discuss the internal algorithms and how the created   parsers are compact in terms of memory usage.               Keywords: automatic conflict removal, lalr parsing, methodology, table compression               Categories: D.3.4, F.4.2  
14|21||Instruction Scheduling Based on Subgraph Isomorphism for a High Performance Computer Processor|  Ricardo Santos (Dom Bosco Catholic University, Brazil)   Rodolfo Azevedo (State University of Campina, Brazil)   Guido Araujo (State University of Campina, Brazil)  Abstract: This paper1 presents an instruction scheduling   algorithm based on the Subgraph Isomorphism Problem. Given a   Directed Acyclic Graph (DAG) G1, our algorithm looks for a subgraph   G02 in a base graph G2, such that G02 is isomorphic to G1. The base   graph G2 represents the arrangement of the processing elements of a   high performance computer architecture named 2D-VLIW and G02 is the   set of those processing elements required to execute operations in   G1. We have compared this algorithm with a greedy list scheduling   strategy using programs of the SPEC and MediaBench suites. In our   experiments, the average Operation Per Cycle (OPC) and Operations   Per Instruction (OPI) achieved by our algorithm are 1.45 and 1.40   times better than the OPC and OPI obtained by the list scheduling   algorithm.               Keywords: 2D-VLIW, instruction scheduling, subgraph isomorphism               Categories: C.1.3, D.3.m, I.2.5  
14|21||Eliminating Cycles in Weak Tables|  Alexandra Barros (Pontifical Catholic University of Rio de Janeiro, Brazil)   Roberto Ierusalimschy (Pontifical Catholic University of Rio de Janeiro, Brazil)  Abstract: Weak References constitute an elegant mechanism   for an application to interact with its garbage collector. In most   of its typical uses, weak references are used through weak tables   (e.g., Java's WeakHashMap). However, most implementations of weak   tables have a severe limitation: Cyclic references between keys and   values in weak tables prevent the elements inside a cycle from being   collected, even if they are no longer reachable from outside. This   ends up bringing difficulties to the use of weak tables in some   kinds of applications.    In this work, we present our   approach for overcoming this problem in the context of the Lua   programming language. Our approach consists of an adaptation of the   ephemerons mechanism to tables. We modified the garbage collector of   the Lua virtual machine in order to offer support to this   mechanism. With this adapted garbage collector we could verify the   efficiency and effectiveness of the implementation in solving the   problem of cycles on weak tables in Lua.               Keywords: Garbage collection, weak references, weak tables               Categories: D.3.3  
14|21||Controlling Aspect Reentrancy|  Éric Tanter (University of Chile, Chile)  Abstract: Aspect languages provide different mechanisms to   control when an aspect should apply based on properties of the   execution context. They however fail to explicitly identify and   cleanly capture a property as basic as that of reentrancy. As a   result, aspect developers have to resort to low-level and complex   pointcut descriptions that are error prone and hamper the   understandability of aspect definitions. We analyze the issue of   aspect reentrancy, illustrate how current languages fail to properly   support it, and define a new linguistic construct to control aspect   reentrancy. Considering aspect reentrancy from the start in the   design of an aspect language simplifies the task of aspect   programmers by raising the level of abstraction of aspect   definitions.               Keywords: aspect reentrancy, aspect-oriented programming, pointcut language               Categories: D.1.m, D.3.3  
14|21||A Lightweight and Extensible AspectJ Implementation|  Rodolfo Toledo (University of Chile, Chile)   Éric Tanter (University of Chile, Chile)  Abstract: Extending AspectJ to experiment with new   language features can be cumbersome, even with an extensible   implementation. Often, a language designer only needs a rapid   prototyping environment, but has to deal with a full compiler   infrastructure, and must address low-level implementation   issues. This work completes a lightweight extensible implementation   of AspectJ with a declarative assimilation layer based on   Stratego. This layer brings together an extensible syntax definition   of AspectJ and the core semantics provided by the Reflex AOP   kernel. Using this implementation, language extensions are defined   using declarative high-level constructs, significantly reducing the   cost of the extension process.               Keywords: aspect-oriented programming, extensible implementation, spectJ               Categories: D.1.m, D.3.4  
14|21||On the Interaction of Advices and Raw Types in AspectJ|  Fernando Barden Rubbo (Universidade Federal do Rio Grande do Sul, Brazil)   Rodrigo Machado (Universidade Federal do Rio Grande do Sul, Brazil)   Álvaro Freitas Moreira (Universidade Federal do Rio Grande do Sul, Brazil)   Leila Ribeiro (Universidade Federal do Rio Grande do Sul, Brazil)   Daltro Jé Nunes (Universidade Federal do Rio Grande do Sul, Brazil)  Abstract: The latest versions of AspectJ, the most popular   aspect-oriented extension for Java, must cope with the complex   changes that occurred in the Java type system, specially with those   that introduced type parameters for classes and methods. In this   work we study the influence of raw types, i.e. parameterless   instantiations of class types, over the semantics of an AspectJ-like   language. As a result, we define an operational semantics and a type   system for a calculus, named Raw Aspect Featherweight Generic Java   (Raw-AFGJ), that represents a minimal aspect-oriented extension of   Raw Featherweight Generic Java. Through our calculus it is possible   to achieve a better understanding of several subtleties of aspect   weaving with the restrictions imposed by raw types support in the   type system.               Keywords: aspect-oriented programming, operational semantics,, type systems               Categories: D.3.1, D.3.3, F.3.2  
14|21||Exploring Lua for Concurrent Programming|  Alexandre Skyrme (Pontifical Catholic University of Rio de Janeiro, Brazil)   Noemi Rodriguez (Pontifical Catholic University of Rio de Janeiro, Brazil)   Roberto Ierusalimschy (Pontifical Catholic University of Rio de Janeiro, Brazil)  Abstract: The popularization of multi-core processors and   of technologies such as hyper-threading demonstrates a fundamental   change in the way processors have been evolving and also increases   interest in concurrent programming, particularly as a means to   improve software performance. However, concurrent programming is   still considered complex, mostly due to difficulties in using the   available programming models, which have been subject to recurring   criticism. The increased interest in concurrency and the lack of   proper models to support it stimulates the development of proposals   aimed at providing alternative models for concurrent programming. In   this paper, we work with some of Lua's facilities to explore such a   model, based on user threads and message passing. We also   demonstrate why Lua was particularly well suited for this objective,   describe the main characteristics of the explored model and present   a library developed to implement it, along with results of a   performance evaluation.               Keywords: Lua, concurrency, luaproc, message passing, non-preemptive multithreading, preemptive multithreading               Categories: D.1.3, D.3.2, D.3.3  
14|21||Algebraic Laws for Feature Models|  Rohit Gheyi (Federal University of Campina Grande, Brazil)   Tiago Massoni (Federal University of Campina Grande, Brazil)   Paulo Borba (Federal University of Pernambuco, Brazil)  Abstract: Software Product Lines (SPL) may be adopted by   either bootstrapping existing software products into a SPL, or   extending an existing SPL to encompass an additional software   product. Program refactorings are usually applied for carrying out   those tasks. The notion of SPL refactoring is an extension of the   traditional definition of refactoring; it involves not only program   refactorings, but also Feature Model (FM) refactorings, in order to   improve configurability. However, FM refactorings are hard to   define, due to the incompleteness of the refactoring catalogs   developed as of today. In this paper, we propose a complete, sound   catalog of algebraic laws, making up special FM refactorings that   preserve configurability. This catalog is also defined as minimal,   as one law cannot be derived from another one in the same   catalog. In addition, a theory for FMs is presented, in the context   of a theorem prover.               Keywords: algebraic laws, feature models, refactoring, software product lines               Categories: D.2.13, D.2.2, D.2.7  
14|21||Disentangling Denotational Semantics Definitions|  Fabio Tirelo (Pontifícia Universidade Católica de Minas Gerais, Brazil)   Roberto S. Bigonha (Universidade Federal de Minas Gerais, Brazil)   Joâo Saraiva (Universidade do Minho, Portugal)  Abstract: Denotational semantics is a powerful technique   to formally define programming languages. However, language   constructs are not always orthogonal, so many semantic equations in   a definition may have to be aware of unrelated constructs   semantics. Current approaches for modularity in this formalism do   not address this problem, providing, for this reason, tangled   semantic definitions. This paper proposes an incremental approach   for denotational semantic specifications, in which each step can   either add new features or adapt existing equations, by means of a   formal language based on function transformation and aspect   weaving.               Keywords: aspect-oriented definitions, denotational semantics, modularity, semantics of programming languages               Categories: D.3.1, D.3.3, F.3.2, F.3.3  
14|21||Formal Action Semantics for a UML Action Language|  Mikai Yang (Heriot-Watt University, United Kingdom)   Greg J. Michaelson (Heriot-Watt University, United Kingdom)   Rob J. Pooley (Heriot-Watt University, United Kingdom)  Abstract: The abstract syntax and static semantics of UML,   the widely-used generalpurpose graphical modeling language, have   been standardized in a four-layer metamodeling framework. However   UML's dynamic semantics, such as UML Precise Action Semantics and   the behaviors like activities, interactions and state machines, are   only standardized in a natural language-English. It is commonly   argued that such informal description inevitably involves   ambiguities and lacks rigorousness, precluding the early simulation   and reasoning about a UML system design. Here we select Action   Semantics (AS) as the vehicle to formalize UML. AS is a mature   semantics description framework which has advantages of   intelligibility, modularity and practicability. In our approach, we   formalize UML indirectly by formalizing its textual   correspondent-an extended Action Language, which plays a key role   as the interface between UML and its action semantics.               Keywords: Action Semantics, Unified Modeling Language, action language, formal semantics               Categories: D.2.1, D.2.2, D.3.1  
14|22|http://www.jucs.org/jucs_14_22|Managing Editor's Column|
14|22||Learning Design in Adaptive Educational Hypermedia Systems|  Adriana J. Berlanga (Open University of the Netherlands, The Netherlands)   Francisco J. García-Peñalvo (University of Salamanca, Spain)  Abstract: After more than ten years of research aiming at defining methods and techniques to deliver personalized instruction, Adaptive Educational Hypermedia Systems have not made the jump into real practice systems. Reasons for this include the complexity of their development, their use of exclusive methods for defining adaptivity and educational elements, and their lack of interoperation amongst courses and applications. A possible alternative to cope with these issues is using as a common notational method the IMS Learning Design specification. This paper attempts to bring AEHS and IMS LD closer to each other in order to define adaptivity behaviour. To this end, it outlines how IMS LD could be used to define personalization properties and adaptive techniques and, based on that, it proposes a component called Adaptive Learning Designs, and an authoring tool to create these components. Furthermore, the paper discusses the benefits and limitations of IMS LD to define adaptivity behaviour, and ends suggesting additional research lines.               Keywords: Adaptive Hypermedia System, Adaptive Rules, Authoring Tools, IMS LD, Learning Design               Categories: H.5.2, H.5.4, J.7  
14|22||Constructive Notions of Maximality for Ideals|  Douglas S. Bridges (University of Canterbury, New Zealand)   Robin S. Havea (University of the South Pacific, Fiji)  Abstract: Working constructively, we discuss two types of   maximality for ideals in a commutative ring with identity, showing   also that the results are the best possible.               Keywords: constructive, ideal, maximal               Categories: F.2.m, G.0  
14|22||IQM3: Information Quality Management Maturity Model|  Ismael Caballero (University of Castilla-La Mancha, Spain)   Angélica Caro (University of Bio Bio, Chile)   Coral Calero (University of Castilla-La Mancha, Spain)   Mario Piattini (University of Castilla-La Mancha, Spain)  Abstract: In order to enhance their global business   performance, organizations must be careful with the quality of their   information since it is one of their main assets. Analogies to   quality management of classical products demonstrate that   Information Quality is also preferably attainable through management   by integrating some corresponding Information Quality management   activities into the organizational processes. To achieve this goal   we have developed an Information Quality Management   Framework (IQMF). It is articulated on the concept of   Information Management Process (IMP), based on   the idea of Software Process. An IMP is a combination of two   sub-processes: the first, a production process, aimed to manufacture   information from raw data, and the second to adequately manage the   required Information Quality level of the first. IQMF consists of   two main components: an Information Quality Management   Maturity Model (IQM3), and a Methodology for the   Assessment and Improvement of Information Quality   Management (MAIMIQ), which uses IQM3 as a reference model   for the assessment and for the improvement goal of an   IMP. Therefore, as a result of an assessment with MAIMIQ, an IMP can   be said to have raised one of the maturity levels described in IQM3,   and as improvement goal, it would be desirable to achieve a higher   maturity level. Since an Information System can be seen as a set of   several IMPs sharing several resources, it is possible to improve   the Information Quality level of the entire Information System by   improving the most critical IMPs. This paper is focused only on   describing the foundations and structure of IQM3, which is based on   staged CMMI.               Keywords: Information Quality Management Maturity Model, data and information quality, information quality, information quality management               Categories: D.2.9, H.1.1, H.2.0, K.6.4  
14|22||On BCK Algebras - Part I.b: An Attempt to Treat Unitarily the Algebras of Logic. New Algebras|"  Afrodita Iorgulescu (Academy of Economic Studies, Romania)  Abstract: Since all the algebras connected to logic have,   more or less explicitely, an associated order relation, it follows   that they have two presentations, dual to each other. We classify   these dual presentations in ""left"" and ""right"" ones and we consider   that, when dealing with several algebras in the same research, it is   useful to present them unitarily, either as ""left"" algebras or as   ""right"" algebras. In some circumstances, this choice is essential,   for instance if we want to build the ordinal sum (product) between a   BL algebra and an MV algebra. We have chosen the ""left"" presentation   and several algebras of logic have been redefined as particular   cases of BCK algebras.  We introduce several new properties of algebras of logic, besides those usually existing in the literature, which generate a more refined classification, depending on the properties satisfied. In this work (Parts I-V) we make an exhaustive study of these algebras - with two bounds and with one bound - and we present classes of finite examples, in bounded case.  In this Part I, divided in two because of its length, after surveying chronologically several algebras related to logic, as residuated lattices, Hilbert algebras, MV algebras, divisible residuated lattices, BCK algebras, Wajsberg algebras, BL algebras, MTL algebras, WNM algebras, IMTL algebras, NM algebras, we propose a methodology in two steps for the simultaneous work with them (the first part of Part I).  We then apply the methodology, redefining those algebras as particular cases of reversed left-BCK algebras. We analyse among others the properties Weak Nilpotent Minimum and Double Negation of a bounded BCK(P) lattice, we introduce new corresponding algebras and we establish hierarchies (the subsequent part of Part I).               Keywords: BCK algebra, BCK(P) lattice, BL algebra, Hertz algebra, Heyting algebra, Hilbert algebra, Hájek(P) algebra, IMTL algebra, MTL algebra, MV algebra, NM algebra, R0 algebra, WNM algebra, Wajsberg algebra, divisible BCK(P) lattice, generalized-BL algebra, generalized-MV algebra, generalized-Wajsberg algebra, pocrim, residuated lattice, t-norm, weak-BL algebra               Categories: F.4.1  "
14|22||Online Network-on-Chip Switch Fault Detection and Diagnosis Using Functional Switch Faults|  Naghmeh Karimi (University of Tehran, Iran)   Armin Alaghi (University of Tehran, Iran)   Mahshid Sedghi (University of Tehran, Iran)   Zainalabedin Navabi (University of Tehran, Iran)  Abstract: This paper presents efficient methods for online   fault detection and diagnosis of Network-on-Chip (NoC) switches. The   fault model considered in this research is a system level fault   model based on the generic properties of NoC switch   functionality. The proposed method is evaluated by fault simulation   in a platform using this system level fault model. The experimental   results show that with a relatively low area overhead, a large   number of NoC switch faults can be detected and diagnosed.               Keywords: fault diagnosis, functional fault model, network-on-chip, online testing, switch               Categories: B.4.3, B.4.5, B.8.1  
14|22||Determining Software Investment Lag|  Gio Wiederhold (Stanford University, USA)  Abstract: The investments needed to bring a software   project to the market are substantial and can extend over several   years. Managing software development requires not only technical   expertise, but communication with funders and economists.  This   paper presents methods to estimate a parameter which captures the   effective investment time, lag.  The lag parameter is useful in   assessing progress towards the goal of having a quality product,   while scheduling resources, assessing the risk, considering options,   capitalization of investments, and predicting taxation   consequences. The paper presents the lag estimation methods for a   new product, for additional versions of a product, and for complete   product replacement.               Keywords: investment, lag, software development               Categories: D.2.7, D.2.9, K.5.1, K.5.2, K.6.0, K.6.1, K.6.3  
14|22||Adapting Clinical Ontologies in Real-World Environments|  Holger Stenzhorn (University Medical Center Freiburg, Germany)   Stefan Schulz (University Medical Center Freiburg, Germany)   Martin Boeker (University Medical Center Freiburg, Germany)   Barry Smith (University at Buffalo, USA)  Abstract: The desideratum of semantic interoperability has   been intensively discussed in medical informatics circles in recent   years. Originally, experts assumed that this issue could be   sufficiently addressed by insisting simply on the application of   shared clinical terminologies or   clinical information models. However, the use of   the term 'ontology has been steadily increasing   more recently. We discuss criteria for distinguishing   clinical ontologies from clinical   terminologies and information   models. Then, we briefly present the role clinical   ontologies play in two multicentric research projects. Finally, we   discuss the interactions between these different kinds of knowledge   representation artifacts and the stakeholders involved in developing   interoperational real-world clinical applications. We provide   ontology engineering examples from two EU-funded projects.               Keywords: clinical ontologies, formal ontologies, knowledge representation               Categories: I.2.4, J.3  
14|22||Semantic Information in Medical Information Systems: Utilization of Text Mining Techniques to Analyze Medical Diagnoses|  Andreas Holzinger (Medical University Graz, Austria)   Regina Geierhofer (Medical University Graz, Austria)   Felix Mödritscher (Vienna University of Economics and Business Administration, Austria)   Roland Tatzl (Graz University of Applied Sciences, Austria)  Abstract: Most information in Hospitals is still only   available in text format and the amount of this data is immensely   increasing. Consequently, text mining is an essential area of   medical informatics. With the aid of statistic and linguistic   procedures, text mining software attempts to dig out (mine)   information from plain text. The aim is to transform data into   information. However, for the efficient support of end users, facets   of computer science alone are insufficient; the next step consists   of making the information both usable and useful. Consequently,   aspects of cognitive psychology must be taken into account in order   to enable the transformation of information into knowledge of the   end users. In this paper we describe the design and development of   an application for analyzing expert comments on magnetic resonance   images (MRI) diagnoses by applying a text mining method in order to   scan them for regional correlations. Consequently, we propose a   calculation of significant co-occurrences of diseases and defined   regions of the human body, in order to identify possible risks for   health.                 Categories: H.3.1, H.3.3, I.2.7, I.7, J.3  
14|3|http://www.jucs.org/jucs_14_3|Cryptography in Computer System Security|
14|3||Optimistic Fair Exchange in a Multi-user Setting|  Yeveniy Dodis (New York University, USA)   Pil Joong Lee (Pohang University of Science and Technology, Korea)   Dae Hyun Yum (Pohang University of Science and Technology, Korea)  Abstract: This paper addresses the security of optimistic   fair exchange in a multi-user setting. While the security of public   key encryption and public key signature schemes in a single-user   setting guarantees the security in a multi-user setting, we show   that the situation is different in the optimistic fair   exchange. First, we show how to break, in the multi-user setting, an   optimistic fair exchange scheme provably secure in the single-user   setting. This example separates the security of optimistic fair   exchange between the single-user setting and the multi-user   setting. We then define the formal security model of optimistic fair   exchange in the multi-user setting, which is the first complete   security model of optimistic fair exchange in the multi-user   setting. We prove the existence of a generic construction meeting   our multi-user security based on oneway functions in the random   oracle model and trapdoor one-way permutations in the standard   model. Finally, we revisit two well-known methodologies of   optimistic fair exchange, which are based on the verifiably   encrypted signature and the sequential two-party multisignature,   respectively. Our result shows that these paradigms remain valid in   the multi-user setting.               Keywords: fair exchange, public key cryptography, security protocol               Categories: C.2.2, H.4.3  
14|3||New Results on NMAC/HMAC when Instantiated with Popular Hash Functions|  Christian Rechberger (Graz University of Technology, Austria)   Vincent Rijmen (Graz University of Technology, Austria)  Abstract: Message Authentication Code (MAC) algorithms can provide cryptographically secure authentication services. One of the most popular algorithms in commercial applications is HMAC based on the hash functions MD5 or SHA-1. In the light of new collision search methods for members of the MD4 family including SHA-1, the security of HMAC based on these hash functions is reconsidered.  We present a new method to recover both the inner- and the outer key used in HMAC when instantiated with a concrete hash function by observing text/MAC pairs. In addition to collisions, also other non-random properties of the hash function are used in this new attack. Among the examples of the proposed method, the first theoretical full key recovery attack on NMAC-MD5 is presented. Other examples are distinguishing, forgery and partial or full key recovery attacks on NMAC/HMAC-SHA-1 with a reduced number of steps (up to 62 out of 80). This information about the new, reduced security margin serves as an input to the selection of algorithms for authentication purposes.               Keywords: authentication, cryptography, security               Categories: C.2.0, D.4.6, E.3, K.6.5  
14|3||Parallel Key Exchange|  Ik Rae Jeong (Korea University, Korea)   Dong Hoon Lee (Korea University, Korea)  Abstract: In the paper we study parallel key exchange   among multiple parties. The status of parallel key exchange can be   depicted by a key graph. In a key graph, a vertex   represents a party and an edge represents a relation of two parties   who are to share a key.  We first propose a security model for a key graph, which extends the Bellare-Rogaway model for two-party key exchange. Next, we clarify the relations among the various security notions of key exchange. Finally, we construct an efficient key exchange protocol for a key graph using the randomness re-use technique. Our protocol establishes the multiple keys corresponding to all edges of a key graph in a single session. The security of our protocol is proven in the standard model.               Keywords: key exchange, key graph, randomness re-use, security notions               Categories: C.2.0, E.3  
14|3||Efficient k-out-of-n Oblivious Transfer Schemes|  Cheng-Kang Chu (National Chiao Tung University, Taiwan)   Wen-Guey Tzeng (National Chiao Tung University, Taiwan)  Abstract: Oblivious transfer is an important cryptographic   protocol in various security applications. For example, in on-line   transactions, a k-out-of-n   oblivious transfer scheme allows a buyer to   privately choose k out of   n digital goods from a merchant without learning   information about other n-k goods. In this paper,   we propose several efficient two-round   k-out-of-n oblivious transfer   schemes, in which the receiver R sends   O(k) messages to the sender   S, and S sends   O(n) messages back to   R. The schemes provide unconditional security for   either sender or receiver. The computational security for the other   side is based on the Decisional Diffie-Hellman (DDH) or   Chosen-Target Computational Diffie-Hellman (CT-CDH) problems. Our   schemes have the nice property of universal parameters, that is,   each pair of R and S need not   hold any secret before performing the protocol. The system   parameters can be used by all senders and receivers without any   trapdoor specification. In some cases, our OTkn schemes are the most   efficient ones in terms of the communication cost, either in rounds   or the number of messages. Moreover, one of our schemes is extended   to an adaptive oblivious transfer scheme. In that scheme,   S sends   O(n) messages to   R in one round in the commitment phase. For each   query of R, only O(1) messages   are exchanged and O(1) operations are   performed. The preliminary version of this paper was published at   PKC '05 [Chu and Tzeng 2005].               Keywords: electronic commerce, oblivious transfer, privacy protection               Categories: D.4.6, E.3, K.6.5  
14|3||Bilateral Unknown Key-Share Attacks in Key Agreement Protocols|  Liqun Chen (Hewlett-Packard Laboratories, United Kingdom)   Qiang Tang (École Normale Supérieure, France)  Abstract: Unknown Key-Share (UKS) resilience is a basic   security attribute in authenticated key agreement protocols. In this   paper we revisit the definitions of this attribute and the method of   proving this attribute under the Bellare-Rogaway (BR) model in the   literature. We propose a new type of UKS attack, which coerces two   entities A and B into sharing   a key with each other but in fact A thinks that   he is sharing the key with another entity C and   B thinks that he is sharing the key with another   entity D, where C and   D might or might not be the same entity. We call   this attack a Bilateral Unknown Key-Share (BUKS) attack. We   demonstrate that a few well-known authenticated key agreement   protocols are vulnerable to this attack. We then explore a gap   between the conventional BR-type proof and a BUKS adversary's   behavior, and extend the BR model to cover the BUKS resilience   attribute. At the end of the paper, we provide a general   countermeasure and its security proof under the extended model and   the assumption that a collision-resistance function   exists.               Keywords: authenticated key agreement, bilateral unknown key-share resilience, the Bellare-Rogaway model, unknown key-share resilience               Categories: E.3, H.1.1, H.4.3  
14|3||Formal Security Definition and Efficient Construction for Roaming with a Privacy-Preserving Extension|  Guomin Yang (City University of Hong Kong, Hong Kong)   Duncan S. Wong (City University of Hong Kong, Hong Kong)   Xiaotie Deng (City University of Hong Kong, Hong Kong)  Abstract: In a secure roaming scenario, a user   U travels to a foreign network and communicates   with a foreign server V securely so that no one   other than U and V can obtain   the messages exchanged between them. U may also   want to travel anonymously so that no one including   V can find out its identity or trace its   whereabouts except its home server H. There have   been many key establishment protocols proposed for secure roaming. A   typical application of these protocols is the mobile roaming service   which may be deployed to interconnected WLAN and 3G   networks. Despite the importance of these protocols, most of the   protocols are analyzed heuristically. They are lack of formal   security treatment.  In this paper, we propose a   formal key exchange definition and formalize secure roaming under   the Canetti-Krawczyk (CK) model. We also propose a formal model for   capturing the notions of user anonymity and untraceability. By using   the modular approach supported by the CK-model, we construct an   efficient key exchange protocol for roaming and then extend it to   support user anonymity and untraceability. The protocols are   efficient and each of them requires only four message flows among   the three parties U, H and   V. For building our protocols, we construct a   one-pass counter based MT-authenticator and show its security under   the assumption of a conventional MAC secure against chosen message   attack.               Keywords: anonymous roaming, authenticated key exchange               Categories: C.2.2, H.4.3  
14|3||Certificateless Public Key Encryption Secure against Malicious KGC Attacks in the Standard Model|  Yong Ho Hwang (Software Laboratories, Samsung Electronics Co., Ltd., Korea)   Joseph K. Liu (Institute for Infocomm Research (I2R), Singapore)   Sherman S.M. Chow (New York University, USA)  Abstract: Recently, Au et al. [Au et   al. 2007] pointed out a seemingly neglected security concern for   certificateless public key encryption (CL-PKE) scheme, where a   malicious key generation center (KGC) can compromise the   confidentiality of the messages by embedding extra trapdoors in the   system parameter. Although some schemes are secure against such an   attack, they require random oracles to prove the security. In this   paper, we first show that two existing CL-PKE schemes without random   oracles are not secure against malicious KGC, we then propose the   first CL-PKE scheme secure against malicious KGC attack, with proof   in the standard model.               Keywords: certificateless encryption, malicious KGC attack, standard model               Categories: E.3  
14|3||Parallel Formulations of Scalar Multiplication on Koblitz Curves|  Omran Ahmadi (University of Waterloo, Canada)   Darrel Hankerson (Auburn University, USA)   Francisco Rodríguez-Henríquez (CINVESTAV-IPN, Mexico)  Abstract: We present an algorithm that by using the τ   and τ-1 Frobenius operators concurrently   allows us to obtain a parallelized version of the classical   τ-and-add scalar multiplicationalgorithm for Koblitz elliptic   curves. Furthermore, we report suitable irreducible polynomials that   lead to efficient implementations of both τ and   τ-1, thus showing that our algorithm   canbe effectively applied on all the NIST-recommended curves. We   also present design details of software and hardware implementations   of our procedure. In a two-processor workstation soft-ware   implementation, we report experimental data showing that our   parallel algorithm is able to achieve a speedup factor of almost 2   when compared with the standard sequential point multipli-cation. In   our hardware implementation, the parallel version yields a more   modest acceleration of 17% when compared with the traditional point   multiplication algorithm. Although the focus ison Koblitz curves,   analogous strategies are discussed for other curves, in particular   for random curves over binary fields.               Keywords: Koblitz curves, elliptic curve cryptography, fast cryptographic algorithms, finite field arithmetic               Categories: B.2.4, E.3  
14|4|http://www.jucs.org/jucs_14_4|Managing Editor's Column|
14|4||Optimizing Assignment of Knowledge Workers to Office Space Using Knowledge Management CriteriaThe Flexible Office Case|  Ronald Maier (University of Innsbruck, Austria)   Stefan Thalmann (University of Innsbruck, Austria)   Florian Bayer (Martin-Luther-University Halle-Wittenberg, Germany)   Michael Krüger (GISA GmbH, Germany)   Hendrik Nitz (GISA GmbH, Germany)   Alexander Sandow (GISA GmbH, Germany)  Abstract: Even though knowledge management has been around   for more than a decade, so far concrete instruments that can be   systematically deployed are still rare. This paper presents an   optimization solution targeted at flexible management of office   space considering knowledge management criteria in order to enhance   knowledge work productivity. The paper presents the Flexible Office   conceptual model and optimization solution. It discusses the   theoretical foundation, assumptions and reasoning. A corresponding   prototype was field-tested, successfully introduced, evaluated with   the help of a series of interviews with users and improved according   to their requirements. The paper also reflects on the organizational   impact and lessons learned from field test and practical   experience.               Keywords: flexibility, hypertext organization, knowledge management, knowledge work, office space, optimization               Categories: G.2.3, H.1.2, H.4.1, H.5.3, K.4.3,, M.5  
14|4||Analyzing Wiki-based Networks to Improve Knowledge Processes in Organizations|  Claudia Müller (University of Potsdam, Germany)   Benedikt Meuthrath (University of Potsdam, Germany)   Anne Baumgraß (University of Potsdam, Germany)  Abstract: Increasingly wikis are used to support existing   corporate knowledge exchange processes. They are an appropriate   software solution to support knowledge processes.  However, it is   not yet proven whether wikis are an adequate knowledge management   tool or not. This paper presents a new approach to analyze existing   knowledge exchange processes in wikis based on network analysis.   Because of their dynamic characteristics four perspectives on wiki   networks are introduced to investigate the interrelationships   between people, information, and events in a wiki information space.   As an analysis method the Social Network Analysis (SNA) is applied   to uncover existing structures and temporal changes.  A scenario   data set of an analysis conducted with a corporate wiki is   presented.  The outcomes of this analysis were utilized to improve   the existing corporate knowledge processes.               Keywords: collaboration network, knowledge work, network analysis, social software, wiki               Categories: A.1, H.0, H.4.3, H.4.m, J.3, K.4.2, K.4.3, M.4  
14|4||Success Factors in a Weblog Community|  Christian Safran (Graz University of Technology, Austria)   Frank Kappe (Graz University of Technology, Austria)  Abstract: User generated content published via weblogs   (also known as blogs) has gained importance in the last years, and   the number of globally available weblogs increases. However, a large   fraction of these show low publishing activity and are rarely   read. This paper is a quantitative analysis of success factors in a   community of over 15.000 weblogs, hosted by a local Austrian   newspaper. We looked at publishing activity by content type,   community activity and writing style. Also, the interconnectedness   of the community was analyzed.               Keywords: blogging, e-communities, user generated content, weblog analysis               Categories: H.3.5, H.4.3, H.5.1, M.6  
14|4||Compensation Models for Interactive Advertising|  Astrid Dickinger (MODUL University Vienna, Austria)   Steffen Zorn (University of Western Australia, Australia)  Abstract: Due to a shift in the marketing focus from mass   to micro markets, the importance of one-to-one communication in   advertising has increased. Interactive media provide possible   answers to this shift. However, missing standards in payment models   for interactive media are a hurdle in the further development. The   paper reviews interactive advertising payment models. Furthermore,   it adapts the popular FCB grid as a tool for both advertisers and   publishers or broadcasters to examine effective interactive payment   models.               Keywords: classification, compensation model, interactive advertising               Categories: H.3.1, H.3.2, H.3.3, H.3.7, H.5.1, M.6  
14|4||A Linear Time Approximation Algorithm for Ruler Folding Problem|"  Ali Nourollah (Amirkabir University of Technology, Iran)   Mohammadreza Razzazi (Amirkabir University of Technology, Iran)  Abstract: A chain or n-link is a   sequence of n links whose lengths are fixed and are joined together   from their endpoints, free to turn about their endpoints, which act   as joints. ""Ruler Folding Problem"", which is   NP-Complete is to find the minimum length of the folded chain. The   best linear approximation algorithm for it were proposed by Hopcroft   et al. Their algorithm folds any open chain in the interval whose   length is less than 2m1,   where m1 is the length of   the longest link in the chain. We propose a linear time   approximation algorithm using O(1) additional   space. Our algorithm has lower upper bound for the length of the   folded chain which is max, where   m1 and   m2are the lengths of the   two distinct maximum length links in the chain respectively, and   k is the number of links whose lengths are   m1 in the chain. Hence it   is the best known approximation algorithm for ""Ruler   Folding Problem"".               Keywords: Carpenter's Ruler, Ruler Folding Problem, approximation algorithms               Categories: F.2, G.2.1  "
14|4||Publication Bias in the Computer           Science Education Research Literature|  Justus J. Randolph (University of Joensuu, Finland)   Roman Bednarik (University of Joensuu, Finland)  Abstract: Publication bias is the tendency for investigations with primarily nonstatistically significant findings to be withheld from the research record. Because publication bias has serious negative consequences for research and practice, we gathered information about the prevalence and predictors of publication bias in the computer science education literature. From an initial random sample of 352 recent computer science education articles, we reviewed the 38 empirical articles that used inferential statistical analyses. We found that (a) the proportion of articles reporting primarily statistically significant findings in computer science education was very similar to the proportion in medical research, (b) that an article's having a female first author was a strong predictor of an article's having primarily statistically significant results, and (c) that there was a tendency for authors to emphasize statistically significant findings and deemphasize nonstatistically significant findings. Neither whether an investigation was reported in a journal or conference proceeding nor whether the source of funding was disclosed were significant predictors of an article's having statistically positive results.               Keywords: computer science education, gender, publication bias, statistical reporting               Categories: K.3, K.3.2  
14|4||Spatial Queries in Road Networks Based on PINE|  Maytham Safar (Kuwait University, Kuwait)  Abstract: Over the last decade, due to the rapid developments in information technology (IT), a new breed of information systems has appeared such as geographic information systems that introduced new challenges for researchers, developers and users. One of its applications is the car navigation system, which allows drivers to receive navigation instructions without taking their eyes off the road. Using a Global Positioning System (GPS) in the car navigation system enables the driver to perform a wide range of queries, from locating the car position, to finding a route from a source to a destination, or dynamically selecting the best route in real time. Several types of spatial queries (e.g., nearest neighbour - NN, K nearest neighbours - KNN, continuous k nearest neighbours - CKNN, reverse nearest neighbour - RNN) have been proposed and studied in the context of spatial databases. With spatial network databases (SNDB), objects are restricted to move on pre-defined paths (e.g., roads) that are specified by an underlying network. In our previous work, we proposed a novel approach, termed Progressive Incremental Network Expansion (PINE), to efficiently support NN and KNN queries. In this work, we utilize our developed PINE system to efficiently support other spatial queries such as CKNN. The continuous K nearest neighbour (CKNN) query is an important type of query that finds continuously the K nearest objects to a query point on a given path. We focus on moving queries issued on stationary objects in Spatial Network Database (SNDB) (e.g., continuously report the five nearest gas stations while I am driving.) The result of this type of query is a set of intervals (defined by split points) and their corresponding KNNs. This means that the KNN of an object travelling on one interval of the path remains the same all through that interval, until it reaches a split point where its KNNs change. Existing methods for CKNN are based on Euclidean distances. In this paper we propose a new algorithm for answering CKNN in SNDB where the important measure for the shortest path is network distances rather than Euclidean distances. Our solution addresses a new type of query that is plausible to many applications where the answer to the query not only depends on the distances of the nearest neighbours, but also on the user or application need. By distinguishing between two types of split points, we reduce the number of computations to retrieve the continuous KNN of a moving object. We compared our algorithm with CKNN based on VN3 using IE (Intersection Examination). Our experiments show that our approach has better response time than approaches that are based on IE, and requires fewer shortest distance computations and KNN queries.               Keywords: PINE, Voronoi, continuous nearest neighbor, nearest neighbor, road network               Categories: E.1, E.2, H.3.3, H.5.1  
14|5|http://www.jucs.org/jucs_14_5|Socio-Economic Issues in Future Generation Internet|
14|5||Quality of Experience in Communications Ecosystem|  Kalevi Kilkki (Nokia Siemens Networks, Finland)  Abstract: Communications ecosystem covers a huge area from   technical issues to business models and human behaviour. Due to this   extreme diversity various societies need to discuss with each other,   each of them using their own language. Engineers talk about network   performance and quality of service, business people talk about   average revenue per user and customer churn while behavioural   scientists talk about happiness and experiences. Thus, everyone who   wants to understand, or even analyze, the whole ecosystem, has to   deal with all these diverse issues. In addition to the apparent   communication problems, the main challenges of ecosystem analysis   are to realistically model human behaviour, and to efficiently   combine the models developed for different domains. A central   concept when solving these problems is quality of experience   (QoE). This paper sheds light on the role of QoE by means of a   common framework that covers the whole communications   ecosystem. Additionally, a research agenda for a holistic ecosystem   analysis is outlined.               Keywords: analysis, business objective, ecosystem, happiness, holistic, modelling, quality of experience, quality of service               Categories: H.1.0  
14|5||Passive Estimation of Quality of Experience|  Denis Collange (Orange Labs, France)   Jean-Laurent Costeux (Orange Labs, France)  Abstract: Quality of Experience (QoE) is a promising   method to take into account the users' needs in design ing,   monitoring and manag ing networks.  However, there is a challenge in   finding a quick and simple way to estimate th e QoE due to the   diversity of needs , habits and customs. We propose a new empirical   method to approximate it automatically from passive network   measurements and we compare its pros and cons with usual   techniques. We apply it, as an example , on ADSL traffic traces to   estimate the QoE dependence on the loss rate for the most used   applications . We analyze more precisely the correlations between   packet losses and some traffic characteristics of TCP connections,   the duration, the sizes and the inter-arrival. We define different   thresholds on the loss rate for network management. A nd we propose   a notion of sensitiveness to compare these correlations on different   applications.               Keywords: end-to-end performance, internet performance, passive performance measurements, quality of experience, traffic analysis, user behaviour               Categories: C.2.3, C.4  
14|5||Trading Links and Paths on a Communication Bandwidth Market|  Wojciech Stańczuk (Warsaw University of Technology, Poland)   Józef Lubacz (Warsaw University of Technology, Poland)   Eugeniusz Toczyłowski (Warsaw University of Technology, Poland)  Abstract: This paper presents a novel market model for balancing communication bandwidth trade. The distinguishing characteristic of the model is that it assumes that market players can place buy offers not only for isolated network resources (inter-node links), but also for end-to-end network paths of predefined capacity. It also enables effective balancing of sell and buy offers for network resources in such a way which maximizes the global economic welfare. From a formal point of view, the model produces a linear programming problem for clearing a multi-commodity market. Three simple examples are used to discuss and illustrate the proposed model.               Keywords: bandwidth market, network design, resource allocation               Categories: C.2.1, K.6.0  
14|5||Cost Model for Bitstream Access Services with QoS Parameters|  Laura Rodríguez de Lope (University of Cantabria, Spain)   Klaus D. Hackbarth (University of Cantabria, Spain)  Abstract: The European Regulator Gr oup (ERG) defines   Bitstream Access Service as a wholesale service offered by a   broadband network operator with significant market power to an   Internet Service Provider , and identifies it as a market subje ct   to regulation.  This paper develops a cost model f or the Bitstream   Access Service under xDSL technology, following the recommendations   of the ERG , considering different user classes with differentiated   QoS requirements. For this purpose, three traffic engineering   methods are analysed: separate virtual tunnels, over-engineering and   priority queuing techniques.               Keywords: TELRIC, bitstream access service, cost model, over-engineering, priority queuing, quality of service               Categories: C.2.1  
14|5||Security and Usability Aspects of Man-in-the-Middle Attacks on ZRTP|  Martin Petraschek (ftw (Telecommunications Research Center Vienna), Austria)   Thomas Hoeher (ftw (Telecommunications Research Center Vienna), Austria)   Oliver Jung (ftw (Telecommunications Research Center Vienna), Austria)   Helmut Hlavacs    Wilfried Gansterer   Abstract: ZRTP is a protocol designed to set up a shared secret between two communication parties which is subsequently used to secure the media stream (i.e. the audio data) of a VoIP connection. It uses Diffie-Hellman (DH) key exchange to agree upon a session key, which is inherently vulnerable to active Man-in-the-Middle (MitM) attacks. Therefore ZRTP introduces some proven methods to detect such attacks. The most important measure is a so called Short Authentication String (SAS). This is a set of characters that is derived essentially from the public values of the Diffie-Hellman key exchange and displayed to the end users for reading out and comparing over the phone. If the SAS on the caller's and the callee's side match, there is a high probability that no MitM attack is going on. Furthermore, ZRTP offers a form of key continuity by caching key material from previous sessions for use in the next call. In order to prevent that a MitM can manipulate the Diffie-Hellman key exchange in such a way that both partners get the same SAS although different shared keys were negotiated, ZRTP uses hash commitment for the public DH value.  Despite these measures a Relay Attack (also known as Mafia Fraud Attack or Chess Grandmaster Attack) is still possible. We present a practical implementation of such an attack and discuss its characteristics and limitations, and show that the attack works only in certain scenarios.               Keywords: Man-in-the-Middle-Attack, ZRTP, security               Categories: K.6.5  
14|5||Enhancing ZRTP by using Computational Puzzles|"  Helmut Hlavacs (University of Vienna, Austria)   Wilfried Gansterer (University of Vienna, Austria)   Hannes Schabauer (University of Vienna, Austria)   Joachim Zottl (University of Vienna, Austria)   Martin Petraschek (ftw (Telecommunications Research Center Vienna), Austria)   Thomas Hoeher (ftw (Telecommunications Research Center Vienna), Austria)   Oliver Jung (ftw (Telecommunications Research Center Vienna), Austria)  Abstract: In this paper we present and discuss a new approach for securing multimedia communication, which is based on three innovations. The first innovation is the integration of a challenge-response scheme for enhancing the Diffie-Hellman based ZRTP protocol. When being called, a callee must present the result of a computational puzzle (a ""token"") within a short amount of time. A Man-in-the-Middle (MitM) would not be able to compute such a token within the required time, and thus fail to get into the media path. The scheme works best in situations when ZRTP is most vulnerable to so-called Mafia Attacks, i.e., if both caller and callee do not know each other.  The second innovation complements the first one on those occasions where the above scheme may fail. The call is delayed for a certain amount of time which depends on the agreed session key. Since during a MitM attack two different keys (and thus waiting times) exist, caller and callee would not start their call at the same time and the MitM attack would fail.  The third innovation is in the definition of a new computational puzzle which forms the basis of the challenge-response scheme. We propose a computational puzzle which is based on computing selected eigenvectors of real symmetric matrices. In contrast to existing puzzles, the one we propose does not rely on a shared secret, can be validated quickly, and existing solution methods exhibit limited scalability so that the threat from attacks based on massively parallel computing resources can be controlled.               Keywords: SRTP, VoIP, ZRTP, call delay, challenge-response, computational puzzle, eigenvectors               Categories: C.2.0, K.6.5  "
14|5||Drives and Barriers for Development of Broadband Access -  CE Perspective|"  Zbigniew Hulicki (AGH University of Science and Technology, Poland)  Abstract: Development of e-services in   the CE (Central European) countries d epends on a number of factors   which can result in overcoming or extending digital divide between   the ""new"" and ""old"" EU member states. These factors comprise both   drives of and barriers to development of broadband access and growth   of e-services. This paper provides insight into   the environment for the CE mass-market broadband adoption, and   examines each of the factors that condition this adoption: novel   approaches to increase ICT penetration; clear policy and legal   regulations; segmented service offerings for specific user needs in   such markets ; and innovative pricing schemes and service   packages.               Keywords: ICT, Web-based multimedia services, broadband access, digital divide, e-services               Categories: C.2.4, C.2.5, H.3.5, H.4, H.4.3, J.4, K.4, K.4.2  "
14|5||Approximation to a Behavioral Model for Estimating Traffic Aggregation Scenarios|  Alberto E. Garcia (University of Cantabria, Spain)   Klaus D. Hackbarth (University of Cantabria, Spain)  Abstract: This article provides a comparison among   different methods for estimating the aggregation of Internet traffic   resulting from different users, network-access types and   corresponding services. Some approximate models usually used as   isolated methods are combined with a temporally scaled ON-OFF model   with binomial approximations. The aggregation problem is solved   using a new form of parameterization based on the composition of the   source traffic accordingly to the concrete characteristics of the   users, the accesses and the services. This is a new concept, called   CASUAL, included within an overall network planning methodology for   the design and dimensioning of Next Generation Internet.               Keywords: network planning, network scenario, traffic modeling               Categories: C.2.1, C.4  
14|5||Optimal Transit Price Negotiation: The Distributed Learning Perspective|  Dominique Barth (PRiSM Laboratory, France)   Loubna Echabbi (INPT, Marocco)   Chahinez Hamlaoui (PRiSM Laboratory, France)  Abstract: We present a distributed learning algorithm for   optimizing transit prices in the inter-domain routing framework. We   present a combined game theoretical and distributed algorithmic   analysis, where the notion of Nash equilibrium with the first   approach meets the notion of stability in the second. We show that   providers can learn how to strategically set their prices according   to a Nash equilibrium; even when assuming incomplete information. We   validate our theoretical model by simulations confirming the   expected outcome. Moreover, we observe that some unilateral   deviations from the proposed rule do not seem to affect the dynamic   of the system.               Keywords: games with incomplete information, interdomain prices, learning, stability               Categories: C.2.4, G.1.7, I.2.6  
14|5||Dynamic Bandwidth Pricing: Provision Cost, Market Size, Effective Bandwidths and Price Games|"  Sergios Soursos (Athens University of Economics and Business, Greece)   Costas Courcoubetis (Athens University of Economics and Business, Greece)   Richard Weber (University of Cambridge, United Kingdom)  Abstract: Nowadays, in the markets of broadband access   services, traditional contracts are of ""static"" type. Customers buy   the right to use a specific amount of resources for a specific   period of time. On the other hand, modern services and applications   render the demand for bandwidth highly variable and bursty. New   types of contracts emerge (""dynamic contracts"") which allow   customers to dynamically adjust their bandwidth demand. In such an   environment, we study the case of a price competition situation   between two providers of static and dynamic contracts. We   investigate the resulting reaction curves, search for the existence   of an equilibrium point and examine if and how the market is   segmented between the two providers. Our first model considers   simple, constant provision costs. We then extend the model to   include costs that depend on the multiplexing capabilities that the   contracts offer to the providers, taking into consideration the size   of the market. We base our analysis on the theory of effective   bandwidths and investigate the new conditions that allow the   provider of dynamic contracts to enter the market.               Keywords: bandwidth on demand, competition, contracts, effective bandwidths, network economics, pricing, provision cost, reaction curves, statistical multiplexing               Categories: C.2.0, G.1.6, J.4  "
14|5||A Normal Copula Model for the Economic Risk Analysis of Correlated Failures in Communications Networks|"  Maurizio Naldi (Università di Roma ""Tor Vergata"", Italy)   Giuseppe D'Acquisto (Università di Roma ""Tor Vergata"", Italy)  Abstract: The reliability of a communications network is   often evaluated without taking into account the economic consequence   of failures. Here a new approach is proposed to assess the economic   consequences of failures as a figure of merit of reliable   networks. For this purpose a partition of the network operator's   market into service basins is proposed, which includes the presence   of correlation between the subsystems needed to serve different   service basins as well as within the same service basin. A   simulation algorithm, based on the Cross-Entropy method, is fully   described to evaluate the probability that the economic loss exceeds   a given threshold. An application of the method to a simple scenario   is finally reported.               Keywords: communications networks, reliability, risk analysis               Categories: C.2, C.4  "
14|6|http://www.jucs.org/jucs_14_6|Computability and Complexity in Analysis|
14|6||The Computable Multi-Functions on Multi-represented Sets are Closed under Programming|"  Klaus Weihrauch (University of Hagen, Germany)  Abstract: In the representation approach to computable   analysis (TTE) [Grz55, KW85, Wei00], abstract data like rational   numbers, real numbers, compact sets or continuous real functions are   represented by finite or infinite sequences (Σ*,   Σω) of symbols, which serve as   concrete names. A function on abstract data is called computable, if   it can be realized by a computable function on names. It is the   purpose of this article to justify and generalize methods which are   already used informally in computable analysis for proving   computability. As a simple formalization of informal programming we   consider flowcharts with indirect addressing. Using the fact that   every computable function on Σω can   be generated by a monotone and computable function on Σ* we   prove that the computable functions on   Σω are closed under flowchart   programming. We introduce generalized multi-representations, where   names can be from general sets, and define realization of   multi-functions by multi-functions. We prove that the function   computed by a flowchart over realized functions is realized by the   function computed by the corresponding flowchart over realizing   functions. As a consequence, data from abstract sets on which   computability is well-understood can be used for writing realizing   flowcharts of computable functions. In particular, the computable   multi-functions on multi-represented sets are closed under flowchart   programming. These results allow us to avoid the ""use of 0s and 1s""   in programming to a large extent and to think in terms of abstract   data like real numbers or continuous real functions. Finally we   generalize effective exponentiation to multi-functions on   multi-represented sets and study two different kinds of   λ-abstraction. The results allow simpler and more formalized   proofs in computable analysis.               Keywords: computable analysis, flowcharts, multi-functions, multi-representations, realization, λ-abstraction               Categories: F.0  "
14|6||Computable Riesz Representation for Locally Compact Hausdorff Spaces|  Hong Lu (Nanjing University, China)   Klaus Weihrauch (University of Hagen, Germany)  Abstract: By the Riesz Representation Theorem for locally   compact Hausdorff spaces, for every positive linear functional   I on K(X)   there is a measure μ such that   I(f) =∫   f dμ where   K(X) is the set of continuous   real functions with compact support on the locally compact Hausdorff   space X. In this article we prove a uniformly   computable version of this theorem for computably locally compact   computable Hausdorff spaces X. We introduce a   representation of the positive linear functionals   I on K(X)   and a representation of the Borel measures on X   and prove that for every such functional I a   measure μ can be computed and vice versa such that I(f) = ∫   f dμ.               Keywords: Hausdorff spaces, Riesz representation theorem, computable analysis, computable topology               Categories: F.0, F.1.0, F.1.1  
14|6||On the Subrecursive Computability of Several Famous Constants|  Dimiter Skordev (Sofia University, Bulgaria)  Abstract: For any class F of total functions in the   set N of the natural numbers, we define the notion of   F-computable real number. A real number α is called   F-computable if there exist one-argument functions   f, g and h   in F such that for any n in N the   distance between the rational number   f(n) -   g(n) over   h(n) + 1 and the number α   is not greater than the reciprocal of n + 1. Most   concrete real numbers playing a role in analysis can be easily shown   to be E3-computable (as usually,   Em denotes the m-th   Grzegorczyk class). Although (as it is proved in Section 5 of this   paper) there exist E3-computable real   numbers that are not E2-computable, we   prove that π, e and other remarkable real numbers are   E2-computable (the number π proves to   be even L-computable, where L is the class of Skolem's   lower elementary functions). However, only the rational numbers   would turn out to be E2-computable   according to a definition of F-computability using   2n instead of   n + 1.               Keywords: Euler's constant, Grzegorczyk classes, Liouville's number, computable real number, lower elementary functions, second Grzegorczyk class, π, e  Categories: F.1.3, F.2.1, G.0, G.1.0  
14|6||Computability of Topological Pressure for Sofic Shifts with Applications in Statistical Physics|  Christoph Spandl (Universität der Bundeswehr München, Germany)  Abstract: The topological pressure of dynamical systems theory is examined from a computability theoretic point of view. It is shown that for sofic shift dynamical systems, the topological pressure is a computable function. This result is applied to a certain class of one dimensional spin systems in statistical physics. As a consequence, the specific free energy of these spin systems is computable. Finally, phase transitions of these systems are considered. It turns out that the critical temperature is recursively approximable.               Keywords: Type-2 computability, hift dynamical systems, statistical physics, topological pressure               Categories: F.2.1, G.1.2, J.2  
14|6||Bloch's Constant is Computable|  Robert Rettinger (FernUniversität Hagen, Germany)  Abstract: We prove the computability of Bloch's constant   by presenting the first algorithm approximating the constant up to   arbitrary precision.               Keywords: Bloch's constant, algorithm, computability               Categories: F.0  
14|6||The Riemann Integral in Weak Systems of Analysis|  Fernando Ferreira (Universidade de Lisboa, Portugal)   Gilda Ferreira (CMAF-Universidade de Lisboa, Portugal)  Abstract: Taking as a starting point (a modification of) a   weak theory of arithmetic of Jan Johannsen and Chris Pollett   (connected with the hierarchy of counting   functions), we introduce successively stronger theories of   bounded arithmetic in order to set up a system   for analysis (TCA2). The   extended theories preserve the connection with the counting   hierarchy in the sense that the algorithms which the   systems prove to halt are exactly the ones in the hierarchy. We show   that TCA2 has the exact   strength to develop Riemannian integration for functions with a   modulus of uniform continuity.               Keywords: Riemann integral, counting hierarchy, weak analysis               Categories: F.1.3, F.4.1  
14|6||The Bit-Complexity of Finding Nearly Optimal Quadrature Rules for Weighted Integration|  Volker Bosserhoff (Universität der Bundeswehr, Germany)  Abstract: Given a probability measure ν and a   positive integer n. How to choose   n knots and n weights such   that the corresponding quadrature rule has the minimum worst-case   error when applied to approximate the ν-integral of Lipschitz   functions? This question has been considered by several authors. We   study this question whithin the framework of Turing   machine-based real computability and complexity theory as   put forward by [Ko 1991] and others. After having defined the notion   of a polynomialtime computable probability   measure on the unit interval, we will show that there are   measures of this type for which there is no computable optimal rule   with two knots. We furthermore characterize - in terms of difficult   open questions in discrete complexity theory - the complexity of   computing rules whose worst-case error is arbitrarily close to   optimal.               Keywords: quadrature rules, real computational complexity               Categories: F.2, F.4.1, G.1.4  
14|6||Notions of Probabilistic Computability on Represented Spaces|  Volker Bosserhoff (Universität der Bundeswehr, Germany)  Abstract: We define and compare several probabilistic   notions of computability for mappings from represented spaces (that   are equipped with a measure or outer measure) into computable metric   spaces. We thereby generalize definitions by [Ko 1991] and Parker   (see [Parker 2003, Parker 2005, Parker 2006]), and furthermore   introduce the new notion of computability in the   mean. Some results employ a notion of computable   measure that originates in definitions by [Weihrauch 1999]   and [Schröder 2007]. In the spirit of the well-known Representation   Theorem (see [Weihrauch 2000]), we establish dependencies between   the probabilistic computability notions and classical properties of   mappings. We furthermore present various results on the   computability of vector-valued integration, composition of mappings,   and images of measures. Finally, we discuss certain measurability   issues arising in connection with our definitions.               Keywords: computable analysis, computable measures, probabilistic computation               Categories: F.1.1, F.1.2, F.4.1  
14|6||On the Relationship between Filter Spaces and Weak Limit Spaces|  Matthias Schröder (Universität der Bundeswehr, Germany)  Abstract: Countably based filter spaces have been   suggested in the 1970's as a model for recursion theory on higher   types. Weak limit spaces with a countable base are known to be the   class of spaces which can be handled by the Type-2 Model of   Effectivity (TTE). We prove that the category of countably based   proper filter spaces is equivalent to the category of countably   based weak limit spaces. This result implies that filter spaces form   yet another category from which the category of qcb-spaces inherits   its cartesian closed structure. Moreover, we compare the   aforementioned categories to other categories of spaces relevant to   computability theory.               Keywords: QCB-spaces, convenient categories, equilogical spaces, filter spaces, higher type computation, topological spaces, weak limit spaces               Categories: F.2, F.4.1, G.1.4  
14|7|http://www.jucs.org/jucs_14_7|Collective Intelligence for Semantic and Knowledge Grid|
14|7||Ranking Retrieval Systems with Partial Relevance Judgements|  Shengli Wu (University of Ulster, United Kingdom)   Fabio Crestani (University of Lugano, Switzerland)  Abstract: Some measures such as mean average precision and   recall level precision are considered as good system-oriented   measures, because they concern both precision and recall that are   two important aspects for effectiveness evaluation of information   retrieval systems. However, such good system-oriented measures   suffer from some shortcomings when partial relevance judgments are   used. In this paper, we discuss how to rank retrieval systems in the   condition of partial relevance judgments, which is common in major   retrieval evaluation events such as TREC conferences and NTCIR   workshops. Four system-oriented measures, which are mean average   precision, recall level precision, normalized discount cumulative   gain, and normalized average precision over all documents, are   discussed. Our investigation shows that averaging values over a set   of queries may not be the most reliable approach to rank a group of   retrieval systems. Some alternatives such as Borda count, Condorcet   voting, and the Zero-one normalization method, are   investigated. Experimental results are also presented for the   evaluation of these methods.               Keywords: distributed information retrieval, ranking retrieval systems               Categories: H.3.1, H.3.3  
14|7||Query Transformation Based on Semantic Centrality in Semantic Social Network1|  Jason J. Jung (Yeungnam University, Korea)  Abstract: Query transformation is a serious hurdle on semantic peer-to-peer environment. Forinteroperability between peers, queries sent from a source peer have to be efficiently transformed to be understandable to potential peers processing the queries. However, the problem is that thetransformed queries might lose some information from the original one, as continuously traveling along peer-to-peer networks. We mainly consider two factors; i) number of transformations and ii) quality of ontology alignment. In this paper, we propose a new measurement of semanticcentrality, i.e., the power of semantic bridging on semantic peer-to-peer environment. Thereby, we want to build semantically cohesive user subgroups, so that semantic affinities between peerscan be computed. Then, given a query, we find out a path of peers for optimal interoperability between a source peer and a target one, i.e., minimizing information loss by the transformation.We have shown an example for retrieving image resources annotated on peer-to-peer environment by using query transformation based on semantic centrality.               Keywords: ontology alignment, query propagation, semantic social network               Categories: H.1.1, H.3.5, I.2.11  
14|7||Schema Mappings and Agents' Actions in P2P Data Integration System|  Grażyna Brzykcy (Poznań University of Technology, Poland)   Jerzy Bartoszek (Poznań University of Technology, Poland)   Tadeusz Pankowski (Poznań University of Technology, Poland)  Abstract: We propose specification of schema mappings and   agents' actions in XML data integration task. We discuss the problem   in a highly-dynamic environment consisting of a community of   peer-to-peer cooperating partners (agents). Peers decide how to   describe their local data, when to join and when to leave the   system, how to communicate and share their information with   partners. An agent responds to the query by asking its partners   (friends), which are able to partly answer the query. All the   answers are merged and final result is constructed. A peer   propagates a query along semantic paths existing in the   system. Semantic paths are determined by schema mappings defined   between partners. We propose a method for specifying schema mappings   and to translate them to XQuery expressions. Mappings are   represented by means of logical formulas. We also propose a   declarative specification of semantic-driven communication in the   system. The specification is made in a peer-oriented extension of   Prolog.               Keywords: Prolog-like computations, agent system, data integration               Categories: H.2,5, H.3.5, I.2.1  
14|7||An Improved Multi-Agent Simulation Methodology for Modelling and Evaluating Wireless Communication Systems Resource Allocation Algorithms|  Panagiotis Minas Papazoglou (University of Portsmouth, United Kingdom)   Dimitrios Alexios Karras (Chalkis Institute of Technology, Greece)   Rallis Constantine Papademetriou (University of Portsmouth, United Kingdom)  Abstract: Multi-Agent Systems (MAS) constitute a well known    approach in modelling dynamical real world systems. Recently, this    technology has been applied to Wireless Communication Systems    (WCS), where efficient resource allocation is a primary goal, for    modelling the physical entities involved, like Base Stations (BS),    service providers and network operators. This paper presents a    novel approach in applying MAS methodology to WCS resource    allocation by modelling more abstract entities involved in WCS    operation, and especially the concurrent network procedures    (services). Due to the concurrent nature of a WCS, MAS technology    presents a suitable modelling solution. Services such as new call    admission, handoff, user movement and call termination are    independent to one another and may occur at the same time for many    different users in the network. Thus, the required network    procedures for supporting the above services act autonomously,    interact with the network environment (gather information such as    interference conditions), take decisions (e.g. call establishment),    etc, and can be modelled as agents. Based on this novel simulation    approach, the agent cooperation in terms of negotiation and    agreement becomes a critical issue. To this end, two negotiation    strategies are presented and evaluated in this research effort and    among them the distributed negotiation and communication scheme    between network agents is presented to be highly efficient in terms    of network performance. The multi-agent concept adapted to the    concurrent nature of large scale WCS is, also, discussed in this    paper.               Keywords: agent negotiation strategies, dynamic channel allocation algorithms, multi-agent systems, resource allocation, simulation methodology, wireless communication systems               Categories: C.2, I.2.11, I.6.3, I.6.5, I.6.7  
14|7||An Agent-Based Solution for Dynamic Supply Chain Management|  Vedran Podobnik (University of Zagreb, Croatia)   Ana Petric (University of Zagreb, Croatia)   Gordan Jezic (University of Zagreb, Croatia)  Abstract: Supply chain management (SCM) deals with   planning and coordinating activities such as material procurement,   product assembly, and the distribution of manufactured   products. This paper offers an agent-based solution as a potentially   adequate approach for the automation of supply chain management. The   greatest obstacle in SCM research is obtaining benchmark designed   solutions since it is difficult to simulate real business   environments, while live testing in real-world systems is not an   option. The Trading Agent Competition Supply Chain Management (TAC   SCM) scenario provides a unique testbed for studying and prototyping   SCM agents by providing a challenging game environment where   competing agents engage in complex decision-making activities with   the purpose of maximizing their profit. In this paper, we describe   the TAC SCM environment and present the main features of the   CrocodileAgent, our TAC SCM 2007 entry. Additionally, the   CrocodileAgents performance in the competition, as well as in a   series of controlled experiments, is discussed.               Keywords: electronic markets, multi-agent simulation, software agents, supply chain management, trading agents               Categories: I.2.1, I.6.0, J.7, K.4.4  
14|7||A Knowledge Discovery Agent for a Topology Bit-map in Ad Hoc Mobile Networks|  SungSoo Lee (Yeungnam University, Korea)   HangKon Kim (Catholic University of Daegu, Korea)   ChongGun Kim (Yeungnam University, Korea)  Abstract: A central characteristic of ad hoc mobile networks is the frequent changes of their topology.  This is the source of many problems that need to be solved. AODV is an on-demand routing protocol for decreasing maintenance overhead in ad hoc networks. However, some path breaks can cause significant overhead and transmission delays. If the maintenance overhead of the ro uting table can be reduced, table -driven routing methods could be an efficient substitution.  In this paper , we propose a knowledge discovery agent for an effective routing method that uses simple bit -map topology information.  The agent node gathers topology knowledge and creates topology bit -map information.  All available paths from a source to a destination can easily be calculate d using the bit-map. All the nodes in the network maintain the bit-map distributed from the agent, and use it for the source of routing. The performance and the correctness of the proposed agent method is verified by computer simulations.               Keywords: AODV, ad hoc networks, bit-map table, knowledge discovery agent, reducing overhead, table-driven routing               Categories: C.2.1, C.2.2, C.2.3  
14|7||Formalizing Agent-Based English Auctions Using Finite State Process Algebra|  Amelia Bădică (University of Craiova, Romania)   Costin Bădică (University of Craiova, Romania)  Abstract: The vision of global agent-based e-commerce   environments that enable dy-namic trading between business partners   requires the study and development of suitable formal modeling   frameworks. In particular, negotiation is a necessary and   importantactivity to allow engagement of business parties in   non-trivial business relationships. In this paper we propose a   formal framework based on finite state process   algebra formodeling and analysis of interaction protocols   in agent-based negotiations. The approach is demonstrated by   applying the framework to model agent interactions in asingle-item   English auction scenario.               Keywords: English auction, formal specification, multi-agent system, process algebra               Categories: I.2.11, I.2.4, K.4.4  
14|7||Reinforcement Learning on a Futures Market Simulator|  Koichi Moriyama (Osaka University, Japan)   Mitsuhiro Matsumoto (Osaka University, Japan)   Ken-ichi Fukui (Osaka University, Japan)   Satoshi Kurihara (Osaka University, Japan)   Masayuki Numao (Osaka University, Japan)  Abstract: In recent years, market forecasting by machine learning methods has been flourishing.Most existing works use a past market data set, because they assume that each trader's individual decisions do not affect market prices at all. Meanwhile, there have been attempts to analyzeeconomic phenomena by constructing virtual market simulators, in which human and artificial traders really make trades. Since prices in a market are, in fact, determined by every trader'sdecisions, a virtual market is more realistic, and the above assumption does not apply. In this work, we design several reinforcement learners on the futures market simulator U-Mart (UnrealMarket as an Artificial Research Testbed) and compare our learners with the previous champions of U-Mart competitions empirically.               Keywords: market simulation, reinforcement learning               Categories: I.2.6, I.6.8  
14|7||Structural Performance Evaluation of Multi-Agent Systems|  Dariusz Król (Wrocław University of Technology, Poland)   Michał Zelmozer (Wrocław University of Technology, Poland)  Abstract: This paper is dedicated to the issue of   structural performance of multi-agent platforms. Due to the wide   range of all available architectures, we have concentrated only on   Java RMI implementations. The main goal of this paper consists of   two parts. The first one is to investigate and develop the   performance metrics to enable evaluation of distributed systems   without reorganization of the running system. The second part is the   programming verification of two considered Java RMI multi-agent   solutions: Aglets and Jade. We have examined the defined metrics in   many experiments with different network and environment   configurations to provide experimental evidence that these metrics   are adequate in variety of conditions.               Keywords: metric, multi-agent system, performance evaluation               Categories: C 2.4, C.4, H.1.0  
14|8|http://www.jucs.org/jucs_14_8|Software Components, Architectures and Reuse|
14|8||Model Interpreter Frameworks:A Foundation for the Analysis of Domain-Specific  Software Architectures|  George Edwards (University of Southern California, USA)   Chiyoung Seo (University of Southern California, USA)   Nenad Medvidovic (University of Southern California, USA)  Abstract: Abstract: Prediction of the quality attributes   of software architectures requires technologies that enable the   application of analyt ic theories to component mode ls. However,   available analytic techniques generally opera te on formal models   specified in notations that cannot flexibly and intuitively capture   the architectures of large- scale distributed system s. The   construction of model interpreters that transform architectural m   odels into analysis mode ls has proved to be a complex and difficult   task. This paper (1) de scribes a methodology for performing   automated analysis of architectural models that simplifies the   development of model interpreters and enables effective reuse of   interpreter logic, an d (2) demonstrates how a framework that   utilizes the methodology can be designed, implemented, utilized, and   evaluated.               Keywords: component-based systems, model-driven engineering, software architecture               Categories: D.2.10, D.2.11, D.2.2  
14|8||Embedded Software Revitalization through Component Mining and Software Product Line Techniques|  Marcelo A. Ramos (VeriFone do Brasil, Brazil)   Rosângela A. D. Penteado (Federal University of Sâo Carlos, Brazil)  Abstract: The mining of generic software components from legacy systems can be used as an auxiliary technique to revitalize systems. This paper presents a software maintenance approach that uses such technique to revitalize one or more embedded legacy systems simultaneously and, in addition, create a core of reusable assets that can be used to support the development of new similar products. Software Product Line techniques are used to support the tasks of domain modelling and software component development. A real case study in the domain of Point of Sale (POS) terminals is presented and it illustrates the use of the proposed approach to revitalize three similar embedded legacy systems, simultaneously. It also shows how it is possible, through the created core of reusable assets, to deliver variations of these systems to meet the requirements of a wide family of POS terminals with different hardware configurations.               Keywords: component mining, embedded system, feature model, gateway, hardware decomposition, maintenance, reuse, software product line               Categories: D.2.13  
14|8||Experimenting the Automated Selection of COTS Components Based on Cost and System Requirements|"  Vittorio Cortellessa (Università dell'Aquila, Italy)   Ivica Crnkovic (Mälardalen University, Sweden)   Fabrizio Marinelli (Università Politecnica delle Marche, Italy)   Pasqualina Potena (Università ""G.D'Annunzio"", Italy)  Abstract: In a component-based development process the   selection of components is an activity that takes place over   multiple lifecycle phases that span from requirement specifications   through design to implementation and integration. In different   phases, different assumptions are valid and different granularity of   information is available, which has a consequence that different   procedure should be used in the selection process and an automated   tool support for an optimized component selection would be very   helpful in each phase. In this paper we analyze the assumptions and   propose the selection procedure in the requirements phase. The   selection criterion is based on cost minimization of the whole   system while assuring a certain degree of satisfaction of the system   requirements that can be considered before designing the whole   architecture. For the selection and optimization procedure we have   adopted the DEER (DEcision support for componEnt-based softwaRe)   framework, previously developed to be used in the selection process   in the design phase. The output of DEER indicates the optimal   combination of single COTS (Commercial-Off-The-Shelf) components and   assemblies of COTS that satisfy the requirements while minimizing   costs. In a case study we illustrate the selection and optimization   procedure and an analysis of the model sensitivity to changes in the   requirements.               Keywords: COTS selection, optimization model, software requirements               Categories: D.2.1  "
14|8||LIFT - A Legacy InFormation Retrieval Tool|  Kellyton dos Santos Brito (Federal University of Pernambuco, Brazil)   Vinícius Cardoso Garcia (Federal University of Pernambuco, Brazil)   Eduardo Santana de Almeida (Recife Center for Advanced Studies and Systems, Brazil)   Silvio Romero de Lemos Meira (Federal University of Pernambuco, Brazil)  Abstract: Nowadays software systems are essential to the   environment of most organizations, and their maintenance is a key   point to support business dynamics. Thus, reverse engineering legacy   systems for knowledge reuse has become a major concern in software   industry. This article, based on a survey about reverse engineering   tools, discusses a set of functional and non-functional requirements   for an effective tool for reverse engineering, and observes that   current tools only partly support these requirements. In addition,   we define new requirements, based on our groups experience and   industry feedback, and present the architecture and implementation   of LIFT: a Legacy InFormation retrieval Tool, developed based on   these demands. Furthermore, we discuss the compliance of LIFT with   the defined requirements. Finally, we applied the LIFT in a reverse   engineering project of a 210KLOC NATURAL/ADABAS system of a   financial institution and analyzed its effectiveness and   scalability, comparing data with previous similar projects performed   by the same institution.               Keywords: knowledge reuse, legacy systems, reverse engineering, system understanding               Categories: D.2.1, D.2.13, D.2.7, K.6.3  
14|8||Mismatch Avoidance in Web Services Software Architectures|  Cristina Gacek (University of Newcastle, United Kingdom)   Carl Gamble (University of Newcastle, United Kingdom)  Abstract: Architectural mismatches are a recognized obstacle to successful software reuse. An architectural mismatch occurs when two or more software components are connected to form a system and those components make differing and incompatible assumptions about their interactions or the environment in which they exist.  Mismatch detection and avoidance has been previously discussed in existing literature. These typically take the form of generic rules and guidelines. Service Oriented Architectures (SOA) are becoming one of the main trends in the current engineering of software. Using web services, as defined by W3C Web Services Architecture Working Group, supports the engineering of SOA by providing rules and restrictions that apply to the definition of web services and how they can interact with other components to form a larger system. We see this as an opportunity to define a web services style with corresponding rules to avoid the introduction of architectural mismatches at design time.  In this paper we describe the development of an environment which supports SOA development by enabling their description, as well as facilitating the detection of potential mismatches between web services. Here we define a web services style in the architectural description language ACME & Armani, and present the environment that we developed in ACME Studio using our web services style definition. This is accompanied by a small case study illustrating the use of our environment.               Keywords: acme, architectural mismatch, architectural style, software architecture, web services               Categories: D.2.11, D.2.12  
14|8||CrossMDA: a Model-driven Approach for Aspect Management|  Marcelo Pitanga Alves (Federal University of Rio de Janeiro (UFRJ), Brazil)   Paulo F. Pires (University of Rio Grande do Norte (UFRN), Brazil)   Flávia C. Delicato (University of Rio Grande do Norte (UFRN), Brazil)   Maria Luiza M. Campos (Federal University of Rio de Janeiro (UFRJ), Brazil)  Abstract: Nowadays, the complexity of software   applications has brought new challenges to developers, having to   deal with a large number of computational requirements. Among these   requirements, those known as crosscutting concerns transpass   components boundaries, leading to maintainability and comprehension   problems. This paper presents CrossMDA, a framework that encompasses   a transformation process to integrate crosscutting concerns in   model-oriented systems. It uses the concepts of horizontal   separation of concerns from AOP to create independent business and   aspect models, integrating those models through MDA transformations   (vertical separation of concerns). CrossMDA comprises a development   process, a set of services and support tools. The main advantages of   this approach are to raise the abstraction level of aspect modeling,   to promote the reuse of crosscutting concerns modeled as PIM   elements, besides automating the process of mapping the relationship   of crosscutting concerns and business models through the process of   MDA transformations.               Keywords: MDA transformations, aspect oriented software development, crosscutting concerns, model driven architecture               Categories: D.2.10, D.2.13, D.2.2, H.4.3  
14|8||A Product Derivation Tool Based on Model-Driven Techniques and Annotations|  Elder Cirilo (Pontifical Catholic University of Rio de Janeiro, Brazil)   Uirá Kulesza (New University of Lisbon, Portugal)   Carlos José Pereira de Lucena (Pontifical Catholic University of Rio de Janeiro, Brazil)  Abstract: In this paper, we present a model-based tool for product derivation. Our tool is centered on the definition of three models (feature, architecture and configuration models) which enable the automatic instantiation of software product lines (SPLs) or frameworks. The Eclipse platform and EMF technology are used as the base for the implementation of our tool. A set of specific Java annotations are also defined to allow generating automatically many of our models based on existing implementations of SPL architectures. We illustrated the use and validation of our tool in the preparation of the automatic derivation of the JUnit framework and a J2ME games product line.               Keywords: generative programming, model-driven development, product derivation tools, software product lines               Categories: D.2.13, D.2.3  
14|8||A Service-oriented Process to Develop Web Applications|  Fábio Zaupa (Universidade Estadual de Maringá, Brazil)   Itana M. S. Gimenes (Universidade Estadual de Maringá, Brazil)   Don Cowan (The University of Waterloo, Canada)   Paulo Alencar (The University of Waterloo, Canada)   Carlos J. P. Lucena (Puc-Rio, Brazil)  Abstract: Web applications are widely disseminated, but,   traditional development methods for this type of application still   require a substantial amount of new modeling and   programming. Current methods do not take significant advantage of   reuse techniques, such as software product lines (PL). This paper   presents the WIDE-PL environment focusing on its application   generation process, called Application DEvelopment based on Services   - ADESE. This environment is an evolution of WIDE - Waterloo   Informatics Development Environment. The WIDE-PL environment   supports the generation of Web applications based on the   Service-oriented Architecture (SOA) and the product line   approach. Our solution encompasses a general software architecture,   an application generation process, and a set of mandatory and   optional services. Examples of applications from two different   domains were developed using ADESE to evaluate its feasibility. The   results show that the process offers several advantages including an   increase in reuse and an explicit separation between the services   and the business process connecting those services.               Keywords: Web applications, Web-based services, business process, product line               Categories: D.2.m  
14|9|http://www.jucs.org/jucs_14_9|Designing the Human Computer Interaction: Trends and Challenges|
14|9||NASDAQ Velocity and Forces: An Interactive Visualization of Activity and Change|  Huyen Tue Dao (University of Maryland, United States)   Adam Bazinet (University of Maryland, United States)   Robin Berthier (University of Maryland, United States)   Ben Shneiderman (University of Maryland, United States)  Abstract: NASDAQ Market Velocity and Market Forces are two   relatively new data products that attempt to capture market   sentiment, something that was previously only observable if one was   on a trading floor. Given the transient and temporal properties of   the data, we were challenged to create a visualization that would   highlight the ever-changing qualities of Velocity and Forces. To   that end, we developed FireStox, a web application that provides   unified representation and filtering solutions to help market   researchers observe the behavior of these metrics for one or many   companies throughout the course of a trading day.               Keywords: NASDAQ velocity and forces, graphical user interface, information visualization, stock market data analysis, stock market visualization               Categories: J.4  
14|9||Supporting Informal Collaboration in Shared-Workspace Groupware|  Carl Gutwin (University of Saskatchewan, Canada)   Saul Greenberg (University of Calgary, Canada)   Roger Blum (University of Saskatchewan, Canada)   Jeff Dyck (University of Saskatchewan, Canada)   Kimberly Tee (University of Calgary, Canada)   Gregor McEwan (University of Calgary, Canada)  Abstract: Shared-workspace groupware has not become common   in the workplace, despite many positive results from research   labs. One reason for this lack of success is that most shared   workspace systems are designed around the idea of planned, formal   collaboration sessions — yet much of the collaboration that occurs   in a co-located work group is informal and opportunistic. To support   informal collaboration, groupware must be designed and built   differently. We introduce the idea of community-based groupware   (CBG), in which groupware is organized around groups of people   working independently, rather than shared applications, documents,   or virtual places. Community-based groupware provides support for   three things that are fundamental to informal collaboration:   awareness of others and their individual work, lightweight means for   initiating interactions, and the ability to move into   closely-coupled collaboration when necessary. We demonstrate three   prototypes that illustrate the ideas behind CBG, and argue that this   way of organizing groupware supports informal collaboration better   than other existing approaches.               Keywords: awareness, community-based groupware, groupware, real-time interaction               Categories: H.5.2, H.5.3  
14|9||CIAM: A Methodology for the Development of Groupware User Interfaces|  Ana I. Molina (La Mancha University, Spain)   Miguel A. Redondo (La Mancha University, Spain)   Manuel Ortega (La Mancha University, Spain)   Ulrich Hoppe (University of Duisburg-Essen, Germany)  Abstract: The design of the groupware systems is a   progressively extended task, which is difficult to tackle. There are   not proposals to support the joint modeling of collaborative and   interactive issues of this kind of systems, that is, proposals that   allow designing the presentation layer of these applications. In   order to solve this lack we propose a methodological approach, based   on a set of notations of both a graphical and a textual nature.               Keywords: groupware design, interaction design, model based design               Categories: D.2.1, D.2.2, H.5.2, H.5.3  
14|9||Collaborative Explicit Plasticity Framework: a Conceptual Scheme for the Generation of Plastic and Group-Aware User Interfaces|  Montserrat Sendín (University of Lleida, Spain)   Víctor López-Jaquero (University of Castilla-La Mancha, Spain)   César A. Collazos (University of Cauca, Colombia)  Abstract: The advent of new advances in mobile computing   has changed the manner we do our daily work, even enabling us to   perform collaborative activities. However, current groupware   approaches do not offer an integrating and efficient solution that   jointly tackles the flexibility and heterogeneity inherent to   mobility as well as the awareness aspects intrinsic to collaborative   environments. Issues related to the diversity of contexts of use are   collected under the term plasticity. A great amount of tools have   emerged offering a solution to some of these issues, although always   focused on individual scenarios. We are working on reusing and   specializing some already existing plasticity tools to the groupware   design. The aim is to offer the benefits from plasticity and   awareness jointly, trying to reach a real collaboration and a deeper   understanding of multi-environment groupware scenarios. In   particular, this paper presents a conceptual framework aimed at   being a reference for the generation of plastic User Interfaces for   collaborative environments in a systematic and comprehensive   way. Starting from a previous conceptual framework for individual   environments, inspired on the model-based approach, we introduce   specific components and considerations related to groupware.               Keywords: awareness, groupware, model-based approach, plasticity, shared-knowledge               Categories: D.2.2, H.1.1, H.1.2, H.5.2  
14|9||Defining Tasks, Domains and Conversational Acts in CSCW Systems: the SPACE-DESIGN Case Study|  Rafael Duque (University of Castilla - La Mancha, Spain)   Jesús Gallardo (University of Castilla - La Mancha, Spain)   Crescencio Bravo (University of Castilla - La Mancha, Spain)   António José Mendes (Universidade de Coimbra, Portugal)  Abstract: Most of the current academic and professional   work requires collaboration between the members of a working   group. Groupware tools play a prevailing role in supporting this   collaborative work, often from different locations and at the same   time. The research field of CSCW (Computer-Supported Cooperative   Work) studies how to design effective groupware tools. To increase   their potential, groupware systems must be flexible and have the   capacity to adapt themselves to multiple tasks and situations. In   order to provide answers to these challenges, in this article we   propose the use of meta-models and XML-based languages to specify   the most important characteristics of a groupware modeling system,   such as the application domain, the requirements of the tasks to be   carried out, how communication takes place and the regulation of the   shared workspace. These models and techniques have been used to   develop a specific groupware system called SPACE-DESIGN   (SPecification and Automatic Construction of collaborative   Environments of DESIGN), a CSCW tool with support for synchronous   distributed collaborative work that adapts and re-configures itself   as a result of processing the domain specification, the task, the   communication and the system working norms.               Keywords: CSCW, groupware, model-driven development               Categories: D.2.2, H.4.3, H.5.3  
14|9||Capturing Interaction Requirements in a Model Transformation Technology Based on MDA|  Jose Ignacio Panach (Technical University of Valencia, Spain)   Sergio España (Technical University of Valencia, Spain)   Inés Pederiva (Technical University of Valencia, Spain)   Óscar Pastor (Technical University of Valencia, Spain)  Abstract: Currently, many models are used to capture   functional software requirements. However, the Software Engineering   community has faded interaction requirements into the background,   dealing with interface mainly in design time. A sound MDA-compliant   software development methodology, called OO-Method, is extended in   this work to bridge this gap. The issue is to define a methodology   for capturing interaction requirements. For this purpose, the formal   notation ConcurTaskTrees (CTT) is used. This notation is a technique   that is well-known in the Human Computer Interaction community. A   set of interaction patterns has been defined to build CTT   models. These patterns are defined with a very precise syntax and   semantics. Moreover, transformation rules are defined to transform   the Task Model into the OO-Method Presentation Model, which   specifies the user interface in an abstract and platform-independent   way. However, since editing the CTT models is hard work, this paper   proposes superimposing a layer to the CTT diagram in order to   capture interaction requirements using sketches. CTT models will be   synchronously generated from these sketches. Because this   transformation is 'transparent' to the analyst, he only needs to   draw the sketches during the interaction requirements   elicitation. The approach presented in this paper is instantiated   for the environment of the OLIVANOVA   technology. This environment makes it possible to obtain a final   software product from its corresponding Conceptual Model through a   Model Compilation process, where interaction modeling is properly   embedded with the most conventional data and process   modeling.               Keywords: Model Compiler, automatic code, automatic code generation, interaction requirements, model transformation, sketches, usability               Categories: H.5.2, I.6.5  
14|9||WebA: A Tool for the Assistance in Design and Evaluation of Websites|  Luis Mena Tobar (Parque Tecnológico Walqa, Spain)   Pedro M. Latorre Andrés (Centro Politécnico Superior, Spain)   Elena Lafuente Lapena (Parque Tecnológico Walqa, Spain)  Abstract: The development, analysis and follow-up of the   processes designed to assure the usability and accessibility of   websites is a tedious work for the moderator or evaluator. This is   why there is a necessity for tools that can automate the processes.   There are some tools that cover some of the technical aspects, but   no tools have been identified that can tackle the process as a   whole. For these reasons the Aragonese Usability Laboratory decided   to develop WebA (Web Analysis), with the objective to have a   complete application. This application is designed through modules   with the objective of covering all of the evaluation and analysis   phases, and it concludes with a process management module. For the   analysis phase a Card Sorting module (open & closed) has been   developed that uses the hierarchical and multidimensional cluster   analysis, which allows a better information architecture. For the   evaluation phases, modules have been developed that allow the   semiautomatic evaluation of usability through user satisfaction   tests based on Nielsen heuristics and ISO standards, the evaluation   of accessibility through the verification of WCAG 1.0   guidelines. The application concludes with a process design and   evaluation management module, and modules that automatically   generate the reports of the analysis carried out.               Keywords: accessibility of websites, human computer interaction, usability engineering, website usability evaluation               Categories: H.1.2, H.5.2, H.5.3  
14|9||Testing Website Usability in Spanish-Speaking Academia through Heuristic Evaluation and Cognitive Walkthroughs|  María Paula González (National Council of Scientific and Technical Research CONICET, Argentina)   Toni Granollers (Universitat de Lleida, Spain)   Afra Pascual (Universitat de Lleida, Spain)  Abstract: Although usability evaluations have been focused   on assessing different contexts of use, no proper specifications   have been addressed towards the particular environment of academic   websites in the Spanish-speaking context of use. Considering that   this context involves hundreds of millions of potential users, the   AIPO Association is running the UsabAIPO Project. The ultimate goal   is to promote an adequate translation of international standards,   methods and ideal values related to usability in order to adapt them   to diverse Spanish-related contexts of use. This article presents   the main statistical results coming from the Second and Third Stages   of the UsabAIPO Project, where the UsabAIPO Heuristic method (based   on Heuristic Evaluation techniques) and seven Cognitive Walkthroughs   were performed over 69 university websites. The planning and   execution of the UsabAIPO Heuristic method and the Cognitive   Walkthroughs, the definition of two usability metrics, as well as   the outline of the UsabAIPO Heuristic Management System prototype   are also sketched.               Keywords: Spanish-speaking context of use, UsabAIPO heuristic method, UsabAIPO metrics, cognitive walkthrough, usability evaluation               Categories: H.3.1, H.3.2, H.3.3, H.3.7, H.5.1  
14|9||Easing the Smart Home: Semi-automatic Adaptation in Perceptive Environments|"  Manuel García-Herranz (Universidad Autónoma de Madrid, Spain)   Pablo A. Haya (Universidad Autónoma de Madrid, Spain)   Abraham Esquivel (Universidad Autónoma de Madrid, Spain)   Germán Montoro (Universidad Autónoma de Madrid, Spain)   Xavier Alamán (Universidad Autónoma de Madrid, Spain)  Abstract: This paper analyses the requirements of   automation and adaptation in the so called perceptive   environments. These environments are places with the ability of   perceiving the context through sensors and other   mechanisms. Focusing on personal/home environments, we present a   first approach and prototype to semi-automatic adaptation of   Perceptive Environments through a system of rule-based, configurable   and modular agents, which are able to explain their behaviors and to   adapt to the changing habits of the users. This prototype has been   implemented over a real environment: a living room equipped with   ambient intelligence capabilities. The core of the system relies on   a set of modular agents equipped with rules. Those rules are   composed of triggers, conditions and actions that enable them to   express desired behaviors of the environment as well as to infer   high-level context from low level context. One of the main   objectives of the system is to leverage the control of the user over   his/her own environment, making it easy to create powerful and   personal behaviors without expert assistance. In this sense this   work follows Greenbergs thought of making ""simple ideas simple to   be done"" [Greenberg 07].               Keywords: ambient intelligence, automatic adaptation, natural programming, smart home, ubiquitous computing               Categories: C.2.4 , H.1.2, H.5.2, I.2.5  "
14|9||Development of Ambient Intelligence Systems Based on Collaborative Task Models|  Roberto F. Arroyo (Universidad de Granada, Spain)   Miguel Gea (Universidad de Granada, Spain)   José Luis Garrido (Granada, Spain)   Pablo A. Haya (Universidad Autónoma de Madrid, Spain)  Abstract: So far, the Ambient Intelligence (AmI) paradigm has been applied to the development of a great variety of real systems. They use advanced technologies such as ubiquitous computing, natural interaction and active spaces, which become part of social environments. In the design of AmI systems, the inherent collaboration among users (with the purpose of achieving common goals) is usually represented and treated in an ad-hoc manner. However, the development of this kind of systems can take advantage of rich design models which embrace concepts in the domain of collaborative systems in order to provide the adequate support for explicit or implicit collaboration. Thereby, relevant requirements to be satisfied, such as an effective coordination of human activities by means of task scheduling, demand to dynamically manage and provide group- and context-awareness information. This paper addresses the integration of both proactive and collaborative aspects into a unique design model for the development of AmI systems; in particular, the proposal has been applied to a learning system. Furthermore, the implementation of this system is based on a blackboard- based architecture, which provides a well-defined high-level interface to the physical layer.               Keywords: Context awareness, ambient intelligence, collaborative model, task modeling, ubiquitous computing               Categories: D.2.1, D.2.11, H.1.2, H.5.3  
volume|issue|url|title|abstract
15|1|http://www.jucs.org/jucs_15_1|Logic, Abstract State Machines and Databases|
15|1||On Defining the Behavior of OR-joins in Business Process Models|  Egon Börger (Università di Pisa, Italy)   Ove Sörensen (University of Kiel, Germany)   Bernhard Thalheim (University of Kiel, Germany)  Abstract: The recent literature on business process   modeling notations contains numerous contributions to the so-called   OR-join (or inclusive merge gateway) problem. We analyze the problem   and present an approach to solve it without compromising any of the   two major concerns that are involved: a) a clear semantical   definition (design), which also clarifies what has to be implemented   to achieve the intended generality of the construct, and b) a   comprehensive set of static and dynamic analysis methods   (verification of properties of business process models using the   construct). We provide a conceptually simple scheme for dynamic   OR-join synchronization policies, which can be implemented with low   run-time overhead and allows the practitioner to effectively link   the design of business process models with OR-joins to an analysis   of the intended model properties. The definitions have been   experimentally validated by a graph-based simulator.               Keywords: BPMN standard, OR-join problem, business processes               Categories: D.1.7, D.2.1, D.2.4  
15|1||Dynamic Query Optimization under Access Limitations and Dependencies|  Andrea Calì (University of Oxford, United Kingdom)   Diego Calvanese (Free University of Bozen-Bolzano, Italy)   Davide Martinenghi (Politecnico di Milano, Italy)  Abstract: Unlike relational tables in a database, data   sources on the Web typically can only be accessed in limited   ways. In particular, some of the source fields may be required as   input and thus need to be mandatorily filled in order to access the   source. Answering queries over sources with access limitations is a   complex task that requires a possibly recursive evaluation even when   the query is non-recursive. After reviewing the main techniques for   query answering in this context, in this article we consider the   impact of functional and inclusion dependencies on dynamic query   optimization under access limitations. In particular, we address the   implication problem for functional dependencies and simple   full-width inclusion dependencies, and prove that it can be decided   in polynomial time. Then we provide necessary and sufficient   conditions, baseon the dependencies together with the data retrieved   at a certain step of the query answering process, that allow   avoiding unnecessary accesses to the sources.               Keywords: access limitations, functional dependencies, inclusion dependencies, query optimization               Categories: H.2  
15|1||Non-Denumerable Infinitary Modal Logic|  Max J. Cresswell (University of Auckland, New Zealand)  Abstract: Segerberg established an analogue of the   canonical model theorem in modal logic for infinitary modal   logic. However, the logics studied by Segerberg and Goldblatt are   based on denumerable sets of pairs ‹Γ, α› of   sets Γ of well-formed formulae and well-formed formulae   α. In this paper I show how a generalisation of the infinite   cut-rule used by Segerberg and Goldblatt enables the removal of the   limitation to denumerable sets of sequents.               Keywords: canonical model, cut-rule, infinitary modal logic, uniform substitution               Categories: F.4.1  
15|1||Reasoning about Nonblocking Concurrency|  Lindsay Groves (Victoria University of Wellington, New Zealand)  Abstract: Verification of concurrent algorithms has been   the focus of much research over a considerable period of time, and a   variety of techniques have been developed that are suited to   particular classes of algorithm, for example algorithms based on   message passing or mutual exclusion. The development of   nonblocking or lock-free   algorithms, which rely only on hardware primitives such as Compare   And Swap, present new challenges for verification, as they allow   greater levels of currency and more complex interactions between   processes.    In this paper, we describe and   compare two approaches to reasoning about nonblocking algorithms. We   give a brief overview of the simulation approach   we have used in previous work. We then give a more detailed   description of an approach based on Lipton's   reduction method, and illustrate it by verifying   two versions of a shared counter and two versions of a shared   stack. Both approaches work by transforming a concurrent execution   into an equivalent sequentia-execution, but they differ in the way   that executions are transformed and the way that transformations are   justified.               Keywords: atomicity, concurrency, linearisability, lock-free algorithms, nonblocking algorithms, reduction, shared memory, simulation relation, verification               Categories: D.1.3, D.2.4, F.3.1  
15|1||Weak Functional Dependencies: Full Propositional Expressiveness for the Database Practitioner|  Sven Hartmann (Clausthal University of Technology, Germany)   Sebastian Link (Victoria University of Wellington, New Zealand)  Abstract: We study inference systems of weak functional dependencies in relational and complex-value databases. Functional dependencies form a very common class of database constraints. Designers and administrators proficiently utilise them in everyday database practice. Functional dependencies correspond to the linear-time decidable fragment of Horn clauses in propositional logic. Weak functional dependencies take advantage of arbitrary clauses, and therefore represent full propositional reasoning about data in databases. Moreover, they can be specified in a way that is very similar to functional dependencies.  In relational databases the class of weak functional dependencies is finitely axiomatisable and the associated implication problem is coNP-complete in general. Our first main result extends this axiomatisation to databases in which complex elements can be derived from atomic ones by finitely many nestings of record, list and disjoint union constructors. In particular, we construct two nested tuples that can serve as a counterexample relation for the implication of weak functional dependencies. We further apply this construction to show an equivalence to truth assignments that serve as counterexamples for the implication of propositional clauses. Hence, we characterise the implication of weak functional dependencies in complex-value databases in completely logical terms. Consequently, state-of-the-art SAT solvers can be applied to reason about weak functional dependencies in relational and complex-value databases.               Keywords: axiomatisation, complex-value database, propositional logic, relational database, weak functional dependency               Categories: F.4, H.2  
15|1||Using Abstract State Machines to Model ARIES-based Transaction Processing|  Markus Kirchberg (Agency forScience, Technology and Research (A*STAR), Singapore)  Abstract: Transaction management is an essential component of database management systems. It enables multiple users to access the database concurrently while preserving transactional properties such as atomicity, consistency, isolation, and durability.  In this paper, we propose a formal framework specification for transaction processing. Our work can be seen as an extension of previous work by Gurevich et al. who have presented a formalism for general database recovery processing. Based on this formalism, we incorporate additional mechanisms that remove several explicit constraints, support normal transaction processing, and, most importantly, apply the approach to more advanced recovery mechanisms.               Keywords: Abstract State Machines, concurrency control, database recovery, transaction processing               Categories: D.2, H.2  
15|1||Global Database Design based on Storage Space and Update Time Minimization|  Henning Köhler (University of Queensland, Australia)  Abstract: A common approach in designing relational databases is to start with a universal relation schema, which is then decomposed into multiple subschemas. A good choice of subschemas can be determined using integrity constraints defined on the schema, such as functional, multivalued or join dependencies.  In this paper we propose and analyze a new normal form based on the idea of minimizing overall storage space and update costs, and as a consequence redundancy as well. This is in contrast to existing normal forms such as BCNF, 4NF or KCNF, which only characterize the absence of redundancy (and thus space and update time minimality) for a single schema. We show that our new normal form naturally extendexisting normal forms to multiple schemas, and provide an algorithm for computing decompositions.               Keywords: database design, dependencies, normal form, universal relation               Categories: F.4, H.2.1  
15|1||Formal Verification of Semistructured Data Models in PVS|  Scott Uk-Jin Lee (The University of Auckland, New Zealand)   Gillian Dobbie (The University of Auckland, New Zealand)   Jing Sun (The University of Auckland, New Zealand)   Lindsay Groves (Victoria University of Wellington, New Zealand)  Abstract: The rapid growth of the World Wide Web has   resulted in a dramatic increase in semistructured data usage,   creating a growing need for effective and efficient utilization of   semistructured data. In order to verify the correctness of   semistructured data design, precise descriptions of the schemas and   transformations on the schemas must be established. One effective   way to achieve this goal is through formal modeling and automated   verification. This paper presents the first step towards this   goal. In our approach, we have formally specified the semantics of   the ORA-SS (Object-Relationship-Attribute data model for   Semistructured data) data modeling language in PVS (Prototype   Verification System) and provided automated verification support for   both ORA-SS schemas and XML (Extensible Markup Language) data   instances using the PVS theorem prover. This approach provides a   solid basis for verifying algorithms that transform schemas for   semistructured data.               Keywords: Automated verification, Data modeling, ORA-SS, PVS, Semistructured data               Categories: D.2.4, H.2.1  
15|1||A Formal Framework of Aggregation for the OLAP-OLTP Model|  Hans-J. Lenz (Free University Berlin, Germany)   Bernhard Thalheim (Christian-Albrechts-University Kiel, Germany)  Abstract: OLAP applications are widely used in business applications. They are often (implicitly) defined on top of OLTP systems and extensively use aggregation and transformation functions. The main OLAP data structure is a multidimensional table with three kinds of attributes: so-called dimension attributes, implicit attributes given by aggregation functions and fact attributes. Domains of dimension attributes are structured and thus support a variety of aggregations. These aggregations are used to generate new values for the fact attributes. In this paper we systematically develop a theory for OLAP applications. We first define aggregation functions and use these to introduce an OLAP algebra. Based on these foundations we derive properties that guarantee or contradict correctness of OLAP computations. Finally, for pragmaticatreatment of OLAP applications the OLTP-OLAP specification frame is introduced.               Keywords: OLAP, OLTP-OLAP specification frame, aggregation functions, cube operator               Categories: D.2.10, H.4  
15|1||A Characterisation of Coincidence Ideals for Complex Values|  Attila Sali (Alfréd Rényi Institute of Mathematics, Hungary)   Klaus-Dieter Schewe (Information Science Research Centre, New Zealand)  Abstract: We investigate properties of coincidence ideals   in subattribute lattices that occur in complex value datamodels,   i.e. sets of subattributes, on which two complex values coincide. We   let complex values be defined by constructors for records, sets,   multisets, lists, disjoint union and optionality, i.e. the   constructors cover the gist of all complex value data models. Such   lattices carry the structure of a Brouwer algebra as long as the   union-constructor is absent, and for this case sufficient and   necessary conditions for coincidence ideals are already known. In   this paper, we extend the characterisation of coincidence ideals to   the most general case. The presence of the disjoint union   constructor complicates all results and proofs significantly. The   reason for this is that the union-constructor causes non-trivial   restructuring rules to hold. The characterisation of coincidence   ideal is of decisive importance for the axiomatisation of (weak)   functional dependencies.               Keywords: coincidence ideal, complex values, restructuring               Categories: F.4.1, H.2.1  
15|1||Dynamic Data Warehouse Design with Abstract State Machines|  Jane Zhao (Information Science Research Centre, New Zealand)   Klaus-Dieter Schewe (kdschewe@acm.org, New Zealand)   Henning Koehler (University of Queensland, Australia)  Abstract: On-line analytical processing (OLAP) systems   deal with analytical tasks that support decision making. As these   tasks do not depend on the latest updates by transactions, it is   assumed that the data required by OLAP systems are kept in a data   warehouse, which separates the input from operational databases from   the outputs to OLAP. However, user requirements for OLAP systems   change over time. Data warehouses and OLAP systems thus are rather   dynamic and the design process is continuous. In order to easily   incorporate new requirements and at the same time ensure the quality   of the system design, we suggest to apply the Abstract State Machine   (ASM) based development method. This assumes we capture the basic   user requirements in a ground model and then apply stepwise   refinements to the ground model for every design decisions or   further new requirements. In this article, we show that a   systematical approach which is tailored for data warehouse design   with a set of formal refinement rules can simplify the work in   dynamic data warehouse design and at the same time improves the   quality of the system.               Keywords: Abstract State Machine, Data Warehouse, On-Line Analytical Processing, Refinement               Categories: D.2.10, H.4  
15|10|http://www.jucs.org/jucs_15_10|Information Integration on Web-based Applications and Services|
15|10||Updates, Schema Updates and Validation of XML Documents - Using Abstract State Machines with Automata-Defined States|  Klaus-Dieter Schewe (Information Science Research Centre, New Zealand)   Bernhard Thalheim (University of Kiel, Germany)   Qing Wang (University of Otago, New Zealand)  Abstract: The exact validation of streaming XML documents can be realised by using visibly push-down automata (VPA) that are defined by Extended Document Type Definitions (EDTD). It is straightforward to represent such an automaton as an Abstract State Machine (ASM). In doing so we enable computations on abstract states that are defined by a certain class of automata, in this case VPAs. In this paper we elaborate on this approach by taking also updates of XML documents into account. In this way the ASM-approach combines vertical refinements, which first make states explicit and then instantiate by a specific EDTD, with horizontal refinements, which replace streaming XML documents by stored ones and then add updates. Furthermore, as the EDTD appears as part of the abstract state, updating it is another natural extension by horizontal refinement. In this way we obtain consistently integrated updates and schema updates for XML documents, which can even be extended to become fault-tolerant by taking at most k errors in the document into consideration. It further provides an example of ASM-based computation with automata-defined states.               Keywords: Abstract State Machines, Validation, XML               Categories: E.m, H.2  
15|10||SQL/XML Hierarchical Query Performance Analysis in an XML-Enabled Database System|  Eric Pardede (La Trobe, Australia)   J. Wenny Rahayu (La Trobe, Australia)   Ramanpreet Kaur Aujla (La Trobe, Australia)   David Taniar (Monash University, Australia)  Abstract: The increase utilization of XML structure for data representation, exchange, and integration has strengthened the need for an efficient storage and retrieval of XML data. Currently, there are two major streams of XML data repositories. The first stream is the Native XML database systems which are built solely to store and manipulate XML data, and equipped with the standard XML query language known as XPath and XQuery. The second stream is the XML-Enabled database systems which are generally existing traditional database systems enhanced with XML storage capabilities. The SQL/XML standard for XML querying is used in these enabled database systems stream. The main specific characteristic of this standard is the fact that XPath and XQuery are embedded within SQL statements. To date, most existing work in XML query analysis have been focussing on the first stream of Native XML database systems. The focus of this paper is to present a taxonomy of different hierarchical query patterns in XML-Enabled database environment, and to analyze the performance of the different query structures using the SQL/XML standard.               Keywords: SQL/XML Query, XML, XML-Enabled Database               Categories: H.2.7  
15|10||An Agent for Web-based Structured Hypermedia Algorithm Explanation System|  Elhadi M. Shakshuki (Acadia University, Canada)   Richard Halliday (Acadia University, Canada)  Abstract: Studying and understanding algorithms is   important for all computer scientists. Over two decades of research   has been devoted to improving algorithm visualization and algorithm   explanation techniques. Knowledge gained from these practices allows   us to design and implement logically correct programs with   considerations to runtime and memory constraints. For many students,   learning algorithms in a traditional manner (i.e. using text-books)   is challenging. We have developed an alternative approach to   teaching algorithms called the Structured Hypermedia Algorithm   Explanation (SHALEX) system, which uses hypermedia and represents   algorithms as an abstract tree structure. Although SHALEX is a fully   functioning teaching tool, currently it does not provide a way of   receiving feedback on students progress. To address this problem,   this paper extends SHALEX with intelligent agent to monitor student   progress, to provide the student with hints where necessary and to   record the results of student interaction, all of which provide a   means of quantifying the level of understanding the student has   achieved. The system is implemented as a web-based application using   the client-server architecture. This allows students to learn   algorithms through both distance education and in the classroom   setting.               Keywords: HCI, agents, algorithm Explanation, hypermedia, trees, visualization               Categories: H.5.1, H.5.2, H.5.4, I.2.4  
15|10||Application Framework with Demand-Driven Mashup for Selective Browsing|  Sohei Ikeda (Kobe University, Japan)   Takakazu Nagamine (Kobe University, Japan)   Tomio Kamada (Kobe University, Japan)  Abstract: We are developing a new mashup framework for   creating flexible applications in which users can selectively browse   through mashup items. The framework provides GUI components called   widgets through which users can browse mashed-up data selectively,   and the system processes demand-driven creation of mashed-up data   upon receiving access requests through widgets. The application   developer has to only prepare a configuration file that specifies   how to combine web services and how to display mashed-up data. This   paper proposes a revised widget model for effective data display,   and introduces practical applications that allow selective   browsing. The revision of the widget model is to accept various GUI   components, process user interactions, and provide cooperative   widgets. To avoid conflict with lazy data creation, we introduce   properties into widgets that are automatically maintained by the   system and can be monitored by other widgets. The case study through   the applications shows the situations where the initially browsed   data helps users to terminate redundant searches, set effective   filter settings, or change the importance of the criteria. Some   applications display synoptic information through columns, maps, or   distribution charts; such information is useful for selective   browsing.               Keywords: Ajax, Mashup, Web, Web Application, Web Service               Categories: D.2.6, H.3.3, H.4.3  
15|11|http://www.jucs.org/jucs_15_11|Software Components, Architectures and Reuse|
15|11||An Approach for Estimating Execution Time Probability Distributions of Component-based Real-Time Systems|  Ricardo Perrone (Federal University of Bahia, Brazil)   Raimundo Macedo (Federal University of Bahia, Brazil)   George Lima (Federal University of Bahia, Brazil)   Veronica Lima (Federal University of Bahia, Brazil)  Abstract: In recent years, many component-based real-time   systems have been proposed as a solution to modular and easily   maintainable distributed real-time systems. This paper proposes a   methodology for estimating probability distributions of execution   times in the context of such systems, where no access to component   internal code is assumed. In order to evaluate the proposed   methodology, experiments were conducted with components, and related   compositions, implemented over CIAO and ARCOS. CIAO is a known   real-time component-based middleware and ARCOS is a software   framework devoted to the construction of real-time control and   supervision applications, also developed over CIAO. The collected   experimental data show that the proposed approach is indeed a good   approximation for component execution time probability   distributions.               Keywords: COTS, distributed middleware, real-time systems, response time estimation               Categories: D.2, D.2.2, D.2.6  
15|11||Distribution Pattern-driven Development of Service Architectures|  Ronan Barrett (Ericsson Ireland Research Centre, Ireland)   Claus Pahl (Dublin City University, Ireland)  Abstract: Distributed systems are being constructed by   composing a number of discrete com-ponents. This practice is   particularly prevalent within the Web service domain in the form of   service process orchestration and choreography. Often, enterprise   systems are built from manyexisting discrete applications such as   legacy applications exposed using Web service interfaces. There are   a number of architectural configurations or distribution patterns,   which express how acomposed system is to be deployed in a   distributed environment. However, the amount of code required to   realise these distribution patterns is considerable. In this paper,   we propose a distri-bution pattern-driven approach to service   composition and architecting. We develop, based on a catalog of   patterns, a UML-compliant framework, which takes existing Web   service interfacesas its input and generates executable Web service   compositions based on a distribution pattern chosen by the software   architect.               Keywords: architecture modelling, distribution pattern, service composition, service process generation, service-oriented architecture               Categories: C.2.4, D.2.11, D.2.2, D.2.7  
15|11||Checking Semantics Equivalence of MDA Transformations in Concurrent Systems|  Paulo Barbosa (Federal University of Campina Grande, Brazil)   Franklin Ramalho (Federal University of Campina Grande, Brazil)   Jorge Figueiredo (Federal University of Campina Grande, Brazil)   Antonio Júnior (Federal University of Campina Grande, Brazil)   Aniko Costa (Universidade Nova de Lisboa, Portugal)   Luis Gomes (Universidade Nova de Lisboa, Portugal)  Abstract: In a previous work we have proposed an extension   to the four-layer MDAarchitecture promoting formal verification for   semantics preserving model transformations. We analyzed semantics   equivalence in transformations involving Platform Specific Models   (PSM s). In this paper, considering concurrent systems domain, we   show how this extended MDA architecture copes with the correctness   verification of horizontal model transformations involving Platform   Independent Models (PIM s). Our approach is supported by four formal   techniques: behavioral equivalence relation, category the-ory,   bisimulation and model-checking. This set of techniques allows the   analysis of semantics equivalence between system model before and   after transformation enablingthe decomposition of the system model   into a set of concurrent sub-models, considered as components. The   validation of our approach occurs in a net splitting operation,where   PIM s are defined as Petri nets models according to the PNML   metamodel with transformations representing formal operations in   this domain.               Keywords: MDA, concurrent systems, formal semantics, petri nets, transformations               Categories: F.3.2, F.4.2, H.1, H.4.2  
15|11||A Flexible Strategy-Based Model Comparison Approach: Bridging the Syntactic and Semantic Gap|  Kleinner Oliveira (Pontifical Catholic University of Rio de Janeiro (PUC-Rio), Brazil)   Karin Breitman (Pontifical Catholic University of Rio de Janeiro (PUC-Rio), Brazil)   Toacy Oliveira (University of Waterloo, Canada)  Abstract: In this paper we discuss the importance of model   comparison as one of the pillars of model-driven development   (MDD). We propose an innovative, flexible, model comparison   approach, based on the composition of matching strategies. The   proposed approach is fully implemented by a match operator that   combines syntactical matching rule,   synonym dictionary and typographic   similarity strategies to a semantic,   ontology-based strategy. Ontologies are   semantically richer, have greater power of expression than UML   models and can be formally verified for consistency, thus providing   more reliability and accuracy to model comparison. The proposed   approach is presented in the format of a workflow that provides   clear guidance to users and facilitates the inclusion of new   matching strategies and evolution.               Keywords: model comparison, model driven development, ontology alignment, unified modeling language               Categories: H.3.1, H.3.2, H.3.3, H.3.7, H.5.1  
15|11||Assessment of the Design Modularity and Stability of Multi-Agent System Product Lines|  Camila Nunes (Pontifical Catholic University of Rio de Janeiro, Brazil)   Uirá Kulesza (Federal University of Rio Grande do Norte - UFRN, Brazil)   Cláudio Sant'Anna (Federal University of Bahia, Brazil)   Ingrid Nunes (Pontifical Catholic University of Rio de Janeiro, Brazil)   Alessandro Garcia (Pontifical Catholic University of Rio de Janeiro, Brazil)   Carlos Lucena (Pontifical Catholic University of Rio de Janeiro, Brazil)  Abstract: A multi-agent system product line (MAS-PL) defines an architecture, whose design and implementation is accomplished using software agents to address its common and variable features. MAS-PL promotes the large-scale reuse of common and variable agency features across multiple MAS applications. The development of MAS-PLs can be achieved through MAS-specific platforms and implementation techniques, such as conditional compilation and aspect-oriented programming (AOP). However, there is not much evidence on how these techniques provide better modularity, allowing the conception of stable MAS-PL designs. This paper presents a quantitative study on the design modularity and stability of an evolving MAS-PL. The MAS-PL was built following the reactive product line adoption approach. The product line was developed and evolved based on several versions of a conference management web-based system, named Expert Committee (EC). Our evaluation is made through a series of change scenarios related to new agency features, which are agent characteristics that enhance the system with autonomous behavior. The quantitative study consists of a systematic comparison between two different versions of the EC MAS-PL based on a MAS-specific platform, called JADE. One version was implemented with object-oriented and conditional compilation techniques. The other one relied on AOP. Our analysis was driven by well-known modularity and change impact metrics.               Keywords: empirical software engineering, multi-agent systems, software metrics, software product lines               Categories: D.1.5, D.2.10, D.2.11, D.2.8  
15|12|http://www.jucs.org/jucs_15_12|Intelligent Environments and Services|
15|12||Causality Join Query Processing for Data Streams via a Spatiotemporal Sliding Window|  Oje Kwon (Pusan National University, South Korea)   Ki-Joune Li (Pusan National University, South Korea)  Abstract: Data streams collected from sensors contain a   large volume of useful information including causal   relationships. Causality join query processing involves retrieving a   set of pairs (cause, effect) from streams of data. However, some   causal pairs may be omitted from the query result, due to the delay   between sensors and the data stream management system, and the   limited size of the sliding window. In this paper, we first   investigate temporal, spatial, and spatiotemporal aspects of   causality join query processing for data streams. Second, we propose   several strategies for sliding window management based on these   results. The accuracy of the proposed strategies is studied via   intensive experimentation. The result shows that we can improve the   accuracy of causality join query processing in data streams with   respect to the simple FIFO strategy.               Keywords: causality join query processing, data stream, spatiotemporal sliding window               Categories: H.3.3  
15|12||Meeting Warming-up: Detecting Common Interests and Conflicts among Participants before a Meeting|  Zhiyong Yu (Northwestern Polytechnical University, P. R. China)   Zhiwen Yu (Northwestern Polytechnical University, P. R. China)   Xingshe Zhou (Northwestern Polytechnical University, P. R. China)   Daqing Zhang (TELECOM & Management SudParis, France)   Yuichi Nakamura (Kyoto University, Japan)  Abstract: In order to boost both efficiency and   effectiveness of meetings, we propose a novel Meeting Warming-up   system to detect common interests and conflicts among participants   before a meeting. The basic idea of the proposed approach is:   firstly, modelling user preference by extending the attribute   concept tree with additional relations both in and across   attributes; secondly, determining common interests and conflicts   through preference propagation and merging; thirdly, visualizing the   detected results via a group preference graph. As a result, each   participant can intuitively understand the groups opinions as a   whole and warm up for discussions around potential outcomes. In   particular, the meeting may have an easy and friendly start with   commonly agreed outcomes, the commonly disagreed items may be   ignored to save time, and participants may be mentally prepared to   discuss the possible conflicts carefully and sufficiently. The   experimental results showed that our approach is   feasible.               Keywords: group dynamics, preference propagation, smart meeting, user preference, visualization               Categories: H.5.3  
15|12||Service Conflict Management Framework  for Multi-user Inhabited Smart Home|  Choonsung Shin (GIST U-VR Lab., South Korea)   Woontack Woo (GIST U-VR Lab., South Korea)  Abstract: In this paper, we propose a service conflict   management framework for detecting and resolving conflicts of   multi-users who share context-aware applications within a smart   home. For supporting a general solution to deal with the multi-user   conflicts, the framework utilizes an ontology that describes   applications and their services, an approach determination tree that   assigns an appropriate resolution strategy to the conflict, and a   set of resolution strategies. Based on this ontology, it dynamically   detects conflicts associated among multiple users who are using   various applications affecting each other, or the same application   with different preferences. An appropriate resolution method is   assigned to the conflict according to the properties involved, their   relationship, and users' preferences. The detected conflict is   resolved either by an automatic decision, based on either priority   or preferences, or by a user decision. Through implementing and   evaluating the framework to a smart home test-bed, we found that the   proposed framework dynamically detected and flexibly resolved   multi-user conflicts which occurred among the services of multiple   applications, as well as within a single application.               Keywords: conflict management, intelligent space, multi-user conflict, ubiquitous computing               Categories: H.5.2, H.5.3  
15|12||On the Personalization of Personal Networks - Service Provision Based on User Profiles|  Ioannis G. Nikolakopoulos (National Technical University of Athens, Greece)   Charalampos Z. Patrikakis (National Technical University of Athens, Greece)   Antonio Cimmino (Alcatel-Lucent Italia S.p.A., Italy)   Martin Bauer (NEC Europe Ltd., Germany)   Henning Olesen (Copenhagen Institute of Technology (AAU), Denmark)  Abstract: In this paper, we present a user profile   definition scheme featuring context awareness. Though the scheme has   been designed to meet the needs of web applications deployed over   heterogeneous devices, emphasis is given in the deployment of the   profile scheme over Personal Networks (PNs), as the personalization   of the deployed applications and services in PN environments is of   great importance. The proposed scheme is presented as part of an   integrated framework for user profile management that takes into   account (and is therefore compliant to) the existing standardization   attempts. The overall architecture and description of the profile   management framework, taking into account security issues inside   Personal Networks, is presented. The paper concludes by showcasing   how user profiles have been incorporated in a selected pilot service   of the EU IST research project MAGNET Beyond.               Keywords: context, identity, personal network, service architecture, user profile               Categories: C.3, J.0  
15|12||Next Generation of Terrorism: Ubiquitous Cyber Terrorism with the Accumulation of all Intangible Fears|  Hai-Cheng Chu (Tunghai University, Taiwan, R.O.C.)   Der-Jiunn Deng (National Changhua University of Education, Taiwan, R.O.C.)   Han-Chieh Chao (National Dong Hwa University, Taiwan, R.O.C.)   Yueh-Min Huang (National Cheng Kung University, Taiwan, R.O.C.)  Abstract: It is an urgent, imminent and present danger   that we have to focus on the traditional terrorists, who are   transforming ICT into the modern attacking tools that can devastate   the metropolitan areas with the deconstruction of critical   infrastructures via the computer network using state-of-the-art   hacking and cracking technologies. The cyber terrorists could   inflict catastrophic loss or damage on civilians, corporations or   the governments physically thousands of miles away and accomplish   severe death polls than the traditional one. The government in the   public sector or the private critical infrastructure administrators   should not underestimate these potential cyber attacks. In this   paper, we presented the cyber terrorism, the next generation of   terrorism, to be a forthcoming and unavoidable threat to the global   community as well as providing a potential rational cyber terrorist   scenario, which could be the global cyber terrorism phenomena. This   paper explicitly demonstrates the feasibility of launching cyber   attacks toward critical infrastructures that might cause severe   casualties.               Keywords: Internet vulnerability, critical infrastructure, cyber terrorism, hacktivism, malicious code, process control system (PCS)               Categories: J.0  
15|12||A Joint Web Resource Recommendation Method based on Category Tree and Associate Graph|  Linkai Weng (Tsinghua University, China)   Yaoxue Zhang (Tsinghua University, China)   Yuezhi Zhou (Tsinghua University, China)   Laurence T. Yang (St .Francis Xavier University, Canada)   Pengwei Tian (Tsinghua University, China)   Ming Zhong (Tsinghua University, China)  Abstract: Personalized recommendation is valuable in various web applications, such as e-commerce, music sharing, and news releasing, etc. Most existing recommendation methods require users to register and provide their private information before gaining access to any services, whereas a majority of users are reluctant to do so, which greatly limits the range of application of such recommendation methods. In the non-register environments, the only available information is the content or attributes of resources and the click-through chains of user sessions, so that many recommendation methods fail to work effectively due to the rating sparsity [Adomavicius and Tuzhilin, 2005] and illegibility of user identity, collaborative filtering [Goldberg et al. 1992] is an example of this case. In this paper we propose a joint recommendation method combining together two approaches, namely the domain category tree and the associate graph, to make full use of all available information. Further, an associate graph propagation method is designed to improve the traditional associate filtering method by integrating additional graphical considerations into them. Experiment results show that our method outperforms either the single category tree approach or the single associate graph approach, and it can provide acceptable recommendation services even in the non-register environment.               Keywords: category tree, graph propagation, personalized recommendation, personalized service               Categories: L.1.3, L.2.2, M.4, M.5  
15|12||Mining Dynamic Databases using Probability-Based Incremental Association Rule Discovery Algorithm|  Ratchadaporn Amornchewin (King Mongkut's Institute of Technology Ladkrabang, Thailand)   Worapoj Kreesuradej (King Mongkut's Institute of Technology Ladkrabang, Thailand)  Abstract: In dynamic databases, new transactions are   appended as time advances. This paper is concerned with applying an   incremental association rule mining to extract interesting   information from a dynamic database. An incremental association rule   discovery can create an intelligent environment such that new   information or knowledge such as changing customer preferences or   new seasonal trends can be discovered in a dynamic environment. In   this paper, probability-based incremental association rule discovery   algorithm is proposed to deal with this problem. The proposed   algorithm uses the principle of Bernoulli trials to find expected   frequent itemsets. This can reduce a number of times to scan an   original database. This paper also proposes a new updating and   pruning algorithm that guarantee to find all frequent itemsets of an   updated database efficiently. The simulation results show that the   proposed algorithm has better performance than that of previous   work.               Keywords: association rule discovery, data mining, incremental association rule discovery               Categories: I.1.2, I.2.6  
15|12||Modeling of an Intelligent e-Consent System in a Healthcare Domain|  Chun Ruan (University of Western Sydney, Australia)   Sang-Soo Yeo (Mokwon University, Korea)  Abstract: Due to rapid advances of computing power and   communications, healthcare services are increasingly rely on the   electronic processing and transmission of confidential patient data   to reduce the costs and improve the quality. It is becoming more and   more important that accessing the health information should be both   secure and privacy preserving. Therefore access control becomes an   important integral part of any secure healthcare computer software   systems. Specification of access control requirements at early steps   of the software life cycle can provide stakeholders rapid feedback   and protect the system in a best possible way. On the other hand,   intelligent systems are widely used in various computing areas   ranging from medicine to manufacturing industries to financial   markets. This paper studies how to model an intelligent e-Consent   system about the security requirements regarding healthcare   information protection. In this paper, we use UML to specify and   visualize the access control policies in a health application   domain. These policies are represented in logic based e-Consent   rules, and the patients consents about their information access can   be derived from these rules. We first identify various parts   necessary to specify the e-Consent rules about patient record   protection requirements, and then propose UML models to demonstrate   these requirements.               Keywords: UML, access control, e-consent               Categories: H.4.3, J.7  
15|13|http://www.jucs.org/jucs_15_13|Knowledge Management for Intelligent Systems|
15|13||Interactive Genetic Algorithms with Individual Fitness Not Assigned by Human|  Dunwei Gong (China University of Mining and Technology, P.R.China)   Xin Yao (University of Birmingham, United Kingdom)   Jie Yuan (China University of Mining and Technology, P.R.China)  Abstract: Interactive genetic algorithms (IGAs) are   effective methods to solve optimization problems with implicit or   fuzzy indices. But human fatigue problem, resulting from evaluation   on individuals and assignment of their fitness, is very important   and hard to solve in IGAs. Aiming at solving the above problem, an   interactive genetic algorithm with an individual fitness not   assigned by human is proposed in this paper. Instead of assigning an   individual fitness directly, we record time to choose an individual   from a population as a satisfactory or unsatisfactory one according   to sensitiveness to it, and its fitness is automatically calculated   by a transformation from time space to fitness space. Then   subsequent genetic operation is performed based on this fitness, and   offspring is generated. We apply this algorithm to fashion design,   and the experimental results validate its efficiency.               Keywords: genetic algorithm, human fatigue, individual fitness, interactive genetic algorithm, optimization               Categories: G.1.6, H.1.2, I.2.8  
15|13||Human Tracking based on Multiple View Homography|  Dong-Wook Seo (University of Ulsan, Korea)   Hyun-Uk Chae (University of Ulsan, Korea)   Byeong-Woo Kim (University of Ulsan, Korea)   Won-Ho Choi (University of Ulsan, Korea)   Kang-Hyun Jo (University of Ulsan, Korea)  Abstract: We propose a method for detection and tracking   for objects under multiple cameras system. To track objects, one   need to establish correspondence objects among multiple views. We   apply the principal axis of objects and the homography constraint to   match objects across multiple cameras. The principal axis belongs to   the silhouette of objects that is extracted by the background   subtraction. We use the multiple background model to the background   subtraction. In an image sequence, many changes happen with respect   to pixel intensity. This cannot be characterized by the single   background model so that is necessary to use the multiple background   model. Also, we use the median background model reducing some   noises. The silhouette is detected by difference with background   models and current image which includes moving objects. For   calculating homography, we use landmarks on the ground plane in 3D   space. The homography means the relation between two correspondence   between two coinciding points from different views. The intersection   of principal axes and ground plane in 3D space are the same point   shown in each view. The intersection occurs when a principal axis in   an image crosses to the transformed ground plane from another   image. We construct the correspondence which means the relationship   between intersection in current image and transformed intersection   from the other image by homography constraint. Those correspondences   confirm within a short distance measuring in the top viewed   plane. Thus, we track a person by these corresponding points on the   ground plane.               Keywords: homography constraint, human tracking, median background, multiple background model, multiple cameras               Categories: H.2, H.3.7, H.5.4  
15|13||A Multiagent System for Hierarchical Control and Monitoring|  Vu Van Tan (University of Ulsan, Korea)   Dae-Seung Yoo (University of Ulsan, Korea)   Jun-Chol Shin (University of Ulsan, Korea)   Myeong-Jae Yi (University of Ulsan, Korea)  Abstract: This paper presents the architecture of a   multiagent system based on new OPC Unified Architecture (UA)   technology for hierarchical control and monitoring of a complex   process control system. This architecture is proposed with   utilization of the OPC technology, which contains both a   continuous-event component and a discreteevent component by   incorporating XML for the negotiation and cooperation with the   multiagent system's environments. The practical applications of the   proposed architecture are provided and the discussion demonstrates   that the proposed architecture is both reliable and effective for   applying to multiagent-based complex control system   applications.               Keywords: OPC, XML, hierarchical control, monitoring, multiagent, process control, unified architecture               Categories: C.2.4, D.2.10, D.2.11, D.2.12, H.1.0, H.4.1, H.4.3, K.1.0, L.3.1  
15|13||A Load Balancing and Congestion-Avoidance Routing Mechanism for Teal-Time Traffic over Vehicular Networks|  Chenn-Jung Huang (National Dong Hwa University, Taiwan)   I-Fan Chen (National Dong Hwa University, Taiwan)   Kai-Wen Hu (National Dong Hwa University, Taiwan)   Hung-Yen Shen (National Dong Hwa University, Taiwan)   You-Jia Chen (National Taiwan University, Taiwan)   Dian-Xiu Yang (National Taiwan University, Taiwan)  Abstract: With the growth up of internet in mobile   commerce, researchers have reproduced various mobile applications   that vary from entertainment and commercial services to diagnostic   and safety tools. Resource management for real-time traffic has   widely been recognized as one of the most challenging problems for   seamless access to vehicular networks. In this paper, a novel load   balancing and congestion-avoidance routing mechanism over short   communication range is proposed to satisfy the stringent QoS   requirement of real-time traffic in vehicular ad hoc networks. Fuzzy   logic systems are used to select the intermediate nodes on the   routing path via inter-vehicle communications, and H-infinity   technique is used to adjust the membership functions employed in the   fuzzy logic systems to adapt to the volatile characteristics of the   vehicular networks. Notably, a prediction of the remaining   connection time among each vehicle and its neighbors is derived to   assisting in the determination of the intermediate nodes on the   routing path.  The experimental results verify the effectiveness and   feasibility of the proposed schemes, in terms of several performance   metrics such as packet delivery ratio, end-to-end delay, control   overhead, throughputs, call blocking probability and call dropping   probability.               Keywords: H-infinity, fuzzy logic, routing enhancement, vehicular ad hoc network (VANET)               Categories: C.2, C.2.2  
15|13||Splice Site Prediction using Support Vector Machines with Context-Sensitive Kernel Functions|  Yifei Chen (Vrije Universiteit Brussel, Belgium)   Feng Liu (Vrije Universiteit Brussel, Belgium)   Bram Vanschoenwinkel (Vrije Universiteit Brussel, Belgium)   Bernard Manderick (Vrije Universiteit Brussel, Belgium)  Abstract: This paper focuses on the use of support vector   machines on a typical context-dependent classification task, splice   site prediction. For this type of problems, it has been shown that a   context-based approach should be preferred over a transformation   approach because the former approach can easily incorporate   statistical measures or directly plug sensitivity information into   distance functions. In this paper, we designed three types of   context-sensitive kernel functions: polynomial-based, radial basis   function-based and negative distance-based kernels. From the   experimental results it becomes clear that the radial basis   function-based kernel with information gain weighting gets the best   accuracies and can always outperform their simple non-sensitive   counterparts both in accuracy and in model complexity. And with well   designed features and carefully chosen context sizes, our system can   predict splice sites with fairly high accuracy, which can achieve   the F P 95% rate, 3.94 for donor sites and 5.98 for acceptor sites,   an approximate state of the art performance for the   moment.               Keywords: kernel functions, splice site prediction, support vector machines               Categories: I.2.6, I.5.4, J.3  
15|13||A Hammerstein-Wiener Recurrent Neural Network with Frequency-Domain Eigensystem Realization Algorithm for Unknown System Identification|  Yi-Chung Chen (National Cheng Kung University, Taiwan, R.O.C.)   Jeen-Shing Wang (National Cheng Kung University, Taiwan, R.O.C.)  Abstract: This paper presents a Hammerstein-Wiener   recurrent neural network (HWRNN) with a systematic identification   algorithm for identifying unknown dynamic nonlinear systems. The   proposed HWRNN resembles the conventional Hammerstein-Wiener model   that consists of a linear dynamic subsystem that is sandwiched in   between two nonlinear static subsystems. The static nonlinear parts   are constituted by feedforward neural networks with nonlinear   functions and the dynamic linear part is approximated by a recurrent   network with linear activation functions. The novelties of our   network include: 1) the structure of the proposed recurrent neural   network can be mapped into a state-space equation; and 2) the   state-space equation can be used to analyze the characteristics of   the identified network. To efficiently identify an unknown system   from its input-output measurements, we have developed a systematic   identification algorithm that consists of parameter initialization   and online learning procedures. Computer simulations and comparisons   with some existing models have been conducted to demonstrate the   effectiveness of the proposed network and its identification   algorithm.               Keywords: Hammerstein-Wiener model, parameter initialization, parameter optimization, recurrent neural networks               Categories: F.1.1, I.2.6, I.2.8  
15|13||Online Detecting and Predicting Special Patterns over Financial Data Streams|  Tao Jiang (Huazhong University of Science & Technology, P.R. China)   Yucai Feng (Huazhong University of Science & Technology, P.R. China)   Bin Zhang (Hengyang Normal University, P.R. China)  Abstract: Online detecting special patterns over financial   data streams is an interesting and significant work. Existing many   algorithms take it as a subsequence similarity matching   problem. However, pattern detection on streaming time series is   naturally expensive by this means. An efficient segmenting algorithm   ONSP (ONline Segmenting and   Pruning) is proposed, which is used to find the   end points of special patterns. Moreover, a novel metric distance   function is introduced which more agrees with human perceptions of   pattern similarity. During the process, our system presents a   pattern matching algorithm to efficiently match possible emerging   patterns among data streams, and a probability prediction approach   to predict the possible patterns which have not emerged in the   system. Experimental results show that these approaches are   effective and efficient for online pattern detecting and predicting   over thousands of financial data streams.               Keywords: detecting, financial data streams, predicting, special patterns               Categories: H.2.8, I.2, I.5  
15|13||Applications of Cerebellar Model Articulation Controllers to Intelligent Landing System|  Jih-Gau Juang (National Taiwan Ocean University, Taiwan)   Chia-Lin Lee (National Taiwan Ocean University, Taiwan)  Abstract: The atmospheric disturbances affect not only flying qualities of an airplane but also flight safety. According to flight records, most aircraft accidents occurred during final approach or landing. If the flight conditions are beyond the preset envelope, the automatic landing system (ALS) is disabled and the pilot takes over. An inexperienced pilot may not be able to guide the aircraft to a safe landing at the airport when wind disturbance is encountered. This study proposes different cerebellar model articulation controllers (CMAC) to improve the performance of conventional ALS. A CMAC with general basis function (CMAC-GBF) and a type-2 fuzzy CMAC (FCMAC) are applied to construct intelligent landing system which can guide the aircraft to a safe landing in severe wind turbulence environment.               Keywords: CMAC, Fuzzy System, Intelligent Landing System, PID control, Turbulence               Categories: L.3.6  
15|13||A Comparison Between a Geometrical and an ANN Based Method for Retinal Bifurcation Points Extraction|  Vitoantonio Bevilacqua (Polytechnic of Bari, Italy)   Lucia Cariello (Polytechnic of Bari, Italy)   Marco Giannini (Polytechnic of Bari, Italy)   Giuseppe Mastronardi (Polytechnic of Bari, Italy)   Vito Santarcangelo (Polytechnic of Bari, Italy)   Rocco Scaramuzzi (Polytechnic of Bari, Italy)   Antonella Troccoli (Polytechnic of Bari, Italy)  Abstract: This paper describes a comparative study between an Artificial Neural Network (ANN) and a geometric technique to detect for biometric applications,the bifurcation points of blood vessels in the retinal fundus. The first step is an image preprocessing phase to extract retina blood vessels. The contrast of the blood vessels from the retinal image background is enhanced in order to extract the blood vessels skeleton. Successively, candidate points of bifurcation are individualized by approximating the skeleton lines in segments. The distinction between bifurcations and vessel bends is carried out through the employment of two methods: geometric (through the study of intersections within the region obtained thresholding the image portion inside a circle centered around the junctions point and the circumference of the same circle) and an ANN. The results obtained are compared and discussed.               Keywords: ANN, blood vessels detection, blood vessels skeleton, crossover points extraction, gaussian derivation, personal identification, preprocessing, retinal fundus               Categories: D.0, G.1.10, G.3, J.3  
15|13||Rough Classification - New Approach and Applications|  Ngoc Thanh Nguyen (Wroclaw University of Technology, Poland)  Abstract: Rough classification has been known as the   concept of Pawlak within the Rough Set Theory. In this paper the   novel rough classification approach and its applications in   e-learning systems and user interface management for recommendation   processes will be presented.               Keywords: E-learning systems, rough classification, user management               Categories: E.1, H.2.1, I.2.11, I.2.4  
15|13||On the Semantics and Verification of Normative Multi-Agent Systems|  Lăcrămioara Aştefănoaei (CWI, The Netherlands)   Mehdi Dastani (Universiteit Utrecht, The Netherlands)   John-Jules Meyer (Universiteit Utrecht, The Netherlands)   Frank S. de Boer (CWI, The Netherlands)  Abstract: This paper presents a programming language that   facilitates the implementation of coordination artifacts which in   turn can be used to regulate the behaviour of individual agents. The   programming language provides constructs inspired by social and   organisational concepts. Depending on the scheduling mechanism of   such constructs, different operational semantics can be defined. We   show how one such possible operational semantics can be prototyped   in Maude, which is a rewriting logic software. Prototyping by means   of rewriting is important since it allows us both to design and to   experiment with the language definitions. To illustrate this, we   define particular properties (like enforcement and regimentation) of   the coordination artifacts which we then verify with the Maude LTL   model-checker.               Keywords: multi-agent systems, norms, rewriting logic, verification               Categories: I.6.5  
15|13||Extended Defeasible Reasoning for Common Goals in n-Person Argumentation Games|"  Duy Hoang Pham (Posts and Telecommunications Institute of Technology, Vietnam)   Guido Governatori (NICTA, Queensland Research Laboratory, Australia)   Subhasis Thakur (Griffith University, Australia)  Abstract: Argumentation games have been proved to be a robust and flexible tool to resolveconflicts among agents. An agent can propose its explanation and its goal known as a claim, which can be refuted by other agents. The situation is more complicated when there are morethan two agents playing the game.   We propose a weighting mechanism for competing premises to tackle with conflicts from multipleagents in an n-person game. An agent can defend its proposal by giving a counter-argument to change the ""opinion"" of the majority of opposing agents. Furthermore, using the extendeddefeasible reasoning an agent can exploit the knowledge that other agents expose in order to promote and defend its main claim.               Keywords: argumentation systems, artificial intelligence, defeasible reasoning               Categories: I.2.4  "
15|13||Analyzing Cooperation in Iterative Social Network Design|  Guido Boella (University of Turin, Italy)   Leendert van der Torre (University of Luxembourg, Luxembourg)   Serena Villata (University of Turin, Italy)  Abstract: We introduce an approach to iteratively design   `small' social networks used in software engineering together with   methods analyzing the cooperation in the system. The degree of   cooperation is measured by the emergence of coalitions and their   stability over time. At the most abstract level, which we call the   coalition view, coalitions are abstract entities that may dominate   or attack other coalitions. During iterative design, these abstract   entities are refined with agents and their dependencies constituting   the coalitions (dependence view), the powers of sets of agents to   see to goals (power view) and finally the beliefs, plans, tasks and   goals of agents (agent view). The analysis methods predict the   emergence of coalitions based on reciprocity and argumentation   theory.               Keywords: argumentation, coalitions, dependence networks, multiagent systems               Categories: I.2.11, I.6.5  
15|13||Interactive Learning of Independent Experts' Criteria for Rescue Simulations|  Thanh-Quang Chu (Institut de la Francophonie pour l'Informatique, Vietnam)   Alexis Drogoul (Institut de la Francophonie pour l'Informatique, Vietnam)   Alain Boucher ((Institut de la Francophonie pour l'Informatique, Vietnam)   Jean-Daniel Zucker (Institut de Recherche pour le Développement, France)  Abstract: Efficient response to natural disasters has an   increasingly important role in limiting the toll on human life and   property. The work we have undertaken seeks to improve existing   models by building a Decision Support System (DSS) of resource   allocation and planning for natural disaster emergencies in urban   areas.  A multi-agent environment is used to simulate disaster   response activities, taking into account geospatial, temporal and   rescue organizational information. The problem we address is the   acquisition of situated expert knowledge that is used to organize   rescue missions. We propose an approach based on participatory   design and interactive learning which incrementally elicits experts   preferences by online analysis of their interventions with rescue   simulations. An additive utility functions are used, assuming mutual   preferential independence between decision criteria, as a preference   for the elicitation process. The learning algorithm proposed refines   the coefficients of the utility function by resolving incremental   linear programming. For testing our algorithm, we run rescue   scenarios of ambulances saving victims. This experiment makes use of   geographical data for the Ba-Dinh district of Hanoi and damage   parameters from well-regarded local statistical and geographical   resources. The preliminary results show that our approach is   initially confident in solving this problem.               Keywords: decision support system, disaster response, interactive learning, multi-agent simulation, multi-criteria decision making, participatory design, preference elicitation, utility function               Categories: L.1.0, L.1.1, L.3.3, L.5.0, L.5.1, M.0, M.4  
15|13||A New Short-term Power Load Forecasting Model Based on Chaotic Time Series and SVM|  Dongxiao Niu (North China Electric Power University, China)   Yongli Wang (North China Electric Power University, China)   Chunming Duan (North China Electric Power University, China)   Mian Xing (North China Electric Power University, China)  Abstract: This paper presents a model for power load   forecasting using support vector machine and chaotic time   series. The new model can make more accurate prediction. In the past   few years, along with power system privatization and deregulation,   accurate forecast of electricity load has received increasing   attention. According to the chaotic and non-linear characters of   power load data, the model of support vector machines (SVM) based on   chaotic time series has been established. The time series matrix has   also been established according to the theory of phase-space   reconstruction. The Lyapunov exponents, one important component of   chaotic time series, are used to determine time delay and embedding   dimension, the decisive parameters for SVM. Then support vector   machines algorithm is used to predict power load. In order to prove   the rationality of chosen dimension, another two random dimensions   are selected to compare with the calculated dimension. And to prove   the effectiveness of the model, BP algorithm is used to compare with   the results of SVM. Findings show that the model is effective and   highly accurate in the forecasting of short-term power load. It   means that the model combined with SVM and chaotic time series   learning system have more advantage than other models.               Keywords: Lyapunov exponents, chaotic time series, load forecasting, parameter selection, support vector machine               Categories: F.2.1, H.1.1, I.1.2, I.1.6  
15|14|http://www.jucs.org/jucs_15_14|Managing Editor's Column|
15|14||Optimal Serverless Networks Attacks, Complexity and some Approximate Algorithms|  Carlos Aguirre (Universidad Autónoma de Madrid, Spain)   Ramon Huerta (University of California, USA)   Lev Tsimring (University of California, USA)  Abstract: A network attack is a set of network elements   that are disabled by an adversary. The goal for the attack is to   produce the most possible damage to the network in terms of network   connectivity by disabling the least possible number of network   elements. We show that the problem of finding the optimal attack in   a serverless network is NP-Complete even when only edges or nodes   are considered for disabling. We study a node attack policy with   polynomial complexity based on shorter paths and show that this   attack policy outperforms in most cases classical attacks policies   such as random attack or maximum degree attack. We also study the   behavior of different network topologies under these attack   policies.               Keywords: NP-complete attack strategies, network connectivity, optimal attack problem               Categories: C.2.1, F.2.2, G.2.2  
15|14||Realtime LEGO Brick Image Retrieval with Cellular Automata|  Leendert Botha (Stellenbosch University, South Africa)   Lynette van Zijl (Stellenbosch University, South Africa)   McElory Hoffmann (Stellenbosch University, South Africa)  Abstract: We consider the realtime content-based image   retrieval of LEGO bricks from a database of images of LEGO   bricks. This seemingly simple problem contains a number of   surprisingly the image signature, and corresponding feature set, and   illustrate cellular automaton-based methods for the whole feature   extraction phase.               Keywords: content-based image retrieval               Categories: H.2.8, I.5  
15|14||A Web-Decision Support System based on Collaborative Filtering for Academic Orientation.  Case Study of the Spanish Secondary School.|  Emilio J. Castellano (University of Jaén, Spain)   Luis Martínez (University of Jaén, Spain)  Abstract: Collaborative Filtering has been widely used in   Recommender Systems helping customers of e-shops to find out items   matching their requirements in huge or complex search spaces. There   exist many commercial applications that show the utility of these   systems, especially in e-commerce whose features and good   performance obtained has driven us to consider their application in   a specific domain as Academic Orientation, in   order to support students decisions through their academic   journey. We propose the use of the ideas behind the Collaborative   Recommender Systems to develop a Web-based Decision Support System   (Web-DSS) for Academic Orientation that analyze the students   skills, attitudes, preferences, etc., and then compute relevant   information to support their decisions concerning their academic   future. Furthermore, we shall study the performance of such   techniques in Academic Orientation by using a dataset gathered from   various Secondary and High Schools in   Spain. OrieB, a web-DSS for academic orientation   is then presented.               Keywords: academic orientation, collaborative filtering, decision support systems, recommender systems               Categories: J.4, K.3.1, L.6.2  
15|14||Petri Net Controlled Grammars: the Case of Special Petri Nets|  Jürgen Dassow (Otto-von-Guericke-Universität Magdeburg, Germany)   Sherzod Turaev (Universiti Putra Malaysia, Malaysia)  Abstract: A Petri net controlled   grammar is a context-free grammar equipped with a Petri   net, whose transitions are labeled with rules of the grammar or the   empty string, and the associated language consists of all terminal   strings which can be derived in the grammar and the the sequence of   rules in every terminal derivation corresponds to some occurrence   sequence of transitions of the Petri net which is enabled at the   initial marking and finished at a final marking of the net. We   present some results on the generative capacity of such grammars so   that the associated Petri nets are restricted to some known special   classes of Petri nets.               Keywords: Petri net controlled grammars, Petri nets, grammars, grammars with regulated rewriting               Categories: F.4.2, F.4.3  
15|14||A Debugging System Based on Natural Semantics|  Alberto de la Encina (Universidad Complutense de Madrid, Spain)   Luis Llana (Universidad Complutense de Madrid, Spain)   Fernando Rubio (Universidad Complutense de Madrid, Spain)  Abstract: Due to the absence of side effects, reasoning about functional programsis simpler than reasoning about their imperative counterparts. However, because of the absence of practical debuggers, finding bugs in lazy functional languages has beenmore complex until quite recently. One of the easiest to use Haskell debuggers is Hood. Its behavior is based on the concept of observation of intermediate data structures.However, although using Hood can be simple when observing some structures, it is known that it can be hard to understand how it works when dealing with complexsituations. In fact, the author of Hood recognizes that it is necessary to formalize its behavior to explain better what should be expected, and also to allow to check whetherthe different implementations work properly.    In this paper, we formalize the behavior of the Hood debugger by extending Sestoft'snatural semantics. Moreover, we also show how to derive an abstract machine including such debugging information. By doing so, we do not only provide a formal foundation,but we also provide an alternative method to implement debuggers. In fact, we have already made a prototype of the abstract machine presented in this paper.               Keywords: abstract machines, debugging, parallel functional programming, semantics               Categories: D.2.5, D.3.1, D.3.2, F.3.2  
15|14||Ideal Homogeneous Access Structures Constructed from Graphs|  Javier Herranz (Universitat Politècnica de Catalunya, Spain)  Abstract: Starting from a new relation between graphs and   secret sharing schemes introduced by Xiao, Liu and Zhang, we show a   method to construct more general ideal homogeneous access   structures. The method has some advantages: it efficiently gives an   ideal homogeneous access structure for the desired rank, and some   conditions can be imposed (such as forbidden or necessary subsets of   players), even if the exact composition of the resulting access   structure cannot be fully controlled. The number of homogeneous   access structures that can be constructed in this way is quite   limited; for example, we show that (t,   l)-threshold access structures can be constructed   from a graph only when t = 1,   t = l - 1 or   t = l.               Keywords: cryptography, graph connectivity, ideal secret sharing               Categories: E.3, G.2  
15|14||A Heuristic Approach for the Automatic Insertion of Checkpoints in Message-Passing Codes|  Gabriel Rodríguez (University of A Coruña, Spain)   Maria J. Martín (University of A Coruña, Spain)   Patricia González (University of A Coruña, Spain)   Juan Touriño (University of A Coruña, Spain)  Abstract: Checkpointing tools may be typically implemented at two different abstraction levels: at the system level or at the application level. The latter has become a more popular alternative due to its flexibility and the possibility of operating in different environments. However, application-level checkpointing tools often require the user to manually insert checkpoints in order to ensure that certain requirements are met (e.g. forcing checkpoints to be taken at the user code and not inside kernel routines). The approach presented in this work is twofold. First, a spatial coordination protocol for checkpointing parallel SPMD applications is proposed, based on forcing checkpoints to be taken at the same places in the application code by all processes. Thus, global consistency is achieved without adding any new runtime communications or piggybacked data, and without the need to use specific fault-tolerant message-passing implementations. Second, the paper also introduces a compilation technique for the automatic insertion of checkpoints using the spatial coordination protocol, based on a static analysis of communications and a heuristic analysis of computational load. These analyses can also be used to achieve automatic checkpoint insertion in approaches based on classical protocols, such as uncoordinated checkpointing or distributed snapshots.               Keywords: checkpointing, compiler-support, fault tolerance, message-passing, parallel programming               Categories: C.4, D.1.3  
15|15|http://www.jucs.org/jucs_15_15|Security in Information Systems: New Advances and Tendencies|
15|15||SeAAS - A Reference Architecture for Security Services in SOA|  Michael Hafner (University of Innsbruck, Austria)   Mukhtiar Memon (University of Innsbruck, Austria)   Ruth Breu (University of Innsbruck, Austria)  Abstract: Decentralized security models and distributed   infrastructures of scenarios based onService Oriented Architectures   make the enforcement of security policies a key challenge - all the   more so for business processes spanning over multiple   enterprises. The current practice to im-plement security   functionality exclusively at the endpoint places a significant   processing burden on the endpoint, renders maintenance and   management of the distributed security infrastructurescumbersome,   and impedes interoperability with external service requesters. To   meet these challenges, we propose a reference security architecture   that transposes the model of Software as aService to the security   domain and thereby realizes Security as a Service (SeAAS). The   proposed architecture goes beyond the mere bundling of security   functionality within one security domain.We illustrate the concepts   of SeAAS at work with the requirement of fair non-repudiation. The   architecture complements the SECTET framework for model-driven   security engineering.               Keywords: security as a service, security requirements, service oriented architecture               Categories: D.2.10, D.2.11  
15|15||Information Theoretically Secure Encryption with Almost Free Authentication|  Basel Alomair (King Saud University, Saudi Arabia)   Radha Poovendran (University of Washington, USA)  Abstract: In cryptology, secure channels enable the exchange of messages in a confidential andauthenticated manner. The literature of cryptology is rich with proposals and analysis that address the secure communication over public (insecure) channels. In this work, we propose an informa-tion theoretically secure direction for the construction of secure channels. First, we propose a method of achieving unconditionally secure authentication with half the amount of key materialrequired by traditional unconditionally secure message authentication codes (MACs). Key reduction is achieved by utilizing the special structure of the authenticated encryption system. That is,authentication exploits the secrecy of the message to reduce the key material required for authentication. After the description of our method, since key material is the most important concernin unconditionally secure authentication, given the message is encrypted with a perfectly secret one-time pad cipher, we extend our method to achieve unconditionally secure authentication withalmost free key material. That is, we propose a method for unconditionally authenticating arbitrarily long messages with much shorter keys. Finally, we will show how the special structure ofthe authenticated encryption systems can be exploited to achieve provably secure authentication that is very efficient for the authentication of short messages.               Keywords: authentication, encryption, unconditional security               Categories: E.3, E.4, F.2, F.2.1, G.2, G.2.3  
15|15||ModelSec: A Generative Architecture for Model-Driven Security|  Óscar Sánchez (University of Murcia, Spain)   Fernando Molina (University of Murcia, Spain)   Jesús García-Molina (University of Murcia, Spain)   Ambrosio Toval (University of Murcia, Spain)  Abstract: Increasingly, the success of software systems depends largely on how their security requirements are satisfied. However, developers are challenged in implementing these requirements, mainly because of the gap between the specification and implementation, and the technical complexities of the current software infrastructures. Recently, Model-Driven Security has emerged as a new software development area aimed at overcoming these difficulties. This new paradigm takes advantage of the benefits of the model driven software development techniques for modeling and implementing security concerns. Following this trend, this paper proposes a model driven security approach named ModelSec that offers a generative architecture for managing security requirements, from the requirement elicitation to the implementation stage. This architecture automatically generates security software artifacts (e.g. security rules) by means of a model transformation chain composed of two-steps. Firstly, a security infrastructure dependent model is derived from three models, which express the security restrictions, the design decisions and the information needed on the target platform. Then, security software artifacts are produced from the previously generated model. A Domain-Specific Language for security requirements management has been built, which is based on a metamodel specifically designed for this purpose. An application example that illustrates the approach and the Eclipse tools implemented to support it are also shown.               Keywords: model driven engineering, model driven security, requirements engineering, requirements metamodelling               Categories: D.2.1  
15|15||Graph-Based Approach to the Edit Distance Cryptanalysis of Irregularly Clocked Linear Feedback Shift Registers|  Pino Caballero-Gil (University of La Laguna, Spain)   Amparo Fúster-Sabater (C.S.I.C., Spain)   Candelaria Hernández-Goya (University of La Laguna, Spain)  Abstract: This paper proposes a speed-up of a   known-plaintext attack on some stream ciphersbased on Linear   Feedback Shift Registers (LFSRs). The algorithm   consists of two basic steps: first, to guess the initial seed value   of one of the LFSRs, and then to use the   resulting binarysequence in order to deduce useful information about   the cipher parameters. In particular, the proposed   divide-and-conquer attack is based on a combination of graph-based   techniques withedit distance concepts. While the original edit   distance attack requires the exhaustive search over the set of all   possible initial states of the involved LFSR,   this work presents a new heuristic op-timization that avoids the   evaluation of an important number of initial states through the   identification of the most promising branches of the search   graph. The strongest aspects of the proposalare the facts that the   obtained results from the attack are absolutely deterministic, and   that many inconsistent initial states of the target   LFSRs are recognized and avoided during search.               Keywords: attack, linear feedback shift register, symmetric cryptography               Categories:  D.4.6, E.3, K.6.5  
15|15||A User Controlled Approach for Securing Sensitive Information in Directory Services|  William Claycomb (Sandia National Laboratories Albuquerque, USA)   Dongwan Shin (New Mexico Tech University, USA)  Abstract: Enterprise directory services are commonly used   in enterprise systems to store object information relating to   employees, computers, contacts, etc. These stores can act as   information providers or sources for authentication and access   control decisions, and could potentially contain sensitive   information. An insider attack, particularly if carried out using   administrative privileges, could compromise large amounts of   directory information. We present two solutions for protecting   directory services information from insider attacks. The first is a   centralized approach utilizing a customized virtual directory   server. The second is a distributed approach using existing key   management infrastructure and a new component called a Personal   Virtual Directory Service. We explain how these solutions interact   with existing directory services and client applications. We also   show how impact to existing users, client applications, and   directory services are minimized, and how we prevent insider attacks   from revealing protected data. We compare and contrast both   solutions, including potential tradeoffs, administrative overhead,   and enterprise systems impact. Additionally, our solution is   supported by implementation results showing the impact to client   performance and directory storage capacity.               Keywords: directory, security and protection               Categories: H.2.7, K.6.5  
15|15||Optimizations for Risk-Aware Secure Supply Chain Master Planning|  Axel Schröpfer (SAP Research Karlsruhe, Germany)   Florian Kerschbaum (SAP Research Karlsruhe, Germany)   Christoph Schütz (SAP Research Karlsruhe, Germany)   Richard Pibernik (EBS Wiesbaden, Germany)  Abstract: Supply chain master planning strives for   optimally aligned production, warehousing and transportation   decisions across a multiple number of partners. Its execution in   practice is limited by business partners' reluctance to share their   vital business data. Secure Multi-Party Computation (SMC) can be   used to make such collaborative computations privacy-preserving by   applying cryptographic techniques. Thus, computation becomes   acceptable in practice, but the performance of SMC remains critical   for real world-sized problems. We assess the disclosure risk of the   input and output data and then apply a protection level appropriate   for the risk under the assumption that SMC at lower protection   levels can be performed faster. This speeds up the secure   computation and enables significant improvements in the supply   chain.               Keywords: linear programming, privacy, security and protection               Categories: C.4, H.3  
15|15||Managing Security and its Maturity in Small and Medium-sized Enterprises|  Luís Enrique Sánchez (SICAMAN NT, Spain)   Antonio Santos-Olmo Parra (SICAMAN NT, Spain)   David G. Rosado (University of Castilla-La Mancha, Spain)   Mario Piattini (University of Castilla-La Mancha, Spain)  Abstract: Due to the growing dependence of information   society on Information and Communication Technologies, the need to   protect information is getting more and more important for   enterprises. In this context, Information Security Management   Systems (ISMSs), have arisen for supporting the processes and   systems for effectively managing information security. The fact of   having these systems available has become more and more vital for   the evolution of Small and Medium-Sized Enterprises (SMEs), but   however, this type of enterprises have special characteristics which   make it difficult for them the correct deployment of ISMSs. In this   article, we show the methodology that we have created for the   development, implementation and maintenance of ISMSs, adapted for   the needs and resources available for SMEs. This approach is being   directly applied to real case studies and thus, we are obtaining a   constant improvement in its application.               Keywords: ISMS, SME, security system               Categories: K.6.5, L.4  
15|15||A System for Managing Security Knowledge using Case Based Reasoning and Misuse Cases|  Corrado Aaron Visaggio (University of Sanni, Italy)   Francesca de Rosa (University of Sanni, Italy)  Abstract: Making secure a software system is a very   critical purpose, especially because it is very hard to consolidate   an exhaustive body of knowledge about security risks and related   countermeasures. To define a technological infrastructure for   exploiting this knowledge poses many challenges. This paper   introduces a system to capture, share and reuse software security   knowledge within a Software Organization. The system collects   knowledge in the form of misuse cases and makes use of Case Based   Reasoning for implementing knowledge management   processes.               Keywords: case base reasoning, misuse case, security knowledge management               Categories: D.2.9  
15|16|http://www.jucs.org/jucs_15_16|Collaborative Technology and Environments|
15|16||Assisting Support Groups of Patients with Chronic Diseases through Persuasive Computing|  Eduardo Gasca (CICESE, Mexico)   Jesus Favela (CICESE, Mexico)   Monica Tentori (Universidad Autónoma de Baja California (UABC), Mexico)  Abstract: Obesity has become a serious health problem   affecting millions of people around the world. Obese people have a   higher risk to attain chronic diseases, a reduced quality of life,   and higher risk of premature death. Persuasive technology and   virtual communities can help address these problems by motivating   patients to follow a healthier life style. This paper presents the   Persuasive Health Network (pHealthNet), a pervasive virtual   community designed to promote a healthy lifestyle in patients with   chronic degenerative diseases that participated in a national   program for the prevention of diseases, education and self-care. The   development and deployment of the system supports the program's goal   of persuading patients to change their eating habits and to increase   their physical activity. The system was incorporated in the program   of two self-support groups whose participants are monitored for a   period of three months. The results of an in situ   evaluation showed that participants increased their trust in   themselves, adopted healthier eating and exercising habits and where   more satisfied with the program that those who followed the   traditional approach.               Keywords: SODHis, chronic diseases, persuasive tools, pervasive ecosystem, self-support groups, virtual community               Categories: H.5.3, J.3  
15|16||Understanding Tools and Practices for Distributed Pair Programming|  Till Schümmer (FernUniversität Hagen, Germany)   Stephan Lukosch (Delft University of Technology, The Netherlands)  Abstract: When considering the principles for eXtreme   Programming, distributed eXtreme Programming, especially distributed   pair programming, is a paradox predetermined to failure. However,   global software development as well as the outsourcing of software   development are integral parts of software projects. Hence, the   support for distributed pair programming is still a challenging   field for tool developers so that failure for distributed pair   programming becomes less mandatory. In this paper, we analyse the   social interaction in distributed pair programming and investigate   how current technology supports this interaction. We present   XPairtise, a plug-in for Eclipse that allows instant pair   programming in distributed development teams. In addition, we report   on experiences and findings when using XPairtise in a distributed   software development setting.               Keywords: distributed pair programming, eXtreme Programming, patterns for computer-mediated interaction               Categories: D.2.3, D.2.6, H.5.3  
15|16||How Interactive Whiteboards Can be Used to Support Collaborative Modeling|  Gwendolyn L. Kolfschoten (Delft University of Technology, The Netherlands)   Mamadou Seck (Delft University of Technology, The Netherlands)   Gert-Jan de Vreede (Delft University of Technology, The Netherlands)  Abstract: Modeling is a key activity in system analysis   and design. Users as well as stakeholders, experts and entrepreneurs   need to be able to create shared understanding about a system   representation in various phases of a design process. In each of   these phases it is important to align views and ensure that   differences in understanding of the system are   resolved. Visualization is of high importance in this process and   thus a logic approach is to involve stakeholders in collaborative   modeling.  Technology like interactive whiteboards may provide new   opportunities in the support of collaborative modeling. In this   paper we offer insights from an exploratory research on experiences   in using interactive whiteboards in collaborative modeling, based on   semi-structured interviews.               Keywords: collaborative modeling, groups, interactive whiteboards, system and design, technology               Categories: H.5.3  
15|16||Diminishing Chat Confusion by Multiple Visualizations|  Torsten Holmer (Upper Austria University of Applied Sciences, Austria)   Stephan Lukosch (Delft University of Technology, The Netherlands)   Verena Kunz (FernUniversität in Hagen, Germany)  Abstract: In this article, we address the problem of   confusion and co-text-loss in chat communication, identify   requirements for a solution, discuss related work and present a new   approach for addressing co-text loss in text-based chats. We report   about first experiences with our solution and give an outlook on   future work directions. The core idea of our solution MuViChat   (multiple-visualization chat) is to support multiple visualizations   of referenced chat transcripts in which users can choose their   preferred view. The multiple visualizations offer different   possibilities to follow and understand a communication and thereby   diminish chat confusion which often occurs in standard chat   systems. By enabling the recording and replaying of chat discussions   and an extensible modular architecture we are supporting evaluation   and further integration of advanced visualization   concepts.               Keywords: chat tool, chat transcript, multiple visualizations, threading               Categories: H.4.3, H.5.3  
15|17|http://www.jucs.org/jucs_15_17|Managing Editor's Column|
15|17||Rearranging Series Constructively|  Josef Berger (Ludwig-Maximilians-Universität München, Germany)   Douglas S. Bridges (University of Canterbury, New Zealand)  Abstract: Riemann's theorems on the rearrangement of   absolutely convergent and conditionally convergent series of real   numbers are analysed within Bishop-style constructive   mathematics. The constructive proof that every rearrangement of an   absolutely convergent series has the same sum is relatively   straightforward; but the proof that a conditionally convergent   series can be rearranged to converge to whatsoever we please is a   good deal more delicate in the constructive framework. The work in   the paper answers affirmatively a question posed many years ago by   Beeson.               Keywords: Rieman's theorems, constructive analysis               Categories: G.0  
15|17||A SWEBOK-based Viewpoint of the Web Engineering Discipline|  Antonio Navarro (Universidad Complutense de Madrid, Spain)  Abstract: Despite web engineering being an emerging   discipline, there is currently an important array of literature on   this subject. The aim of this paper is to provide a software   engineering-based view of the web engineering discipline reviewing   and classifying a significant part of the software   engineering-related literature that makes up its body of   knowledge. In order to facilitate the classification of this   software engineering literature, this paper categorizes it into   knowledge areas, providing a brief analysis of each area. These   knowledge areas match the knowledge areas defined in the Guide to   the Software Engineering Body of Knowledge (SWEBOK). As an immediate   consequence of this paper, a comparison between software engineering   and web engineering disciplines arises.               Keywords: design, management, measurement, software engineering body of knowledge, web engineering, web engineering body of knowledge               Categories: D.2  
15|17||Extending SD-Core for Ontology-based Data Integration|  Ismael Navas-Delgado (University of Málaga, Spain)   José F. Aldana-Montes (University of Málaga, Spain)  Abstract: This paper describes the main elements of a functional platform for building Semantic Web Applications, the Semantic Directory (additional information can be found at http://khaos.uma.es/SD-Core). A Semantic Directory provides a resource directory, in which web resources are registered and their semantics published. Using the Semantic Directories we provide a solution for publishing the semantics of resources, and interoperating them with some other applications in the same or different domains. The main idea behind this proposal is to help developers build Semantic Web applications by providing them with functional components for this task. This paper also describes some applications that have been developed using an SD-Core extension: SD-Data. Then, we describe the instantiation of the Khaos Ontology-based Mediation Framework (KOMF) in the Systems Biology domain. This framework provides an architecture that enables the research on the development of ontology-based mediators. Thus, an ontology-based mediator has been produced that has demonstrated its utility in two applications developed in the Amine System Project using the SD-Data for registering semantics: AMMO-Prot and SBMM Assistant. The use of ontologies is limited in the current version of the mediator, but its development as a framework enables the implementation of improvements based on the use of reasoning.               Keywords: knowledge management, metadata               Categories: M.1, M.8  
15|17||Modeling of Robustness Margins of the Control of a Predictive Control-Supervisory Architecture|  Achraf Jabeur Telmoudi (SEPE, Ecole Supérieure des Sciences et Techniques de Tunis, Tunisia)   Lotfi Nabli (Monastir, Tunisia)   Radhi M'hiri (RME, Institut National des Sciences Appliquées et de Technologie, Tunisia)  Abstract: In this article a new Control-Supervisory architecture of Flexible Manufacturing Systems (FMS) is presented. We are interested particularly in construction and modelling of FMS robust control of flow-shop type to time constraints.  Other than the control of production system, the goal is to observe and interpreted the robustness of resources and of manufacturing system. The P-time Petri Nets which is used for modeling of the time constraints. A methodology of construction of a robust control system generating the margins of passive and active robustness is elaborated. The redundancy of the robustness of the elementary parameters between passive and active leads us to define the ways ensuring the total robus tness of the system. To do so, a set of definitions lemmas and theorems are developed and affirmed by examples of applications.               Keywords: FMS, P-time Petri Nets, control-supervisory architecture, modeling, robustness, time constraints               Categories: D.2.2, G.4, I.2.3, I.6.5, J.6  
15|17||A Chronicle-based Diagnosability Approach for Discrete Timed-event Systems: Application to Web-Services|  Yannick Pencolé (CNRS, LAAS, France)   Audine Subias (Université de Toulouse, UPS, INSA, INP, ISAE, LAAS, France)  Abstract: This paper addresses the problem of   diagnosability analysis in Web Services. In particular, it focuses   on the analysis of the impact of time to the diagnostic capabilities   in Web Service workflows. The diagnosability analysis that is   proposed in this paper aims at determining the diagnostic   capabilities of a previously developped algorithm for the diagnosis   of Web Services. This diagnostic algorithm is based on chronicle   recognitions. Faults that can occur during the execution of service   workflows are described by means of chronicles.   To perform this diagnosability analysis, the problem is firstly defined as a languagebased analysis which leads to the definition of exclusiveness tests between the languages represented by the chronicles. To deal with the time aspects inherent to the chronicles, we then propose to perform the automatic analysis by the use of time Petri nets. Exclusiveness tests are then defined on reachability graphs of time Petri nets which implicitly represent chronicle languages.               Keywords: chronicle, diagnosability, diagnosis, discrete-event systems, time Petri nets, web service, workflow               Categories: I.6.4  
15|17||Parametric Model-Checking of Stopwatch Petri Nets|  Louis-Marie Traonouez (IRCCyN, France)   Didier Lime (IRCCyN, France)   Olivier H. Roux (IRCCyN, France)  Abstract: At the border between control and verification,   parametric verification can be used to synthesize constraints on the   parameters to ensure that a system verifies given specifications. In   this paper we propose a new framework for the parametric   verification of time Petri nets with stopwatches. We first introduce   a parametric extension of time Petri nets with inhibitor arcs   (ITPNs) with temporal parameters and we define a symbolic   representation of the parametric state-space based on the classical   state-class graph method. Then, we propose semi-algorithms for the   parametric modelchecking of a subset of parametric TCTL formulae on   ITPNs. These results have been implemented in the tool Romeo and we   illustrate them in a case-study based on a scheduling   problem.               Keywords: model-checking, parameters, state-class graph, stopwatches, time Petri nets               Categories: D.2.2, D.2.4  
15|18|http://www.jucs.org/jucs_15_18|Processing Camera-Based Documents|
15|18||Layout Analysis for Camera-Based Whiteboard Notes|  Szilárd Vajda (TU Dortmund, Germany)   Thomas Plötz (Newcastle University, United Kingdom)   Gernot A. Fink (TU Dortmund, Germany)  Abstract: A domain where, even in the era of electronic document processing, handwriting is still widely used is note-taking on a whiteboard. Such documents are either captured by a pen-tracking device or — which is much more challenging — by a camera.  In both cases the layout analysis of realistic whiteboard notes is an open research problem.   In this paper we propose a camera-based three-stage approach for the automatic layout analysis of whiteboard documents. Assuming a reasonable foreground-background separation of the handwriting it starts with a locally adaptive binarization followed by connected component extraction. The latter are then automatically classified as representing either simple graphical elements of a mindmap or elementary text patches. In the final stage the text patches are subject to a clustering procedure in order to generate hypotheses for those image regions where textual annotations of the mindmap can be found.   In order to demonstrate the effectiveness of the proposed approach we report results of a writer independent experimental evaluation on a data set of mindmap images created by several different writers without any constraints on writing or drawing style.               Keywords: camera based recognition, handwriting recognition, mindmap recognition, whiteboard notes, writer independent document layout analysis               Categories: H.3.1, H.3.3, H.4.1  
15|18||Robust Extraction of Text from Camera Images using Colour and Spatial Information Simultaneously|  Shyama Prosad Chowdhury (Queen's University Belfast, United Kingdom)   Soumyadeep Dhar (Videonetics Technology Pvt. Ltd., India)   Karen Rafferty (Queen's University Belfast, United Kingdom)   Amit Kumar Das (Bengal Engineering and Science University, India)   Bhabatosh Chanda (Indian Statistical Institute, India)  Abstract: The importance and use of text extraction from   camera based coloured scene images is rapidly increasing with   time. Text within a camera grabbed image can contain a huge amount   of meta data about that scene. Such meta data can be useful for   identification, indexing and retrieval purposes. While the   segmentation and recognition of text from document images is quite   successful, detection of coloured scene text is a new challenge for   all camera based images. Common problems for text extraction from   camera based images are the lack of prior knowledge of any kind of   text features such as colour, font, size and orientation as well as   the location of the probable text regions. In this paper, we   document the development of a fully automatic and extremely robust   text segmentation technique that can be used for any type of camera   grabbed frame be it single image or video. A new algorithm is   proposed which can overcome the current problems of text   segmentation. The algorithm exploits text appearance in terms of   colour and spatial distribution. When the new text extraction   technique was tested on a variety of camera based images it was   found to out perform existing techniques (or something similar). The   proposed technique also overcomes any problems that can arise due to   an unconstraint complex background. The novelty in the works arises   from the fact that this is the first time that colour and spatial   information are used simultaneously for the purpose of text   extraction.               Keywords: camera image, discrete edge boundary, text extraction, text localisation, video frame               Categories: I.4, I.4.6, I.4.8  
15|18||Adaptive Binarization of Unconstrained Hand-Held Camera-Captured Document Images|  Syed Saqib Bukhari (Technical University of Kaiserslautern, Germany)   Faisal Shafait (German Research Center for Artificial Intelligence (DFKI), Germany)   Thomas M. Breuel (Technical University of Kaiserslautern, Germany)  Abstract: This paper presents a new adaptive binarization   technique for degraded hand-held camera-captured document   images. State-of-the-art locally adaptive binarization methods are   sensitive to the values of free parameter. This problem is more   critical when binarizing degraded camera-captured document images   because of distortions like non-uniform illumination, bad shading,   blurring, smearing and low resolution. We demonstrate in this paper   that local binarization methods are not only sensitive to the   selection of free parameters values (either found manually or   automatically), but also sensitive to the constant free parameters   values for all pixels of a document image. Some range of values of   free parameters are better for foreground regions and some other   range of values are better for background regions. For overcoming   this problem, we present an adaptation of a state-of-the-art local   binarization method such that two different set of free parameters   values are used for foreground and background regions   respectively. We present the use of ridges detection for rough   estimation of foreground regions in a document image. This   information is then used to calculate appropriate threshold using   different set of free parameters values for the foreground and   background regions respectively. Evaluation of the method using an   OCR-based measure and a pixel-based measure show that our method   achieves better performance as compared to state-of-the-art global   and local binarization methods.               Keywords: binarization, camera-captured document images, document and text processing, image processing and computer vision               Categories: I.4, I.4.1, I.4.3, I.7, I.7.2  
15|18||Automatically Deciding if a Document was  Scanned or Photographed|  Gabriel Pereira e Silva (ederal University of Pernambuco, Brazil)   Marcelo Thielo (HP Labs, Brazil)   Rafael Dueire Lins (Federal University of Pernambuco, Brazil)   Brenno Miro (Federal University of Pernambuco, Brazil)   Steven J. Simske (HP Labs, USA)  Abstract: Portable digital cameras are being used widely   by students and professionals in different fields as a practical way   to digitize documents. Tools such as PhotoDoc enable the batch   processing of such documents, performing automatic border removal   and perspective correction. A PhotoDoc processed document and a   scanned one look very similar to the human eye if both are in true   color. However, if one tries to automatically binarize a batch of   documents digitized from portable cameras compared to scanners, they   have different features. The knowledge of their source is   fundamental for successful processing. This paper presents a   classification strategy to distinguish between scanned and   photographed documents. Over 16,000 documents were tested with a   correct classification rate of over 99.96%.               Keywords: MPEG-7, Web-based services, XML, content-based multimedia retrieval, hypermedia systems, multimedia, semantic web               Categories: H.3.1, H.3.2, H.3.3, H.3.7, H.5.1  
15|2|http://www.jucs.org/jucs_15_2|Multimedia Security in Communication (MUSIC)|
15|2||On the Superdistribution of Digital Goods|  Andreas U. Schmidt (CREATE-NET Research Consortium, Italy)  Abstract: Business models involving buyers of digital   goods in the distribution process are called superdistribution   schemes. We review the state-of-the art of research and application   of superdistribution and propose a systematic approach to market   mechanisms using super-distribution and technical system   architectures supporting it. The limiting conditions on such markets   are of economic, legal, technical, and psychological nature. Large   scale applications of superdistribution such as video-on-demand and   multimedia over peer-to-peer type networks pose particular   requirements on security and efficiency.               Keywords: content superdistribution, copyright protection, digital good, trusted computing               Categories: C.2.0, H.1.1, K.4.2, K.5.1  
15|2||On the Design of Secure Multimedia Authentication|"  Jinwei Wang (CETC, P.R. China)   Jianmin Lü (CETC, P.R. China)   Shiguo Lian (France Telecom R&D Beijing, P.R. China)   Guangjie Liu (Nanjing University of Science and Technology, P.R. China)  Abstract: At present, the proposed authentication schemes can be classified into three categories. The first category is the watermarking authentication schemes in which the watermark is independent of the multimedia content. The second category is the signature-based authentication schemes in which the signature is generated by the multimedia content and is not embedded into the multimedia content. The third category is the content-based watermarking authentication schemes in which the watermark is generated by the multimedia content. However, there exists the security question in the above-mentioned three categories of the authentication schemes. In this paper, a novel concept that is called ""authentication set"" is used to analyze the security of the authentication schemes in detail. Several novel concepts on the authentication set are defined, which are called ""Cover Authentication Set"", ""Attack Authentication Set"", ""Watermark-based Authentication Set"" or ""Signature-based Authentication Set"", ""Verified Authentication Set"" and ""Malicious-attack Authentication Set"". According to the relation among the aforementioned sets, the security of the authentication schemes is exploited. Furthermore, a conclusion is drawn according to the analysis result. At the same time the principle that guides the design of the more secure authentication schemes is presented. Finally, as an example, a novel authentication design method based on multi-feature watermarks is proposed according to the design principle. The experimental results prove the validity of the design method and the significance of the guide principle.               Keywords: authentication, authentication set, content-based, design principle, watermarking               Categories: H.3.3, H.4.0, H.5.1  "
15|2||Stability in Heterogeneous Multimedia Networks under Adversarial Attacks|  Dimitrios Koukopoulos (University of Ioannina, Greece)  Abstract: A distinguishing feature of today's large-scale platforms for multimedia distribution and communication, such as the Internet, is their heterogeneity, predominantly manifested by the fact that a variety of communication protocols are simultaneously running over different hosts. A fundamental question that naturally arises for such common settings of heterogeneous multimedia systems concerns the presence (or not) of stability properties when individual greedy, contention-resolution protocols are composed in a large packet-switched multimedia network. A network is stable under a greedy protocol (or a composition of protocols) if, for any adversary of injection rate less than 1, the number of packets in the network remains bounded at all times. We focus on a basic adversarial model for packet arrival and path determination for which the time-averaged arrival rate of packets requiring a single edge is no more than 1. Within this framework, we study the property of stability under various compositions of contention-resolution protocols (such as LIS (Longest-in-System), FIFO (First-In-First-Out), FFS (Furthest-from-Source), and NTG (Nearest-to-Go)) and different packet trajectories trying to characterise this property in terms of network topologies. Such a characterisation provides us with the family of network topologies that, under specific compositions of protocols, can be made unstable by some adversarial traffic pattern. Finally, we present an experimental evaluation of the stability behaviour of specific network constructions with different protocol compositions under an adversarial strategy. Interestingly, some of our results indicate that such a composition leads to worst stability behaviour than having a single unstable protocol for contention-resolution. This suggests that the potential for instability incurred by the composition of protocols may be worse than that of any single protocol.               Keywords: adversarial attacks, adversarial queueing theory, multimedia communication networks, network stability               Categories: C.2.0, C.2.4, D.4.6, K.6.5  
15|2||The Topology Change Attack: Threat and Impact|  Mahdi Amine Abdelouahab (University of Technology of Compiegne, France)   Abdelmadjid Bouabdallah (University of Technology of Compiegne, France)   Mohamed Achemlal (Orange Labs, France)   Sylvie Laniepce (Orange Labs, France)  Abstract: Peer to peer (P2P) network has received in past few years a significant attention, especially such file sharing network as eDonkey [Kulbak and Kirkpatrick, 2005] or BitTorrent [Cohen 2008]. The shift from the classical client-server based paradigm of the Internet, with a clear distinction between information providers and consumers, towards consumers sharing information among each other led to the rise of the P2P paradigm. This distributed architecture, enables users to share content autonomously; Information remains at end-users' computers at the edge of the Internet and is not gathered and organized at central servers. While P2P has emerged as a new hot communication concept among the Internet users, security concerns still taking its first steps. The deployment of classic security protocols to provide services such as node authentication, content integrity or access control, presents several difficulties, most of them are due to the decentralized nature of these environments and the lack of central authorities. The fast emergence and the open nature of P2P applications, make appearing new attacks, so it is extremely important to study them and develop new counter measurements. Furthermore, existing studies focus on attacks that disrupt the overlay functioning and does not take in account their impact on ISPs (Internet Service Provider) infrastructure. In this paper, we present the Topology Change Attack [Abdelouahab et al. 2008] that harms the underlying networks (ISPs infrastructure) by unbalancing the P2P workload repartition. In order to evaluate and validate the TCA impact, we developed a new cycle-based simulator which simulates eDonkey clients hosted on different ISPs. The obtained results are very interesting and show the increasing of inter-ISPs traffic when a Topology Change Attack is conducted.               Keywords: PeerSim, attack, file sharing application, peer-to-peer, topology change               Categories: C.2  
15|2||A New Detection Method for Distributed Denial-of-Service Attack Traffic based on Statistical Test|  Chin-Ling Chen (National Pingtung Institute of Commerce, Taiwan)  Abstract: This study has proposed a new detection method   for DDoS attack traffic based on two-sample t-test. We first   investigate the statistics of normal SYN arrival rate (SAR) and   confirm it follows normal distribution. The proposed method   identifies the attack by testing 1) the difference between incoming   SAR and normal SAR, and 2) the difference between the number of SYN   and ACK packets. The experiment results show that the possibilities   of both false positives and false negatives are very low. The   proposed mechanism is also demonstrated to have the capability of   detecting DDoS attack quickly.               Keywords: network monitoring, security and protection, statistical computing               Categories: C.2.0, C.2.3, G.3  
15|3|http://www.jucs.org/jucs_15_3|Managing Editor's Column|
15|3||Advances in Homomorphic Cryptosystems|  Mufutau Akinwande (Lagos State University, Nigeria)  Abstract: During the last few years homomorphic encryption   techniques have been studied extensively since they have become more   and more important in many different cryptographic protocols such as   voting protocols, lottery protocols, anonymity, privacy, and   electronic auctions.   This paper critically summarizes the current state-of-art of homomorphic cryptosystems. It recalls the basic ideas, discusses their parameters, performances and security issues. And, finally we present their capabilities in the future applications.   Attention: Based on the investigations by the J.UCS office, this article needs to be retracted due to plagiarism issue. The paper was found to duplicate word by word without proper citation significant parts of the content from   Fontaine, C., Galand, F. (2007). A survey of homomorphic encryption for nonspecialists. Journal of Information Security, 1, 41-50. Retrieved from http://downloads.hindawi.com/journals/is/2007/013801.pdf    One of the conditions of submission of a paper for publication is that authors declare explicitly that the paper is not under consideration for publication elsewhere. Re-use of any data should be appropriately cited. As such this article represents a severe abuse of the scientific publishing system. The scientific community takes a very strong view on this matter and apologies are offered to the authors of the original article and readers of the journal that this was not detected during the submission process.  August 4, 2014.               Keywords: cryptosystems, homomorphic encryption, probability encryption               Categories: E.3  
15|3||Linear and Quadratic Complexity Bounds on the Values of the Positive Roots of Polynomials|"  Alkiviadis G. Akritas (University of Thessaly, Greece)  Abstract: In this paper we review the existing   linear and quadratic   complexity (upper) bounds on the values of the positive roots of   polynomials and their impact on the performance of the   Vincent-Akritas-Strzeboński (VAS)   continued fractions method for the isolation of real roots of   polynomials. We first present the following four linear complexity   bounds (two ""old"" and two ""new"" ones,   respectively): Cauchy's, (C),   Kioustelidis', (K),   First-Lambda, (FL) and   Local-Max,   (LM); we then state the quadratic complexity   extensions of these four bounds, namely: CQ,   KQ, FLQ, and   LMQ — the second, (KQ),   having being presented by Hong back in 1998. All   eight bounds are derived from Theorem 5 below. The estimates   computed by the quadratic complexity bounds are less than or equal   to those computed by their linear complexity counterparts. Moreover,   it turns out that VAS(lmq) — the   VAS method implementing LMQ — is 40%   faster than the original version   VAS(cauchy).               Keywords: Vincent's theorem, positive roots, real root isolation, upper bounds               Categories: F.2.1, G.1.5  "
15|3||DS RBAC - Dynamic Sessions in Role Based Access Control|  Jörg R. Mühlbacher (Johannes Kepler University Linz, Austria)   Christian Praher (Johannes Kepler University Linz, Austria)  Abstract: Besides the well established access control models, Discretionary Access Control (DAC) and Mandatory Access Control (MAC), the policy neutral Role Based Access Control (RBAC) is gaining increasingly momentum. An important step towards a wide acceptance of RBAC has been achieved by the standardization of RBAC through the American National Standards Institute (ANSI) in 2004.  While the concept of sessions specified in the ANSI RBAC standard allows for differentiated role selections according to tasks that have to be performed by users, it is very likely that more roles will be activated in a session than are effectively needed to perform the intended activity. Dynamic Sessions in RBAC (DS RBAC) is an extension to the existing RBAC ANSI standard that dynamically deactivates roles in a session if they are not exercised for a certain period of time. This allows for the selection of an outer-shell of possibly needed permissions at the initation of a session through a user, while adhering to the principle of least privilege by automatically reducing the effective permission space to those roles really exercised in the session.  Analogous to the working set model known from virtual memory, only the minimal roles containing permissions recently exercised by the user are left in a session in the DS RBAC model. If the user tries to access a role that has aged out due to inactivity, a role fault occurs. A role fault can be resolved by the role fault handler that is responsible for re-activating the expired role. As will be presented in this paper, role re-activation may be subject to constraints that have to be fulfilled by the user in order to re-access the aged role.               Keywords: ANSI RBAC, Role Based Access Control, least privilege, security, session               Categories: D.4.6, K.6.5, L.4.0  
15|3||A New Fair Non-repudiation Protocol for Secure Negotiation and Contract Signing|  Antonio Ruiz-Martínez (University of Murcia, Spain)   C. Inmaculada Marín-López (University of Murcia, Spain)   Laura Baño-López (University of Murcia, Spain)   Antonio F. Gómez-Skarmeta (University of Murcia, Spain)  Abstract: The participation of an e-notary, acting as an   on-line Trusted Third Party is required in some scenarios, such as   Business to Business, Intellectual Property Rights contracting, or   even as a legal requirement, in contract signing is frequently   necessary. This e-notary gives validity to the contract or performs   some tasks related to the contract, e.g. contract registration. In   the abovementioned contracting scenarios, two important additional   features are needed: the negotiation of the e-contract and   confidentiality. However, until now, e-contract signing protocols   have not considered these issues as an essential part of the   protocol. In this paper, we present a new protocol which is designed   to make negotiation and contract signing processes secure and   confidential. Moreover, compared to other previous proposals based   on an on-line Trusted Third Party, this protocol reduces the   e-notarys workload. Finally, we describe how the protocol is being   used to achieve agreements on the rights of copyrighted   works.               Keywords: Intellectual Property Rights contracts, confidentiality, contract signing protocol, fair exchange, secure negotiation               Categories: C.2.2, K.4.4, K.6.5  
15|3||Structural Coverage Criteria for Testing SQL Queries|  M. José Suárez-Cabal (University of Oviedo, Spain)   Javier Tuya (University of Oviedo, Spain)  Abstract: Adequacy criteria provide an objective   measurement of test quality. Although these criteria are a major   research issue in software testing, little work has been   specifically targeted towards the testing of database-driven   applications. In this paper, two structural coverage criteria are   provided for evaluating the adequacy of a test suite for SQL queries   that retrieve information from the database. The first deals with   the way in which the queries select and join information from   different tables and the second with the way in which selected data   is further processed. The criteria take into account both the   structure and the data loaded in the database, as well as the syntax   and semantics of the query. The coverage criteria are subsequently   used to develop test inputs of queries drawn from a real-life   application. Finally, a number of issues related to the kind of   faults that can be detected and the size of the test suite are   discussed.               Keywords: SQL testing, database testing, test adequacy criteria, test coverage               Categories: D.2.5  
15|3||Supporting Composition of Structural Aspects in an AOP Kernel|  Éric Tanter (University of Chile, Chile)   Johan Fabry (University of Chile, Chile)  Abstract: Structural aspects modify the structure of a   program, for instance by adding fields and methods to existing   classes. Like behavioral aspects, which operate on execution events,   structural aspects may interact and raise conflicts. Current aspect   systems however do not thoroughly handle this issue. This paper   discusses how complete support for structural aspect composition can   be integrated in an AOP kernel, that is, a generic transformation   framework on top of which aspect languages are defined. An iterative   composition process is proposed that involves the programmer in a   cycle of automatic detection of interactions and explicit,   declarative resolution of these interactions. Beyond a general   analysis of the issue of composition of structural aspects and an   associated composition process, this work reports on the concrete   extension of the Reflex AOP kernel to fully support the requirements   drawn from our analysis. Based on a structural model supporting   per-aspect subjective views, and using the power of an embedded   logic engine, the result is a versatile aspect system supporting   automatic detection of various kinds of structural aspect   interactions, extensible reporting tools, and declarative mechanisms   for the resolution of interactions between structural   aspects.               Keywords: AOP kernel, Aspect-Oriented Programming, Reflex, aspect composition, structural aspects               Categories: D.1.5, D.2.3, D.3.3, D.3.4  
15|3||Modelling Mailing List Behaviour in Open Source Projects: the Case of ARM Embedded Linux|  Sergio L. Toral (University of Seville, Spain)   Rocío Martínez Torres (University of Seville, Spain)   Federico Barrero (University of Seville, Spain)  Abstract: One of the benefits firms can derive from using   Open Source Software (OSS) is informal development collaboration,   and the primary tool for collaboration and coordination are group   mailing lists. The purpose of the paper is modelling mailing lists   behaviour in OSS projects, using a set of descriptors that could   inform about their quality and their evolution. As a case study, a   mailing list focused on ARM embedded Linux has been   selected. Messages posted to this list from 2001 to 2006 have been   extracted, and factor analysis has been applied to obtain the   underlying patterns of behaviours. Theory about communities of   practice has been used to understand the meaning of the extracted   patterns. Their time distribution is finally described. The paper   provides new insights into the behaviour of mailing list as a source   of support for OSS projects and highlights the importance of an   involved core of individuals inside the community.               Keywords: collaborative work, embedded systems, information systems, open source projects, social networks, virtual communities, web-based communities               Categories: H.3.5, H.4.3  
15|3||Knowledge Sharing and Collaborative Learning in Second Life: A Classification of Virtual 3D Group Interaction Scripts|  Andreas Schmeil (University of Lugano, Switzerland)   Martin J. Eppler (University of Lugano, Switzerland)  Abstract: In this paper we propose a classification and   systematic description structure based on the pattern paradigm for   interaction scripts in Second Life that aim at facilitating on the   one side knowledge sharing and knowledge integration in groups, and   on the other side knowledge creation in formal and informal ways. We   present 13 examples of interaction patterns, a description structure   to formalize them, and classify them into four classes according to   their design effort and added value. Based on this classification we   distinguish among sophisticated 3D collaboration patterns, seamless   patterns, decorative patterns, and pseudo patterns.               Keywords: MUVE, Second Life, collaboration patterns, knowledge sharing, online collaboration, virtual worlds               Categories: H.4.3, H.5.3, J.5, L.3.0, M.0  
15|3||Providing Multi Source Tag Recommendations in a Social Resource Sharing Platform|  Martin Memmel (DFKI GmbH, Germany)   Michael Kockler (DFKI GmbH, Germany)   Rafael Schirru (DFKI GmbH, Germany)  Abstract: In today's information environments, tagging is   widely used to provide information about arbitrary types of digital   resources. This information is usually created by end users with   different motivations and for different kinds of purposes. When   aiming to support users in the tagging process, these differences   play an important role. In this paper several approaches to generate   tag recommendations are discussed, and a prototypical recommender   system for the social resource sharing platform ALOE is   presented. This interactive system allows users to control the   generation of the recommendations by selecting the sources to be   used as well as their impact. The component was introduced at DFKI,   and a first evaluation showed that the recommender component was   considered as helpful by a majority of users.               Keywords: classification, collaborative tagging, digital resources, knowledge management, knowledge sharing, metadata, recommender, tagging, web 2.0               Categories: H.3.0, H.3.2, H.3.3, H.3.4, H.3.5, H.5.0, H.5.1, H.5.2  
15|3||Web 2.0 Adoption by Danish Newspapers - Urgent Need for New Business Models?|"  Niels Bjørn-Andersen (Copenhagen Business School, Denmark)   Leif Bloch Rasmussen (Copenhagen Business School, Denmark)   Soley Rasmussen (Copenhagen Business School, Denmark)  Abstract: This paper presents findings from the   development process of a general innovation framework for an ongoing   Nordic R&D project on e-business and media. It focuses on the   current state of the Danish news media sector and the conclusions we   can draw from the ""Web 2.0 activity"" of the Danish   newspapers. The paper concludes that the Web 2.0 implies the need   for fundamental re-thinking of the business models of the news media   sector and for developing a new framework for business modelling for   this sector.               Keywords: Web 2.0, Wikinomics, business models, heterarchy, new media, newspapers, social media               Categories: H.4.2, K.4.4, L.6.1  "
15|4|http://www.jucs.org/jucs_15_4|Knowledge Management for Autonomous Systems and Computational Intelligence|
15|4||An Efficient Data Preprocessing Procedure for Support Vector Clustering|  Jeen-Shing Wang (National Cheng Kung University, Taiwan, R.O.C.)   Jen-Chieh Chiang (National Cheng Kung University, Taiwan, R.O.C.)  Abstract: This paper presents an efficient data preprocessing procedure for the of support vector clustering (SVC) to reduce the size of a training dataset. Solving the optimization problem and labeling the data points with cluster labels are time-consuming in the SVC training procedure. This makes using SVC to process large datasets inefficient. We proposed a data preprocessing procedure to solve the problem. The procedure contains a shared nearest neighbor (SNN) algorithm, and utilizes the concept of unit vectors for eliminating insignificant data points from the dataset. Computer simulations have been conducted on artificial and benchmark datasets to demonstrate the effectiveness of the proposed method.               Keywords: noise elimination, shared nearest neighbors, support vector clustering               Categories: I.2.6, I.5.0, I.5.1, I.5.3  
15|4||PDE-PEDA: A New Pareto-Based Multi-objective Optimization Algorithm|  Xuesong Wang (China University of Mining and Technology, China)   Minglin Hao (China University of Mining and Technology, China)   Yuhu Cheng (China University of Mining and Technology, China)   Ruhai Lei (China University of Mining and Technology, China)  Abstract: Differential evolution (DE) algorithm puts emphasis particularly on imitating the microscopic behavior of individuals, while estimation of distribution algorithm (EDA) tries to estimate the probabilistic distribution of the entire population. DE and EDA can be extended to multi-objective optimization problems by using a Pareto-based approach, called Pareto DE (PDE) and Pareto EDA (PEDA) respectively. In this study, we describe a novel combination of PDE and PEDA (PDE-PEDA) for multi-objective optimization problems by taking advantage of the global searching ability of PEDA and the local optimizing ability of PDE, which can, effectively, maintain the balance between exploration and exploitation. The basic idea is that the offspring population of PDE-PEDA is composed of two parts, one part of the trial solution generated originates from PDE and the other part is sampled in the search space from the constructed probabilistic distribution model of PEDA. A scaling factor Pr used to balance contributions of PDE and PEDA can be adjusted in an on-line manner using a simulated annealing method. At an early evolutionary stage, a larger Pr should be adopted to ensure PEDA is used more frequently, whereas at later stage, a smaller Pr should be adopted to ensure that offspring is generated more often using PDE. The hybrid algorithm is evaluated on a set of benchmark problems and the experimental results show that PDE-PEDA outperforms the NSGA-II and PDE algorithms.               Keywords: Pareto differential evolution, Pareto estimation of distribution algorithm, multi-objective optimization, offspring generation scheme               Categories: G.1.6, I.1.2, I.2.8  
15|4||Integrative Discovery of Multifaceted Sequence Patterns by Frame-Relayed Search and Hybrid PSO-ANN|  Sing-Wu Liou (National Yunlin University of Science and Technology, Taiwan)   Chia-Ming Wang (National Yunlin University of Science and Technology, Taiwan)   Yin-Fu Huang (National Yunlin University of Science and Technology, Taiwan)  Abstract: For de novo pattern mining in genomic sequences, the main issues are constructingpattern definition model (PDM) and mining sequence patterns (MSP). The representations of PDMs and the discovery of patterns are functionally dependent; the performances thus dependon the adopted PDMs. The popular PDMs provide only descriptive patterns; they lack multifaceted considerations. Many of existing MSP methods are tied up with the exclusively devisedPDMs, and the specialized and sophisticated models make the mined results hard to be reused. In this research, an integrative pattern mining system is proposed, which consists of a computation-oriented PDM (CO-PDM) and general-purpose MSP (GP-MSP) methods. The CO-PDM defines four computational concerns (CCs) as facets of MSP: expression (E), location (L), range (R)and weight (W), which are integrated into a frame-relayed pattern model (FRPM). The GP-MSP develops a frame-relayed search strategy to resolve the ELR-CCs firstly, with the aids of critical-parameter automating (CPA) procedure; and then the W-CC is determined by hybridizing particle swarm optimization (PSO) and artificial neural network (ANN). The proposed FRPM andGP-MSP had been implemented and applied to 22,448 human introns; from the results, all the well-known patterns were recovered and some new ones were also discovered. Furthermore, theeffectiveness of identified patterns were verified by a two-layered k-nearest neighbor (k-NN) classifier; the average precision and recall are 0.88 and 0.92, respectively. By the case study, theintegrative PDM-MSP system is believed to be effective and reliable; it is optimistic the proposed CO-PDM and GP-MSP are both widely applicable and reusable for mining sequence patterns inthe eukaryotic protein-coding genes.               Keywords: computation-oriented pattern definition model, computational concerns, frame-relayed pattern mode, multifaceted sequence patterns, pattern mining               Categories: I.2.4, I.2.6, I.5.2, J.3  
15|4||A Quantum-Inspired Immune Algorithm for Hybrid Flow Shop with Makespan Criterion|  Qun Niu (Shanghai University, China)   Taijin Zhou (Shanghai University, China)   Shiwei Ma (Shanghai University, China)  Abstract: This paper presents a quantum-inspired immune algorithm (QIA) for Hybrid flow shop problems (HFSP) to minimize makespan. Since HFSP have been proved to be NP-hard in a strong sense when the objective is to minimize the makespan, an effective immune algorithm (IA) is used to solve the problems. IA is a kind of evolutional computation strategies, which is developed on the basis of a real immune mechanism in the human body, and has been employed to tackle complex scheduling problems and produce a reasonable manufacturing schedule. In order to achieve better results, the standard IA is combined with quantum algorithm (QA), which is based on Q-bit and uses quantum rotation gate to update. A real number representation is proposed to convert the Q-bit representation to job permutation for evaluating value of solutions. The proposed QIA can overcome the limitations of IA, quicken up convergence speed and improve the solution. Forty one benchmarks are examined to validate the efficiency of the proposed algorithm. The computational experiments show that the proposed QIA can also obtain both better and more robust results than IA and QA.               Keywords: hybrid flow shop scheduling, immune algorithm, quantum algorithm, quantum rotation gate               Categories: F.2.2, I.2.8  
15|4||Graph-based Approach for Robust Road Guidance Sign Recognition from Differently Exposed Images|  Andrey Vavilin (University of Ulsan, Korea)   Kang-Hyun Jo (University of Ulsan, Korea)  Abstract: In this paper we present an approach to detect traffic guidance signs and recognise the structure of junction information on them. The detection algorithm is based on using differently exposed images. These images are combined into one using tone mapping technique in order to minimize effects of bad environment conditions and low dynamic range of CCD-cameras. This technique allows robust sign detection in various lighting conditions. To localize sign candidates color segmentation is used. To minimize number of false detection filtering operations based on geometrical and color properties is applied. Recognition process is based on graph theory. Each sign candidate is decomposed into principal components and the region which represents junction structure is mapped into a graph. This graph is checked for possible mapping mistakes. Finally, the graph is analyzed in order to extract all possible paths of junction crossing. These paths must represent the real structure of the junction and correspond to the road law. The proposed method allows more effective detection in different lighting and environmental conditions such as insufficient or excessive lighting, rain, fog etc compared with conventional approaches.               Keywords: HDR, graph theory, sign detection, sign recognition               Categories: I.4.0, I.4.6, I.4.8, I.4.9  
15|4||Fingerprinting Lexical Contexts over the Web|  Vincenzo Di Lecce (Polytechnic of Bari, Italy)   Marco Calabrese (Polytechnic of Bari, Italy)   Domenico Soldo (Polytechnic of Bari, Italy)  Abstract: In this paper a novel technique for identifying   lexical contexts in web resources is presented. The basic idea is to   consider web site anchortexts as lexicalized descriptions of an   individual ontology organized in the form of a graph of concept   words. In the search for peculiar semantic patterns, the concept of   web minutia (transposed from the forensic domain) is introduced. The   proposed technique consists in searching for web minutiae in the   analyzed web sites by means of a golden ontology. Web minutiae act   as fingerprints for context-specific web resources; in this sense   they are a powerful computational tool to identify and categorize   the Web. The WordNet database has been used as golden ontology for   our experiments on English web documents. WordNet allows for   indexing and retrieving word senses and inter-word taxonomical   relations like hyponymy and hypernymy. It has proven to be an   efficient mediator between web ontologies and context-dependent   taxonomies. Our experiments have been carried out on a preliminary   data set of several tens of thousand links taken by web sites of   thirteen UK universities. Preliminary results seem to confirm the   ability of web minutiae to identify lexical contexts across the Web.               Keywords: Semantic Web, Web Mining, WordNet, golden ontology, knowledge discovery, minutia               Categories: I.2.4, L.1.4  
15|4||Bayesian Gene Regulatory Network Inference Optimization by means of Genetic Algorithms|  Vitoantonio Bevilacqua (Politecnico di Bari, Italy)   Giuseppe Mastronardi (Politecnico di Bari, Italy)   Filippo Menolascina (Politecnico di Bari, Italy)   Paolo Pannarale (Politecnico di Bari, Italy)   Giuseppe Romanazzi (Politecnico di Bari, Italy)  Abstract: Inferring gene regulatory networks from data   requires the development of algorithms devoted to structure   extraction. When time-course data is available, gene interactions   may be modeled by a Bayesian Network (BN). Given a structure, that   models the conditional independence between genes, we can tune the   parameters in a way that maximize the likelihood of the observed   data. The structure that best fit the observed data reflects the   real gene network's connections. Well known learning algorithms   (greedy search and simulated annealing) devoted to BN structure   learning have been used in literature. We enhanced the fundamental   step of structure learning by means of a classical evolutionary   algorithm, named GA (Genetic algorithm), to evolve a set of   candidate BN structures and found the model that best fits data,   without prior knowledge of such structure. In the context of genetic   algorithms, we proposed various initialization and evolutionary   strategies suitable for the task. We tested our choices using   simulated data drawn from a gene simulator, which has been used in   the literature for benchmarking [Yu et al. (2002)]. We assessed the   inferred models against this reference, calculating the performance   indicators used for network reconstruction.  The performances of the   different evolutionary algorithms have been compared against the   traditional search algorithms used so far (greedy search and   simulated annealing). Finally we individuated as best candidate an   evolutionary approach enhanced by Crossover-Two Point and Selection   Roulette Wheel for the learning of gene regulatory networks with BN.   We show that this approach outperforms classical structure learning   methods in elucidating the original model of the simulated dataset.   Finally we tested the GA approach on a real dataset where it reach   62% of recovered connections (sensitivity) and 64% of direct   connections (precision), outperforming the other algorithms.               Keywords: Bayesian network, gene networks, genetic algorithms               Categories: D.0, G.1.6, G.3, J.3  
15|4||Multilayer Ensemble Pruning via Novel Multi-sub-swarm Particle Swarm Optimization|  Jun Zhang (Chinese Academy of Science, China)   Kwok-Wing Chau (The Hong Kong Polytechnic University, Hong Kong)  Abstract: Recently, classifier ensemble methods are   gaining more and more attention in the machine-learning and   data-mining communities. In most cases, the performance of an   ensemble is better than a single classifier. Many methods for   creating diverse classifiers were developed during the past   decade. When these diverse classifiers are generated, it is   important to select the proper base classifier to join the   ensemble. Usually, this selection process is called pruning the   ensemble. In general, the ensemble pruning is a selection process in   which an optimal combination will be selected from many existing   base classifiers. Some base classifiers containing useful   information may be excluded in this pruning process. To avoid this   problem, the multilayer ensemble pruning model is used in this   paper. In this model, the pruning of one layer can be seen as a   multimodal optimization problem. A novel multi-sub-swarm particle   swarm optimization (MSSPSO) is used here to find multi-solutions for   this multilayer ensemble pruning model. In this model, each base   classifier will generate an oracle output. Each layer will use   MSSPSO algorithm to generate a different pruning based on previous   oracle output. A series of experiments using UCI dataset is   conducted, the experimental results show that the multilayer   ensemble pruning via MSSPSO algorithm can improve the generalization   performance of the multi-classifiers ensemble system. Besides, the   experimental results show a relationship between the diversity and   the pruning technique.               Keywords: classifier ensemble, ensemble pruning, multi-layer ensemble model, particle swarm optimization               Categories: L.1.3  
15|4||A DCM Based Orientation Estimation Algorithm with an Inertial Measurement Unit and a Magnetic Compass|  Nguyen Ho Quoc Phuong (University of Ulsan, South Korea)   Hee-Jun Kang (University of Ulsan, South Korea)   Young-Soo Suh (University of Ulsan, South Korea)   Young-Sik Ro (University of Ulsan, South Korea)  Abstract: In this paper, Direction Cosine Matrix (DCM)   method for attitude and orientation estimation is discussed. DCM   method was chosen due to some advantages over the popular methods   such as namely Euler Angle, Quaternion in light of reliability,   accuracy and computational efforts. Proposed model for each method   is developed for methodology comparison. It is shown that normal   Kalman Filter in DCM method is better than extended Kalman Filter in   Euler and Quaternion based method because it helps avoid the first   order approximation error.  Methodology errors are verified using   Aerospace Blockset of Matlab Simulink.               Keywords: DCM, Euler Representation, Quaternion, orientation estimation               Categories: I.2.9, I.3.5, I.3.7  
15|4||Complexity Analysis of Ontology Integration Methodologies:a Comparative Study|  Trong Hai Duong (Inha University, Korea)   Geun Sik Jo (Inha University, Korea)   Jason J. Jung (Yeungnam University, Korea)   Ngoc Thanh Nguyen (Wroclaw University of Technology, Poland)  Abstract: Most previous research on ontology integration   has focused on similarity measure-ments between ontological   entities, e.g., lexicons,   instances, schemas and   taxonomies, resulting in high computational costs   of considering all possible pairs between two given ontologies. In   this paper, we propose a novel approach to reducing computational   complexity in ontology integration. Thereby, we address the   importance and types of   concepts, for priority matching anddirect matching between   concepts, respectively. Identity-based similarity   is computed, to avoid comparisons of all properties related to each   concept, while matching between concepts. Theproblem of conflict in   ontology integration has initially been explored on the   instance-level and   concept-level. This is useful to avoid many cases   of mismatching.               Keywords: conflict, identity-based similarity, importance concepts, ontology integration               Categories: E.1, H.3.0, H.3.3, I.2.0, I.2.1, I.2.2, I.2.3, I.2.4, M.7  
15|4||SDLMAS: A Scenario Modeling Framework for Multi-Agent Systems|  Igor Čavrak (University of Zagreb, Croatia)   Armin Stranjak (Rolls-Royce plc, United Kingdom)   Mario Žagar (University of Zagreb, Croatia)  Abstract: In this paper we analyze existing methods and   languages for modeling agent interactions and propose a SDLMAS   Framework for rapid design, development and runtime support of   multi-agent systems. The framework provides a simple but expressive   declarative language for modeling complex interactions among   agents. Proposed language is based on scenarios, sequences of   conversation actions directed towards achieving a goal. Scenario   descriptions are converted into program code for a chosen target   agent platform and system execution is supported by a runtime   framework.               Keywords: Interaction, Language, Multi-Agent System, Scenario               Categories: D.2.0, I.2.11, I.2.5, I.6.0  
15|4||A Personalized URL Re-ranking Method using Psychological User Browsing Characteristics|"  Shohel Ahmed (Inha University, Korea)   Sungjoon Park (Kongju Communication and Arts College, Korea)   Jason J. Jung (Yeungnam University, Korea)   Sanggil Kang (Inha University, Korea)  Abstract: This paper proposes a personalized URL   re-ranking method based on psychological characteristics of users   browsing. The characteristics are classified into three groups,   which are ""common-mind,"" ""uncommon-mind,"" and ""extremely   uncommonmind."" Our personalization method constructs an index of the   anchor text retrieved from the web pages that the user has clicked   during his/her past searches. Our method provides different weights   to the anchor text according to the psychological characteristics   for re-ranking URLs. In the experimental section, we show that our   method can provide better performance than Google and another web   personalization method in terms of the average rank.               Keywords: personalization, re-ranking, search engine, user browsing               Categories: H.1.1, H.3.5, I.2.11  "
15|4||Agent Migration: Framework for Analysis|  Dariusz Król (Wrocŀaw University of Technology, Poland)   Aleksander Lupa (Wrocŀaw University of Technology, Poland)  Abstract: A lot of work is devoted to analysing architectures for coordinating the behaviour of individual agents. However, providing agents with abilities to migrate continues to be a highly challenging problem. We propose a novel multi-agent framework, called Agent-based Migration (AM). We begin by defining the principal objective, which is the migration phenomenon applied, in our case, to distributed calculation of prime numbers. We present the AM architecture in detail. Then, we introduce different types of migration and the communication scheme. We also conduct a set of experiments in two environments: 4 heterogeneous computers and 45 (almost) homogeneous computers. Specifically, we are looking for a way to find optimal configurations for migration in both environments. The conclusion from this work is that introducing propagation to a system in a form of agent migration in both networks could considerably decrease the execution time according to used algorithms and established assumptions.               Keywords: mobile agent, multi-agent system, performance evaluation, propagation               Categories: C.2.4, C.4, H.1.0  
15|5|http://www.jucs.org/jucs_15_5|Data Security and Privacy Protection in Pervasive Computing Environments|
15|5||Security Mechanisms and Access Control Infrastructure for e-Passports and General Purpose e-Documents|  Pablo Najera (University of Malaga, Spain)   Francisc Moyano (University of Malaga, Spain)   Javier Lopez (University of Malaga, Spain)  Abstract: Traditional paper documents are not likely to   disappear in the near future as they are present everywhere in daily   life, however, paper-based documentation lacks the link with the   digital world for agile and automated processing. At the same time   it is prone to cloning, alteration and counterfeiting   attacks. E-passport defined by ICAO and implemented in 45 countries   is the most relevant case of hybrid documentation (i.e. paper format   with electronic capabilities) to date, but, as the advantages of   hybrid documentation are recognized more and more will undoubtedly   appear. In this paper, we present the concept and security   requirements of general-use e-documents, analyze the most   comprehensive security solution (i.e. ePassport security mechanisms)   and its suitability for general-purpose e-documentation. Finally, we   propose alternatives for the weakest and less suitable protocol from   ePassports: the BAC (Basic Access Control). In particular, an   appropriate key management infrastructure for access control to   document memory is discussed in conjunction with a prototype   implementation.               Keywords: RFID security, RFID technology, access control infrastructure, e-Passport, e-documents, electronic documents, pervasive computing, security, security mechanisms               Categories: D.2.1,, D.2.11, K.6.5  
15|5||Agent Platform for Wireless Sensor Network with Support for Cryptographic Protocols|  Peter Pecho (Brno University of Technology, Czech Republic)   Frantisek Zboril Jr. (Brno University of Technology, Czech Republic)   Martin Drahansky (Brno University of Technology, Czech Republic)   Petr Hanacek (Brno University of Technology, Czech Republic)  Abstract: This paper deals with a description of wireless   sensor networks at the beginning. Further follows the introduction   to the agent platform suitable for wireless networks. Mobile code   and sensor networks suffer from considerable security problems. Our   proposal of countermeasure is based on combination of smartcards   with sensor nodes. Smartcards as a tamper resistant devices offer   solution for the most of commonly required security   objectives. Analysis of proposed hardware cryptographic platform   includes link level communication, transport protocol description,   application interface description and demands for power   consumption. Today smartcards are highly standardized devices that   offer common communication interface and platform could be used with   various smartcards in accordance with ISO/EMV standards. At the end,   we discuss the combination of agents in wireless sensor networks in   conjunction with usage of cryptographic protocols for securing of   wireless networks.               Keywords: agent, cryptography, protocol, smartcard, wireless sensor network               Categories: C.2.0  
15|5||Security Analysis of the Full-Round CHESS-64 Cipher Suitable for Pervasive Computing Environments|  Changhoon Lee (Hanshin University, Korea)   Jongsung Kim (Korea University, Korea)   Seokhie Hong (Korea University, Korea)   Yang-Sun Lee (FUMATE Co., Korea)  Abstract: Wireless networks, telecommunications, and   information technologies connected de-vices in pervasive computing   environments require a high speed encryption for providing a high   security and a privacy. The CHESS-64 based on various controlled   operations is designed forsuch applications. In this paper, however,   we show that CHESS-64 doesn't have a high security level, more   precisely, we present two related-key differential attacks on   CHESS-64. The first at-tack requires about   244 data and 244 time   complexities (recovering 20 bits of the master key)while the second   attack needs about 239 data and   239 time complexities (recovering 6 bits of   themaster key). These works are the first known cryptanalytic   results on CHESS-64 so far.               Keywords: Block Cipher, CHESS-64, Data-Dependent Operation, Data-Dependent Permutation, Differential Cryptanalysis, Related-Key Attack               Categories: E.3, L.4, L.7  
15|5||Protecting Mobile TV Multimedia Content in   DVB/GPRS Heterogeneous Wireless Networks|  Shiguo Lian (France Telecom R&D (Orange Labs), China)   Yan Zhang (Simula Research Laboratory, Norway)  Abstract: Normally, the multimedia content provider and network service providers are separated in mobile TV systems. The TV programs are broadcasted from the content provider to the mobile terminals through Digital Video Broadcasting Transmission System for Handheld Terminals (DVB-H), and the access information is unicasted from the service provider to the user via General Packet Radio Services (GPRS) networks. Due to the network architecture heterogeneity, protocols variation and algorithms difference, securing mobile TV content is becoming a significant challenge. In this paper, we present the architecture, protocol, user identification and digital right management (DRM) for protecting mobile TV multimedia content. The network architecture describes the integrated DVB-H and GPRS to provide secure mobile TV services. The efficient protocols and algorithms are proposed to encrypt the content and also decrypt the coded content. The user identification is able to identify the legal user by matching the username-password pair or the scanned fingerprint. The DRM is able to protect the data from both DVB-H and GPRS. Following this framework, the illegal usage of the mobile TV services can be efficiently prevented and the real-time multimedia Quality-of-Service (QoS) with respect to delay can be guaranteed. The real implementation has demonstrated the effectiveness of the multimedia content protection in the heterogeneous mobile networks. In addition, the delay is sufficiently low to provide live TV.               Keywords: DVB-H, Digital Rights Management (DRM), Fingerprint Matching, GPRS, Secure Multimedia Distribution, User Identification, mobile TV, video scrambling               Categories: D.4.6, H.1.1, H.3.7, H.4.0, H.5.0, H.5.1, H.5.5  
15|5||Light-Weight Key Exchange with Different Passwords in the Standard Model|  Jeong Ok Kwon (Samsung SDS, Korea)   Ik Rae Jeong (Korea University, Korea)   Dong Hoon Lee (Korea University, Korea)  Abstract: In this paper, we consider password-based   authenticated key exchange with different passwords, where the users   only share a password with the trusted server but do not share   between themselves. The server helps the users share a   cryptographically secure session key by using their different   passwords. We propose a light-weight password-based authenticated   key exchange protocol with different passwords, i.e., it requires   only 2 rounds and 4 modular exponentiations per user. The protocol   provides forward secrecy, known-key secrecy, key secrecy against the   curious server, and security against undetectable online dictionary   attacks without random oracles.               Keywords: different passwords, forward secrecy, key secrecy, password-based key exchange               Categories: C.2.0, D.4.6, E.3  
15|5||USF-PAS : Study on Core Security Technologies for Ubiquitous Security Framework|  Jong Hyuk Park (Kyungnam University, Korea)  Abstract: Ubi-Com has emerged as an exciting new paradigm   to provide intelligent computig and communications at anytime and   anywhere. But, In order to take the advantages of such services, it   is important that intelligent security framework be suitable for   Ubi-Com. In this paper, we propose privacy and access control scheme   by surveillance which is one of core security technologies for   ubiquitous hybrid intelligent security framework. In this scheme,   the device information and the signature information can be added to   the image data obtained by the image capturing device to maintain   security of the image data and use the image data as digital proof   when a specific event is generated.               Keywords: Ubi-com, access control, intelligent security framework, privacy, surveillance               Categories: H.4.3, H.5.1, J.7  
15|5||Vascular Pattern Analysis towards Pervasive  Palm Vein Authentication|  Debnath Bhattacharyya (Heritage Institute of Technology, India)   Poulami Das (Heritage Institute of Technology, India)   Tai-hoon Kim (Hannam University, Korea)   Samir Kumar Bandyopadhyay (University of Calcutta, India)  Abstract: In this paper we propose an Image Analysis   technique for Vascular Pattern of Hand Palm, which in turn leads   towards Palm Vein Authentication of an individual. Near-Infrared   Image of Palm Vein pattern is taken and passed through three   different processes or algorithms to process the Infrared Image in   such a way that the future authentication can be done accurately or   almost exactly. These three different processes are: a. Vascular   Pattern Marker Algorithm (VPMA); b. Vascular Pattern Extractor   Algorithm (VPEA); and c. Vascular Pattern Thinning Algorithm   (VPTA). The resultant Images will be stored in a Database, as the   vascular patterns are unique to each individual, so future   authentication can be done by comparing the pattern of veins in the   palm of a person being authenticated with a pattern stored in a   database.               Keywords: Vascular Pattern, authentication, biometric, multimodal, near-infrared, signature and thinning               Categories: I.4.10, I.4.6, I.4.7, I.5.2  
15|5||Cooperation Enforcement in a Highly Dynamic Mobile Ad Hoc Network|  Yao H. Ho (University of Central Florida, USA)   Ai Hua Ho (University of Central Florida, USA)   Kien A. Hua (University of Central Florida, USA)   Fei Xie (University of Central Florida, USA)  Abstract: Operations of mobile ad hoc networks rely on the   collaboration of participating nodes to route data for each other.   This standard approach using a fixed set of nodes for each   communication link cannot cope with high mobility due to a high   frequency of link breaks.  A recent approach based on virtual   routers has been proposed to address this problem.  In this new   environment, virtual routers are used for forwarding data.  The   functionality of each virtual router is provided by the mobile   devices currently within its spatial proximity.  Since these routers   do not move, the communication links are much more robust compared   to those of the conventional techniques.  In this paper, we   investigate techniques to enforce collaboration among mobile devices   by identify and punish misbehaving users in supporting the virtual   router functionality.  Simulation results based on various system   configurations are given.  They indicate that the proposed technique   is effective.               Keywords: cooperation-enforcement, mobile ad hoc networks, selfishness               Categories: C.2.2, C.4  
15|5||A Neural Network Based Vehicle Classification System for Pervasive Smart Road Security|  Naixue Xiong (Georgia State University, USA)   Jing He (Georgia State University, USA)   Jong Hyuk Park (Kyungnam University, Korea)   Donald Cooley (Utah State University, USA)   Yingshu Li (Georgia State University, USA)  Abstract: Pervasive smart computing environments make people get accustomed to convenient and secure services. The overall goal of this research is to classify vehicles along the I215 freeway in Salt Lake City, USA. This information will be used to predict future roadway needs and the expected life of a roadway. The classification of vehicles will be performed by a synthesis of multiple sets of features. All feature sets have not yet been determined; however, one such set will be the reduced wavelet transform of the image of a vehicle. In order to use such a feature, it is necessary that the image be normalized with respect to size, position, and so on. For example, a car in the right most lane in an image will appear smaller than one in the left most lane, because the right most lane is closest to the camera. Likewise, a vehicles size will vary depending on where in a lane its image is captured. In our case, the image capture area for each lane is approximately 100 feet of roadway. A goal of this paper is to normalize the image of a vehicle so that regardless of its lane or position in a lane, the features will be approximately the same. The wavelet transform itself will not be used directly for recognition. Instead, it will be input to a neural network and the output of the neural network will be one element of the feature set used for recognition.               Keywords: Neural Network, Normalization, Recognition, Vehicle classification, Wavelet, Wavelet transform, image processing               Categories: H.5.1, I.2.0, I.2.11, I.2.6, I.2.8, L.2.0  
15|6|http://www.jucs.org/jucs_15_6|Computability and Complexity in Analysis|
15|6||On the Effective Existence of Schauder Bases|  Volker Bosserhoff (Universität der Bundeswehr, Germany)  Abstract: We construct a computable Banach space which   possesses a Schauder basis, but does not possess any computable   Schauder basis.               Keywords: Schauder basis, computatable functional analysis               Categories: F.1, F.m, G.m  
15|6||Effective Computability of Solutions of Differential Inclusions The Ten Thousand Monkeys Approach|"  Pieter Collins (Centrum voor Wiskunde en Informatica, The Netherlands)   Daniel S. Graça (Universidade of Algarve, Portugal)  Abstract: In this paper we consider the computability of   the solution of the initialvalue problem for differential equations   and for differential inclusions with semicontinuous right-hand   side. We present algorithms for the computation of the solution   using the ""ten thousand monkeys"" approach, in which we generate all   possible solution tubes, and then check which are valid. In this   way, we show that the solution of a locally Lipschitz differential   equation is computable even if the function is not effectively   locally Lipschitz, and recover a result of Ruohonen, in which it is   shown that if the solution is unique, then it is computable. We give   an example of a computable locally Lipschitz function which is not   effectively locally Lipschitz. We also show that the solutions of a   convex-valued upper-semicontinuous differential inclusion are   upper-semicomputable, and the solutions of a lower-semicontinuous   one-sided Lipschitz differential inclusion are   lower-semicomputable.               Keywords: Lipschitz condition, computable analysis, differential inclusions, ordinary differential equations, semicomputability               Categories: F.1.1, F.2.1, G.1.m  "
15|6||Oracles and Relativizations of the P =? NP Question for Several Structures|  Christine Gaßner (Ernst-Moritz-Arndt-Universität Greifswald, Germany)  Abstract: We consider the uniform model of computation   over any structure with two constants. For several structures, we   construct oracles which imply that the relativized versions of P and   NP are equal or are not equal. We construct universal oracles which   imply the equality of the relativized versions of P and NP and we   show that we lose the possibility to define these oracles   recursively if we try to compress their elements to tuples of fixed   length. Moreover we give new oracles for the BSS model in order to   separate the classes P and NP relative to these oracles.               Keywords: BSS machines, Halting Problem, P-NP problem, oracle machines, relativizations               Categories: F.1, F.1.1, F.1.2, F.1.3  
15|6||Chainable and Circularly Chainable Co-r.e. Sets in Computable Metric Spaces|  Zvonko Iljazović (University of Zagreb, Croatia)  Abstract: We investigate under what conditions a   co-recursively enumerable set S in a computable   metric space (Χ, d, α) is   recursive. The topological properties of S play   an important role in view of this task. We first study some   properties of computable metric spaces such as the effective   covering property. Then we examine co-r.e. sets with disconnected   complement, and finally we focus on study of chainable and   circularly chainable continua which are co-r.e. as subsets of   Χ. We prove that, under some assumptions on Χ, each   co-r.e. circularly chainable continuum which is not chainable must   be recursive. This means, for example, that each co-r.e. set in Rn   or in the Hilbert cube which has topological type of the Warsaw   circle or the dyadic solenoid must be recursive. We also prove that   for each chainable continuum S which is   decomposable and each ε > 0 there exists a recursive   subcontinuum of S which is ε-close to   S.               Keywords: chainable continuum, circularly chainable continuum, co-r.e. set, computable metric space, recursive set, the effective covering property               Categories: F.0, G.0  
15|6||Constructive Urysohn Universal Metric Space|  Davorin Lešnik (Institute for Mathematics, Physics and Mechanics, Slovenia)  Abstract: We construct the Urysohn metric space in   constructive setting without choice principles. The Urysohn space is   a complete separable metric space which contains an isometric copy   of every separable metric space, and any isometric embedding into it   from a finite subspace of a separable metric space extends to the   whole domain.               Keywords: Urysohn universal space, constructive mathematics, metric space               Categories: G.0  
15|6||Fine-computable Functions on the Unit Square and their Integral|  Takakazu Mori (Kyoto Sangyo University, Japan)   Mariko Yasugi (Kyoto Sangyo University, Japan)   Yoshiki Tsujii (Kyoto Sangyo University, Japan)  Abstract: We discuss the integral and Fubini's Theorem for   a Fine-computable function F(x,   y) on the upper-right open unit square [0, 1) x [0,1). The   core objective is Fine-computability of   f(x) = ∫   [0,1) F(x,y)dy as   a function of x ∈ [0,1).               Keywords: Fine-computable function, Fubini's Theorem, integral operator               Categories: F.0, F.m  
15|6||Representing Measurement Results|  Arno Pauly (University of Cambridge, United Kingdom)  Abstract: To gain insight into the relationship between physical theories and computation, we examine the link between measurement devices and computers in the framework of TTE. Starting from a formal definition of a measurement procedure, different approaches to associate a representation with a measurement procedure are studied, and an equivalence class of representations suitable for representing the results of a measurement is defined for each measurement procedure.               Keywords: admissible representation, computable analysis, computation by physical devices, measurement, normal distribution               Categories: F.0, F.1.1  
15|6||Topological Complexity of Blowup Problems|"  Robert Rettinger (University of Hagen, Germany)   Klaus Weihrauch (University of Hagen, Germany)   Ning Zhong (University of Cincinnati, Germany)  Abstract: Consider the initial value problem of the   first-order ordinary differential equation    where the   locally Lipschitz continuous function  with open   domain and the initial datum   (t0,   x0) ∈  are given. It is shown   that the solution operator producing the maximal ""time"" interval of   existence and the solution on it is computable. Furthermore, the   topological complexity of the blowup problem is studied for   functions f defined on the whole space. For each   such function f the set Z of   initial conditions (t0,   x0) for which the positive solution does not   blow up in finite time is a -set. There   is even a computable operator determining Z from   f. For l ≥ 2 this upper   -complexity   bound is sharp. For l = 1 the blowup problem is   simpler.               Keywords: Type-2 theory, blowup, differential equation               Categories: F.2.1  "
15|6||An Effective Tietze-Urysohn Theorem for QCB-Spaces|  Matthias Schröder (Universität der Bundeswehr, Germany)  Abstract: The Tietze-Urysohn Theorem states that every   continuous real-valued function defined on a closed subspace of a   normal space can be extended to a continuous function on the whole   space. We prove an effective version of this theorem in the Type Two   Model of Effectivity (TTE). Moreover, we introduce for qcb-spaces a   slightly weaker notion of normality than the classical one and show   that this property suffices to establish an Extension Theorem for   continuous functions defined on functionally closed   subspaces. Qcb-spaces are known to form an important subcategory of   the category Top of topological   spaces. QCB is cartesian closed in contrast to   Top.               Keywords: Qcb-spaces, computable Analysis, topological spaces               Categories:  F.1.1  
15|6||Computing the Solution Operators of Symmetric Hyperbolic Systems of PDE|  Svetlana Selivanova (Siberian Division of the Russian Academy of Sciences, Russia)   Victor Selivanov (Siberian Division of the Russian Academy of Sciences, Russia)  Abstract: We study the computability properties of   symmetric hyperbolic systems of PDE , with   the initial condition  =   φ(x1,...,xm). Such   systems first considered by K.O. Friedrichs can be used to describe   a wide variety of physical processes. Using the difference equations   approach, we prove computability of the operator that sends (for any   fixed computable matrices A,   B1, ...,   Bm satisfying certain   conditions) any initial function φ ∈   Cp+1(Q,   ℝn) (satisfying   certain conditions), p ≥ 2, to the unique   solution u ∈   Cp(H,   ℝn), where   Q =   [0,1]m and   H is the nonempty domain of correctness of the   system.               Keywords: PDE, computability, difference scheme, finite-dimensional approximation, hyperbolic system, matrix pencil, metric space, norm, stability               Categories: F.2, F.2.1  
15|6||On Finite-time Computability Preserving Conversions|  Hideki Tsuiki (Kyoto University, Japan)   Shuji Yamada (Kyoto Sangyo University, Japan)  Abstract: A finite-time computable function is a partial   function from ∑ω to ∑   ω whose value is constructed by   concatenating a finite list with a suffix of the argument. A   finite-time computability preserving conversion α :   X → Y for   X, Y ⊂   ∑ω is a bijection which preserves   finite-time computability. We show that all the finite-time   computability preserving conversions with the domain   ∑ω are extended sliding block   functions.               Keywords: computable analysis, constant-time computable functions, domain theory, finite-time computable functions, sliding block functions               Categories: F.1.m, F.4.3, G.2.m  
15|6||Elementary Computable Topology|"  Klaus Weihrauch (University of Hagen, Germany)   Tanja Grubba (University of Hagen, Germany)  Abstract: We revise and extend the foundation of computable topology in the framework of Type-2 theory of effectivity, TTE, where continuity and computability on finite and infinite sequences of symbols are defined canonically and transferred to abstract sets by means of notations and representations. We start from a computable topological space, which is a T0-space with a notation of a base such that intersection is computable, and define a number of multi-representations of the points and of the open, the closed and the compact sets and study their properties and relations. We study computability of boolean operations. By merely requiring ""provability"" of suitable relations (element, non-empty intersection, subset) we characterize in turn computability on the points, the open sets (!), computability on the open sets, computability on the closed sets, the compact sets(!), and computability on the compact sets. We study modifications of the definition of a computable topological space that do not change the derived computability concepts. We study subspaces and products and compare a number of representations of the space of partial continuous functions. Since we are operating mainly with the base elements, which can be considered as regions for points (""pointless topology""), we study to which extent these regions can be filled with points (completions). We conclude with some simple applications including Dini's Theorem as an example.               Keywords: computability, computable analysis, topology               Categories: F.0, F.1, F.1.1, G.0  "
15|7|http://www.jucs.org/jucs_15_7|Computers in Education: Advances in Software Technology|
15|7||Innovation and Quality in e-Learning: a European Perspective|"  Claudio Dondi (SCIENTER, Italy)  Abstract: This paper presents a new vision of e-Learning   and quality in e-Learning based on two main assumptions: e-Learning   cannot be seen as a ""one-size-fits all"" solution as it has as many   definitions as the fields and sectors where it is implemented, and   to define quality in e-Learning one must consider the influence of   visions of stakeholders on quality perception. The paper analyses   in-depth the e-Learning territory concept and provides an innovative   view on quality approaches for e-Learning as well as a set of   recommendations addressing e-Learning stakeholders.               Keywords: e-learning territories, innovation, quality, stakeholders, visions               Categories: K.3.1  "
15|7||A Meta-modeling based Approach for the Multi-Disciplinary Design of Web Educational Systems|  Paloma Díaz (Universidad Carlos III de Madrid, Spain)   Esther Guerra (Universidad Carlos III de Madrid, Spain)   Telmo Zarraonandía (Universidad Carlos III de Madrid, Spain)   Ignacio Aedo (Universidad Carlos III de Madrid, Spain)   Carmen L. Padrón (Universidad Carlos III de Madrid, Spain)  Abstract: Multi-disciplinary teams might provide a   multi-faceted perspective of web educational systems that integrates   experience from different fields. Each expert has a view of the   system and she uses domain specific languages in order to express   solutions to the problems she is concerned with. In this way, the   final system can be seen as a combination of a number of   complementary views, each of which focuses on problems of a   different nature. However, such views are expressed with different   specification tools so that they have to be integrated to produce a   common design that is complete and consistent. Creating a common   language encompassing multi-disciplinary design views is a   challenging endeavor but it might impose a cognitive overload to   each member of the group who is exposed to unfamiliar concepts of   other disciplines in her design view. Alternatively, this paper   describes an approach called MODUWEB that consists of letting each   designer use the tool she is proficient in for her design tasks and   then complementary design perspectives are integrated using   meta-modeling techniques. MODUWEB also includes a number of   constraints and semantic rules that guarantee the completeness and   consistency of the resulting model.               Keywords: Web design, educational design, model-driven development, multi-disciplinary design               Categories: D.2.11, K.3.1  
15|7||Application Scenarios for the Learning Objects Pool|"  Patrícia Dinis (Escola Sec. Jaime Moniz, Portugal)   Alberto Rodrigues da Silva (INESC-ID & Instituto Superior Técnico, Universidade Técnica de Lisboa, Portugal)  Abstract: Learning Objects Repositories are becoming increasingly available on the Internet. Learning Objects Pool (LOP) built around the ""stock exchange"" metaphor, brings a new concept of Learning Objects Repositories pushing users motivation to produce good LOs as well as increasing the cooperation between users, either by submitting suggestions and comments or rating existing LOs. To achieve such high level of motivation and interest some kind of healthy competition is promoted, assigning credits to users and setting a value cost for each LO. This credit-based system rewards users that collaborate by creating LOs or by adding valuable information. It consequently increases the value of the most popular LOs, and also allows the creation of users and LOs rankings. This paper provides a comprehensive overview of the LOP system and, in particular, describes some application scenarios where, through configuration and parameterization we show the LOPs high levels of versatility.               Keywords: Collaborative Learning, Learning Object, Learning Objects Repository, e-Learning               Categories: H.3.5, H.5.3, K.3.1  "
15|7||Learning to Program with COALA, a Distributed Computer Assisted Environment|"  Francisco Jurado (University of Castilla-La Mancha, Spain)   Ana I. Molina (University of Castilla-La Mancha, Spain)   Miguel A. Redondo (University of Castilla-La Mancha, Spain)   Manuel Ortega (University of Castilla-La Mancha, Spain)   Adam Giemza (Universität Duisburg-Essen, Germany)   Lars Bollen (Universität Duisburg-Essen, Germany)   H. Ulrich Hoppe (Universität Duisburg-Essen, Germany)  Abstract: Learning to program is an important subject for   students of Computer Science. Mentoring these students is a   time-consuming and complex task. In this paper, we present a   learning and tutoring environment that integrates task/solution   delivery, assessment support and tutors annotations, by extending   Eclipse to a ""Real World Integrated Development Environment"". We   will present a distributed system that uses Tuple Space architecture   to integrate Eclipse with an evaluation module and a hand-writing   annotation feature.               Keywords: intelligent tutoring system, learning programming               Categories: D.2.4, D.2.5, D.2.6, D.2.7, D.2.8, I.2.4, L.0.0, L.2.0  "
15|7||TQ-Bot: An AIML-based Tutor and Evaluator Bot|  Fernando A. Mikic Fonte (University of Vigo, Spain)   Juan Carlos Burguillo Rial (University of Vigo, Spain)   Martín Llamas-Nistal (University of Vigo, Spain)  Abstract: Intelligent Tutoring Systems are computer   programs that aim at providing personalized instruction to   students. In recent years, conversational robots, usually known as   chatterbots, become very popular in the Internet, and ALICE   (Artificial Linguistic Internet Computer Entity) is probably the   most popular one. ALICE brain is written in AIML (Artificial   Intelligence Markup Language), an open XML language. We have   considered the combination of both approaches, i.e, the use of   AIML-based bots for tutoring purposes in open e-Learning platforms   such as Claroline or Moodle. With that aim in mind, we have   developed a bot (chatterbot) for helping the students during their   learning process and for supporting the activities of the   teacher. This bot (TQ-Bot) is able to analyse the requests made by   the learners in written natural language and to provide adequate and   domain specific answers orienting the student to the right course   contents. Besides, TQ-Bot is able to track and supervise the student   progress by means of personalized questionnaires. This bot has been   developed and integrated as user-friendly modules in Claroline and   Moodle.               Keywords: AIML, ALICE, BDI, Claroline, Intelligent Tutoring Systems, Moodle, TQ-BOT, chatterbots               Categories: I.2.7, K.3.1  
15|7||Eduquito: Virtual Environment for Digital Inclusion of People with Special Educational Needs|  Lucila Maria Costi Santarosa (Universidade Federal do Rio Grande do Sul, Brazil)   Lourenço de Oliveira Basso (Universidade Federal do Rio Grande do Sul, Brazil)  Abstract: Eduquito is intended to be a virtual environment   for digital/social inclusion where people can exercise their   citizenship with interaction and personal development. As a virtual   space, it comprises a Learning by Project Environment which provides   not only access resources for People with Special Educational Needs   but also an array of special tools, which foster a process of   creative dialogue as well as dynamic individual and collective   development.               Keywords: accessibility, persons with disabilities, virtual environment               Categories: K.3.1, K.4.2  
15|7||Development of a Web Application for Management of Learning Styles|  Rosa Silva (Escola Secundária Ferreira de Castro, Portugal)   António Andrade (Universidade Católica Portuguesa, Portugal)  Abstract: Information and Communication Technologies (ICT)   permit the innovation of teaching and learning processes. ICT allow   teachers to create or select and adjust contents that take advantage   of the digital environment and interaction between peers. Teaching   methodologies and strategies should be adjusted to the learning   styles of students, offering them, in turn, the possibility to   reflect about the way in which they might learn better. This article   introduces a work of creation and validation of a web-based   application, which aims to enhance the Management of Learning Styles   (MLS) on the part of students and teachers, based on   Felder-Solomans Index of Learning Styles Questionnaire (ILS) and   Honey-Mumfords Learning Styles Questionnaire (LSQ). The prototype   has been validated and the results suggest its applicability and the   relevance of the information this tool is capable of obtaining -    reports on the learning styles profiles by student, teacher and   class - with the objective of supporting them in the selection of   strategies to improve teaching and learning, developing at the same   time skills which will allow them to learn throughout their lives.               Keywords: Web-based application, learning styles               Categories: K.3.1  
15|7||Semantic Spiral Timelines Used as Support for e-Learning|  Diego Alonso Gómez Aguilar (Universidad de Salamanca, Spain)   Roberto Therón (Universidad de Salamanca, Spain)   Francisco J. García-Peñalvo (Universidad de Salamanca, Spain)  Abstract: This article presents Semantic Spiral Timelines   (SST) as an interactive visual tool aimed at the exploration and   analysis of additional academic information stored in current   e-learning platforms. Despite the development of contents   specifically for these platforms, and in spite of the various   features they provide, knowledge of the actual use made by   individual participants is emerging as an unavoidable necessity, so   as to ensure proper operation and effective use of e-learning   platforms. SST supports the discovery of temporal patterns by   incorporating an innovative highly interactive visual   representation, which can be explored at various levels.  This tool   makes it possible to assess, at first glance, the use of the   e-learning platform during the development of courses; one can also   perceive how it is used by class participants. Then, through   different interaction mechanisms, it is possible for students and   professors to uncover specific details about courses, which would   otherwise remain hidden.               Keywords: Moodle, e-learning, spiral, timeline, visualization               Categories: L.2, L.3, L.6, M.0  
15|7||Visualization of Syntax Trees for Language Processing Courses|  Francisco J. Almeida-Martínez (Universidad Rey Juan Carlos, Spain)   Jaime Urquiza-Fuentes (Universidad Rey Juan Carlos, Spain)   J. Ángel Velázquez-Iturbide (Universidad Rey Juan Carlos, Spain)  Abstract: This article describes the educational tool   VAST. We designed VAST to be used in compiler and language   processing courses. The current version allows generat- ing and   visualizing syntax trees and their construction process. The main   advantages of VAST follow: it is designed to be as independent from   the parser generator as possible, it allows students to visualize   the behavior of parsers they develop, and it has an inter- face   designed to easily handle huge syntax trees. Finally, we describe   two satisfactory preliminary evaluations from the usability and   educational points of view.               Keywords: educational software, syntax trees, visualization               Categories: D.3.4, K.3.1, K.3.2  
15|8|http://www.jucs.org/jucs_15_8|Managing Editor's Column|
15|8||Tools and Stochastic Metrics for Debugging Temporal Behaviour of Real-Time Systems|"  Joaquín Entrialgo (University of Oviedo, Spain)   Javier García (University of Oviedo, Spain)   José Luis Díaz (University of Oviedo, Spain)   Daniel F. García (University of Oviedo, Spain)  Abstract: In real-time systems, temporal behaviour is as   important as functional behaviour, so several techniques have been   especially developed for these systems. Stochastic analysis   techniques model the execution time of tasks as random variables and   constitute a very powerful tool to study the temporal behaviour of   real-time systems. However, as they can not avoid all the timing   bugs in the implementation, they must be combined with measurement   techniques in order to gain more confidence in the implemented   system. This paper presents a monitoring tool which can measure   real-time systems developed using POSIX. The corresponding analysis   and a visualization tool that makes it possible to find errors   easily is also introduced. In order to find bugs in the timing   behaviour of the system when an stochastic analysis technique is   used, two metrics, called ""pessimism"" and ""optimism"", are   proposed. They are based on two random variables, the optimistic and   the pessimistic execution time, which are also introduced in this   paper. These metrics are used in the debugging tools to compare the   model and the measured system in order to find errors. The metrics   are examined in four case studies.               Keywords: debugging aids, monitors, real-time systems               Categories: C.3, D.2.4, D.2.5  "
15|8||Modelling Weblog Success: Case of Korea|  Junseok Hwang (Seoul National University, Korea)   Youngjin Lee (Seoul National University, Korea)   Seunghyun Kim (Seoul National University, Korea)  Abstract: Weblogs have received attention as new, personalized media. Yet, only few of them attract public attention and become successful. This study explores weblog success factors in three categories: content creation, content features and content diffusion. During the process of content creation in weblogs, we argue that weblog service providers (WSPs) support bloggers resource collection. We also presume that the volume or the quality of posts in weblogs could be matter to gain visitors attention when weblog content (i.e., post) is generated. During the process of content diffusion, we assume that use of blogging technologies (BTs) such as trackback or RSS would enhance content-sharing activities between weblogs. Based on the data from a sample of Korean individual weblogs, our analysis indicates that weblog success (in terms of the number of unique visitors per week) is related to the WSPs support level for content creation as well as content features.               Keywords: BTs Contribution for Content Diffusion, WSPs Support for Content Creation, Weblog success, content features               Categories: H.3.5, H.4.3, H.5.1, M.6  
15|8||Designing Secure Data Warehouses by Using MDA and QVT|  Emilio Soler (University of Matanzas, Cuba)   Juan Trujillo (University of Alicante, Spain)   Carlos Blanco (University of Castilla-La Mancha, Spain)   Eduardo Fernández-Medina (University of Castilla-La Mancha, Spain)  Abstract: The Data Warehouse (DW) design is based on   multidimensional (MD) modeling which structures information into   facts and dimensions. Due to the confidentiality of the data that it   stores, it is crucial to specify security and audit measures from   the early stages of design and to enforce them throughout the   lifecycle. Moreover, the standard framework for software   development, Model Driven Architecture (MDA), allows us to define   transformations between models by proposing   Query/View/Transformations (QVT). This proposal permits the   definition of formal, elegant and unequivocal transformations   between Platform Independent Models (PIM) and Platform Specific   Models (PSM). This paper introduces a new framework for the design   of secure DWs based on MDA and QVT, which covers all the design   phases (conceptual, logical and physical) and specifies security   measures in all of them. We first define two metamodels with which   to represent security and audit measures at the conceptual and   logical levels. We then go on to define a transformation between   these models through which to obtain the traceability of the   security rules from the early stages of development to the final   implementation. Finally, in order to show the benefits of our   proposal, it is applied to a case study.               Keywords: MDA, QVT, data warehousing, security               Categories: D.2.10, H.0  
15|8||Computing as Engineering|  Matti Tedre (Tumaini University, Tanzania)  Abstract: Computing as a discipline is often characterized as a combination of three major traditions: theoretical, scientific, and engineering tradition. Although the three traditions are all considered equally necessary for modern computing, the engineering tradition is often considered to be useful but to lack intellectual depth. This article discusses the basic intellectual background of the engineering tradition of computing. The article depicts the engineering aims manifest in the academic field of computing, compares the engineering tradition with the other traditions of computing as a discipline, and presents some epistemological, ontological, and methodological views concerning the engineering tradition of computing. The article aims at giving the reader an overview of the engineering tradition in computing and of some open questions about the intellectual foundations and contributions of the engineering tradition in computing.               Keywords: computing, engineering, information technology, philosophy of computer science, philosophy of technology               Categories: K.7, K.7.1, K.7.m  
15|8||Certificate-based Signatures Revisited|  Wei Wu (University of Wollongong, Australia)   Yi Mu (University of Wollongong, Australia)   Willy Susilo (University of Wollongong, Australia)   Xinyi Huang (University of Wollongong, Australia)  Abstract: Certificate-based encryption was introduced in   Eurocrypt'03 to solve the certificate management problem in public   key encryption. Recently, this idea was extended to   certificate-based signatures. Several new schemes and security   models of certificate-based signatures have been proposed. In this   paper, we first take a closer look at the certificate-based   signature by comparing it with digital signatures in other popular   public key systems. We introduce a new security model of   certificate-based signature, which defines several new types of   adversaries against certificate-based signatures, along with the   security model of certificate-based signatures against them. The new   model is clearer and more elaborated compared with other existing   ones. We then investigate the relationship between certificate-based   signatures and certificateless signatures, and propose a generic   construction of certificate-based signatures. We prove that the   generic construction is secure (in the random oracle model) against   all types of adversaries defined in this paper, assuming the   underlying certificateless signatures satisfying certain security   notions. Based on our generic construction, we are able to construct   new certificate-based signature schemes, which are more efficient in   comparison with other schemes with similar security   levels.               Keywords: certificate-based signatures, certificateless signatures, concrete scheme, generic construction, security model               Categories: E.3 , K.6.5  
15|8||Discovering Semantic Aspects of  Socially Constructed Knowledge Hierarchy  to Boost the Relevance of Web Searching|  Dengya Zhu (Curtin University of Technology, Australia)   Heinz Dreher (Curtin University of Technology, Australia)  Abstract: The research intends to boost the relevance of   Web search results by classifying Websnippet into socially   constructed hierarchical search concepts, such as the most   comprehensive human edited knowledge structure, the Open Directory   Project (ODP). The semantic aspects of the search concepts   (categories) in the socially constructed hierarchical knowledge   repositories are extracted from the associated textual information   contributed by societies. The textual information is explored and   analyzed to construct a category-document set, which is subsequently   employed to represent the semantics of the socially constructed   search concepts. Simple API for XML (SAX), a component of JAXP (Java   API for XML Processing) is utilized to read in and analyze the two   RDF format ODP data files, structure.rdf and content.rdf. kNN, which   is trained by the constructed category-document set, is used to   categorized the Web search results. The categorized Web search   results are then ontologically filtered based on the interactions of   Web information seekers. Initial experimental results demonstrate   that the proposed approach can improve precision by   23.5%.               Keywords: HTML, SAX, Web search, ontology, semantic analysis, socially constructed knowledge repository, the Open Directory Project               Categories: H.3.3, H.3.4  
15|8||ActiveTM - The Factory for Domain-customised Portal Engines|  Lutz Maicher (University of Leipzig, Germany)   Benjamin Bock (University of Leipzig, Germany)  Abstract: Our goal is increasing the users' value and experience and decreasing the implementation time for web portals. To achieve this goal we adopt a subject-centric perspective on information architecture. The fundament of this approach is that portals should be driven by subject-centric models of the portals' domains. Out of these domain models, the interaction and interface design of the portals is self-evident. Amongst others, the international industry standard Topic Maps is a portal technology and an implementation of the subject-centric modelling paradigm. With ActiveTM we introduce a technology, which implements a Model-driven approach to automatically create domain-customised, subject-centric portal engines, based on Topic Maps. Extending ActiveTM, Information Shapes provide domain-specific views of the ActiveTM data, increasing the reusability of view components. ActiveTM and Information Shapes have proved as techniques for reducing the implementation cost of portals enormously and the implied subject-centricness increases the users value and experience significantly.               Keywords: ActiveTM, Information Architecture, Information Shapes, RTM,, Ruby, Ruby Topic Maps, Semantic domain models, Shapes, Topic Maps, Web 2.0, XML, XTM, internationalisation, localisation, model-driven development, portal federation, subject-centric               Categories: D.2, H.1, H.5  
15|8||Fostering Knowledge Flow and Community Engagement in the Development of Interactive Entertainment|  Steffen Lohmann (University of Duisburg-Essen, Germany)   Jörg Niesenhaus (University of Duisburg-Essen, Germany)   Philipp Heim (University of Duisburg-Essen, Germany)   Jürgen Ziegler (University of Duisburg-Essen, Germany)  Abstract: Due to an increasing professionalization, specialization, and globalization in the development of interactive entertainment new demands for comprehensive knowledge management support emerge. This article aims at sensitizing and systematizing the needs and potentials for continuous knowledge flow and community engagement in this application area. It starts with an analysis of typical development activities and involved parties that could benefit from a continuous knowledge management support. Then, a general framework architecture and implementation examples are presented that provide different levels of knowledge management support for interactive entertainment development.               Keywords: community engagement, continuous integration, interactive entertainment, knowledge management, open innovation               Categories: D.2.0, M.0, M.1, M.2, M.3, M.7, M.8  
15|8||Success and Failure Factors for KM: The Utilization of Knowledge in the Swedish Armed Forces|  Ulrica Pettersson (Swedish National Defence College, Sweden)  Abstract: Developing successful knowledge management (KM)   processes is extremely difficult. In general, a large number of all   KM projects end unsuccessfully. The aim of this paper is to   summarize and study the attempts to take advantage of Lessons   Learned in the Swedish Armed Forces (SwAF), focusing on   international missions. Relevant reports, articles and literature   have been studied. With the purpose of understanding the reasons for   failure and the failure factors in SwAFs attempts at KM, Chua and   Lams model for unsuccessful KM implementation has been applied to   four cases from the organization. The results show that SwAF are   aware of the importance of knowledge and have attempted to implement   KM on several occasions. In most cases, however, the KM projects do   not achieve widespread use and eventually end   unsuccessfully. Furthermore, many of the KM tools that have been   developed are no longer in use. The Swedish Explosive Ordnance   Disposal and Demining Centre (SWEDEC) and the Swedish Air Force are   notable exceptions.               Keywords: evaluation of knowledge management, knowledge management, lessons learned               Categories: H.3.3, H.4.3, H.5.3, J.7  
15|9|http://www.jucs.org/jucs_15_9|CSCWD Technologies, Applications and Challenges|
15|9||Organizational Simulation of Complex  Process Engineering Projects in the Chemical Industry|"  Sven Tackenberg (RWTH Aachen University, Germany)   Bernhard Kausch (RWTH Aachen University, Germany)   Sönke Duckwitz (RWTH Aachen University, Germany)   Christopher M. Schlick (RWTH Aachen University, Germany)   Selvinaz Karahancer (RWTH Aachen University, Germany)  Abstract: The complexity of process engineering projects in the chemical industry — resulting from the large number of activities to be accounted for as well as the required actors and resources — and the number of projects running simultaneously within an enterprise are rapidly increasing. In order to stay competitive, the factors relevant to the success of project planning and execution, e.g. the project budget or duration, must be accurately predicted and controlled. For this reason, a novel simulation approach for development projects is introduced and validated. A formal description of a development project and of an activity-oriented simulation model is given. This ""meta model"" is able to describe the influencing factors of a development project as well as their interrelations during the course of a project. On the basis of the meta model, an activity-oriented simulation model is developed in cooperation with enterprises from the chemical industry. The simulation model enables the automatic creation and prospective benchmarking of complex, detailed project plans. The dynamics of such a development project are represented as a stochastic Petri net, including Java functions. Organizational factors of a development project such as task scheduling, the limited availability of actors and tools or uncertainty regarding the effort required to solve a task can be systematically studied through simulation experiments. The results of these experiments assist project managers in understanding the influence of the quantity and characteristics of actors and resources on project performance. In the validation study, a chemical process design project in a large enterprise is considered and the external validity of the stochastic project model is analyzed.               Keywords: Petri Net simulation, collaborative design, formal description of development projects, project engineering               Categories: J.4, J.6, K.3  "
15|9||A Tree Similarity Measuring Method and its Application to Ontology Comparison|  Yunjiao Xue (University of Western Ontario, Canada)   Chun Wang (Concordia University, Canada)   Hamada H. Ghenniwa (University of Western Ontario, Canada)   Weiming Shen (University of Western Ontario, Canada)  Abstract: Classical tree similarity measuring approaches   focus on the structural and geometrical characteristics of the   trees. The degree of similarity between two trees is measured by the   minimal cost of editing sequences that convert one tree into the   other one from pure structural perspective. Differently, when the   trees are created to represent concept structures in a knowledge   context (known as concept trees), the tree nodes represent concepts,   not merely abstract elements occupying specific   positions. Therefore, measuring similarity of such trees requires a   more comprehensive method which takes the position, significance of   the concepts (represented by the tree nodes), and conceptual   similarity among the concepts from different trees into   consideration. This paper extends the classical tree similarity   measuring method to introduce tree transformation operations which   transform one concept tree to another one. We propose definitions   for the costs of the operations based on the position, importance of   each concept within a concept structure, and similarity between   individual concepts from different concept structures in a knowledge   context. The method for computing the transformation costs and   measuring similarity between different trees is presented. We apply   the proposed method to ontology comparison where different   ontologies for the same domain are represented as trees and their   similarity is required to be measured. We show that the proposed   method can facilitate the initiation of ontology integration and   ontology trust evaluation.               Keywords: ontology comparison, ontology integration, similarity measuring, transformation cost, transformation operation, tree               Categories: M.1  
15|9||Authorization Algorithms for Permission-Role Assignments|  Lili Sun (University of Southern Queensland, Australia)   Hua Wang (University of Southern Queensland, Australia)   Jianming Yong (University of Southern Queensland, Australia)  Abstract: Permission-role assignments (PRA) is one   important process in Role-based access control (RBAC) which has been   proven to be a flexible and useful access model for information   sharing in distributed collaborative environments.  However,   problems may arise during the procedures of PRA. Conflicting   permissions may assign to one role, and as a result, the role with   the permissions can derive unexpected access capabilities.  This paper aims to analyze the problems during the procedures of permission-role assignments in distributed collaborative environments and to develop authorization allocation algorithms to address the problems within permission-role assignments.  The algorithms are extended to the case of PRA with the mobility of permission-role relationship.  Finally, comparisons with other related work are discussed to demonstrate the effective work of the paper.               Keywords: access control, authorization, conflicts               Categories: H.1.1, H.2.8, I.1.2  
15|9||A Resilient P2P Anonymous Routing Approach Employing Collaboration Scheme|  Junzhou Luo (Southeast University, China)   Xiaogang Wang (Southeast University, China)   Ming Yang (Southeast University, China)  Abstract: Node churn is a hindrance to construction of   P2P-based anonymous networks, which makes anonymous paths fragile   and results in message losses and communication failures. A   collaboration scheme combining Friendly Neighbor-based Incentive   (FNI) and Re-encryption mechanism is proposed to deal with the high   node churn characteristic of P2P networks. The FNI mechanism   encourages peers to forward other peers messages, and establishes   more connections to improve the performance of P2P networks, where   only stable and well-behaved nodes can be chosen as relay nodes to   improve the durability of anonymous paths. The Re-encryption   mechanism is designed to replace those failed relay nodes and   achieve routing resilience upon different node availabilities in   real-world systems. The results from security analysis and   simulation show that the P2P anonymous routing approach employing   collaboration scheme significantly improves routing resilience and   maintains low latency and modest communication overhead.               Keywords: FNI mechanism, anonymous routing, peer-to-peer, re-encryption mechanism               Categories: C.2.0, C.2.4, C.2.6  
15|9||Estimating Software Projects Based On Negotiation|  Sergio F. Ochoa (Universidad de Chile, Chile)   José A. Pino (Universidad de Chile, Chile)   Fabián Poblete (Universidad de Chile, Chile)  Abstract: The Software Engineering community has been trying to get fast and accurate software estimations for many years. Most of the proposed methods require historical information and/or experts judgment. Because of that, the current methods are not suitable for novice developers or persons who do not know the company development capability. In order to help overcome such need, this paper proposes a software estimation method named CEBON (Collaborative Estimation Based On Negotiation). The method is applicable to small/medium-size projects (1-6 months). It focuses on supporting estimation of Web information systems in scenarios where historical data is not available. The CEBON method has been used to estimate eight real projects. The obtained results were compared with the real projects execution, which were carried out by novice developers in Chile. The comparison indicates the method is able to deliver quite accurate results. In addition, a survey applied to the involved developers shows they feel comfortable using the estimation method. The article also describes a collaborative software application supporting the CEBON process and a preliminary evaluation of both the estimation method and the supporting tool.               Keywords: Novice Software Developers, collaborative work, groupware system, software estimation               Categories: D.2.0, D.2.9, H.4.m, M.0, M.8  
15|9||MC-Supporter: Flexible Mobile Computing Supporting Learning though Social Interactions|  Nelson Baloian (Universidad de Chile, Chile)   Gustavo Zurita (Universidad de Chile, Chile)  Abstract: Nowadays, we are experiencing a rapid   development in mobile computing because of the sinking prices of the   mobile devices and the availability of wireless networks that can   connect them. The ability of many of these devices to set up ad-hoc   networks by proximity allows face-to-face interaction combined with   mobility. However, mobile devices are much weaker in computing power   compared with desktop or laptop computing. Therefore, a key aspect   to ensure success of an application supporting mobile learning is   whether mobility is really needed for the activity it supports and   if mobile devices do really represent an added value compared with   the same application implemented on non-mobile devices. This work   presents MCI-Supporter, an application supporting collaborative   learning practises in the classroom. MCI-Supported was conceived by   first analyzing the best known collaborative learning practices   trying to find out which are the real needs for mobility and   face-to-face interaction and then designing the application   supporting learning activities where mobile computing does really   represents an added value compared to the desktop computing   scenario.               Keywords: Computer Supported Collaborative Llearning (CSCL), mobile learning, social interactions               Categories: L.6.2, L.7.0  
15|9||An Application of the Dynamic Pattern Analysis Framework to the Analysis of Spatial-Temporal Crime Relationships|  Kelvin Leong (The Hong Kong Polytechnic University, Hong Kong)   Junco Li (The Hong Kong Polytechnic University, Hong Kong)   Stephen Chan (The Hong Kong Polytechnic University, Hong Kong)   Vincent Ng (The Hong Kong Polytechnic University, Hong Kong)  Abstract: Dynamic pattern analysis refers to analyzing the   relationship of spatial patterns at different time   points. Traditional spatial pattern analysis such as data clustering   can find the spatial patterns extant at a geographical location at a   particular time point but failing to identify spatial dynamics, or   changes that occur over time in a particular place. In this paper,   we present a dynamic pattern analysis framework, the DPA   framework. This framework allows user to identify three   types of dynamic patterns in spatial-temporal data: 1) similar   spatial patterns at different time points, 2) interactive   relationship between two geographical locations as a result of a   specific reason and 3) frequent association rules related to   particular types of events, geographical locations, and time   points. To evaluate the proposed framework, we used it to analyze a   set of reported crime data for a district of Hong Kong and compared   the identified patterns with some expectations of field experts and   prior empirical studies for this kind of data and patterns. In line   with expert predictions, we found strong correlations between school   holidays and crime clusters. On the contrary, in our data set, we   could not find obvious seasonal dependency.  These findings are   corroborated by related empirical crime studies.               Keywords: CSCW, crime analysis, spatial-temporal data mining               Categories: I.2.1, L.6.2  
15|9||A QoS Perspective on Exception Diagnosis in Service-Oriented Computing|  Nazaraf Shah (University of Essex, United Kingdom)   Rahat Iqbal (Coventry University, United Kingdom)   Kashif Iqbal (Universiti Sains Malaysia (USM), Malaysia)   Anne James (Coventry University, United Kingdom)  Abstract: Unlike object-oriented applications it is   difficult to address exceptions in multi-agent systems due to their   highly dynamic and autonomous nature. Our previous work has examined   exception diagnosis in multi-agent systems based on a heuristic   classification method. In this paper, we extend our work by applying   an exception diagnosis method to web services (WS) by proposing a   unified framework for dealing with exceptions occurring in   multi-agent systems as well as in web services. Importantly, we   relate the impact of exceptions to Quality of Service (QoS), as   exceptions normally degrade the quality of service offered to a   service consumer.  Our framework consists of a QoS monitoring agent   that monitors all interactions taking place between service   consumers and service providers.  The monitoring agent encodes the   knowledge of exceptions, their causes and applies the heuristic   classification method for reasoning in order to diagnose underlying   causes of monitored exceptions.  In this paper, we categorize   exceptions into three levels in multi-agent systems: Environment   Level Exception; Knowledge Level Exception and Social Level   Exception. This paper also discusses different classes of exceptions   in web services based on the web service stack.               Keywords: QoS, exception diagnoses, heuristic classfication, multi-agent systems               Categories: D.2.5, M.4  
15|9||Applying Reputation Mechanisms in Communities of Practice: A Case Study|  Claudia C. P. Cruz (Federal University of Rio de Janeiro, Brazil)   Claudia L. R. Motta (Federal University of Rio de Janeiro, Brazil)   Flávia Maria Santoro (State Federal University of Rio de Janeiro, Brazil)   Marcos Elia (Federal University of Rio de Janeiro, Brazil)  Abstract: Communities of Practice (CoP) are groups of   people sharing practices, interests, and work objectives. In the   virtual world, however, it is difficult to trust contributions from   people we do not know, because of the variety of information sources   and behaviors. In this context, a Reputation Model for CoP (ReCoP)   was developed. This paper presents a case study that evaluates one   ReCoP mechanism: the degree of agreement among members in evaluating   artifacts shared within the community. Data was extracted from a   real scenario, and the results provide useful feedback for further   studies and improvements in implementing the model.               Keywords: community of practice, recommender systems, reputation systems               Categories: L.6.0, L.6.1, L.6.2  
15|9||Application of Intelligent Strategies for Cooperative Manufacturing Planning|  Weidong Li (Coventry University, United Kingdom)   Liang Gao (Huazhong University of Science and Technology, China)   Xinyu Li (Huazhong University of Science and Technology, China)  Abstract: Manufacturing planning is crucial for the   quality and efficiency of product development. Process planning and   scheduling are the most important and challenging tasks in   manufacturing planning. These two processes are usually arranged in   a sequential way. Recently, a significant trend is to make the   processes to work more concurrently and cooperatively to achieve a   globally optimal result. In this paper, several intelligent   strategies have been developed to build up Cooperative Process   Planning and Scheduling (CPPS). Three Game Theory-based strategies,   i.e., Pareto strategy, Nash strategy and Stackelberg strategy, have   been introduced to analyze the cooperative integration of the two   processes in a systematic way. To address the multiple constraints   in CPPS, a fuzzy logic-based Analytical Hierarchical Process (AHP)   technique has been applied. Modern heuristic algorithms, including   Particle Swarm Optimization (PSO), Simulated Annealing (SA) and   Genetic Algorithms (GAs), have been developed and applied to CPPS to   identify optimal or near-optimal solutions from the vast search   space efficiently. Experiments have been conducted and results show   the objectives of the research have been achieved.               Keywords: Game Theory, Genetic Algorithms, Particle Swarm Optimization, Simulated Annealing, analytical hierarchical process, collaborative system               Categories: I.1.2, I.1.4, I.2.1, I.2.4, J.6  
15|9||Pattern-Oriented Workflow Generation and  Optimization|  Yong Xiang (Tsinghua University, P.R.China)   Shaohua Zhang (Tsinghua University, P.R.China)   Yuzhu Shen (Tsinghua University, P.R.China)   Meilin Shi (Tsinghua University, P.R.China)  Abstract: Automatic workflow generation is becoming an   active research area for dealing with the dynamics of grid   infrastructure, because it has a pervasive impact on system   usability, flexibility and robustness. Artificial intelligence   technology and explicit knowledge have been exploited in some   research for workflow construction or composition. With the   increasing use of knowledge, its quality has growing impact on   system performance. In this report, we present the process pattern   as a vehicle for knowledge representation to capture process   expertise at the business level. A pattern-based planning approach   is proposed for automated workflow generation. Our pattern-oriented   approach decreases user-visible complexity and makes systems more   scalable and flexible by utilizing explicit knowledge support. Then   we propose a hybrid method of pattern knowledge optimization for   pattern-based workflow generation planning; experts define the   primary model, and subsequent classifier training adjusts and   improves the pattern knowledge settings. Experiments with a   prototype application demonstrated that this approach can   substantially reduce modelling difficulties and effectively improve   pattern knowledge quality.               Keywords: business knowledge optimization, classifier training, knowledge management, workflow generation, workflow pattern               Categories: C.2.4, H.1.0, H.4.3, I.2.6  
15|9||Supporting Awareness in Groupware through an Aspect-Oriented Middleware Service|  Rita Suzana P. Maciel (Universidade Estadual da Bahia, Brazil)   José Maria N. David (Faculdade Ruy Barbosa, Brazil)   Michel Ridwan Oei (Faculdade Ruy Barbosa, Brazil)   Adriano Augusto de Oliveira Bastos (Faculdade Ruy Barbosa, Brazil)   Leandro de Oliveira Menezes (Faculdade Ruy Barbosa, Brazil)  Abstract: Solutions have been proposed to support   awareness in groupware. Frequently, this requirement is fulfilled by   similar functionalities that are implemented in different modules   within these collaborative applications. These solutions usually   represent crosscut concerns related to awareness by the use of   object-oriented programming. As a result, tightly coupled components   are generated as well as code redundancy and scattering. Flexibility   and agility, related to awareness maintenance and evolution can be   considered a challenge. This paper presents an awareness service   named Aw2SOA, which was developed to support awareness   functionalities in a Web-based Groupware Service-Oriented   Architecture (WGWSOA) environment. The WGWSOA infrastructure is   based on middleware services for collaborative applications. Aw2SOA   is a middleware specific service which was implemented according to   service-oriented architecture (SOA) principles and aspect-oriented   programming (AOP) concepts. Case studies were carried out focusing   on service integration activities as well as using groupware   application development in order to evaluate this   solution.               Keywords: SOA, aspect-oriented programming, awareness, groupware, middleware services               Categories: H.3.4, H.5.3  
15|9||Integrating Semantic Web and Object-Oriented Programming for Cooperative Design|  Po-Huan Chiu (National Chiao Tung University, Taiwan)   Chi-Chun Lo (National Chiao Tung University, Taiwan)   Kuo-Ming Chao (Coventry University, United Kingdom)  Abstract: Object-oriented programming (OOP) is a   mainstream paradigm for engineering design software tool   development. An emerging requirement is the introduction of   semantics to achieve heterogeneous information sharing, but many   challenges exist. Examples include using object methods to   manipulate an RDF data, automatically converting data into RDF   format, and supporting various programming languages. In addition,   limitations to description capabilities for relationships among   object-oriented classes exceed those of RDF, thus hindering direct   mapping between object-oriented and Semantic Web classes. Our   proposed semantic object framework (SOF) combines object-oriented   design and Semantic Web features. SOF utilizes embedded comments in   source code to describe semantic relationships between classes and   attributes. We use a mobile phone design case study to illustrate   how the proposed system operates.               Keywords: Semantic Web, cooperative design, object-oriented programming               Categories: D.1.5, D.2.13, D.2.2  
15|9||Using Embodied Conversational Assistants to Interface Users with Multi-Agent Based CSCW Applications: The WebAnima Agent|  Emerson Cabrera Paraiso (Pontifical Catholic University of Paraná, Brazil)   Cesar A. Tacla (Universidade Tecnológica Federal do Paraná, Brazil)  Abstract: We have been using personal assistants (PA)   coupled with multi-agent systems (MASs) in several CSCW   applications. Since we are considering professional environments,   where users have many tasks to perform, and where users are using   several different applications at the same time (browsers, CADs,   etc.), the PA interface should motivate users to keep using their   assistant. To achieve this goal, we propose WebAnima. WebAnima is a   web-based embodied interface agent specially designed to assist team   members of a CSCW application during their daily work based on   computers. In WebAnima, the intelligent behaviour is guaranteed   thanks to a conversational interface and ontologies that support   semantic interpretation. We believe that embodied conversational   assistants will improve the quality of assistance and increase   collaboration between project members. With WebAnima, we expect to   acquire information that can be further processed and reused in   current and subsequent projects aiming at increasing   productivity. In this paper, we present the embodied conversational   assistant and its insertion into an MAS designed for research and   development projects. We describe the design of the agent,   highlighting the role of ontologies for semantic interpretation and   the dynamic behaviour of the embodied animated agent.               Keywords: CSCW, embodied conversational assistants, ontologies, personal assistants               Categories: H.1.2, H.5.2, I.2.4, I.2.7  
15|9||Transmission Latency based Network Friendly Tree for Peer-to-Peer Streaming|  Ting Peng (Xian Jiaotong University, P.R.China)   Qinghua Zheng (Xian Jiaotong University, P.R.China)   Yinli Jin (Chang'an University, P.R.China)  Abstract: In Peer-to-Peer(P2P) streaming system, the multicasting tree construction method influences considerably on network load. Under current available strategies, network resources are not used economically, or network resource friendship and the flexibility can't be approached thoroughly. With the increasing application of Internet, network infrastructure itself becomes a precious resource, which should be performed effectively. In our implementation, network transmission delay between the peers is detected, used as practical performance metrics of the P2P streaming system. According to the metrics, network friendly tree is provided as overlay multicasting tree construction strategy for P2P streaming system. In this strategy, additional transmission delays are minimized as new peers enter. The simulation experiment presents that the proposed strategy network friendly tree works better than other contrasts. And the transmission performance improves significantly at minor additional cost.               Keywords: Network Friendly Tree, Performance Metrics, Transmission Latency, peer-to-peer, streaming               Categories: C.2.3, C.4, H.4.3, H.5.1  
volume|issue|url|title|abstract
16|1|http://www.jucs.org/jucs_16_1|Information Fusion and Logic-based Reasoning  Approaches for Decision Making under Uncertainty|
16|1||Some Views on Information Fusion and Logic Based Approaches in Decision Making under Uncertainty|  Yang Xu (Southwest Jiaotong University, China)   Jun Liu (University of Ulster, Northern Ireland, UK)   Luis Martínez (University of Jaén, Spain)   Da Ruan (Ghent University, Belgium)  Abstract: Decision making under uncertainty is a key issue   in information fusion and logic based reasoning approaches. The aim   of this paper is to show noteworthy theoretical and applicational   issues in the area of decision making under uncertainty that have   been already done and raise new open research related to these   topics pointing out promising and challenging research gaps that   should be addressed in the coming future in order to improve the   resolution of decision making problems under uncertainty.               Keywords: computing with words, decision making, information fusion, logics, uncertain information processing, uncertainty               Categories: F.4.1, I.1, I.2, M.4  
16|1||Integration of Similar Evolving Data Sources for Supporting Decision Making Tasks|  Alberto Salguero (University of Granada, Spain)   Francisco Araque (University of Granada, Spain)  Abstract: Information Systems usually rely on external and   independent data sources. When integrating the data to build the   integrated repository it is possible to make use of the temporal   characteristics of the data sources to improve the whole integration   process and the quality of the integrated data, which support the   organizations decision-making tasks. In this work the usage of an   Ordered Weighted Averaging-based operator is presented as the best   option when the data sources refer to similar facts but the data on   each data source is expressed with different temporal   characteristics. This is a common issue in Information Systems   development.               Keywords: OWA, data integration, information system, temporal               Categories: H.2.5, H.2.8, H.4.0  
16|1||Track-To-Track Measurement Fusion Architectures and Correlation Analysis|  Mourad Oussalah (University of Birmingham, United Kingdom)   Zahir Messaoudi (University of Birmingham, United Kingdom)   Abdelaziz Ouldali (Military Polytechnic School, Algeria)  Abstract: The purpose of this paper is to address some   theoretical issues related to the track-to-track fusion problem when   the measurements tracking the same target are inherently correlated   by the common process noise of the underlying target. This problem   has been intensively investigated using standard Kalman filter with   some appealing theoretical results, however such results are no   longer valid in case of suboptimality due to either the presence of   strong nonlinearity or to the discrete uncertainty pervading the   origin of the measurement. This paper reviews several architectures   of parallelized blocks of Kalman filters, including the augmented   stacked measurement, sequential and data compression   architectures. Next, convex combination architecture will be   investigated and some theoretical results concerning its extension   as well as in case of presence of correlation are investigated. Two   special cases of correlation are highlighted. This concerns the case   of presence of only two correlated tracks among all tracks and the   case of weak correlation. In both cases some original theoretical   results are put forward. Finally, links with related fusion   architectures is investigated.               Keywords: correlation, estimation, tracking               Categories: I.2.9, I.6.1  
16|1||A Selection Process Based on Additive Consistency to Deal with Incomplete Fuzzy Linguistic Information|  Francisco Javier Cabrerizo (UNED, Spain)   Rubén Heradio (UNED, Spain)   Ignacio Javier Pérez (University of Granada, Spain)   Enrique Herrera-Viedma (University of Granada, Spain)  Abstract: In group decision making situations, there may   be cases in which experts do not have an in-depth knowledge of the   problem to be solved and, as a result, they may present incomplete   information. In this paper, we present a new selection process to   deal with incomplete fuzzy linguistic information. As part of it, we   use an iterative procedure to estimate the missing information. This   procedure is guided by the additive consistency property and only   uses the preference values provided by the experts. In addition, the   additive consistency property is also used to measure the level of   consistency of the information provided by the experts. The main   novelties of this selection process are both the possibility to   manage decision situations under incomplete fuzzy linguistic   information and the importance of the experts' preferences in the   aggregation processes is modeled by means of the experts'   consistency.               Keywords: aggregation, consistency, fuzzy linguistic information, group decision making, incomplete information               Categories: H.0, I.2, I.6, J.6  
16|1||Selection among Renewable Energy Alternatives Using Fuzzy Axiomatic Design: The Case of Turkey|  Cengiz Kahraman (Istanbul Technical University, Turkey)   Selcuk Cebi (Istanbul Technical University, Turkey)   İhsan Kaya (Istanbul Technical University, Turkey)  Abstract: Renewable energy is a source of energy derived   from natural resources such as sunlight, wind, water, tides, hot dry   rocks, magma, hot water springs, fire wood, animal manure, and crop   residues and waste. These renewable energy technologies are called   with its source such as solar power, wind power, hydropower,   geothermal and biomass. Energy resources are so important in   perspective of economics and politics for all countries. Hence, the   selection of the best alternative for any country takes an important   role for energy investments. In this paper, axiomatic design (AD)   methodology is suggested for the selection among renewable energy   alternatives under fuzzy environment. AD methodology works under   fuzziness which evaluates the alternatives under objective or   subjective criteria with respect to the functional requirements   obtained from experts. In the application of the proposed   methodologies the most appropriate renewable energy alternative is   determined for Turkey under fuzziness.               Keywords: Renewable energy, axiomatic design, decision making, fuzzy               Categories: H.0, I.2, I.6, J.6  
16|1||Multi-criteria Group Decision Support with Linguistic Variables in Long-term Scenarios for Belgian Energy Policy|  Da Ruan (Belgian Nuclear Research Centre, Belgium)   Jie Lu (University of Technology, Sydney (UTS), Australia)   Erik Laes (Flemish Institute for Technological Research (VITO), Belgium)   Guangquan Zhang (University of Technology, Sydney (UTS), Australia)   Jun Ma (University of Technology, Sydney (UTS), Australia)   Gaston Meskens (Belgian Nuclear Research Centre, Belgium)  Abstract: Real world decisions often made in the presence   of multiple, conflicting, and incommensurate criteria. Decision   making requires multiple perspectives of different individuals as   more decisions are made now in groups than ever before. This is   particularly true when the decision environment becomes more complex   such as sustainability policies study in environmental and energy   sectors. Group decision making processes judgments or solutions for   decision problems based on the input and feedback of multiple   individuals. Multi-criteria decision and evaluation problems at   tactical and strategic levels in practice involve fuzziness in terms   of linguistic variables vis-à-vis criteria, weights, and decision   maker judgments. Relevant alternatives or scenarios are evaluated   according to a number of desired criteria.  A fuzzy multi-criteria   group decision software tool is developed to analyze long-term   scenarios for Belgian energy policy in this paper.               Keywords: Fuzzy numbers, energy policy, evaluation model, group decision support, linguistic variables, multi-criteria decision making (MCDM)               Categories: F.4.3, H.5.3, J.5, M.4  
16|1||A Demand Forecasting Methodology for Fuzzy Environments|  Özgür Kabak (Istanbul Technical University, Turkey)   Füsun Ülengin (Doğuş University, Turkey)  Abstract: Several supply chain and production planning   models in the literature assume the demands are fuzzy but most of   them do not offer a specific technique to derive the fuzzy   demands. In this study, we propose a methodology to obtain a   fuzzy-demand forecast that is represented by a possibilistic   distribution. The fuzzy-demand forecast is found by aggregating   forecasts based on different sources; namely statistical forecasting   methods and experts judgments. In the methodology, initially, the   forecast derived from the statistical forecasting techniques and   experts judgments are represented by triangular possibilistic   distributions. Subsequently, those results are combined by using   weights assigned to each of them. A new objective weighting approach   is used to find the weights. The proposed methodology is illustrated   by an example and a sensitivity analysis is provided.               Keywords: Fuzzy-demand forecast, aggregation, objective weights               Categories: F.2.1, G.3, I.2.1, I.2.3  
16|1||An Approach to Generation of Decision Rules|  Zhang Mingyi (Southwest University, China)   Li Danning (Guizhou Academy of Sciences, China)   Zhang Ying (Guizhou Academy of Sciences, China)  Abstract: Classical classification and clustering based on   equivalence relations are very important tools in   decision-making. An equivalence relation is usually determined by   properties of objects in a given domain. When making decision,   anything that can be spoken about in the subject position of a   natural sentence is an object, properties of which are fundamental   elements of the knowledge of the given domain. This gives the   possibility of representing the concept related to a given   domain. In general, the information about a set of the objects is   uncertain or incomplete. Various approaches representing uncertainty   of a concept were proposed. In particular, Zadeh?s fuzzy set theory   and Pawlak?s rough set theory have been most influential on this   research field. Zadeh characterizes uncertainty of a concept by   introducing a membership function and a similarity (fuzzy   equivalence) relation of a set of objects. Pawlak then characterizes   uncertainty of a concept by union of some equivalence classes of an   equivalence relation. As one of particular important and widely used   binary relations, equivalence relation plays a fundamental role in   classification, clustering, pattern recognition, polling, automata,   learning, control inference and natural language understanding,   etc.  An equivalence relation is a binary relation with reflexivity,   symmetry and transitivity. However, in many real situations, it is   not sufficient to consider equivalence relations only. In fact, a   lot of relations determined by the attributes of objects do not   satisfy transitivity. In particular, information obtained from a   domain of objects is not transitive, when we make decision based on   properties of objects. Moreover, the information about symmetry of a   relation is mostly uncertain. So, it is needed to approximately make   decision and reasoning by indistinct concepts. This provokes us to   explore a new class of relations, so-called class of fuzzy   semi-equivalence relations. In this paper we introduce the notion of   fuzzy semi-equivalence relations and study its properties. In   particular, a constructive method of fuzzy semi-equivalence classes   is presented.  Applying it we present approaches to the   fuzzyfication of indistinct concepts approximated by fuzzy relative   and semi-equivalence classes, respectively. And an application of   the fuzzy semi-equivalence relation theory to generate decision   rules is outlined.               Keywords: approximate definability of indistinct concepts, fuzzy semi-equivalence relation, fuzzy theory, rough set               Categories: H.3.1, H.3.2, H.3.3, H.3.7, H.5.1  
16|1||Decision Making with Uncertainty Information Based on Lattice-Valued Fuzzy Concept Lattice|  Li Yang (Southwest Jiaotong University, P.R. China)   Yang Xu (Southwest Jiaotong University, P.R. China)  Abstract: For the processing of decision making with   uncertainty information, this paper establishes a decision model   based on lattice-valued logic and researches the algorithm for   extracting the maximum decision rules. Firstly, we further research   the lattice-valued fuzzy concept lattice by combining the lattice   implication algebra and classical concept lattice; secondly, we   define the lattice-valued decision context as the equivalent form of   decision information system and establish the single-target decision   model and talk about some properties of the decision rules; finally,   we give the calculating methods of decision rules with different   decision values and the algorithm for extracting the maximum   decision rules.               Keywords: concept lattice, decision making, decision rule, lattice-valued logic, uncertainty               Categories: I.2.3  
16|1||Deontic Logic-based Framework for Ontology Aligment in Agent Communities|  Grzegorz Kolaczek (Wroclaw University of Technology, Poland)   Krzysztof Juszczyszyn (Wroclaw University of Technology, Poland)  Abstract: In this paper we consider a multiagent system   with multiple ontologies. The agents maintain the ontologies   individually which leads to frequent changes and possible knowledge   inconsistencies. We propose a general framework for decision making   about ontology alignment and negotiation which takes into account   the properties of the actual communication network and utilizes the   Deontic Logic formalism for reasoning.               Keywords: deontic logic, multiagent systems, ontology aligment, semantic web, social web               Categories: H.1.0, H.1.2, H.1.3  
16|1||LCP-Nets: A Linguistic Approach for Non-functional Preferences in a Semantic SOA Environment|  Pierre Châtel (Thales Communications, France)   Isis Truck (LIASD - EA 4383, Université Paris, France)   Jacques Malenfant (Université Pierre et Marie Curie, France)  Abstract: This paper addresses the problem of expressing   preferences among nonfunctional properties of services in a Web   service architecture. In such a context, semantic and non-functional   annotations are required on service declarations and business   process calls to services in order to select the best available   service for each invocation. To cope with these multi-criteria   decision problems, conditional and unconditional preferences are   managed using a new variant of conditional preference networks   (CPnets), taking into account uncertainty related to the preferences   to achieve a better satisfaction rate. This variant, called   LCP-nets, uses fuzzy linguistic information inside the whole   process, from preference elicitation to outcome query computation, a   qualitative approach that is more suitable to business process   programmers. Indeed, in LCP-nets, preference variables and utilities   take linguistic values while conditional preference tables are   considered as fuzzy rules which interdependencies may be   complex. The expressiveness of the graphical model underlying   CP-nets provides for solutions to gather all the preferences under   uncertainty and to tackle interdependency problems. LCP-nets are   applied to the problem of selecting the best service among a set of   offers, given their dynamic non-functional properties. The   implementation of LCP-nets is presented step-by-step through a real   world example.               Keywords: CP-nets, Web service filtering, fuzzy linguistic approach, preference modelling               Categories: H.3, J.0  
16|10|http://www.jucs.org/jucs_16_10|Multimedia Services and Applications|
16|10||Pose Estimation of Rotating   Sensors in the Context of Accurate 3D Scene Modeling|  Karsten Scheibe (German Aerospace Center (DLR), Germany)   Fay Huang (National Ilan University, Taiwan)   Reinhard Klette (The University of Auckland, New Zealand)  Abstract: Sensor-line cameras have been designed for space   missions in the 1980s, and are used for various tasks, including   panoramic imaging. Laser range-finders are able to generate dense   depth maps (of isolated surface points). Panoramic sensor-line   cameras and laser range-finders may both be implemented as rotating   sensors, and we used them together this way to reconstruct   accurately 3D environments (such as, for example, large buildings).   This article reviews related developments, followed by a detailed description of designed calibration and pose estimation techniques which have been used for both rotating sensors. Related experiments evaluate the accuracy of calibrated sensor parameters and of estimated poses.               Keywords: camera calibration, panoramic imaging, pose estimation, sensor-line camera               Categories: I.3.5, I.4.8  
16|10||A Service-Oriented Platform for Ubiquitous Personalized Multimedia Provisioning|  Zhiwen Yu (Northwestern Polytechnical University, P. R. China)   Changde Li (Northwestern Polytechnical University, P. R. China)   Xingshe Zhou (Northwestern Polytechnical University, P. R. China)   Haipeng Wang (Northwestern Polytechnical University, P. R. China)  Abstract: As multimedia contents are becoming widely used   in ubiquitous computing environments among many application fields,   e.g., education, entertainment, and live surveillance, the demand of   personalized access to these contents has increased   dramatically. The provisioning of ubiquitous personalized multimedia   services (UPMSs) is a challenging task, which involves a lot of   heterogeneous entities ranging from objects, devices to software. In   this work, we propose a three-layer software platform, called UPmP   to support efficient development and deployment of UPMSs. It   fulfills the core functionalities for ubiquitous personalized   multimedia provisioning including service management, multimedia   recommendation, adaptation, and delivery. We adopt service-oriented   approach in building the platform. The enabling technologies such as   component representation, service lifecycle management, platform   configuration, and service composition are described in detail. The   experimental results show that the UPmP is flexible to be configured   under different settings.               Keywords: personalization, platform, service management, service-oriented, ubiquitous multimedia               Categories: H.3.1  
16|10||Near Eyes-Free Chauffeur Computer Interaction with Chording and Visual Text Mnemonics|  Frode Eika Sandnes (Oslo University College, Norway)   Yo-Ping Huang (National Taipei University of Technology, Taiwan)   Yueh-Min Huang (National Cheng Kung University, Taiwan)  Abstract: Modern cars are equipped with advanced   technology requiring cognitively complex operation that is reliant   on the users visual attention. It is therefore hazardous for   drivers to operate such devices while driving. In this paper a user   interface interaction style for in-car user interfaces are   proposed. Users interact with the in-car computer using three   chording keys and chording pattern sequences are derived based on   visual mnemonics. Cases are illustrated for an in-car multimedia   system, a mobile phone and a GPS-navigation system. Experimental   results demonstrate that the technique is easy to learn, efficient   to use and require low visual attention.               Keywords: chording, human computer interaction, in-car user interface, limited visual feedback, mobile text entry, spatial mnemonics, ubiquity               Categories: H.5.2  
16|10||Gabor Filter Aided 3D Ultra-Sonography Diagnosis System with WLAN Transmission Consideration|  Wei-Ming Chen (National Ilan University, Taiwan, ROC)   Chi-Hsiang Lo (National Ilan University, Taiwan, ROC)   Han-Chieh Chao (National Ilan University, Taiwan, ROC)   Chun-Cheng Chang (National Dong Hwa University, Taiwan, ROC)  Abstract: The Gabor filter aided diagnosis system for 3-dimensional ultra-sonography (3DUS) under the WLAN environment is introduced. Due to the important relationship between breast tumour surface features and internal architecture, we applied our system using 3D inter-pixel correlations instead of 2D features. Gabor filters provide a multi-resolution representation of texture, which increases ultrasound technology capability in the differential diagnosis of solid breast tumours. Our experiments show that the performance of the proposed diagnostic method is effective. Moreover, physicians manipulate our diagnostic system using hand-held devices in the hospital. Because WLAN is unstable, our system ensures good transmission quality. We also focus on transmission control strategies that adapt to the time varying wireless network conditions. We analyze strategies that use competitive analysis techniques. The experiments show that the algorithms performance is effective.               Keywords: 3D ultrasound, 3DUS, Gabor filter, WLAN transmission, auto-correlation, breast tumour, neural network, speckle noise               Categories: I.4.0  
16|10||Cross Layer Optimization for Data Gathering in Wireless Multimedia Sensor Networks within Expected Network Lifetime|  Lei Shu (National University of Ireland, Ireland)   Manfred Hauswirth (National University of Ireland, Ireland)   Yan Zhang (Simula Research Laboratory, Norway)   Jianhua Ma (Hosei University, Japan)   Geyong Min (University of Bradford, United Kingdom)   Yu Wang (University of North Carolina at Charlotte, USA)  Abstract: The use of multimedia sensor nodes can   significantly enhance the capability of wireless sensor networks   (WSNs) for event description. In a number of scenarios, e.g., an   erupting volcano, the WSNs are not deployed to work for an extremely   long time. Instead, the WSNs aim to deliver continuous and reliable   multimedia data as much as possible within an expected lifetime. In   this paper, we focus on the efficient gathering of multimedia data   in WSNs within an expected lifetime. An adaptive scheme to   dynamically adjust the transmission Radius and data generation Rate   Adjustment (RRA) is proposed based on a cross layer design by   considering the interaction among physical, network and transport   layers. We first minimize the end-to-end transmission delay in WSNs   while using the minimum data generation rate. In this phase, an   optimal transmission radius can be derived. Then, using this   transmission radius, we adaptively adjust the data generation rate   to increase the amount of gathered data. Simulation results show   that the proposed RRA strategy can effectively enhance the data   gathering performance in wireless multimedia sensor networks (WMSNs)   by dynamically adjusting the transmission radius of sensor nodes and   the data generation rate of source nodes.               Keywords: cross layer optimization, expected network lifetime, stream data gathering, wireless multimedia sensor networks               Categories: C.2.0, C.2.1, C.2.2, C.2.3, C.2.4  
16|10||Classifying and Tracking Free Riders in Multimedia-Based Systems|  Farag Ahmed Azzedin (King Fahd University of Petroleum and Minerals, Saudi Arabia)  Abstract: The ever growing explosion in technological   advancements is paving the way to the expansion of multimedia   applications. Unfortunately, current multimedia applications use   centralized architectures. Before decentralized architectures are   utilized and used, some issues related to decentralization must be   addressed. In this paper, we focus on the problem of free riding in   decentralized collaborative environments. We propose a novel   taxonomy of free riders in multimedia systems based on   trustworthiness. To the best of our knowledge, no existing   literature considers trustworthiness, which we believe is a vital   dimension that should be considered when identifying free riders. We   also propose a new mechanism to filter out and isolate free   riders. Our extensive simulation experiments show that our proposed   algorithm is reasonably successful in identifying free riders in   multimedia-based systems.               Keywords: P2P, distributed computing, free riders, multimedia systems               Categories: C.2.0, C.2.4, H.5.1  
16|11|http://www.jucs.org/jucs_16_11|Advances in Spatial and Temporal Reasoning|
16|11||Spatial Reasoning with Integrated Qualitative-Metric Fuzzy Constraint Networks|  Marco Falda (University of Padova, Italy)  Abstract: Qualitative Spatial Reasoning can be greatly improved if metric information can be represented and reasoning can be performed on it; moreover, modelling vagueness and uncertainty in both qualitative and metric relations allows reasoning in a more flexible way about data coming from real world.   In this paper Rectangle Algebra is integrated with a bi-dimensional Point Algebra by defining a set of 25 Point-Region relations, in this way a Spatial Qualitative Algebra (SQA) among point and regions is obtained. Besides, SQA is extended to deal with uncertain data by means of the Fuzzy Sets Theory. Fuzzy metric information is represented using pyramidal possibility distributions, and transformation functions that allow passing from qualitative to metric information and vice versa are provided.               Keywords: approximate reasoning, fuzzy relations, qualitative spatial reasoning               Categories: I.2.4  
16|11||A Pragmatic Qualitative Approach for Juxtaposing Shapes|  Lledó Museros (Universitat Jaume I, Spain)   Luis González-Abril (Universidad de Sevilla, Spain)   Francisco Velasco (Universidad de Sevilla, Spain)   Zoe Falomir (Universitat Jaume I, Spain)  Abstract: This paper presents a qualitative shape   description scheme which has been defined in order to have a formal   theory to allow the construction of new shapes from a set of given   shapes by using a juxtaposition operation. Specifically, the   qualitative shape description scheme defined is a pragmatic scheme   since it has been defined in order to be applied in the automatic   and intelligent assembling of trencadís   mosaics.               Keywords: qualitative shape description, shape description scheme, trencadís               Categories: I.2.1, I.2.4, I.4.10  
16|11||Finding a Consistent Scenario to an Interval Algebra Network Containing Possibly Infinite Intervals|  André Trudel (Acadia University, Canada)  Abstract: Interval algebra networks are traditionally   defined over finite intervals. In this paper, we relax this   restriction by allowing one or more of the intervals involved to be   infinite. Intervals in the network can be finite, left-infinite,   right-infinite, or infinite in both directions. The network's   intervals can all be of the same type, or different. We present   algorithms for finding a consistent scenario.               Keywords: Allen's Interval Algebra, infinite temporal intervals, temporal knowledge representation and reasoning               Categories: I.2.4  
16|11||An Axiomatization of a First-order Branching Time Temporal Logic|  Dragan Doder (Belgrade University, Serbia)   Zoran Ognjanović (Serbian Academy of Sciences and Arts, Serbia)   Zoran Marković (Serbian Academy of Sciences and Arts, Serbia)  Abstract: We introduce a first-order temporal logic for   reasoning about branching time. It is well known that the set of   valid formulas is not recursively enumerable and there is no   finitary axiomatization. We offer a sound and strongly complete   axiomatization for the considered logic.               Keywords: branching time logic, first order logic, strong completeness               Categories: F.4.1, I.2.4  
16|11||A Graph Model for Spatio-temporal Evolution|  Géraldine Del Mondo (Naval Academy Research Institute, France)   John G. Stell (University of Leeds, United Kingdom)   Christophe Claramunt (Naval Academy Research Institute, France)   Rémy Thibaud (Naval Academy Research Institute, France)  Abstract: Evolving entities in space and time generate   complex networks whose structural properties require the development   of formal models. The research presented in this paper introduces a   graph-based model whose objective is to retain the semantics of   these networks. Entities are related at a given time, through space   according to the locations they occupy, and across time according to   some dependency relations. We propose an approach that characterises   these different properties using several graphs, and where emerging   properties are analysed at the local and global levels. This allows   for a manipulation of these spatial, spatio-temporal and temporal   graphs using neighbourhood, descendant and ancestor operations at   the local level. Global properties are studied according to the way   two given entities in one of these graphs are related according to   the possible routes between them. The principles of the modelling   approach are illustrated by a case study of the propagation of   brambles.               Keywords: graph theory, spatio-temporal information theory               Categories: H.1.1  
16|12|http://www.jucs.org/jucs_16_12|Ambient Intelligence Vision: A Perspective|
16|12||Ambient Intelligence: Beyond the Inspiring Vision|  Rui José (University of Minho, Portugal)   Helena Rodrigues (University of Minho, Portugal)   Nuno Otero (University of Minho, Portugal)  Abstract: Ambient Intelligence (AmI) has emerged in the   past 10 years as a multidisciplinary field within ubiquitous   computing, attracting considerable research, funding and public   attention and leading to many research groups, and conferences   specifically focused on Ambient Intelligence topics. From its   conception, AmI has always been a field strongly driven by a   particular vision of how ICT technologies would shape our   future. This has given the AmI vision, essentially as proposed by   ISTAG, an excessively central role in shaping the field and setting   its research agenda. We argue that this inspiring vision should no   longer be the main driver for AmI research and that we should now   re-interpret its role in the background of 10 years of research.   In this paper, we reflect on what it means for AmI to move behind its foundational vision and we identify a number of emerging trends around some of its core concepts, more specifically the notion of intelligence, the system view and the requirements process. The main motivation is to search for alternative research directions that may be more effective in delivering today the essence of the AmI vision, even if they mean abandoning some of the currently prevailing approaches and assumptions. Overall, these trends provide a more holistic view of AmI and may represent important contributions for bringing this field closer to realisation, delivery and real social impact.               Keywords: Ambient Intelligence, design, global computing, innovation, open innovation, scenarios, situated intelligence, ubiquitous computing               Categories: D.2.1, D.2.10, H.1.2, I.2.0, K.4.2  
16|12||An Agent-based Architecture for Developing Activity-Aware Systems for Assisting Elderly|"  Juan Pablo García-Vázquez (UABC, Mexico)   Marcela D. Rodríguez (UABC, Mexico)   Mónica E. Tentori (UABC, Mexico)   Diana Saldaña (UABC, Mexico)   Ángel G. Andrade (UABC, Mexico)   Adán N. Espinoza (UABC, Mexico)  Abstract: Ageing is a global phenomenon which has   motivated many research and development projects with the aim of   providing computing services that support the active and independent   living of the elderly. To integrate the ambient intelligence (AmI)   vision into the home environment to allow elders to ""age in place"",   it has been identified the necessity of providing high-level   software support for creating ambient assisted living (AAL)   environments. We propose activity-aware computing to allow smart   environments to provide continuous activity awareness and   opportunistically offer assistance aimed at supporting the elders   current activity. This new paradigm calls for novel tools to help   developers mirror human activities in the digital domain, and adapt   smart environments based on the activities executed by the   users. This paper proposes the use of autonomous agents to cope with   the design issues for developing activity-aware systems. We   specialized the SALSA agent architecture by incorporating   customizable activity-aware mechanisms to infer and represent   activities. We illustrate the capabilities offered by SALSA   autonomous agents through a design of an activity-aware application   for helping elders to manage their medication activity.               Keywords: artificial intelligence, information interfaces and presentation, knowledge representation formalisms and methods, multiagents systems, smart environments, ubiquitous computing               Categories: H.5, I.2.11, I.2.4, I.2.6, L.7  "
16|12||An Ambient Assisted Living Platform Integrating RFID Data-on-Tag Care Annotations and Twitter|  Diego López-de-Ipiña (Deusto Institute of Technology, Spain)   Ignacio Díaz-de-Sarralde (Deusto Institute of Technology, Spain)   Javier García-Zubia (Deusto Institute of Technology, Spain)  Abstract: Although RFID is mainly used to identify objects   whose data can then be accessed over the network, passive HF RFID   tags do have significant data storage capacity (up to 4K), which can   be utilised to store data rather than only IDs. This work explores   the potential of storing, accessing and exploiting information on   tags both, theoretically, by studying how much data can actually be   stored in HF RFID tags, and practically, by describing an   NFC-supported platform adopting the data-on-tag approach to improve   data management in a care centre. Such platform illustrates two key   aspects for AAL: a) RFID tags can serve as temporary repositories of   care events whenever a continuous data link is not desirable and b)   interactions between RFID wristbands worn by residents and care   staff's NFC mobiles can improve care data management and keep   relatives up-to-date with elderly people's evolution, through a Web   2.0 social service.               Keywords: AAL, IoT, NFC, RFID, Twitter, Web 2.0               Categories: C.2.4, C.2.6, D.2.11, D.2.12, D.2.2, D.2.6  
16|12||A Context Model based on Ontological Languages: a Proposal for Information Visualization|  Ramón Hervás (Castilla-La Mancha University, Spain)   José Bravo (Castilla-La Mancha University, Spain)   Jesús Fontecha (Castilla-La Mancha University, Spain)  Abstract: In the last few years, people are increasingly   demanding personalized information to carry out their daily   activities. Information systems are needed to manage a   representation of the user's situation, identify user needs and   preferences, and implement information retrieval techniques that   pull together data from diverse and heterogeneous sources. It is   necessary to define and formalize context models for achieving these   goals. In this paper, we present a formal context model based on   advances on the Semantic Web. The model is compounded by four   independent and related ontologies: users, devices, environment and   services. Each of these ontologies describes general concepts and   relationships involved in intelligent environments. The proposed   design enables model specializations to particular domains and   interoperability with external ontologies. Moreover, the model   supports inference mechanisms to enhance the automatic context   generation and the proactive behavior of particular   services. Finally, this paper shows a specific prototype that offers   personalized and context-aware information to the user, aided by the   context model.               Keywords: Semantic Web, ambient intelligence, context-awareness, information visualization, knowledge management               Categories: H.5.2, I.2.4, M.4  
16|12||Context Awareness for Collaborative Learning with Uncertainty Management|  Roc Messeguer (Universitat Politècnica de Catalunya, Spain)   Leandro Navarro (Universitat Politècnica de Catalunya, Spain)   Pedro Damian-Reyes (CICESE, Mexico)   Jesus Favela (CICESE, Mexico)  Abstract: In Collaborative Learning, groups of students   work together using traditional and computer-based tools or   applications. Participants are continuously moving and reorganizing   in groups as tasks develop and the contextual information about the   physical arrangement of people within groups determines the context   of each sub-activity. The electronic environment needs to be in sync   with the physical arrangement of the groups, but providing group   context information to computer-based tools cannot effectively be   done manually. This paper explores and addresses the problem of   automating group awareness in CSCL applications by estimating group   arrangements from location sensors and the history of   interaction. We derive from case studies the requirements for   context-awareness in collaborative learning, focusing on the Jigsaw   technique supported by mobile devices. In our prototype system with   real users, groups are detected from the location of the students   within the classroom. However, this information needs filtering to   avoid disturbing interruptions caused by uncertain location   measures. A three-phase filtering strategy is proposed to manage   uncertain contextual information by identifying sources of   uncertainty, representing uncertain information, and determining how   to proceed. Validation with experimental data shows the usefulness   of introducing mobile devices with group-supporting applications   that incorporate automatic group awareness. Results show that by   managing uncertainty in the estimation of location, group membership   information becomes reliable enough to satisfy the need for   supporting collaborative learning with applications that are   automatically group-aware, without introducing extra burdens or   interruptions.               Keywords: Computer Supported Collaborative Learning (CSCL), context awareness, ubiquitous computing               Categories: K.3.1, L.6.2, L.7.0  
16|12||PICTAC: A Model for Perceiving Touch Interaction through Tagging Context|  Gabriel Chavira (Autonomous University of Tamaulipas, Mexico)   José Bravo (Castilla La Mancha University, Spain)   Salvador W. Nava-Díaz (Autonomous University of Tamaulipas, Mexico)   Julio C. Rolón (Autonomous University of Tamaulipas, Mexico)  Abstract: A natural interface is one of three key   technologies of Ambient Intelligence (AmI); one of its main   objectives is to minimize the user's interactive effort, which is   the difficulty level that depends on the diversity and quantity of   devices that surround people in existing environments. The worldwide   penetration of mobile phones at present makes mobile phones   excellent devices for delivering new services to users without   requiring learning effort. An NFC-enabled mobile phone will allow a   user to demand and obtain services by touching its different   elements in a given smart environment. In this paper, we present a   proposal in which we analyze the scope of touch interaction and   develop a perceived touch interaction through tagging context   (PICTAC) model.               Keywords: context aware, tagging context, touch interaction,, ubiquitous computing               Categories: F.1.1, H.1, H.1.1, H.1.2, H.5, H.5.2  
16|12||Configuration Process of a Software Product Line for AmI Middleware|  Lidia Fuentes (University of Malaga, Spain)   Nadia Gámez (University of Malaga, Spain)  Abstract: Developing Ambient Intelligence applications is a very complex task since it implies dealing with low-level software and hardware resources. The use of a middleware platform may alleviate this task by providing a set of high-level and platform-independent services to these kinds of applications. Nevertheless, the tendency is that the middleware deployed in each device has a flat and homogeneous architecture, although these devices and the requirements of intelligence environments are heterogeneous. This implies the middleware software deployed in each device normally contains more functionality than strictly required, leading to waste resources so scarce in lightweight devices. But the configuration and deployment of a minimal middleware customized to a target platform is a complex task, due to the diversity of hardware and software present in devices and the variable requirements of ambient intelligence applications. In order to solve these shortcomings, we propose to customize the piece of software related to the middleware platform by using a Software Product Line engineering approach. This paper presents an innovative configuration process for a software product line for ambient intelligence middleware where a minimal set of high-level parameters needs to be specified. So, the software engineers for this kind of systems can automatically obtain customized middleware by simply specifying this high-level information.               Keywords: AAL, AmI, SPL, middleware, variability               Categories: C.2.1, D.2.1, D.2.11, D.2.2, D.4.7  
16|12||Developing Augmented Objects: A Process Perspective|  Luis A. Guerrero (Universidad de Chile, Chile)   Hector Horta (Universidad de Chile, Chile)   Sergio F. Ochoa (Universidad de Chile, Chile)  Abstract: There are many examples of augmented objects in   the literature. Augmented objects should provide intelligence to the   ambient where they are located and also they must require a low   cognitive effort to be used. Few works have been reported providing   guidelines to conceive and design these components. Therefore,   developers have to use improvised ad hoc software processes to   support the development of augmented objects. In order to help   dealing with this situation, this article presents a software   process to develop these components. The proposed process was named   Augmented Objects Development Process (AODeP) and it is based on the   authors previous experiences and software engineering best   practices. The article also reports two case studies in which AODeP   was used to guide the development of augmented objects in specific   problems. The obtained results are encouraging.               Keywords: ambient intelligence, augmented objects development, software process               Categories: D.2.10, D.2.2, H.5.2  
16|12||Towards a Ubiquitous End-User Programming System for Smart Spaces|  Manuel García-Herranz (Universidad Autónoma de Madrid, Spain)   Pablo Haya (Universidad Autónoma de Madrid, Spain)   Xavier Alamán (Universidad Autónoma de Madrid, Spain)  Abstract: This article presents a rule-based agent   mechanism as the kernel of a ubiquitous end-user,   UIindependent programming system. The underlying goal of our   work is to allow endusers to control and program their   environments in a uniform, application-independent way. The   heterogeneity of environments, users and programming skills, as well   as the coexistence of different users and domains of automation in   the same environment are some of the main challenges analyzed. For   doing so, we present our system and describe some of the   realenvironments, user studies and experiences we have had in   the development process.               Keywords: command and control, human-centered computing, rule-based processing, ubiquitous computing               Categories: H.1.2, I.2.4, I.2.5  
16|12||Mobile Intelligence|  Yang Cai (Carnegie Mellon University, USA)  Abstract: Analyzing human motion in a building has been an active subject in Ambient Intelligence and Universal Design for many years. In this study, we present a rapid prototype of a mobile and interactive sensing platform for smart buildings. The biologically inspired robot can follow the moving person around, memorize the motion patterns in form of sequences of symbols, and detect surprising events, based on similarity between the priori and posteriori probability distributions. The key modules in this study have been prototyped and tested with real-world data, such as the twomonth sensory data in a building. Furthermore, the author believes that simple and recursive algorithms would enable mobile robots to simulate natural ethological intelligence.               Keywords: anomaly detection, instinctive computing, motion, sensor network, smart environment               Categories: H.1, J.0, L.7  
16|13|http://www.jucs.org/jucs_16_13|Recent Trends in Service Science|
16|13||Service Networks Modelling: An SOA & BPM Standpoint|  Olha Danylevych (University of Stuttgart, Germany)   Dimka Karastoyanova (University of Stuttgart, Germany)   Frank Leymann (University of Stuttgart, Germany)  Abstract: Services are quintessential in the current economical landscape. Enterprises and businesses at large rely on the consumption and providing of services to ensure their operations and to realize their business offers. That is, nowadays businesses all over the world are interconnected with each other by complex service-centric webs called service networks. The ubiquity and pervasiveness of service networks call for models, methods, mechanisms and tools to understand them and harness their potential.  This paper investigates the modelling of the service networks with a focus on business relationships and exchanges of software services among the involved parties. The contribution of this work is threefold. Firstly, we provide an overview of what service networks modelling can offer in combination with Business Process Management (BPM) and Service Oriented Architecture (SOA) technologies. Secondly, we propose a formalism to model service networks that depicts them as aggregations of participants - e.g. enterprises or individuals - that offer, request, consume and provide services to each other. With the goal of providing a foundation for the alignment between service network- and business process models, we finally map the constructs of our service networks modelling formalism to the ones of the Business Process Modelling Notation (BPMN).               Keywords: BPMN, business process management, business processes, service networks, service oriented architecture, software services               Categories: D.2.9, H.1, H.3.5  
16|13||Toward the Next Wave of Services: Linked Services for the Web of Data|  Carlos Pedrinaci (The Open University, United Kingdom)   John Domingue (The Open University, United Kingdom)  Abstract: It has often been argued that Web services would have a tremendous impact on the Web, as a core enabling technology supporting a highly efficient service-based economy at a global scale. However, despite the outstanding progress in the area we are still to witness the application of Web services in any significant numbers on the Web. In this paper, we analyse the state of the art highlighting the main reasons we believe have hampered their uptake. Based on this analysis, we further discuss about current trends and development within other fields such as the Semantic Web and Web 2.0 and argue that the recent evolution provides the missing ingredients that will lead to a new wave of services - Linked Services - that will ultimately witness a significant uptake on a Web scale. Throughout the presentation of this vision we outline the main principles that shall be underpinning the development of Linked Services and we illustrate how they can be implemented using a number of technologies and tools we have developed and are in the process of extending.               Keywords: Linked Services, Semantic Web, Semantic Web Services, Web Services, Web of Data               Categories: D.2.11, H.3.5, I.2.11, K.4.4  
16|13||Trust-Oriented Composite Service Selection with QoS Constraints|  Lei Li (Macquarie University, Australia)   Yan Wang (Macquarie University, Australia)   Ee-Peng Lim (Singapore Management University, Singapore)  Abstract: In Service-Oriented Computing (SOC) environments, service clients interact with service providers for consuming services. From the viewpoint of service clients, the trust level of a service or a service provider is a critical factor to consider in service selection, particularlywhen a client is looking for a service from a large set of services or service providers. However, a invoked service may be composed of other services. The complex invocations in composite services greatly increase the complexity of trust-oriented service selection. In this paper, we propose novel approaches for composite service representation, trust evaluation and trust-oriented com-posite service selection (with QoS constraints). Our experimental results illustrate that compared with the existing approaches our proposed trust-oriented (QoS constrained) composite serviceselection algorithms are realistic and enjoy better efficiency.               Keywords: Monte Carlo method, composite service, composite service representation, composite service selection, trust evaluation               Categories: H.3.3,, H.3.5, H.4.m  
16|13||On Sustainability of Context-Aware Services Among Heterogeneous Smart Spaces|  Jason J. Jung (Yeungnam University, Korea)  Abstract: Most of ambient intelligence studies have tried   to employ inductive methods (e.g., data mining) to discover useful   information and patterns from data streams on sensor   networks. However, since the spaces have been sharing their   information with each other, it is difficult for such inductive   methods to conduct the discovery process from the sensor streams   intermixed from the heterogeneous sensor networks. In this paper, we   propose an ontology-based middleware system to improve   sustainability of context-aware service in the interconnected smart   spaces. Two main challenges of this work are i) sensor data   preprocessing (i.e., session identification) and ii) information   fusion (i.e., information integration). The ontology in each sensor   space can provide and describe semantics of data measured by each   sensor. By aligning these ontologies from the sensor spaces, the   semantics of sensor data captured inside can be compared. Thus, we   can find out not only relationships between sensor streams but also   temporal dynamics of a data stream. To evaluate the proposed method,   we have collected sensor streams from in our building during 30   days. By using two well-known data mining methods (i.e.,   co-occurrence pattern and sequential pattern), the results from raw   sensor streams and ones from sensor streams with preprocessing were   compared with respect to two measurements recall and   precision.               Keywords: ontology, preprocessing, semantic sensor networks;, stream mining               Categories: H.1.1, H.3.5, I.2.11  
16|13||Typology of Service Innovation from Service-Dominant Logic Perspective|  Kichan Nam (Sogang University, Korea)   Nam Hee Lee (Sogang University, Korea)  Abstract: This study provides a conceptual framework with   respect to service innovation, especially from a service-dominant   logic (S-D logic) perspective.  Even though innovation has been   discussed as one of the most critical elements in enhancing the   competitiveness of service industry, it was not clear how service   innovation should be different from diverse types of existing   innovation.  The S-D logic provides a novel and valuable theoretical   perspective that unifies the conventional literature on innovation.   According to this new logic, four types of service innovation are   presented based on two dimensions: the degree of co-creation and the   degree of networked collaboration.  We argue that service innovation   can arise by the activity of value co-creation between firm and   customer on the first dimension. On the second dimension, the firm   needs to enhance their own capabilities for service innovation by   applying the resources of all actors including suppliers and   customers. Our framework indicates that it is critical for   productive service innovation to make customers participate in value   creation process and to integrate the dispersed resources held by   participants.  Examples are discussed with respect to different   types of services innovation.               Keywords: networked-collaboration, service innovation, service science, service-dominant logic, value co-creation               Categories: A.1, H.0, H.1.0  
16|13||Information Support Services for Intermediation Tasks of Collaborative Networks|  Heiko Thimm (Pforzheim University, Germany)   Karsten Boye Rasmussen (University of Southern Denmark, Denmark)  Abstract: Companies in collaborative networks require   intermediation to perform. The collaborative network forms the   breeding environment for the configuration of a Virtual Enterprise   that can handle a business request. This configuration task can be   supported by IT services. For collaborative networks such as   production networks focused on non-digital services and products we   propose to assign specific intermediation tasks to a human network   moderator supported by these IT services. The obvious support is   targeted for the configuration of the Virtual Enterprise i.e. the   search and selection from the available products, services, and   competences found among the network participants. The configuration   decision can jeopardize the network performance by harming the trust   necessary to build new Virtual Enterprises. Through a further   intermediation task trust can be inspired and promoted in the   network. This article shows how the configuration is supported by a   Decision Support Service and how a Transparency Support Service   supports the downloading and acceptance of decisions in   collaborative networks. The article outlines the IT supportive   service system and exemplifies the use by a scenario   example. Results on intermediation in collaborative networks can   prove helpful for general service science problems.               Keywords: collaborative work, decision support, network moderation and intermediation, organizational trust, service science, virtual organizations               Categories: H.3.5, H.4.2, K.4.4, L.6.1, L.6.2  
16|13||"Toward an Understanding of the Mediating Role of ""Trust"" in Mobile Banking Service: An Empirical Test of Indonesia Case"|  Chulmo Koo (Chosun University, South Korea)   Yulia Wati (Chosun University, South Korea)  Abstract: Mobile banking has been considered to be one of   the most value-added and important mobile services currently   available. Considering the fact that the penetration of this   technology is undefined well, particularly in developing country,   this study clarified the role of trust as a mediating variable in   mobile banking environment. An empirical study was undertaken in   Indonesia and the data of 100 respondents were collected. The   empirical results provided strong evidence for the explanatory power   of our research model. Firstly, we found that the trust mediated the   effects of information quality to perceived usefulness and end-user   satisfaction. Second, the both relationships of system quality and   perceived usefulness and system quality and end-user satisfaction   were partially mediated by trust. Third, trust also showed a direct   effect on both end-user satisfaction and perceived   usefulness. Lastly, the result provided support of the positive   relationship between perceived usefulness and end-user   satisfaction. Implication for both practice and further research   were also discussed.               Keywords: IS success factors, Indonesia, Mobile Banking, Trust               Categories: H.1.2, J.4  
16|14|http://www.jucs.org/jucs_16_14|Managing Editor's Column|
16|14||Design of Arbiters and Allocators Based on  Multi-Terminal BDDs|  Václav Dvořák (Brno University of Technology, Czech Republic)   Petr Mikušek (Brno University of Technology, Czech Republic)  Abstract: Assigning one (more) shared resource(s) to   several requesters is a function of arbiters (allocators). This   class of decision-making modules can be implemented in a number of   ways, from hardware to firmware to software. The paper presents a   new computer-aided technique that can produce representations of   arbiters/allocators in a form of a Multi-Terminal Binary Decision   Diagram (MTBDD) with close to minimum cost and width. This diagram   can then serve as a prototype for a cascade of multiple-output   look-up tables (LUTs) that implements the given function, or for   efficient firmware implementation. The technique makes use of   iterative decomposition of integer functions of Boolean variables   and a variable-ordering heuristic to order variables. The LUT   cascades lead directly to the pipelined design, simplify wiring and   testing and can compete with the traditional FPGA design in   performance and with PLA design in chip area.               Keywords: LUT cascades, allocators., arbiter circuits, iterative disjunctive decomposition, multi-terminal BDDs               Categories: B.1.1, B.1.4, B.6.1, B.6.3, C.3, C.5.4  
16|14||A Treasure Hunt Model for Inquiry-Based Learning in the Development of a Web-based Learning Support System|  Dong Won Kim (University of Regina, Canada)   JingTao Yao (University of Regina, Canada)  Abstract: One of the main problems of web-based learning   is staying motivated at a sufficientlevel. Learning games offering   challenges and entertainment may stimulate student motivation for   learning and mitigate this problem. Web-based learning support   systems combined with learninggames may efficiently promote learning   by encouraging student participation in learning. This study   introduces a treasure hunt model, which represents the idea of   inquiry-based learning usingset theory. We demonstrate this via a   prototype of a web-based learning support system called OTHI, which   employs an online treasure hunt game as the learning game. We   integrate the soundlearning strategies of inquiry-based learning   with the Web and online game technologies in this system. We expect   that our learning support system will motivate students, and furnish   an inter-active student-centered learning environment.               Keywords: game-based learning, inquiry-based learning, treasure hunt, web-based learning support systems               Categories: H.1, H.5, J.4, K.3.1  
16|14||Applying RFD to Construct Optimal Quality-Investment Trees|  Pablo Rabanal (Universidad Complutense de Madrid, Spain)   Ismael Rodríguez (Universidad Complutense de Madrid, Spain)   Fernando Rubio (Universidad Complutense de Madrid, Spain)  Abstract: River Formation Dynamics (RFD) is an   evolutionary computation methodbased on copying how drops form   rivers by eroding the ground and depositing sediments. Given a   cost-evaluated graph, we apply RFD to find a way to connect a   givenset of origins with a given destination in such a way that   distances from origins to the destination are minimized (thus   improving the quality of service) but costs to build theconnecting   infrastructure are minimized (thus reducing investment   expenses). After we prove the NP-completeness of this problem, we   apply both RFD and an Ant ColonyOptimization (ACO) approach to   heuristically solve it, and some experimental results are   reported.               Keywords: Ant Colony Optimization Algorithms, Heuristic Algorithms, NP-hard problems, River Formation Dynamics               Categories: F.2.0, G.1.6, I.2.8  
16|14||Geometric Point Pattern Matching in the Knuth-Morris-Pratt Way|"  Esko Ukkonen (University of Helsinki, Finland)  Abstract: Given finite sets P and   T of points in the Euclidean space   Rd, the   point pattern matching problem studied in this paper is to find all   translations f ∈   Rd such   that P + f ⊆   T. A fast search algorithm with some variants is   presented for point patterns P that have regular   grid-like geometric shape. The algorithm is analogous to the   Knuth-Morris-Pratt algorithm of string matching. The time   requirement of the search is   O(r|T|)   where r is the grid dimension of   P. Pattern P has grid   dimension r = 1 if it consists of evenly spaced   points on a line. In general, a pattern P is an   r-dimensional grid if it has for some   p ∈ P and   e1, ... ,   er ∈   Rd and   positive integers m1,   ... , mr a representation   P = {p +   i1e1   + ⋅⋅⋅ +   irer   | 0 ≤ ij ≤   mj} where the   ij's are integers. Both   P and T are given to the   search algorithm in the lexicographic order.               Keywords: Knuth-Morris-Pratt algorithm, pattern matching, point sets, translation,               Categories: F.2, I.3, I.7  "
16|14||A Heuristic Approach to Positive Root Isolation for Multiple Power Sums|  Ming Xu (Chinese Academy of Sciences, China)   Chuandong Mu (East China Normal University, China)   Zhenbing Zeng (East China Normal University, China)   Zhi-bin Li (East China Normal University, China)  Abstract: Given a multiple power sum (extending   polynomial's exponents to real numbers), the positive root isolation   problem is to find a list of disjoint intervals, satisfying that   they contain all positive roots and each of them contains exactly   distinct one. In this paper, we develop the pseudo-derivative   sequences for multiple power sums, then generalize Fourier's theorem   and Descartes' sign rule for them to overestimate the number of   their positive roots. Furthermore we bring up some formulas of   linear and quadratic complexity to compute complex root bounds and   positive root bounds based on Descartes' sign rule and Cauchy's   theorem. Besides, we advance a factorization method for multiple   power sums with rational coefficients utilizing Q-linear   independence, thus reduce the computational complexity in the   isolation process. Finally we present an efficient algorithm to   isolate all positive roots under any given minimum root   separation.               Keywords: Descartes' sign rule, Fourier's theorem, multiple power sums, root bounds, root isolation               Categories: F.2.1, G.1.5  
16|15|http://www.jucs.org/jucs_16_15|Mobile Context-Aware Applications for Ubiquitous Computing|
16|15||Mobile Agent-based Context-aware Services|  Ichiro Satoh (National Institute of Informatics, Japan)  Abstract: This paper presents an agent-based system for   building and operating agent-basedcontext-aware services in public   spaces, including museums. The system provides users with agents and   detects the locations of users and deploys location-aware   user-assistant agents at com-puters near the their current locations   by using active RFID-tags. When a visitor moves between exhibits in   a museum, this dynamically deploys his/her agent at the computers   close to the ex-hibits by using mobile agent technology. It   annotates the exhibits in his/her personalized form and navigate   him/her user to the next exhibits along his/her routes. It also   introduces user move-ment as a natural approach to interacting   between users and agents. To demonstrate the utility and   effectiveness of the system, we constructed location/user-aware   visitor-guide services andexperimented them for two weeks in a   public museum.               Keywords: RFID, context-aware service, mobile agent, user navigation               Categories: C.2.4, D.2.9, F.1.2, H.5.2  
16|15||Real-time Analysis of Time-based Usability and Accessibility for Human Mobile-Web Interactions in the Ubiquitous Internet|  Yung Bok Kim (Sejong University, Korea)  Abstract: In the ubiquitous Internet, human mobile-web   interactions can be evaluated with real-time analysis of time-based   usability and accessibility with the different types of mobile   Internet devices including smart phones (e.g. iPhone, Android phone,   etc.). A ubiquitous mobile-web interaction server, accessible with a   variety of mobile Internet devices, could be a unified estimation   hub in real-time analysis of human-centric mobile-web   interactions. We propose the real-time analysis scheme based on   real-time estimation of time-based usability and accessibility for   human mobile-web interactions with a name-based directory server for   social networking in the ubiquitous Internet environment. We present   an implementation of a ubiquitous mobile-web directory service and   discuss our approach with some empirical results.               Keywords: SNS, interaction, mobile-web, time-based usability/accessibility, ubiquitous               Categories: H.3.1, H.3.3, H.5.2  
16|15||Multi-Level Context Management and Inference Framework for Smart Telecommunication Services|  Carlos Baladrón (University of Valladolid, Spain)   Alejandro Cadenas (TelefónicaI+D, Spain)   Javier Aguiar (University of Valladolid, Spain)   Belén Carro (University of Valladolid, Spain)   Antonio Sánchez-Esguevillas (TelefónicaI+D, Spain)  Abstract: Telco operators and other players are searching   for intelligent value-added services, i.e., communication   applications that take advantage of the huge amount of user data   available to the operators (location, contact lists, etc.) in order   to adapt themselves to the preferences and context of each   individual. However, the current networks of the operators lack the   proper infrastructure to handle context data in a clean and unified   way, so smart context-aware applications are extremely difficult to   engineer, develop and deploy. Accordingly in this paper a global   context processing architecture is presented. In addition, the   monitoring of users in order to extract and process the context is a   task potentially resource consuming. That is a significant problem   in global telco deployments.This paper also presents a proposal for   a multi-level context management framework for smart   telecommunications services, whose objective is to optimise the   available processing resources of the presented architecture to   provide contextual monitoring to a high number of subscribers with   limited resources.               Keywords: IMS, application, context-aware, convergent, network architecture, service layer, ubiquitous computing               Categories: C.2.1, I.2.12, I.2.13, I.2.4, I.2.9  
16|15||SimCon: A Tool to Support Rapid Evaluation of Smart Building Application Design using Context Simulation and Virtual Reality|  Kris McGlinn (Trinity College Dublin, Ireland)   Eleanor O'Neill (Trinity College Dublin, Ireland)   Alan Gibney (Cork Institute of Technology, Ireland)   Declan O'Sullivan (College Dublin, Ireland)   Dave Lewis (College Dublin, Ireland)  Abstract: The promise of smart buildings (SBs) is a safer   more productive environment for users and a more operationally   efficient building for owners. The automation of building function   is highly dependent on sensing devices and Smart Building   Applications(SBAs), which are often only evaluated in situ post   deployment, making re-development costly. In this paper we explore   our experiences developing a Simulated Context (SimCon) Model which   currently supports taking information from a Virtual Reality (VR) SB   and converting it into three types of location context to conduct   early rapid evaluation of location based SBAs. This model is   expressed using the Sensor Modelling Language (sensorML). It also   explores the integration of this model into the Industry Foundation   Classes (IFC) for modelling and simulating SBs. It also details   usability evaluations of the SimConfig and SimConViz Tool for   improving evaluation during the design phase of smart building   development life cycle.               Keywords: evaluation, modelling, simulation, smart building applications               Categories: I.6.3, I.6.5, J.7, L.0.0  
16|15||Supporting Mobile Users in Selecting Target Devices|  Giuseppe Ghiani (ISTI-CNR, Italy)   Fabio Paternò (ISTI-CNR, Italy)  Abstract: The availability of applications able to exploit   multi-device environments is steadily increasing. Rather than using   all devices in the same way, users tend to assign different roles to   devices due to the capabilities needed, such as computational power   and screen size. Researchers and developers have started to   introduce various techniques and tools to support managing   applications across multiple devices. In this context, target device   selection is often problematic, especially in unfamiliar   environments. We present a novel technique for supporting device   selection by providing dynamic graphical representations of users   orientation and position in relation to the available target devices   in the current environment. We report on its design, implementation   and discuss two possible location-aware representations of the user   and the target devices.               Keywords: context-aware interactive systems, device selection, mobile devices, multi-device environments, user location and orientation               Categories:  H.5.m  
16|15||Multi-Device Context-Aware RIAs Using a Model-Driven Approach|  Marino Linaje (Universidad de Extremadura, Spain)   Juan Carlos Preciado (Universidad de Extremadura, Spain)   Fernando Sánchez-Figueroa (Universidad de Extremadura, Spain)  Abstract: Model-Driven Development concepts are exhibiting   as a good engineering solution for the design of ubiquitous   applications with multi-device user interfaces and other   context-aware capacities. The Web has become an ideal platform for   the deployment of such applications and therefore traditional Web   development techniques are rapidly adopting Model-Driven principles   to cope with the adaptation issues imposed by context-awareness and   multichannel solutions. This discipline is being known as Model   Driven Web Engineering. However, at the same time that the use of   the Web and the number of people with mobile devices is growing,   users are demanding more and better user experiences through the   user interface. Web vendors answered introducing Rich Internet   Applications that take advantage of the single-page paradigm and   expand traditional Web features, providing richer content types,   richer controls, richer temporal behaviors, richer interactivity and   richer communications. While many recent devices support some type   of RIA technology, RIAs extended features are showing some   limitations of Model Driven Web Engineering methodologies to cope   with multi-device context-awareness at the presentation level. This   paper presents the combination of two different methodologies, WebML   and RUX-Method, both using MDD principles, to obtain multi-device   context-aware Rich Internet Applications using a Model-Driven   approach. While WebML provides context-awareness at the data and   business logic levels, RUX-Method deals with the presentation issues   introduced by Rich Internet Applications.               Keywords: Rich Internet Applications, Web Engineering, model-driven development, multi-device context-aware, user interfaces               Categories:  H.5.2, D.2.2, H.3.5, H.5.4  
16|15||A Mobile Intelligent Interruption Management System|  Sina Zulkernain (Marquette University, USA)   Praveen Madiraju (Marquette University, USA)   Sheikh Iqbal Ahamed (Marquette University, USA)   Karl Stamm (Marquette University, USA)  Abstract: Mobile phones have become the most hated device   that people cannot live without. For its primary usage as a   communication device, it has surpassed any other medium. But it   comes with a high price, interruption, anywhere anytime. These   unwanted interruptions cause loss of productivity and also mostly   not beneficial to the immediate task at hand, and moving them few   minutes into the future can increase productivity. Considering   receivers unavailability, it is possible to manage cell phone   disruptions using advanced features like sensing capability,   ubiquitous computing and context aware systems. This paper proposes   the architecture of a system named Mobile Intelligent Interruptions   Management (MIIM), created for the automated administration of   personal unavailability with regard to cell phones. We provide the   problem description of interruption and its impact. Next, we state   the desirable characteristics and architecture of the MIIM   system. We also provide a case study implementation of MIIM system   on the Android platform. Simulation and evaluation results show that   its computational volumes are low enough for a mobile device. The   analysis of the system also successfully satisfies all the   characteristics requirements.               Keywords: context aware system, interruption, ubiquitous computing, unavailability               Categories: H.5.m  
16|15||Multi-Purpose Infrastructure for Delivering and Supporting Mobile Context-Aware Applications|  Juan Miguel López (University of Lleida, Spain)   Montserrat Sendín (University of Lleida, Spain)  Abstract: The use of contextual information in mobile   devices is receiving increasing attention in mobile and ubiquitous   computing research. An important requirement for mobile development   today is that devices should be able to interact with the   context. In this paper we present a series of contributions   regarding previous work on context-awareness. In the first place, we   describe a client-server architecture that provides a mechanism for   preparing target non context-aware applications in order to be   delivered as context-aware applications in a semi-automatic   way. Secondly, the framework used in the server to instantiate   specific components for context-awareness, the Implicit Plasticity   Framework, provides independence from the underlying mobile   technology used in client device, as it is shown in the case studies   presented. Finally, proposed infrastructure deals with the   interaction among different context constraints provided by diverse   sensors. All of these contributions are extensions to the   infrastructure based on the Dichotomic View of plasticity, which now   offers multi-purpose support.               Keywords: adaptation, context-awareness, mobile development, multi-sensor context               Categories: C.2.4, D.1.m  
16|15||Integrating Social Networks for Context Fusion in Mobile Service Platforms|  Jason J. Jung (Yeungnam University Gyeongsan, Korea)  Abstract: It is important for mobile service providers to   be aware of user contexts and to provide contextually relevant   mobile services to users. Thereby, in this paper, we propose a novel   mechanism for integrating online social networks, which are regarded   as an important channel for exchanging and propagating contexts. To   efficiently discover personal contexts of certain users, the   contexts of their neighbors can be fused to provide mobile   recommendation services to mobile subscribers. However, since the   social network of each user is distributed across several systems,   it has been difficult to integrate contexts from distributed social   networks. Thereby, we mobilize all possible on- and off-line social   networks to build an ego-centric social network. We implemented the   proposed system by collecting the social network dataset from online   sources (e.g., Facebook, Twitter, CyWorld, and co-authoring patterns   in major Korean journals) and offline (e.g., co-participation   patterns in a number of Korean domestic conferences). After the   system was implemented, we provided mobile services to conference   participants by sending text messages about time schedules of   relevant presentations.               Keywords: mobile recommendation service, social network analysis, social network portability, sontext fusion               Categories: H.1.1, H.3.5, I.2.11  
16|15||CAUCE: Model-driven Development of Context-aware Applications for Ubiquitous Computing Environments|  Ricardo Tesoriero (University of Castilla-La Mancha, Spain)   José A. Gallud (University of Castilla-La Mancha, Spain)   María D. Lozano (University of Castilla-La Mancha, Spain)   Víctor M. R. Penichet (University of Castilla-La Mancha, Spain)  Abstract: In order to develop context-aware applications for ubiquitous computing environments we have defined an MDA approach that defines three layers of models. The first layer captures the conceptual characteristics of the application. This layer defines three complementary points of view of the system that are used to build the task, space and social views of the system. The second layer defines the software characteristics of the application.  It is composed by three new complementary points of view of the system that are used to build the referential space, the information flow and the entity context views of the system. Finally, the third layer defines the deployment environment of the system according to the views generated by the second layer.               Keywords: context awareness, model-driven architectures, ubiquitous computing               Categories: D.2.11, D.2.13, D.2.2, D.2.6  
16|15||Situation-Aware Community Computing Model for Developing Dynamic Ubiquitous Computing Systems|  Youna Jung (University of Pittsburgh, USA)   Minsoo Kim (University of Pittsburgh, USA)  Abstract: For many complex and dynamic ubiquitous   services, context-aware cooperation can be a solution. However, the   way is not yet clear to make individual objects cooperate with each   other as situations change. In addition, in the present environment   in which many smart agents are already deployed, we are able to   quickly develop ubiquitous services by utilizing existing agents. In   the case of urgent but unavailable services, such fast development   is required but there is no existing work to provide a path. To meet   such requirements, in this paper, we thus introduce community   computing as a new paradigm in which ubiquitous services are   provided through context-aware cooperation among existing agents. To   design such systems intuitively, we propose an abstraction model,   called the situation-aware community computing model which includes   the community situation model and the situation-aware cooperation   model. In addition, for fast and convenient system development, we   propose a development process based on the MDA (Model-Driven   Architecture) approach [OMG, 03]. Following the development steps of   MDA, we propose three models each having different abstraction   levels and the model transformation process from the high-level   model, CCM, to the source code. To make such transformation   semi-automatic, we develop a toolkit, called CDTK. By using CDTK, we   are able to implement a community computing system conveniently and   systematically. To verify the proposed work, we implemented two   small systems based on motivated scenarios; CHILDCARE and   COEX-Mall. Through the simulated results of those systems, we   examined the possibility of community computing as a new development   paradigm.               Keywords: community computing, context-awareness, cooperation, model driven architecture, multi-agent system development, ubiquitous computing System               Categories: H.5.3, I.2.11, K.6.3  
16|16|http://www.jucs.org/jucs_16_16|Context-aware Recommender Systems|
16|16||The 3A Personalized, Contextual and Relation-based Recommender System|  Sandy El Helou (École Polytechnique Fédérale de Lausanne, Switzerland)   Christophe Salzmann (École Polytechnique Fédérale de Lausanne, Switzerland)   Denis Gillet (École Polytechnique Fédérale de Lausanne, Switzerland)  Abstract: This paper discusses the 3A recommender system   that targets CSCL (computer-supported collaborative learning) and   CSCW (computer-supported collaborative work) environments. The   proposed system models user interactions in a heterogeneous   graph. Then, it applies a personalized, contextual, and   multi-relational ranking algorithm to simultaneously rank actors,   activity spaces, and assets. The results of an empirical evaluation   carried out on an Epinions dataset indicate that the proposed   recommendation approach exploiting the trust and authorship networks   performs better than user-based collaborative filtering in terms of   recall.               Keywords: CSCL, CSCW, Recommender systems, algorithms, design, pagerank, trust               Categories: H.2.8, L.3.2, L.3.6, M.5  
16|16||Extraction of Contextualized User Interest Profiles in Social Sharing Platforms|  Rafael Schirru (University of Kaiserslautern, Germany)   Stephan Baumann (German Research Center for Artificial Intelligence, Germany)   Martin Memmel (University of Kaiserslautern, Germany)   Andreas Dengel (University of Kaiserslautern, Germany)  Abstract: Along with the emergence of the Web 2.0, E-learning more often takes place in open environments such as wikis, blogs, and resource sharing platforms. Nowadays, many companies deploy social media technologies to foster the knowledge transfer in the enterprise. They offer Enterprise 2.0 platforms where knowledge workers can share contents according to their different topics of interest.  In this article we present an approach extracting contextualized user profiles in an enterprise resource sharing platform according to the users' different topics of interest. The system analyses the social annotations of each user's preferred resources and identifies thematic groups. For every group a weighted term vector is derived that represents the respective topic of interest. Each user profile consists of several such vectors that way enabling recommendation lists with a high degree of inter-topic diversity as well as targeted context-sensitive recommendations.  The proposed approach has been tested in our Enterprise 2.0 platform ALOE. A first evaluation has shown that the method is likely to identify reasonable user interest topics and that resource recommendations for these topics are widely appreciated by the users.               Keywords: E-Learning 2.0, Enterprise 2.0, Web 2.0 resource sharing, topic detection, user modeling               Categories: H.3.1  
16|16||Content Recommendation in APOSDLE using the Associative Network|  Hermann Stern (Graz University of Technology, Austria)   Rene Kaiser (JOANNEUM RESEARCH, Austria)   Philip Hofmair (JOANNEUM RESEARCH, Austria)   Peter Kraker (Know-Center GmbH, Austria)   Stefanie N. Lindstaedt (Know-Center GmbH, Austria)   Peter Scheir (Styria Media Group AG, Austria)  Abstract: One of the success factors of Work Integrated   Learning (WIL) is to provide the appropriate content to the users,   both suitable for the topics they are currently working on, and   their experience level in these topics. Our main contributions in   this paper are (i) overcoming the problem of sparse content   annotation by using a network based recommendation approach called   Associative Network, which exploits the user context as input; (ii)   using snippets for not only highlighting relevant parts of   documents, but also serving as a basic concept enabling the WIL   system to handle text-based and audiovisual content the same way;   and (iii) using the Web Tool for Ontology Evaluation (WTE) toolkit   for finding the best default semantic similarity measure of the   Associative Network for new domains. The approach presented is   employed in the software platform APOSDLE, which is designed to   enable knowledge workers to learn at work.               Keywords: associative networks, multimedia information systems, recommender systems, work integrated learning               Categories: H.5.1, L.2.1, M.7, M.8  
16|16||Web Context Classification Based on Information Quality Factors|  Jinhyuk Choi (Korea Advanced Institute of Science and Technology (KAIST), Republic Korea)   Geehyuk Lee (Korea Advanced Institute of Science and Technology (KAIST), Republic Korea)   Junghoon Moon (Seoul National University, Republic Korea)  Abstract: The fact that the World Wide Web is being used for various purposes also implies that users may have various information quality factors to consider according to their current context. In this regards, it is important for Web recommendation services to recognize what quality factors should be considered in current context in order to enhance user satisfaction. We showed that it is necessary to classify Web contexts based on the information quality factors users consider in their minds when they choose websites or Web pages. The results of user interviews showed that there are four quality factors: credibility, recency, popularity, and relevance. From survey data analysis, we recognized that user tasks can be clustered into two groups based on the quality factors that users consider. Finally, the results of log data analysis and performances of our proposed algorithm showed that it is possible to enable Web services to infer the context group. This result implies that context recognition is possible using the limited data that are collected at browser side.               Keywords: Web Recommendation Services, World Wide Web, context classification and inference, information quality factors               Categories: H.1.2, H.3.5, H.5.0, M.5  
16|16||User Context and Personalized Learning: a Federation of Contextualized Attention Metadata|  Valentin Butoianu (Université Paul Sabatier, France)   Philippe Vidal (Université Paul Sabatier, France)   Katrien Verbert (K.U. Leuven, Belgium)   Erik Duval (K.U. Leuven, Belgium)   Julien Broisin (Université Paul Sabatier, France)  Abstract: Nowadays, personalized education is a very hot topic in technology enhanced learning (TEL) research. To support students during their learning process, the first step consists in capturing the context in which they evolve. Users typically operate in a heterogeneous environment when learning, including learning tools such as Learning Management Systems and non-learning tools and services such as e-mails, instant messaging, or web pages. Thus, user attention in a given context defines the Contextualized Attention Metadata (CAM). Various initiatives and projects allow capturing CAMs in a knowledge workers environment not only in the TEL area, but also in other domains like Knowledge Work Support, Personal Information Management and Information Retrieval. After reviewing main existing approaches according to some specific criteria that are of main interest for capturing and sharing user contexts, we present in this paper a framework able to gather CAMs produced by any tool or computer system. The framework is built on the Web-Based Enterprise Management (WBEM) standard dedicated to system, network and application management. Attention information specific to heterogeneous tools are represented as a unified and extensible structure, and stored into a central repository compliant with the above-mentioned standard. To facilitate access to this attention repository, we introduced a middleware layer composed of two dynamic services: the first service allows users to define the attention data they want to collect, whereas the second service is dedicated to receive and retrieve the traces produced by computer systems. An implementation for collecting and storing CAM data generated by the Ariadne Finder and Moodle validates our approach.               Keywords: contextualized attention metadata, technology enhanced learning               Categories: L.2.0, L.2.2, L.3.0, L.3.6  
16|16||Usage-based Object Similarity|  Katja Niemann (Fraunhofer Institute for Applied Information Technology FIT, SchlossBirlinghoven, Germany)   Maren Scheffel (Fraunhofer Institute for Applied Information Technology FIT, SchlossBirlinghoven, Germany)   Martin Friedrich (Fraunhofer Institute for Applied Information Technology FIT, SchlossBirlinghoven, Germany)   Uwe Kirschenmann (Fraunhofer Institute for Applied Information Technology FIT, SchlossBirlinghoven, Germany)   Hans-Christian Schmitz (Fraunhofer Institute for Applied Information Technology FIT, SchlossBirlinghoven, Germany)   Martin Wolpers (Fraunhofer Institute for Applied Information Technology FIT, SchlossBirlinghoven, Germany)  Abstract: Recommender systems are widely used online to   support users in finding relevant information. They can be based on   different techniques such as content-based and collaborative   filtering. In this paper, we introduce a new way of similarity   calculation for item-based collaborative filtering. Thereby we focus   on the usage of an object and not on the object's users as we claim   the hypothesis that similarity of usage indicates content   similarity. To prove this hypothesis we use learning objects   accessible through the MACE portal where students can query several   architectural repositories. For these objects, we generate object   profiles based on their usage monitored within MACE. We further   propose several recommendation techniques to apply this usagebased   similarity calculation in real systems.               Keywords: attention metadata, item-based collaborative filtering, recommender systems               Categories: H.3.3, H.4.0, L.3.2  
16|17|http://www.jucs.org/jucs_16_17|Foundations and Practices of Unified Modeling Language|
16|17||Checking the Conformance between Models Based on Scenario Synchronization|  Duc-Hanh Dang (University of Engineering and Technology, Vietnam)   Anh-Hoang Truong (University of Engineering and Technology, Vietnam)   Martin Gogolla (University of Bremen, Germany)  Abstract: Narrowing the wide conceptual gap between problem and implementation domains is considered a significant factor within software engineering. Currently, such a relation is often obtained using mappings between metamodels for a structural semantics. This paper proposes an approach based on the integration of Triple Graph Grammars (TGGs) and the Object Constraint Language (OCL) in order to explain a behavioral relation between models at different levels of abstraction. Triple rules incorporating OCL allow us to synchronize execution scenarios of a system at two levels. In this way we obtain an integrated operational semantics of the models as well as the possibility for conformance verification between them. We illustrate our approach with a case study for the relation between use case and design models.               Keywords: Invariant, OCL, Pre- and Postcondition, Snapshot, UML, graph transformation, model transformation, model validation, model-driven development               Categories: D.2.4, D.m, H.2.3  
16|17||UML Support for Designing Software Product Lines:  The Package Merge Mechanism|  Miguel A. Laguna (University of Valladolid, Spain)   José M. Marqués (University of Valladolid, Spain)  Abstract: Software product lines have become a successful   but challenging approach to software reuse. Some of the problems   that hinder the adoption of this development paradigm are the   conceptual gap between the variability and design models, as well as   the complexity of the traceability management between them. Most   current development methods use UML stereotypes or modify UML to   face variability and traceability issues. Commercial tools focus   mainly on code management, at a fine-grained level. However, the use   of specialized techniques and tools represent additional barriers   for the widespread introduction of product lines in software   companies. In this paper, we propose an alternative based on the UML   package merge mechanisms to reflect the structure   of the variability models in product line package   architecture, thus making the traceability of the   configuration decisions straightforward. This package architecture   and the configuration of the concrete products are automatically   generated (using Model Driven Engineering techniques) from the   variability models. As an additional advantage, the package merge   mechanism can be directly implemented at code level using partial   classes (present in languages such as C#). To support the proposal,   we have developed a tool incorporated into MS Visual Studio. This   tool permits the product line variability to be modeled and the   required transformations to be automated, including the final   compilation of concrete products. A case study of a successful   experience is described in the article as an example of applying   these techniques and tools. The proposed approach, a combination of   UML techniques and conventional IDE tools, can make the development   of product lines easier for an organization as it removes the need   for specialized tools and personnel.               Keywords: Merge Relationship, Software Product Line, UML, traceability, variability               Categories: D.2.13, D.2.2  
16|17||Developing a Secure Mobile Grid System through a UML Extension|  David G. Rosado (Alarcos Research Group, University of Castilla-La Manch, Spain)   Eduardo Fernández-Medina (Alarcos Research Group, University of Castilla-La Manch, Spain)   Javier López (University of Málaga, Spain)   Mario Piattini (Alarcos Research Group, University of Castilla-La Mancha, Spain)  Abstract: The idea of developing software through systematic development processes to improve software quality is not new. Nevertheless, there are still many information systems such as those of Grid Computing which are not developed through methodologies that are adapted to their most differentiating features. A systematic development process for Grid systems that supports the participation of mobile nodes and incorporates security aspects into the entire software lifecycle will thus play a significant role in the development of systems based on Grid computing. We are creating a development process for the construction of information systems based on Grid Computing, which is highly dependent on mobile devices, in which security plays a highly important role. One of the activities in this process is that of analysis which is focused on ensuring that the system's security and functional requirements are elicited, specified and modelled. In our approach, this activity is driven by use cases and supported by the reusable repository. This obtains, builds, defines and refines the use cases of the secure Mobile Grid systems which represent the functional and non-functional requirements of this kind of systems. In this paper, we present the proposed development process through which we introduce the main aspects of the UML profile defined for building use case diagrams in the mobile Grid context through which it is possible to represent specific mobile Grid features and security aspects, showing in detail how to build use case diagrams for a real mobile Grid application by using our UML profile, denominated as GridUCSec-Profile.               Keywords: UML extension, Use Cases, secure development, secure mobile grid, security               Categories: C.2.4, D.2.1, K.6.5, L.4, L.7  
16|17||Linking UML and MDD through UML Profiles: a Practical Approach based on the UML Association|  Giovanni Giachetti (Universidad Politécnica de Valencia, Spain)   Manuela Albert (Universidad Politécnica de Valencia, Spain)   Beatriz Marín (Universidad Politécnica de Valencia, Spain)   Oscar Pastor (Universidad Politécnica de Valencia, Spain)  Abstract: In a model-driven development context, the   definition (or selection) of an appropriate modeling language is a   crucial task. OMG, in the model-driven architecture specification,   recommends the use of UML for model-driven developments. However,   the lack of semantic precision in UML has led to different   model-driven approaches proposing their own domain-specific modeling   languages in order to introduce their modeling needs. This paper   focuses on customizing the UML association in order to facilitate   its application in model-driven development environments. To do   this, a well-defined process is defined to integrate the abstract   syntax of a domain-specific modeling language that supports a   precise semantics for the association construct in UML by means of   the automatic generation of a UML profile. Finally, a brief example   shows how the results obtained by the application of the proposed   process can generate software products through a real model   compilation tool.               Keywords: Association, DSML, MDA, MDD, Profile, UML               Categories: D.2.12, D.2.2, D.3.3, H.1.1, I.6.5  
16|17||Systematic Management of Variability in UML-based Software Product Lines|  Edson A. Oliveira Junior (University of Sã Paulo, Brazil)   Itana M. S. Gimenes (State University of Maringá, Brazil)   José C. Maldonado (University of Sã Paulo, Brazil)  Abstract: This paper presents SMarty, a   variability management approach for UMLbased software product lines   (PL). SMarty is supported by a UML profile, the   SMartyProfile, and a process for managing   variabilities, the   SMartyProcess. SMartyProfile   aims at representing variabilities, variation points, and variants   in UML models by applying a set of   stereotypes. SMartyProcess consists of a set of   activities that is systematically executed to trace, identify, and   control variabilities in a PL based on SMarty. It   also identifies variability implementation mechanisms and analyzes   specific product configurations. In addition, a more comprehensive   application of SMarty is presented using SEI's   Arcade Game Maker PL. An evaluation of SMarty and   related work are discussed.               Keywords: Profile, Stereotypes, UML-based Software Product Lines, Variability Management               Categories: D.2, D.2.10, D.2.2  
16|17||Developing and Analyzing the MP (Materialization Pattern) Model for Math Educational Standards|  Namyoun Choi (Drexel University, USA)   Il-Yeol Song (Drexel University, USA)   Yuan An (Drexel University, USA)  Abstract: Educational standard s alignment , which matches   similar or equivalent concepts of educational standards, is a   necessary task for educational resource retrieval.  In order to   automate the alignment task, it is important to model the semantics   of educational standards statements that are imperative mood   sentences .  In this paper, we present the MP (Materialization   Pattern) model for representing the semantics of math educational   standards for the purpose of aligning math educational standard s.   This article first classifies math educational standard s statements   into 16 types and then converts them to the MP model.  The MP model   is based on the Reed-Kellogg sentence diagrams, and created as MP   diagrams using the UML notation. The MP model explicitly represents   the semantics of the sentences by capturing math concepts and the   cognitive process of the math concepts from math educational   standards statements .  The MP model is developed for automating the   alignment of math educational standards.               Keywords: MP (Materialization Pattern) model, Unified Modeling Language               Categories: H.1  
16|17||UML Behavior Models of Real-Time Embedded Software for Model-Driven Architecture|  Jinhyun Kim (Korea University, S.Korea)   Jin-Young Choi (Korea University, S.Korea)   Inhye Kang (University of Seoul, S.Korea)   Insup Lee (University of Pennsylvania, USA)  Abstract: Model-Driven Architecture (MDA) presents a set of layered models to separate design concerns from platform concerns. The model executability for each model element is still challenging although MDA is currently able to cope with most syntactic and transformation definition issues. Moreover, the importance of rigorous specification and verification of the system is increasing, as the embedded software is more widely used for systems closely related to our life. Thus, this paper suggests behavior modeling views characterizing Platform-Independent Model (PIM) and Platform-Specific Model (PSM) behaviors and formal and verifiable models for them. In this, the PIM behavior is given from the view of the functionality of the software in Statecharts, whereas the PSM behavior is modeled from the view of a timed and resource-constrained behavior in TRoS, an extension of Statecharts in respect of time and resource constraints. Moreover, we provide an efficient way where PIM in Statecharts is transformed into PSM in TRoS. Using our approach, PIM and PSM behavior are captured in formal semantics for rigorous analysis in terms of system behavior, and the PSM behavior in TRoS is effectively and consistently obtained from the PIM behavior in Statecharts. We present a case study, in which safety-critical software for a railway control system is developed to show the feasibility of our approach.               Keywords: MDA, behavior models, formal models, real-time embedded software, statecharts               Categories: D.2, D.2.1, D.2.10  
16|17||Toward an Integrated Tool Environment for Static Analysis of UML Class and Sequence Models|  Wuliang Sun (Colorado State University, USA)   Eunjee Song (Baylor University, USA)   Paul C. Grabow (Baylor University, USA)   Devon M. Simmonds (University of North Carolina at Wilmington, USA)  Abstract: There is a need for more rigorous analysis   techniques that developers can use for verifying the critical   properties in UML models. The UML-based Specification Environment   (USE) tool supports verification of invariants, preconditions, and   postconditions specified in the Object Constraint Language   (OCL). Due to its animation and analysis power, it is useful when   checking critical non-functional properties such as security   policies. However, the USE requires one to specify a model using its   own textual language and does not allow one to import any model   specification files created by other UML modeling tools. Hence, you   would create a model with OCL constraints using a modeling tool such   as the IBM Rational Software Architect (RSA) and then use the USE   for the model verification. This approach, however, requires a   manual transformation between two different specification formats,   which diminishes advantage of using tools for model-level   verification. In this paper, we describe our own implementation of a   specification transformation engine based on the Model-Driven   Architecture (MDA) framework. Our approach currently supports   automatic tool-level transformations to USE from UML modeling tools   built on the Eclipse-based Modeling Framework (EMF).               Keywords: MDA, Model Analysis, OCL, USE, XMI, model transformation               Categories: D.2.1, D.2.2, D.2.4  
16|17||Verification of Structural Pattern Conformance Using Logic Programming|  Lunjin Lu (Oakland University, USA)   Dae-Kyoo Kim (Oakland University, USA)   Yuanlin Zhu (Oakland University, USA)   Sangsig Kim (Oakland University, USA)  Abstract: This paper formalizes UML class diagrams and   structural patterns as mathematical objects and provides a precise   notion of conformance of a structural model specified as a class   diagram to a structural pattern. We also present a conformance   verification method which represents a class diagram as a logic   program and a structural pattern as a query. The conformance of the   class diagram to the structural pattern is verified by computing all   the answers to the query by the logic program and checking the   satisfaction of realization multiplicity constraints imposed by the   pattern.               Keywords: Prolog, UML, design pattern, logic programming, pattern conformance               Categories: D.2.10, D.2.13  
16|17||An MDA Approach for Goal-oriented Requirement Analysis in Web Engineering|  José Alfonso Aguilar (University of Alicante, Spain)   Irene Garrigós (University of Alicante, Spain)   Jose-Norberto Mazón (University of Alicante, Spain)   Juan Trujillo (University of Alicante, Spain)  Abstract: Web designers usually ignore how to model real user expectations and goals, mainly due to the large and heterogeneous audience of the Web. This fact leads to websites which are difficult to comprehend by visitors and complex to maintain by designers. In order to ameliorate this scenario, an approach for using the i* modeling framework in Web engineering has been developed in this paper. Furthermore, due to the fact that most of the existing Web engineering approaches do not consider how to derive conceptual models of the Web application from requirements analysis we also propose the use of MDA (Model Driven Architecture) in Web engineering for: (i) the definition of the requirements of a Web application in a Computational Independent Model (CIM), (ii) the description of Platform Independent Models (PIMs), and (iii) the definition of a set of QVT (Query/View/Transformation) transformations for the derivation of PIMs from requirements specification (CIM), thus to enable the automatic generation of Web applications. Finally, we include a sample of our approach in order to show its applicability and we describe a prototype tool as a proof of concept of our research.               Keywords: MDA, Web engineering, goal-oriented requirements, model transformations, requirements analysis               Categories: D.2.1, D.2.2  
16|18|http://www.jucs.org/jucs_16_18|Computability and Complexity in Analysis|
16|18||Canonical Effective Subalgebras of Classical Algebras as Constructive Metric Completions|  Andrej Bauer (University of Ljubljana, Slovenia)   Jens Blanck (Swansea University, United Kingdom)  Abstract: We prove general theorems about unique existence   of effective subalgebras of classical algebras. The theorems are   consequences of standard facts about completions of metric spaces   within the framework of constructive mathematics, suitably   interpreted in realizability models. We work with general   realizability models rather than with a particular model of   computation. Consequently, all the results are applicable in various   established schools of computability, such as type 1 and type 2   effectivity, domain representations, equilogical spaces, and   others.               Keywords: computable and effective algebra, constructive metric spaces, realizability               Categories: G.0  
16|18||A Constructive Study of Landau's Summability Theorem|  Josef Berger (Ludwig-Maximilians-Universität München, Germany)   Douglas S. Bridges (University of Canterbury, New Zealand)  Abstract: A summability theorem of Landau, which   classically is a simple consequence of the uniform boundedness   theorem, is examined within Bishop-style constructive   mathematics. It is shown that the original theorem is   nonconstructive, and that a natural weakening of the theorem is   constructively equivalent to Ishihara's principle   BD-N. The paper ends with a number of results   that, while not as strong as Landau's theorem, nevertheless contain   positive computational information related to its   conclusion.               Keywords: lp space, Landau, constructive, summability               Categories: F.4.0  
16|18||Realisability for Induction and Coinduction with Applications to Constructive Analysis|  Ulrich Berger (Swansea University, United Kingdom)  Abstract: We prove the correctness of a formalised realisability interpretation of extensions of first-order theories by inductive and coinductive definitions in an untyped λ-calculus with fixed-points. We illustrate the use of this interpretation for program extraction by some simple examples in the area of exact real number computation and hint at further non-trivial applications in computable analysis.               Keywords: coinduction, constructive analysis, program extraction, realisability               Categories: F.3, F.3.1, F.3.2  
16|18||On Choice Principles and Fan Theorems|  Hannes Diener (Universität Siegen, Germany)   Peter Schuster (University of Leeds, United Kingdom)  Abstract: Veldman proved that the contrapositive of   countable binary choice is a theorem of full-fledged intuitionism,   to which end he used a principle of continuous choice and the fan   theorem. It has turned out that continuous choice is unnecessary in   this context, and that a weak form of the fan theorem suffices which   holds in the presence of countable choice. In particular, the   contrapositive of countable binary choice is valid in Bishop-style   constructive mathematics. We further discuss a generalisation of   this result and link it to Ishihara's boundedness principle   BD-N.               Keywords: constructive mathematics, countable choice, fan theorem               Categories: G.0  
16|18||The Separation of Relativized Versions of P and DNP for the Ring of the Reals|  Christine Gaßner (Ernst-Moritz-Arndt-Universität Greifswald, Germany)  Abstract: We consider the uniform BSS model of computation   where the machines can perform additions, multiplications, and tests   of the form x ≥ 0. The oracle machines can also   check whether a tuple of real numbers belongs to a given oracle set   or not. We present oracle sets containing positive integers and   pairs of numbers, respectively, such that the classes P and DNP   relative to these oracles are not equal. The first set is   constructed by diagonalization techniques and the second one is   derived from the Knapsack Problem.               Keywords: BSS model, binary non-determinism, digital non-determinism, oracle machine, relativizations               Categories: F.1, F.1.1, F.1.2, F.1.3  
16|18||Isometries and Computability Structures|  Zvonko Iljazović (University of Zagreb, Croatia)  Abstract: We investigate the relationship between   computable metric spaces (Χ, d, α) and   (Χ, d, β), where (Χ,   d) is a given metric space. In the case of   Euclidean space, α and β are equivalent up to isometry,   which does not hold in general. We introduce the notion of   effectively dispersed metric space and we use it in the proof of the   following result: if (Χ, d, α) is   effectively totally bounded, then (Χ, d, β)   is also effectively totally bounded. This means that the property   that a computable metric space is effectively totally bounded (and   in particular effectively compact) depends only on the underlying   metric space. In the final section of this paper we examine compact   metric spaces (Χ, d) such that there are   only finitely many isometries Χ → Χ. We prove that   in this case a stronger result holds than the previous one: if   (Χ, d, α) is effectively totally   bounded, then α and β are equivalent. Hence if (Χ,   d, α) is effectively totally bounded, then   (Χ, d) has a unique computability   structure.               Keywords: computability structure, computable metric space, effective compactness, effective dispersion, effective total boundedness, isometry               Categories: F.0, F.1, G.0  
16|18||Semantics of Query-Driven Communication of Exact Values|  Michal Konečný (Aston University, United Kingdom)   Amin Farjudian (Aston University, United Kingdom)  Abstract: We address the question of how to communicate among distributed processes valuessuch as real numbers, continuous functions and geometrical solids with arbitrary precision, yet efficiently. We extend the established concept of lazy communication using streams of approximants by introducing explicit queries. We formalise this approach using protocols of a query-answer nature. Such protocols enable processes to provide valid approximations with certain accuracy and focusing on certain locality as demanded by the receiving processes through queries.   A lattice-theoretic denotational semantics of channel and process behaviour is developed. Thequery space is modelled as a continuous lattice in which the top element denotes the query demanding all the information, whereas other elements denote queries demanding partial and/or local information. Answers are interpreted as elements of lattices constructed over suitable domains of approximations to the exact objects. An unanswered query is treated as an error anddenoted using the top element.      A robust prototype implementation of our model is available.               Keywords: dataflow networks, denotational semantics, distributed computation, domain theory, exact real computation               Categories: C.2.4, F.1.1, F.3.2, G.0, G.1.0  
16|18||Compositional Semantics of Dataflow Networks with Query-Driven Communication of Exact Values|  Michal Konečný (Aston University, United Kingdom)   Amin Farjudian (Aston University, United Kingdom)  Abstract: We develop and study the concept of   dataflow process networks as used for exampleby   Kahn to suit exact computation over data types related to real   numbers, such as continuous functions and geometrical   solids. Furthermore, we consider communicating these exact   objectsamong processes using protocols of a query-answer nature as   introduced in our earlier work. This enables processes to provide   valid approximations with certain accuracy and focusing on   certainlocality as demanded by the receiving processes through   queries.  We define domain-theoretical denotational semantics of our networks in two ways: (1) directly, i. e. by viewing the whole network as a composite process and applying the process semantics introduced in our earlier work; and (2) compositionally, i. e. by a fixed-point construction similarto that used by Kahn from the denotational semantics of individual processes in the network. The direct semantics closely corresponds to the operational semantics of the network (i. e. it iscorrect) but very difficult to study for concrete networks. The compositional semantics enablescompositional analysis of concrete networks, assuming it is correct.  We prove that the compositional semantics is a safe approximation of the direct semantics. Wealso provide a method that can be used in many cases to establish that the two semantics fully coincide, i. e. safety is not achieved through inactivity or meaningless answers. The results are extended to cover recursively-defined infinite networks as well as nested finitenetworks.  A robust prototype implementation of our model is available.               Keywords: dataflow networks, denotational semantics, distributed computation, domain theory, exact real computation               Categories: C.2.4, F.1.1, F.3.2, G.0, G.1.0  
16|18||From Computing Sets of Optima, Pareto Sets, and Sets of Nash Equilibria to General Decision-Related Set Computations|  Vladik Kreinovich (University of Texas at El Paso, USA)   Bartlomiej Jacek Kubica (Warsaw University of Technology, Poland)  Abstract: Several algorithms have been proposed to compute sets of optima, Pareto sets, and sets of Nash equilibria. In this paper, we present a general algorithm for decision-related set computations that includes all these algorithms as particular cases.   To make our algorithm understandable to people working in optimization and in game theory, we also provide motivations and explanations for our formalizations of the corresponding problems and for the related notions of computable mathematics.               Keywords: Nash equilibria, Pareto sets, computing sets, sets of optima               Categories: F.2.1, F.4, G.1.m  
16|18||How Incomputable is Finding Nash Equilibria?|  Arno Pauly (University of Cambridge, United Kingdom)  Abstract: We investigate the Weihrauch-degree of several solution concepts from noncooperative game theory. While the consideration of Nash equilibria forms the core of our work, also pure and correlated equilibria, as well as various concepts of iterated strategy elimination, are dealt with. As a side result, the Weihrauch-degree of solving systems of linear inequalities is settled.               Keywords: Computable Analysis, Discontinuity, Game Theory, Nash Equilibrium,, Weihrauch-degree               Categories: F.2.0  
16|18||A Note on Closed Subsets in Quasi-zero-dimensional Qcb-spaces|  Matthias Schröder (Universität der Bundeswehr, Germany)  Abstract: We introduce the notion of   quasi-zero-dimensionality as a substitute for the notion of   zero-dimensionality, motivated by the fact that the latter behaves   badly in the realm of qcb-spaces. We prove that the category   QZ of quasi-zero-dimensional qcblt;sub>0lt;/sub>-spaces is   cartesian closed. Prominent examples of spaces in   QZ are the spaces of the Kleene-Kreisel   continuous functionals equipped with the respective sequential   topology. Moreover, we characterise some types of closed subsets of   QZ-spaces in terms of their ability to allow   extendability of continuous functions. These results are related to   a problem in Computable Analysis.               Keywords: Computable Analysis, Extendability, Qcb-spaces               Categories: F.1.1  
16|18||Computable Separation in Topology, from T0 to T2|  Klaus Weihrauch (University of Hagen, Germany)  Abstract: This article continues the study of computable   elementary topology started in [Weihrauch and Grubba 2009]. For   computable topological spaces we introduce a number of computable   versions of the topological separation axioms   T0,   T1 and   T2. The axioms form an   implication chain with many equivalences. By counterexamples we show   that most of the remaining implications are proper. In particular,   it turns out that computable   T1 is equivalent to   computable T2 and that for   spaces without isolated points the hierarchy collapses, that is, the   weakest computable T0   axiom WCT0 is equivalent to the strongest computable   T2 axiom SCT2. The   SCT2-spaces are closed   under Cartesian product, this is not true for most of the other   classes of spaces. Finally we show that the computable version of a   basic axiom for an effective topology in intuitionistic topology is   equivalent to SCT2.               Keywords: axioms of separation, computable analysis, computable topology               Categories: F.0, F.m, G.0, G.m  
16|19|http://www.jucs.org/jucs_16_19|Advances in Authoring of Adaptive Web-based Systems|
16|19||Merging Strategies for Authoring QoE-based Adaptive Hypermedia|  Joshua Scotton (The University of Warwick, United Kingdom)   Sabine Moebs (Dublin City University, Ireland)   Jennifer McManis (Dublin City University, Ireland)   Alexandra I. Cristea (The University of Warwick, United Kingdom)  Abstract: Personalization is desirable, but writing the   adaptation behaviour description to go with it is   taxing. Even more challenging is the application of multiple   adaptation strategies over the same static content. This paper   focuses on recent work on strategy modularisation and   merger development in the authoring process of adaptive   hypermedia. The reason for the modularisation of   strategies is to break a complex adaptation decision into   a number of simpler ones, which may be reused more easily and   applied in different orders. The rationale for strategy   merger is to be able to apply multiple adaptation   strategies over the same content — a challenge which is not yet   fully addressed in current adaptive hypermedia systems. To   demonstrate the proposed method we present an example case study and   sample strategies written in the LAG adaptation language. The case   study is based on a recently proposed model for Quality of   Experience in e-learning. This model exposes the complex interaction   between a number of factors affecting QoE and hence presents a good   candidate for the application of a strategy merger, as well as   modularisation. We have then evaluated this approach via structured   questionnaires used with a number of design experts of hypermedia   content creation, especially in the domain of education. This allows   us to draw generic conclusions for both our own further research, as   well as for the community at large, interested in the area of reuse   and modularisation of adaptation.               Keywords: Adaptation, Adaptive (Educational) Hypermedia, LAG, Multimedia Learning, Quality of Experience, Quality of Service, Strategy merger, Strategy modularisation               Categories: M.5, M.6, M.7, M.8  
16|19||Authoring and Delivering Personalised Simulations — an Innovative Approach to Adaptive eLearning for Soft Skills|  Conor Gaffney (Trinity College Dublin, Ireland)   Declan Dagger (Trinity College Dublin, Ireland)   Vincent Wade (Trinity College Dublin, Ireland)  Abstract: This paper examines the personalization of   online training simulations which are a key modern approach in   computer aided education. More specifically it focuses on the   difficulties involved in authoring personalized training   simulations. The composition of such systems is very difficult which   has hampered their wide spread adoption [Joolingen, 03]. Presently   adaptive training simulations can only be authored by programmers   working closely with subject matter experts. One of the key ways for   adaptive simulations to increase their popularity in online   eLearning [Wade, 09] is to reduce the effort and technical skills   required by authors in their development. We argue that personalized   online simulations need to be composed by subject matter experts,   inexpensively and quickly. This paper details the twin challenges in   composing content for both educational simulations and   personalization. It also describes ACTSim, a new and unique   composition tool that supports the rapid development of personalized   training simulations. In particular ACTSim focuses on situational   simulations for inter personal dialogue, so called soft skills. This   paper concludes with a series of evaluations of the composition tool   and of courses developed using the composition tool.               Keywords: adaptive, authoring, simulation, soft skills               Categories: I.6.8, J.7, L.2, L.3.0, L.5.0  
16|19||Authoring of Probabilistic Sequencing in Adaptive Hypermedia with Bayesian Networks|  Sergio Gutierrez-Santos (Birkbeck College, United Kingdom)   Jaime Mayor-Berzal (Carlos III University of Madrid, Spain)   Carmen Fernandez-Panadero (Carlos III University of Madrid, Spain)   Carlos Delgado Kloos (Carlos III University of Madrid, Spain)  Abstract: One of the difficulties that self-directed   learners face on their learning process is choosing the right   learning resources. One of the goals of adaptive educational systems   is helping students in finding the best set of learning resources   for them. Adaptive systems try to infer the students'   characteristics and store them in a user model whose information is   used to drive the adaptation. However, the information that can be   acquired is always limited and partial. In this paper, the use of   Bayesian networks is proposed as a possible solution to adapt the   sequence of activities to students. There are two research questions   that are answered in this paper: whether Bayesian networks can be   used to adaptively sequence learning material, and whether such an   approach permits the reuse of learning units created for other   systems. A positive answer to both question is complemented with a   case study that illustrates the details of the process.               Keywords: Bayesian networks, adaptive educational hypermedia, sequencing               Categories: L.2.0, L.2.1, L.3.5  
16|19||Execution Model and Authoring Middleware Enabling Dynamic Adaptation in Educational Scenarios Scripted with PoEML|  Roberto Perez-Rodriguez (University of Vigo, Spain)   Manuel Caeiro-Rodríguez (University of Vigo, Spain)   Luis Anido-Rifon (University of Vigo, Spain)   Martín Llamas-Nistal (University of Vigo, Spain)  Abstract: The design of adaptive e-learning systems has   been approached from different points of view. Adaptive Educational   Hypermedia (AEH) conceptual frameworks, usually decompose this   problem into separate concerns: a User Model (UM), an Adaptation   Model (AM), and a Domain Model (DM). Regarding Educational Modelling   Languages (EMLs), they provide adaptation mechanisms such as the   modelling of participants following conditional learning   paths over a common content   structure. The design of adaptive learning paths in EMLs   (the Adaptation Model) is predefined during design-time, and no   changes on it are allowed during run-time. In this paper we describe   the support of dynamic adaptation features (run-time changes on   models) using PoEML (Perspective-oriented EML) as modelling   language, with focus on the execution model of the PoEML engine and   on a SOA-based middleware used by authoring tools to invoke change   primitives.               Keywords: Adaptive Learning Systems, Dynamic Adaptation, Educational Modelling Languages               Categories: M.5  
16|19||A Tool for Managing Domain Knowledge and Helping Tutors in Intelligent Tutoring Systems|  Panayiotis Kyriakou (University of Patras, Greece)   Ioannis Hatzilygeroudis (University of Patras, Greece)   John Garofalakis (University of Patras, Greece)  Abstract: Intelligent Tutoring Systems (ITSs) constitute a popular type of intelligent educational systems. Domain Knowledge (DK) is a basic part of an ITS and usually includes information about the concepts the ITS is dealing with and the teaching material itself. The teaching material consists of a set of learning objects (LOs). A LO is described by a data set called its metadata. Concepts are usually organized in a network, called a concept network (or map). Each concept is associated with a number of LOs. Existing tools for managing DK mainly deal with either LOs or concepts, but not with connecting them. In this paper, we present a tool for managing both types of information in DK: creating and editing a concept network and LO metadata as well as connecting them. Additionally, the tool can produce corresponding XML descriptions for each LO metadata. Finally, it provides facilities for helping tutors in organizing and composing their lessons. A small scale evaluation has shown more than satisfactory acceptability of the tool.               Keywords: Domain Knowledge management, Intelligent Tutoring Systems, Learning Objects management, Lesson organization               Categories: K.3.1, L.1.0, L.1.2, L.2.0, L.3.0  
16|19||Model-driven Transformation and Validation of Adaptive Educational Hypermedia using CAVIAr|  Mark Melia (Dublin City University, Ireland)   Claus Pahl (Dublin City University, Ireland)  Abstract: Authoring of Adaptive Educational Hypermedia is   a complex activity requiring the combination of a range of design   and validation techniques. We demonstrate how Adaptive Educational   Hypermedia can be transformed into CAVIAr courseware validation   models allowing for its validation. The model-based representation   and analysis of different concerns and model-based mappings and   transformations are key contributors to this integrated solution. We   illustrate the benefits of Model Driven Engineering methodologies   that allow for interoperability between CAVIAr and a well known   Adaptive Educational Hypermedia framework. By allowing for the   validation of Adaptive Educational Hypermedia, the course creator   limits the risk of pedagogical problems in migrating to Adaptive   Educational Hypermedia from static courseware.               Keywords: Adaptive e-learning, Courseware Validation, Courseware authoring, Courseware construction, Model-driven engineering               Categories: D.2.2, H.1.0, L.2.0, L.3.0  
16|19||A Method for Supporting Heterogeneous-Group Formation through Heuristics and Visualization|  Pedro Paredes (Universidad Autónoma de Madrid, Spain)   Alvaro Ortigosa (Universidad Autónoma de Madrid, Spain)   Pilar Rodriguez (Universidad Autónoma de Madrid, Spain)  Abstract: Group formation is a key issue in e-learning   environments that make use of collaborative work to enhance student   performance. While there are many ways to arrange students to work   in cooperative groups, recent works have shown that learning styles   offer good opportunities to organize students. Particularly, it   seems the case that regarding learning styles, heterogeneous groups   tend to perform better than groups formed by students with similar   characteristics. This work addresses the issue of supporting the   authors task of forming effective learner groups to improve student   and group performance. This support is provided through a supervised   method which, backed by a visualization tool, is able to produce   groups with a good level of heterogeneity. Moreover, this method is   not time-consuming for teachers.               Keywords: Authoring Tool, Collaborative Work, Group Formation, Learning Styles               Categories: L.3.3, L.3.6, L.6.2  
16|2|http://www.jucs.org/jucs_16_2|Lisp: Research and Experience|
16|2||An Extensible Interpreter Framework for Software Transactional Memory|  Charlotte Herzeel (Vrije Universiteit Brussel, Belgium)   Pascal Costanza (Vrije Universiteit Brussel, Belgium)   Theo D'Hondt (Vrije Universiteit Brussel, Belgium)  Abstract: Software transactional memory (STM) is a new   approach for coordinating concurrent threads, for which many   different implementation strategies are currently being   researched. In this paper we show that if a language implementation   provides reflective access to explicit memory locations, it becomes   straightforward to both (a) build an STM framework for this language   and (b) to implement STM algorithms using this framework. A   proof-of-concept implementation in the form of a Scheme interpreter   (written in Common Lisp) is presented.               Keywords: Lisp, memory location objects, software transactional memory               Categories: D.1.3, D.3.3  
16|2||"Revisiting the Visitor: the ""Just Do It"" Pattern"|  Didier Verna (Epita Research and Development Laboratory, France)  Abstract: While software design patterns are a generally   useful concept, they areoften (and mistakenly) seen as ready-made   universal recipes for solving common problems. In a way, the danger   is that programmers stop thinking about their actual prob-lem, and   start looking for pre-cooked solutions in some design pattern book   instead. What people usually forget about design patterns is that   the underlying programminglanguage plays a major role in the exact   shape such or such pattern will have on the surface. The purpose of   this paper is twofold: we show why design pattern expressionis   intimately linked to the expressiveness of the programming language   in use, and we also demonstrate how a blind application of them can   in fact lead to very poorlydesigned code.               Keywords: Lisp, design patterns, meta-programming, object orientation               Categories: D.1.5, D.3.3  
16|2||Embedding Hygiene-Compatible Macros in an Unhygienic Macro System|  Pascal Costanza (Vrije Universiteit Brussel, Belgium)   Theo D'Hondt (Vrije Universiteit Brussel, Belgium)  Abstract: It is known that the essential ingredients of a   Lisp-style unhygienic macro system can be expressed in terms of   advanced hygienic macro systems. We show that the reverse is also   true: We present a model of a core unhygienic macro system, on top   of which a hygiene-compatible macro system can be built, without   changing the internals of the core macro system and without using a   code walker. To achieve this, the internal representation of source   code as Lisp s-expressions does not need to be changed. The major   discovery is the fact that symbol macros can be used in conjunction   with local macro environments to bootstrap a hygiene-compatible   macro system. We also discuss a proof-of-concept implementation in   Common Lisp and give historical notes.               Keywords: common Lisp, hygiene-compatible macro systems, scheme               Categories: D.1.1, D.3.3, D.3.4  
16|2||Systematic Unit Testing in a Read-eval-print Loop|  Kurt Nørmark (Aalborg University, Denmark)  Abstract: Lisp programmers constantly carry out   experiments in a read-eval-print loop. The experimental activities   convince the Lisp programmers that new or modified pieces of   programs work as expected. But the experiments typically do not   represent systematic and comprehensive unit testing efforts. Rather,   the experiments are quick and dirty one shot validations which do   not add lasting value to the software, which is being developed. In   this paper we propose a tool that is able to collect, organize, and   re-validate test cases, which are entered as expressions in a   read-eval-print loop. The process of collecting the expressions and   their results imposes only little extra work on the programmer. The   use of the tool provides for creation of test repositories, and it   is intended to catalyze a much more systematic approach to unit   testing in a read-evalprint loop. In the paper we also discuss how   to use a test repository for other purposes than testing. As a   concrete contribution we show how to use test cases as examples in   library interface documentation. It is hypothesized--but not yet   validated--that the tool will motivate the Lisp programmer to take   the transition from casual testing to systematic testing.               Keywords: Emacs, interactive unit testing, program examples, scheme programming               Categories: D.1.1, D.2.5, D.2.6  
16|2||Using Lisp Implementation Internals Unportable but Fun|  Christophe Rhodes (University of London New Cross, United Kingdom)  Abstract: We present a number of developer tools and   language extensions that are available for use with Steel Bank   Common Lisp, but which are perhaps not as wellknown as they could   be. Our motivation is twofold: firstly, to introduce to a developer   audience facilities that can make their development or deployment of   software more rapid or efficient. Secondly, in the context of the   development of the Common Lisp language itself, we offer some   observations of patterns of use of such extensions within the   development community, and discuss the implications this has on   future evolution of the language.               Keywords: Lisp, development tools, language evolution, language extensions               Categories: D.2.12, D.2.3, D.3.3  
16|20|http://www.jucs.org/jucs_16_20|Evolving Theories of Conceptual Modelling|
16|20||Validating Modal Aspects of OntoUML Conceptual Models Using Automatically Generated Visual World Structures|  Alessander Botti Benevides (Federal University of Espírito Santo (UFES), Brazil)   Giancarlo Guizzardi (Federal University of Espírito Santo (UFES), Brazil)   Bernardo Ferreira Bastos Braga (Federal University of Espírito Santo (UFES), Brazil)   Joao Paulo Andrade Almeida (Federal University of Espírito Santo (UFES), Brazil)  Abstract: Assessing the quality of conceptual models is   key to ensure that conceptual models can be used effectively as a   basis for understanding, agreement and construction of information   systems. This paper proposes an approach to assess conceptual models   defined in OntoUML by transforming these models into specifications   in the logic-based language Alloy. These Alloy specifications   include the modal axioms of the theory underlying OntoUML, allowing   us to validate the modal meta-properties representing ontological   commitments of the OntoUML types and relations.               Keywords: formal definitions and theory, knowledge representation formalisms and methods, model validation and analysis               Categories: D.3.1, I.2.4, I.6.4  
16|20||Redundant Relations in Relational Databases: A Model Theoretic Perspective|  Flavio Antonio Ferrarotti (Universidad de Santiago de Chile, Chile)   Alejandra Lorena Paoletti    José María Turull Torres (Massey University, New Zealand)  Abstract: We initiate in this work the study of a sort of   redundancy problem revealed by what we call redundant   relations. Roughly, we define a redundant relation in a database   instance (dbi) as a k-ary relation R such that there is a   first-order query which evaluated in the reduced dbi, (i.e., the dbi   without the redundant relation R) gives us R. So, given that   first-order types are isomorphism types on finite structures, we can   eliminate that relation R as long as the equivalence classes of the   relation of equality of the first-order types for all k-tuples in   the dbi are not altered. It turns out that in a fixed dbi, the   problem of deciding whether a given relation in the dbi is redundant   is decidable, though intractable, as well as the problem of deciding   whether there is any relation symbol in the schema which is a   redundant relation in the given dbi. We then study redundant   relations with a restricted notion of equivalence so that the   problem becomes tractable.               Keywords: first-order types, isomorphism types, redundancy, relational databases               Categories: H.2, H.2.1, H.2.3  
16|20||Internal Representation of Database Views|  Stephen J. Hegner (Umeå University, Sweden)  Abstract: Although a database view embodies partial   information about the state of the main schema, the state of the   view schema is a quotient (and not a subset) of the state of the   main schema. It is the information content of the view state, the   set of sentences which are true for that state, and not the state   itself which is a subset of the information content of the state of   the main schema. There are thus two dual approaches to modelling   this partiality, one based upon structures, with a consequent   quotient relationship, and another based upon logical theories, with   a consequent subset relationship. In this work, a representation for   database views is developed which combines these two approaches. The   state-based representation is expanded so that the information   content embodied in a wide class of views, including those defined   by SPJ queries, is fully representable, thus permitting the view   state to be modelled internally as a subset of the main database   state. The utility of this framework is demonstrated with a simple   solution to the uniqueness problem for view updates via constant   complement.               Keywords: database, information, modelling, view               Categories: H.1.1, H.2.1  
16|20||A Geometrically Enhanced Conceptual Model and Query Language|  Hui Ma (Victoria University of Wellington, New Zealand)  Abstract: Motivated by our experiences with spatial   modelling for the sustainable land use initiative we present a   geometrically enhanced ER model (GERM), which preserves the key   principles of entity-relationship modelling and at the same time   introduces bulk constructors and geometric features. The model   distinguishes between a syntactic level of types and an explicit   internal level, in which types give rise to polyhedra that are   defined by algebraic varieties. It further emphasises the stability   of algebraic operations by means of a natural modelling algebra that   extends the usual Boolean operations on point sets.               Keywords: conceptual model, entity-relationship model, geometric model, natural modelling algebra, query language, spatial model               Categories: E.m, H.1.10  
16|20||Providing a Proof-Theoretical Basis for Explanation: A Case Study on UML and ALCQI Reasoning|  Alexandre Rademaker (PUC-Rio, Brazil)   Edward Hermann Haeusler (PUC-Rio, Brazil)  Abstract: In this article we argue in favour of Natural   Deduction Systems as a basis for formal proof explanations. We   illustrate our choice presenting a Natural Deduction for   ALCQI and use it to help explain UML reasoning.               Keywords: ALC, ALCQI, Description Logics, Proof Theory, Sequent Calculus, UML, natural deduction               Categories:  F.4.1, M.4  
16|20||XML Database Transformations|  Klaus-Dieter Schewe (Software Competence Centre Hagenberg, Austria)   Qing Wang (University of Otago, New Zealand)  Abstract: Database transformations provide a unifying umbrella for queries and updates. In general, they can be characterised by five postulates, which constitute the database analogue of Gurevich's sequential ASM thesis. Among these postulates the background postulate supposedly captures the particularities of data models and schemata. For the characterisation of XML database transformations the natural first step is therefore to define the appropriate tree-based backgrounds, which draw on hereditarily finite trees, tree algebra operations, and extended document type definitions. This defines a computational model for XML database transformation using a variant of Abstract State Machines. Then the incorporation of weak monadic second-order logic provides an alternative computational model called XML machines. The main result is that these two computational models for XML database transformations are equivalent.               Keywords: Abstract State Machine, Monadic Second-order Logic, Tree Algebra, computation background, database transformation, eXtensible Markup Language               Categories: E.1, F.1.1, F.4.1, H.2.3, I.7.2  
16|20||Support for Schema Evolution in Data Stream Management Systems|  James F. Terwilliger (Microsoft Corporation, USA)   Rafael J. Fernández-Moctezuma (Portland State University, USA)   Lois M. L. Delcambre (Portland State University, USA)   David Maier (Portland State University, USA)  Abstract: Unlike Database Management Systems (DBMSs), Data Stream Management Systems (DSMSs) do not evaluate queries over static data sets — rather, they continuously produce result streams to standing queries, and often operate in a context where any interruption can lead to data loss. Support for schema evolution in such an environment is currently unaddressed. In this work we address evolution in DSMSs by introducing a new element to streams, called an accent, that precedes and describes an evolution. We characterize how a subset of commonly used query operators in DSMS act on and propagate accents with respect to three evolution primitives: Add Attribute, Drop Attribute, and Alter Data.               Keywords: data streams, schema evolution               Categories: H.2.1, H.2.4, H.2.8  
16|20||Towards a Theory of Conceptual Modelling|  Bernhard Thalheim (Christian Albrechts University Kiel, Germany)  Abstract: Conceptual modelling is a widely applied practice and has led to a large body of knowledge on constructs that might be used for modelling and on methods that might be useful for modelling. It is commonly accepted that database application development is based on conceptual modelling. It is however surprising that only very few publications have been published on a theory of conceptual modelling.  Modelling is typically supported by languages that are well-founded and easy to apply for the description of the application domain, the requirements and the system solution. It is thus based on a theory of modelling constructs. At the same time, modelling incorporates a description of the application domain and a prescription of requirements for supporting systems. It is thus based on methods of application domain gathering. Modelling is also an engineering activity with engineering steps and engineering results. It is thus engineering. The first facet of modelling has led to a huge body of knowledge. The second facet is considered from time to time in the scientific literature. The third facet is underexposed in the scientific literature.  This paper aims in developing principles of conceptual modelling. They cover modelling constructs as well as modelling activities as well as modelling properties. We first clarify the notion of conceptual modelling. Principles of modelling may be applied and accepted or not by the modeler. Based on these principles we can derive a theory of conceptual modelling that combines foundations of modelling constructs, application capture and engineering.  A general theory of conceptual modelling is far too comprehensive and far too complex. It is not yet visible how such a theory can be developed. This paper therefore aims in introducing a framework and an approach to a general theory of conceptual modelling. We are however in urgent need of such a theory. We are sure that this theory can be developed and use this paper for the introduction of the main ingredients of this theory.               Keywords: conceptual modelling, general theory of models, modelling, modelling act(ivity), principles of models and modelling               Categories: H.0, H.1.0, H.2.1, H.2.2, I.6.4, I.6.5, L.1.0, M.4  
16|20||Extending the Methods for Computing the Importance of Entity Types in Large Conceptual Schemas|  Antonio Villegas (Universitat Politècnica de Catalunya, Spain)   Antoni Olivé (Universitat Politècnica de Catalunya, Spain)  Abstract: Visualizing and understanding large conceptual schemas requires the use of specific methods. These methods generate clustered, summarized, or focused schemas that are easier to visualize and understand. All of these methods require computing the importance of each entity type in the schema. In principle, the totality of knowledge defined in the schema could be relevant for the computation of that importance but, up to now, only a small part of that knowledge has been taken into account. In this paper, we extend seven existing methods for computing the importance of entity types by taking into account more relevant knowledge de_ned in the structural and behavioural parts of the schema. We experimentally evaluate the original and extended versions of these methods with three large real-world schemas. We present the two main conclusions we have drawn from the experiments.               Keywords: Conceptual Modeling, Large Schemas, Visualization               Categories: H.0, H.1, H.3.3, H.5  
16|21|http://www.jucs.org/jucs_16_21|Managing Editor's Column|
16|21||Watermarking Techniques for Relational Databases: Survey, Classification and Comparison|  Raju Halder (Università Ca' Foscari Venezia, Italy)   Shantanu Pal (University of Calcutta, India)   Agostino Cortesi (Università Ca' Foscari Venezia, Italy)  Abstract: Digital watermarking for relational databases   emerged as a candidate solution to provide copyright protection,   tamper detection, traitor tracing, maintaining integrity of   relational data. Many watermarking techniques have been proposed in   the literature to address these purposes. In this paper, we survey   the current state-of-theart and we classify them according to their   intent, the way they express the watermark, the cover type, the   granularity level, and their verifiability.               Keywords: digital watermarking, fingerprinting, relational databases               Categories: D.2.4, E.3, H.2.4  
16|21||Assessing the Learning Path Specification: a Pragmatic Quality Approach|  José Janssen (Open University in the Netherlands, The Netherlands)   Adriana J. Berlanga (Open University in the Netherlands, The Netherlands)   Stef Heyenrath (Logica, The Netherlands)   Harry Martens (Open University in the Netherlands, The Netherlands)   Hubert Vogten (Open University in the Netherlands, The Netherlands)   Anton Finders (Open University in the Netherlands, The Netherlands)   Eelco Herder (L3S Research Centre, Germany)   Henry Hermans (Open University in the Netherlands, The Netherlands)   Javier Melero Gallardo (Universitat Pompeu Fabra, Spain)   Leon Schaeps (Open University in the Netherlands, The Netherlands)   Rob Koper (Open University in the Netherlands, The Netherlands)  Abstract: Finding suitable ways to achieve particular   learning goals is not an easy task, both in initial education and   lifelong learning.  To facilitate selection, personalisation and   navigation of learning paths we propose to describe learning paths   in a formal and uniform way by means of a learning path   specification. This paper explains the rationale behind the Learning   Path Specification. Based on a framework developed for the   evaluation of the specification the paper describes a study that was   carried out to establish pragmatic quality, i.e.  whether   stakeholders can understand and use the specification. The paper   explores the relationship between the concepts pragmatic quality,   usability, and desirability, and distinguishes first-order and   second-order pragmatic quality, relating it to different   stakeholders: software developers and end-users. First-order   pragmatic quality of the Learning Path Specification was evaluated   during the process of developing a tool that describes learning   paths according to the specification: the Learning Path   Editor. Second-order pragmatic quality was evaluated through   workshop sessions with end-users involving some hands-on experiences   with this tool. The paper describes adaptations made to the   specification in the process of developing the Editor. End-user   evaluations were quite positive, leading to one more   adaptation.               Keywords: desirability, evaluation, learning path specification, pragmatic quality, usability               Categories: L.3, L.3.0, L.3.6  
16|21||Refinement and Extension of SMDM, a Method for Defining Valid Measures|  Luis Reynoso (University of Comahue, Argentina)   Marcela Genero (University of Castilla-La Mancha, Spain)   Mario Piattini (University of Castilla-La Mancha, Spain)  Abstract: Although literature contains a huge amount of   measures for measuring quality characteristics of software artifacts   throughout the development life-cycle, the majority go no further   than the step of definition. The key to obtaining valid measures   which may be useful in practice is to carry out a definition of   these by following a rigorous method. In a previous work we defined   a method for obtaining valid measures, called SMDM (Software Measure   Definition Method). In this paper we present the extensions and   refinements of this method, which has been redefined in the light of   seven years of application to various software artifacts, such as   OCL expressions, UML diagrams, ER diagrams, Relational database   schemas, Datawarehouse conceptual models, etc. In order to   illustrate the redefined method, an example of the definition of a   measure for the import-coupling of OCL expressions is   presented.               Keywords: empirical validation, measure definition, psychological explanation, software measures, theoretical validation               Categories: D.2.8  
16|21||Biologically Plausible Connectionist Prediction of Natural Language Thematic Relations|"  João Luis Garcia Rosa (University of Sõo Paulo at Sõo Carlos, Brazil)   Juan Manuel Adan-Coello (Pontifical Catholic University of Campinas, Brazil)  Abstract: In Natural Language Processing (NLP) symbolic   systems, several linguistic phenomena, for instance, the thematic   role relationships between sentence constituents, such as AGENT,   PATIENT, and LOCATION, can be accounted for by the employment of a   rule-based grammar. Another approach to NLP concerns the use of the   connectionist model, which has the benefits of learning,   generalization and fault tolerance, among others. A third option   merges the two previous approaches into a hybrid one: a symbolic   thematic theory is used to supply the connectionist network with   initial knowledge. Inspired on neuroscience, it is proposed a   symbolic-connectionist hybrid system called BIOθPRED   (BIOlogically plausible thematic (θ)   symbolic-connectionist PREdictor),   designed to reveal the thematic grid assigned to a sentence. Its   connectionist architecture comprises, as input, a featural   representation of the words (based on the verb/noun WordNet   classification and on the classical semantic microfeature   representation), and, as output, the thematic grid assigned to the   sentence. BIOθPRED is designed to ""predict"" thematic   (semantic) roles assigned to words in a sentence context, employing   biologically inspired training algorithm and architecture, and   adopting a psycholinguistic view of thematic theory.               Keywords: biologically plausible connectionist models, natural language processing, thematic (semantic) role labeling               Categories: I.2.4, I.2.6, I.2.7, I.5.4  "
16|21||Integrating Personal Web Data through Semantically Enhanced Web Portal|"  Lidia Rovan (University of Zagreb, Croatia)   Tomislav Jagušt (University of Zagreb, Croatia)   Mirta Baranović (University of Zagreb, Croatia)  Abstract: Currently, the World Wide Web is mostly composed   of isolated and loosely connected ""data islands"". Connecting them   together and retrieving only the information that is of interest to   the user is the common Web usage process. Creating infrastructure   that would support automation of that process by aggregating and   integrating Web data in accordance to user's personal preferences   would greatly improve today's Web usage. A significant part of Web   data is available only through the login and password protected   applications.  As that data is very important for the usefulness of   described process, proposed infrastructure needs to support   authorized access to user's personal data. In this paper we propose   a semantically enhanced Web portal that presents unique personalized   user's entry to the domain-specific Web information. We also propose   an identity management system that supports authorized access to the   protected Web data. To verify the proposed solution, we have built   Sweb - a semantically enhanced Web portal that uses proposed   identity management system.               Keywords: OAuth, OpenID, Semantic Web, Web architecture, Web portal, personalization                "
16|21||Impact of CPU-bound Processes on IP Forwarding of Linux and Windows XP|  Khaled Salah (khaled.salah@kustar.ac.ae, UAE)   Mohamed Hamawi (King Fahd University of Petroleum and Minerals (KFUPM), Saudi Arabia)  Abstract: These days, commodity-off-the-shelf (COTS)   hardware and software are used to build high-end and powerful   workstations and servers to be deployed in today's local area   networks of private homes and small- to medium-sized   business. Typically, these servers are multipurpose and shared -   running networking functionalities involving IP packet forwarding in   addition to other CPU intensive applications.  In this paper we   study and investigate the impact of running CPU-bound applications   on the performance of IP packet forwarding.  We measure and compare   the impact and performance for the two operating systems of choice   for home and small-business users, namely Linux and Windows XP.  The   performance is studied in terms of key performance metrics which   include throughput, packet loss, round-trip delay, and CPU   availability. For our measurements, we consider today's typical home   network hosts of modern processors and Gigabit network cards.  We   also consider different configuration setups and utilize open-source   tools to generate relatively high traffic rates. Our empirical   results show that Linux exhibits superior performance over Windows   XP in terms of IP forwarding performance.  Results also show that,   unlike Windows XP, the IP forwarding performance of Linux is not   significantly impacted by running CPU-bound applications.               Keywords: IP forwarding, Linux, Windows, computer networks, network performance, operating systems               Categories: C.2, C.2.0, C.2.1, C.2.2, C.2.m  
16|21||Information Consolidation in Large Bodies of Information|"  Gerhard Wurzinger (Graz University of Technology, Austria)  Abstract: Due to information technologies the problem we   are facing today is not a lack of information but too much   information.  This phenomenon becomes very clear when we consider   two figures that are often quoted: Knowledge is doubling in many   fields (biology, medicine, computer science, ...) within some 6   years; yet information is doubling every 8 months! This implies that   the same piece of information/knowledge is published a large number   of times with small variations.    Just look at an arbitrary news   item. If considered of some general interest reports of it will   appear in all major newspapers, journals, electronic media,   etc. This is also the problem with information portals that tie   together a number of large databases.    It is our contention that we   need methods to reduce the huge set of information concerning a   particular topic to a number of pieces of information (let us call   each such piece an ""essay"" in what follows) that present a   good cross-section of potential points of view.  We will explain why   one essay is usually not enough, yet the problem of reducing a huge   amount of contributions to a digestible number of essays is   formidable, indeed is science fiction at the moment. We will argue   in this paper that it is one of the important tasks of computer   sciences to start tackling this problem, and we will show that in   some special cases partial solutions are possible.               Keywords: information consolidation               Categories: H.3.4, H.3.5, H.3.7, H.4.3, H.5.1, M.1  "
16|3|http://www.jucs.org/jucs_16_3|Managing Editor's Column|
16|3||Enabling Personal Privacy for Pervasive Computing Environments|"  Susana Alcalde Bagüés (Siemens AG, Germany)   Andreas Zeidler (Siemens AG, Germany)   Ignacio R. Matias (Public University of Navarra, Spain)   Cornel Klein (Siemens AG, Germany)   Carlos Fernandez Valdivielso (Public University of Navarra, Spain)  Abstract: Protection of personal data in the Internet is   already a challenge today. Users have toactively look up privacy   policies of websites and decide whether they can live with the terms   of use. Once discovered, they are forced to make a ""`take or leave""'   decision. In future living andworking environments, where sensors   and context-aware services are pervasive, this becomes an even   greater challenge and annoyance. The environment is much more   personalized and userscannot just ""`leave""'. They require measures   to prevent, avoid and detect misuse of sensitive data, as well as to   be able to negotiate the purpose of use of data. We present a novel   modelof privacy protection, complementing the notion of enterprise   privacy with the incorporation of personal privacy towards a   holistic privacy management system. Our approach allows   non-expertusers not only to negotiate the desired level of privacy   in a rather automated and simple way, but also to track and monitor   the whole life-cycle of data.               Keywords: personal privacy, pervasive computing, privacy architecture, user manageability               Categories: D.2.11, K.4.2, K.6.5, L.7  "
16|3||Mobile Agent Routing with Time Constraints: A Resource Constrained Longest-Path Approach|  Eduardo Camponogara (Federal University of Santa Catarina, Brazil)   Ricardo Boveto Shima (Federal University of Santa Catarina, Brazil)  Abstract: Mobile agent technology advocates the mobility   of code rather than the transfer of data. As data is found in   several sites, a mobile agent has to plan an itinerary to visit   several sites where it collects resources to accomplish its   mission. This gives rise to the mobile-agent itinerary problem (MIP)   which seeks a route maximizing overall benefit from the resources   while meeting a deadline. This paper formalizes MIP and develops a   reduction to the resource constrained longest-path problem (CLPP) in   acyclic graphs. A dynamic programming (DP) algorithm was designed to   produce a family of optimal routes, allowing a mobile agent to   dynamically revise its route. A fully-polynomial approximation   scheme was developed to reduce the pseudo-polynomial running time of   DP, whereby the distance to the optimal is controlled by a parameter   ffl and the running time is limited by a polynomial on problem size   and 1/ffl. The paper reports results from experiments assessing the   performance of the algorithms and discusses extensions to handle   non-additive objectives, non-additive constraints, and probabilistic   resource constraints.               Keywords: approximation algorithms, constrained longest-path, constrained routing, dynamic programming, mobile agents               Categories: F.2.2, G.2.2, I.2.11  
16|3||Block-based Against Segmentation-based Texture Image Retrieval|  Mohammad Faizal Ahmad Fauzi (Multimedia University, Malaysia)   Paul H. Lewis (University of Southampton, United Kingdom)  Abstract: This paper concerns the best approach to the capture of local texture features for use in content-based image retrieval (CBIR) applications. From our previous work, two approaches have been suggested, the multiscale block-based approach and the automatic texture segmentation approach. Performance comparison as well as advantages and disadvantages of the two methods are presented in this paper. The databases used are the Brodatz and VisTex databases, as well as three museum image collections of various sizes and contents, with each collection presenting different challenges to the CBIR systems. Experimental observations suggest that the two approaches both perform well, with the multiscale technique having the edge in retrieval performance and scale invariance, while the segmentation technique has the edge in lighter computational complexity as well as having the shape information for later purposes. The choice between the two approaches thus depends on application.               Keywords: content-based image retrieval, discrete wavelet frames, multiscale technique, texture, texture segmentation               Categories: H.3.1, H.3.3  
16|3||Situational Method Engineering: State-of-the-Art Review|"  Brian Henderson-Sellers (University of Technology, Australia)   Jolita Ralyté (University of Geneva, Switzerland)  Abstract: The situational method engineering (SME)   literature is surveyed and a synoptic evaluation presented in the   context of formalizing and regularizing the conceptual framework and   underpinning theory. Metamodels proposed for use in SME are   evaluated as well as high-level process models for method   construction. Method fragments and method chunks are then described   formally followed by their identification and creation (from   existing methods, from scratch or from past usage). Method creation   is then analyzed in terms of various processes for constructing a   full methodology from the method fragments/chunks. In particular, we   contrast the use of the ""map"" technique and of the ""deontic matrix""   technique. The survey is concluded with an evaluation of some ideas   on method tailoring and the emerging research on quality evaluation   applied to SME.               Keywords: design, information systems, metamodels, method chunks, method component, method configuration, method construction, method fragments, method tailoring, methodology, situational method engineering, software engineering               Categories: D.2.2  "
16|3||A Model for Capturing and Managing Software Engineering Knowledge and Experience|"  Gerardo Matturro (Universidad ORT Uruguay, Uruguay)   Andrés Silva (Universidad Politécnica de Madrid, Spain)  Abstract: During software development projects there is always a particular working ""product"" that is generated but rarely managed: the knowledge and experience that team members acquire. This knowledge and experience, if conveniently managed, can be reused in future software projects and be the basis for process improvement initiatives. In this paper we present a model for managing the knowledge and experience team members acquire during software development projects in a non-disruptive way, by integrating its management into daily project activities. The purpose of the model is to identify and capture this knowledge and experience in order to derive lessons learned and proposals for best practices that enable an organization to preserve them for future use, and support software process improvement activities. The main contribution of the model is that it enables an organization to consider knowledge and experience management activities as an integral part of its software projects, instead of being considered, as it was until now, as a follow-up activity that is (infrequently) carried out after the end of the projects.               Keywords: experience capture, knowledge management, software engineering               Categories: M.2, M.8  "
16|4|http://www.jucs.org/jucs_16_4|Trusted Computing|
16|4||On Reliable Platform Configuration Change Reporting Mechanisms for Trusted Computing Enabled Platforms|  Kurt Dietrich (Graz University of Technology, Austria)  Abstract: One of the most important use-cases of Trusted   Computing is Remote Attestation. Itallows platforms to get a   trustworthy proof of the loaded software and current configuration   of certain remote platforms, thereby enabling them to make decisions   about the remote platforms'trust status. Common concepts like   Internet Protocol security or Transport Layer Security make these   decisions based on shared secrets or certificates issued by third   parties. Unlike remote at-testation, these concepts do not take the   current configuration or currently loaded software of the platforms   into account. Consequently, combining remote attestation and   existing secure channelconcepts can solve the long lasting problem   of secure channels that have to rely on insecure channel   endpoints. Although this gap can now be closed by Trusted Computing,   one important prob-lem remains unsolved: A platform's configuration   changes everytime new software is loaded. Consequently, a reliable   and in-time method to provide a proof for this configuration change   -especially on multiprocess machines - is required to signal the   platforms involved in the communication that a configuration change   of the respectively other platform has taken place. Ourresearch   results show that a simple reporting mechanism can be integrated   into current Trusted Platform Modules and Transport Layer Security   implementations with a few additional TrustedPlatform Modules   commands and a few extensions to the TLS protocol.               Keywords: TLS, platform configuration reporting, remote attestation, secure channels, trusted computing               Categories: K.6.5, L.4  
16|4||Performance Optimizations for DAA Signatures on Java enabled Platforms|  Kurt Dietrich (Graz University of Technology, Austria)   Franz Röck (Graz University of Technology, Austria)  Abstract: With the spreading of embedded and mobile devices, public-key cryptography hasbecome an important feature for securing communication and protecting personal data. However, the computational requirements of public-key cryptosystems are often beyond the constraints em-bedded processors are bound to. This is especially true for cryptosystems that make heavy use of modular exponentiation like the Direct Anonymous Attestation scheme. The most popular al-gorithm for modular exponentiation is the Montgomery exponentiation based on sliding window technology. This technology offers several configuration options in order to get the best trade-offbetween the amount of precomputations and multiplications that are required for different exponentiation operands. Consequently, the optimum configuration and best parameters for receivingthe highest performance gain are of interest. In this paper, we analyse different approaches for improving the performance of modular exponentiations with respect to the DAA scheme on Javaenabled platforms. In particular, we analyse the optimal parameter setting for the Montgomery exponentiation and investigate how natively executed modular multiplications and modular re-ductions, with respect to a minimum of native code involved, can be integrated to improve the performance of mobile Java applications. Our experimental results show that the optimal setupof the Montgomery algorithm for a single modular exponentiation differs from the optimal setup used for the combination of all operations and operands used in the Direct Anonymous Attesta-tion scheme. We also show that it is possible to get an immense performance gain by executing small parts of critical arithmetic operations natively on the platform thereby, not reducing theflexibility of mobile Java code.               Keywords: DAA, anonymous credentials, remote attestation, trusted computing               Categories: K.6.5, L.4  
16|4||Towards a Virtual Trusted Platform|  Martin Pirker (Graz University of Technology, Austria)   Ronald Toegl (Graz University of Technology, Austria)  Abstract: The advances and adoption of Trusted Computing   and hardware assisted virtualisation technologies in standard PC   platforms promise new approaches in building a robust virtualisation   platform for security sensitive software modules. The amalgam of   these technologies allows an attractive off-the-shelf environment,   capable of supporting security levels potentially higher than   commonly deployed today. This article proposes a practical approach   of combining technology elements available today to create such a   platform using available components. The design supports operating   high-security and low-security compartments side by side. The high   security compartment is able to use the functionality of the Trusted   Platform Module. The low security compartment is isolated through   hardware-assisted virtualisation. The platform boots via Intel   Trusted Execution Technology to resist manipulation. We discuss the   building blocks of the architecture and present a number of open   research challenges.               Keywords: security, trusted computing, virtualisation               Categories: D.4.6  
16|4||Static Analysis of the XEN Kernel using Frama-C|  Armand Puccetti (Centre d'Etudes Nucléaires, France)  Abstract: In this paper, we describe the static analysis   of the XEN 3.0.3 hypervisor using the Frama-C static analysis   tool.               Keywords: Linux, abstract interpretation, static analysis, virtualisation               Categories: D.2.4  
16|4||VIMM: Runtime Integrity Measurement of a Virtualized Operating System|  Chun Hui Suen (TU München, Germany)  Abstract: This paper discusses the design of the Virtualization Integrity Measurement Monitor (VIMM) framework, which aims to provide runtime integrity measurement of a virtualized guest OS. Kernel memory and additional hardware state changes are constantly monitored and aggregated into a combined guest OS state, which is reported to a Trusted Platform Module (TPM), thus providing a trusted integrity measurement in runtime. This measurement can then be used for data protection (sealing of secret keys) and remote attestation based on the runtime integrity of the guest OS.               Keywords: management, security and protection               Categories: D.2.9, D.4.6, K.6.5  
16|5|http://www.jucs.org/jucs_16_5|Seventy Years Derick Wood|
16|5||On Succinct Representations of Textured Surfaces by Weighted Finite Automata|"  Jürgen Albert (University of Würzburg, Germany)   German Tischler (King's College London, United Kingdom)  Abstract: Generalized finite automata with weights for   states and transitions have been successfully applied to image   generation for more than a decade now. Bilevel images (black and   white), grayscale- or color-images and even video sequences can be   effectively coded as weighted finite automata. Since each state   represents a subimage within those automata the weighted transitions   can exploit self-similarities for image compression. These ""fractal""   approaches yield remarkable results in comparison to the well-known   standard JPEG- or MPEG-encodings and frequently provide advantages   for images with strong contrasts. Here we will study the combination   of these highly effective compression techniques with a   generalization of weighted finite automata to higher dimensions,   which establish d-dimensional relations between resultsets of   ordinary weighted automata. For the applications we will restrict   ourselves to three-dimensional Bezier spline-patches and to   grayscale images as textures.               Keywords: Bezier splines, Parametric Weighted Finite Automata, Weighted Finite Automata, bicubic Bezier patches, image compression, polynomials, self-similarity, textured surfaces               Categories: F.1.1, I.3.3, I.3.5, I.3.7  "
16|5||Investigating a Correlation between Subcellular Localization and Fold of Proteins|  Johannes Aßfalg (Ludwig-Maximilians-Universität München, Germany)   Jing Gong (Ludwig-Maximilians-Universität München, Germany)   Hans-Peter Kriegel (Ludwig-Maximilians-Universität München, Germany)   Alexey Pryakhin (Ludwig-Maximilians-Universität München, Germany)   Tiandi Wei (Ludwig-Maximilians-Universität München, Germany)   Arthur Zimek (Ludwig-Maximilians-Universität München, Germany)  Abstract: When considering the prediction of a structural   class for a protein as a classificationproblem, usually a classifier   is based on a feature vector x ∊   ℝn, where the   features represent certain attributes of the primary sequence or   derived properties (e.g., the predicted secondary structure) of a   given protein. Since the structure of a protein (i.e., its native   conformation) is stable only under specific environmental conditions,   it is commonly accepted to assume proteins being evolutionarily   adapted to specific subcellular localizations and according to their   physicochemical environment. Our statistical evaluation shows a   strong correlation between the subcellular localization of proteins   and their structural class. The correlation is strong enough to   allow fora classification of proteins into their structural class   solely based on information regarding the subcellular   localization. We conclude that knowledge regarding the subcellular   localization ofproteins can be useful as a feature for the   structural classification of proteins.               Keywords: bioinformatics, protein fold prediction, protein subcellular localization               Categories: I.2.6, J.3  
16|5||NP-completeness and FPT Results for Rectilinear Covering Problems|  Vladimir Estivill-Castro (Griffith University, Australia)   Apichat Heednacram (Griffith University, Australia)   Francis Suraweera (Griffith University, Australia)  Abstract: This paper discusses three rectilinear (that is,   axis-parallel) covering problems in   d dimensions and their   variants. The first problem is the RECTILINEAR LINE COVER where the   inputs are n points in   ℝd and a positive integer   k, and we are asked to answer if we can cover   these n points with at most k   lines where these lines are restricted to be axis parallel. We show   that this problem has efficient fixed-parameter tractable (FPT)   algorithms. The second problem is the RECTILINEAR   k-LINKS SPANNING PATH PROBLEM where the inputs   are also n points in   ℝd and a positive   integer k but here we are asked to answer if   there is a piecewise linear path through these n   points having at most k line-segments (links)   where these line-segments are axisparallel. We prove that this   second problem is FPT under the assumption that no two line-segments   share the same line. The third problem is the RECTILINEAR HYPERPLANE   COVER problem and we are asked to cover a set of   n points in d dimensions with   k axis-parallel hyperplanes of   d - 1 dimensions. We also demonstrate this has an   FPT-algorithm. Previous to the results above, only conjectures were   enunciated over several years on the NP-completeness of the   RECTILINEAR MINIMUM LINK TRAVELING SALESMAN PROBLEM, the MINIMUM   LINK SPANNING PATH PROBLEM and the RECTILINEAR HYPERPLANE COVER. We   provide the proof that the RECTILINEAR MINIMUM LINK TRAVELING   SALESMAN PROBLEM and the RECTILINEAR MINIMUM LINK SPANNING PATH   PROBLEM are NP-complete by a reduction from the ONE-IN-THREE 3-SAT   problem. The NP-completeness of the RECTILINEAR HYPERPLANE COVER   problem is proved by a reduction from 3-SAT. This suggests dealing   with the intractability just discovered with fixed-parameter   tractability. Moreover, if we extend our problems to a finite set of   orientations, our approach proves these problems remain   FPT.               Keywords: computational geometry, parameterized complexity, restricted orientations               Categories: F.1, F.2, F.2.2  
16|5||Orthogonal Concatenation: Language Equations and State Complexity|  Mark Daley (University of Western Ontario London, Canada)   Michael Domaratzki (University of Manitoba Winnipeg, Canada)   Kai Salomaa (Queen's University, Canada)  Abstract: A language L is the   orthogonal concatenation of languages   L1 and   L2 if every word of   L can be written in a unique way as a   concatenation of a word in   L1 and a word in   L2. The notion can be   generalized for arbitrary language operations. We consider   decidability properties of language orthogonality and the   solvability of language equations involving the orthogonal   concatenation operation. We establish a tight bound for the state   complexity of orthogonal concatenation of regular   languages.               Keywords: decidability, language equations, language operations, regular languages, state complexity               Categories: F.1.3, F.4.3  
16|5||The Tourist in the Shopping Arcade|  Rudolf Fleischer (Fudan University, China)   Tom Kamphans (Braunschweig University of Technology, Germany)   Rolf Klein (University of Bonn, Germany)   Elmar Langetepe (University of Bonn, Germany)   Gerhard Trippen (University of British Columbia, Canada)  Abstract: A tourist is searching for a gift and moves   along a shopping arcade until the desired object gets into   sight. The location of the corresponding shop is not known in   advance. Therefore in this on-line setting the tourist has to make a   detour in comparison to an optimal off-line straight line path to   the desired object. We can show that there is a strategy for the   tourist, so that the path length is never greater than C* times the   optimal off-line path length, where C* = 1.059401   . . . holds. Furthermore, there is no strategy that attains a   competitive factor smaller than C*.               Keywords: computational geometry, on-line algorithms, on-line navigation               Categories: F.2, G.2  
16|5||Reachability in Restricted Walk on Integers|  Philip Ginzboorg (Nokia Research Center, Finland)   Valtteri Niemi (Nokia Research Center, Switzerland)  Abstract: We prove that two conditions are sufficient, and   with three exceptions also necessary, for reachability of any   position in restricted walk on integers in which the sizes of the   moves to the left and to the right are constant but need not be   equal. A method to compute the length of the shortest path between   any two positions, as well as a shortest path algorithm when the   reachability conditions are true are given. Also a complete   characterization for Hamiltonian restricted walks between absorbing   boundaries is given.               Keywords: Hamiltonian path, random walk, reachability, shortest path, strong connectivity               Categories: C.3, G.2.2  
16|5||On the Linear Number of Matching Substrings|  Yo-Sub Han (Yonsei University, Republic of Korea)  Abstract: We study the number of matching substrings in   the pattern matching problem. In general, there can be a quadratic   number of matching substrings in the size of a given text. The   linearizing restriction enables to find at most a linear number of   matching substrings. We first explore two well-known linearizing   restriction rules, the longest-match rule and the   shortest-match substring search rule, and show   that both rules give the same result when a pattern is an infix-free   set even though they have different semantics. Then, we introduce a   new linearizing restriction, the leftmost nonoverlapping   match rule that is suitable for find-and-replace   operations in text searching, and propose an efficient algorithm for   the new rule when a pattern is described by a regular expression. We   also examine the problem of obtaining the maximal number of   non-overlapping matching substrings.               Keywords: Thompson automata, linearizing restriction, regular expression searching, string pattern matching               Categories: F.2, F.4.3  
16|5||Algebras and Update Strategies|"  Michael Johnson (Macquarie University Sydney, Australia)   Robert Rosebrugh (Mount Allison University, Canada)   Richard Wood (Dalhousie University, Canada)  Abstract: The classical (Bancilhon-Spyratos)   correspondence between view update translations and views with a   constant complement reappears more generally as the correspondence   between update strategies and meet complements in the order based   setting of S. Hegner. We show that these two theories of database   view updatability are linked by the notion of ""lens"" which is an   algebra for a monad. We generalize lenses from the category of sets   to consider them in categories with finite products, in particular   the category of ordered sets.               Keywords: algebra, lens, update strategy               Categories: E.1, H.1, H.2  "
16|5||Entropy and Higher Moments of Information|  Helmut Jürgensen (University of Waterloo, Canada)   David E. Matthews (University of Waterloo, Canada)  Abstract: The entropy of a finite probability space or,   equivalently, a memoryless source is the average information content   of an event. The fact that entropy is an expectation suggests that   it could be quite important in certain applications to take into   account higher moments of information and parameters derived from   these like the variance or skewness. In this paper we initiate a   study of the higher moments of information for sources without   memory and sources with memory. We derive properties of these   moments for information defined in the sense of Shannon and indicate   how these considerations can be extended to include the concepts of   information in the sense of Aczél or Rényi. For memoryless sources,   these concepts are immediately supported by the usual definitions of   moments; for general stationary sources, let alone general sources,   no such applicable framework seems to exist; on the other hand, the   special properties of stationary Markov sources suggest such   definitions which are both, well-motivated and mathematically   meaningful.               Keywords: entropy, information, moments of information, variance of information               Categories: F.1.0, F.2.0  
16|5||A Note on the P-completeness of Deterministic One-way Stack Language|  Klaus-Jörn Lange (Universiy of Tübingen, Germany)  Abstract: The membership problems of both stack automata   and nonerasing stack automata are shown to be complete for   polynomial time.               Keywords: automata, completeness, complexity classes, grammars               Categories: F.1.3, F.4.3  
16|5||SOM Clustering to Promote Interoperability of Directory Metadata: A Grid-Enabled Genetic Algorithm Approach|  Lei Li (Columbus State University, USA)   Vijay K. Vaishnavi (Georgia State University, USA)   Art Vandenberg (Georgia State University, USA)  Abstract: Directories provide a general mechanism for   describing resources and enabling information sharing within and   across organizations. Directories must resolve differing structures   and vocabularies in order to communicate effectively, and   interoperability of the directories is becoming increasingly   important. This study proposes an approach that integrates a genetic   algorithm with a neural network based clustering algorithm -   Self-Organizing Maps (SOM) - to systematically cluster directory   metadata, highlight similar structures, recognize developing   patterns of practice, and potentially promote homogeneity among the   directories. The proposed approach utilizes the computing power of   Grid infrastructure to improve system performance. The study also   explores the feasibility of automating the SOM clustering process in   a converging domain by incrementally building a stable SOM map with   respect to an initial reference set. Empirical investigations were   conducted on sets of Lightweight Directory Access Protocol (LDAP)   directory metadata. The experimental results show that the proposed   approach can effectively and efficiently cluster LDAP directory   metadata at the level of domain experts and a stable SOM map can be   created for a set of converging LDAP directory metadata.               Keywords: LDAP directory, clustering analysis, genetic algorithm, grid, reference set, self-organizing maps               Categories: H.3.1, H.3.3, H.4.0, H.5.0  
16|5||Ordered Catenation Closures and Decompositions of Languages Related to a Language of Derick Wood|  Arto Salomaa (Turku Centre for Computer Science, Finland)  Abstract: We investigate the problem of decomposing a   language into a catenation of nontrivial languages, none of which   can be decomposed further. In many cases this leads to the operation   of an ordered catenation closure, introduced in this paper. We study   properties of this operation, as well as its iterations. Special   emphasis is on laid on ordered catenation closures of finite   languages. It is also shown that if an infinite language is a code   or a length code, then its ordered catenation closure does not   possess a finite decomposition of indecomposable factors.               Keywords: code, decomposition of languages, finite language, indecomposable language, length code, ordered catenation closure               Categories: F.1.1, F.4.3  
16|5||Evaluating Linear XPath Expressions by Pattern-Matching Automata|  Panu Silvasti (Helsinki University of Technology, Finland)   Seppo Sippu (University of Helsinki, Finland)   Eljas Soisalon-Soininen (Helsinki University of Technology, Finland)  Abstract: We consider the problem of efficiently evaluating a large number of XPath expressions, especially in the case when they define subscriber profiles for filtering of XML documents. For each document in an XML document stream, the task is to determine those profiles that match the document. In this article we present a new general method for filtering with profiles expressed by linear XPath expressions with child operators (/), descendant operators (//), and wildcards (*). This new filtering algorithm is based on a backtracking deterministic finite automaton derived from the classic Aho-Corasick pattern-matching automaton. This automaton has a size linear in the sum of the sizes of the XPath filters, and the worst-case time bound of the algorithm is much less than the time bound of the simulation of linear-size nondeterministic automata.    Our new algorithm has a predecessor that can handle child and descendant operators but not wildcards, and has been shown to be extremely efficient when a documenttype definition (DTD) has been used to prune out all the wildcards and most of the descendant operators. But in some cases, such as when the DTD is highly recursive, it may not be possible to prune out all wildcards without producing a too large set of filters. Then it is important to have the full generality of an evaluation algorithm, as presented in this article, that can also handle wildcards.               Keywords: filtering of streams of XML documents, linear XPath expressions               Categories: H.3.3  
16|5||Detecting Market Trends by Ignoring It, Some Days|  Jessie Wenhui Zou (Bioinformatics Solution Inc., Canada)   Xiaotie Deng (City University of Hong Kong, Hong Kong)   Ming Li (II) (University of Waterloo, Canada)  Abstract: The last k days of trading together tell the   financial market trends. It may be inconceivable if we are told to   ignore the 3rd, 6th, and 8th day, a priori. We   introduce a novel approach to show exactly that - it pays to ignore   some fixed days among the recent k days, fixed a   priori,in order to minimize risk and maximize profit   simultaneously. The theory developed here has direct implications to   our common senses on how we should look at the financial market   trends.               Keywords: market trend prediction, optimal spaced seeds               Categories: F.0, J.0  
16|5||Derick Wood's Publications|  Helmut Jürgensen (The University of Western Ontario, Canada)  Abstract: This list of Derick Wood's publications has been   collected from several sources; the bibliographic data have been   verified and corrected or completed whenever possible. Technical   reports or similar internal publications are not listed if the   results of these were also published elsewhere; to generate a   complete list of Derick's technical reports would be a major   task. Electronic addresses of publications are only provided when   the only means by which to access such a work is the   internet.  We thank Tom Neumann and Jasna   Todorovic, students of Helmut Jürgensen, for compiling the   initial lists. We also thank Maia Hoeberechts, then PhD student of   Helmut Jürgensen, for her help with many aspects of the whole   project.  As Derick's publications span a vast variety of fields, we could not rely on just a few obvious sources, like the Mathematical Reviews, the Zentralblatt für Mathematik und ihre Grenzgebiete or the database at http://www.informatik.unitrier.de/~ley/db/index.html, but needed to search many other printed and electronic sources as well.               Keywords: theory of computation               Categories: F.0  
16|6|http://www.jucs.org/jucs_16_6|Computational Science and its Applications|
16|6||Newton Method for Nonlinear Dynamic Systems with Adaptive Time Stepping|  Wensheng Shen (State University of New York, USA)   Changjiang Zhang (University of Kentucky, USA)   Jun Zhang (University of Kentucky, USA)   Xiaoqian Ma (South China University of Technology, China)  Abstract: This paper presents a nonlinear solver based on   the Newton-Krylov methods, where the Newton equations are solved by   Krylov-subspace type approaches. We focus on the solution of   unsteady systems, in which the temporal terms are discretized by the   backward Euler method using finite difference. To save computational   cost, an adaptive time stepping is used to minimize the number of   time steps. The developed program can be applied to solve any   nonlinear equations, provided the users could supply the discrete   form of the equations. In particular, the nonlinear solver is   implemented to solve unsteady reacting flows.               Keywords: Newton-Krylov method, diffusion flame, iterative solver, nonlinear dynamics               Categories: G.1.8, J.2, J.6  
16|6||3D Head Pose and Facial Expression Tracking using a Single Camera|  Lucas D. Terissi (Universidad Nacional de Rosario, Argentina)   Juan C. Gómez (Universidad Nacional de Rosario, Argentina)  Abstract: Algorithms for 3D head pose and facial   expression tracking using a single camera (monocular image   sequences) is presented in this paper. The proposed method is based   on a combination of feature-based and model-based approaches for   pose estimation. A generic 3D face model, which can be adapted to   any person, is used for the tracking. In contrast to other methods   in the literature, the proposed method does not require a training   stage. It only requires an image of the person's face to be tracked   facing the camera to which the model is fitted manually through a   graphical user interface. The algorithms were evaluated perceptually   and quantitatively with two video databases. Simulation results show   that the proposed tracking algorithms correctly estimate the head   pose and facial expression, even when occlusions, changes in the   distance to the camera and presence of other persons in the scene,   occur. Both perceptual and quantitative results are similar to the   ones obtained with other methods proposed in the   literature. Although the algorithms were not optimized for speed,   they run near real time. Additionally, the proposed system delivers   separate head pose and facial expression information. Since   information related with facial expression, which is represented   only by six parameters, is independent from head pose information,   the tracking algorithms could also be used for facial expression   analysis and video-driven facial animation.               Keywords: 3D deformable models, computer vision, facial expression, head pose tracking, image processing               Categories: I.2.10, I.4, I.4.8  
16|6||A General Framework for Multi-Human Tracking using Kalman Filter and Fast Mean Shift Algorithms|  Ahmed Ali (University of Tokushima, Japan)   Kenji Terada (University of Tokushima, Japan)  Abstract: The task of reliable detection and tracking of   multiple objects becomes highly complex for crowded scenarios. In   this paper, a robust framework is presented for multi-Human   tracking. The key contribution of the work is to use fast   calculation for mean shift algorithm to perform tracking for the   cases when Kalman filter fails due to measurement error. Local   density maxima in the difference image - usually representing moving   objects - are outlined by a fast non-parametric mean shift   clustering procedure. The proposed approach has the robu st ability   to track moving objects, both separately and in groups, in   consecutive frames under some kinds of difficulties such as rapid   appearance changes caused by image noise and occlusion.               Keywords: Kalman filter, fast mean algorithm, human tracking               Categories: I.2.10, I.4  
16|6||Mining Feature-Opinion in Online Customer Reviews for Opinion Summarization|  Gamgarn Somprasertsri (King Mongkut's Institute of Technology Ladkrabang, Thailand)   Pattarachai Lalitrojwong (King Mongkut's Institute of Technology Ladkrabang, Thailand)  Abstract: Online customer reviews is considered as a   significant informative resource which is useful for both potential   customers and product manufacturers. In web pages, the reviews are   written in natural language and are unstructured-free-texts   scheme. The task of manually scanning through large amounts of   review one by one is computational burden and is not practically   implemented with respect to businesses and customer   perspectives. Therefore it is more efficient to automatically   process the various reviews and provide the necessary information in   a suitable form. The high-level problem of opinion summarization   addresses how to determine the sentiment, attitude or opinion that   an author expressed in natural language text with respect to a   certain feature. In this paper, we dedicate our work to the main   subtask of opinion summarization. The task of product feature and   opinion extraction is critical to opinion summarization, because its   effectiveness significantly affects the performance of opinion   orientation identification. It is important to properly identify the   semantic relationships between product features and opinions. We   proposed an approach for mining product feature and opinion based on   the consideration of syntactic information and semantic   information. By applying dependency relations and ontological   knowledge with probabilistic based model, the result of our   experiments shows that our approach is more flexible and   effective.               Keywords: customer feedback, dependency grammars, maximum entropy, opinion mining, opinion summarization, text mining               Categories: H.2.8, H.3.1, H.3.5, I.2.7  
16|6||Ontology based Approach in Knowledge Sharing Measurement|  Behrang ZadJabbari (Curtin University of Technology, Australia)   Pornpit Wongthongtham (Curtin University of Technology, Australia)   Farookh Khadeer Hussain (Curtin University of Technology, Australia)  Abstract: For many years, physical asset indicators were the main evidence of an organizations successful performance. However, the situation has changed following the revolution of information technology in the knowledge-based economy and in the new ideas in economy; knowledge assets are a critical strategic resource in economy. Knowledge management [KM] tools have become very important and in order to gain a competitive advantage, it is necessary to create, store, share and apply knowledge. Knowledge sharing is one of the key issues in knowledge management. One of the main challenges facing pioneer firms is to provide an effective strategy to exchange knowledge formally or informally. In this paper, we will discuss the effectiveness of knowledge sharing and our proposal for an effective knowledge sharing strategy. Based on a review of knowledge sharing literature, we will focus more on the trust and knowledge contexts as key issues in knowledge sharing. Trust is the most important issue when creating a relationship, knowledge sharing and partnership. Moreover, there are a number of forms that trust can take in these relationships and the most regularly cited forms are competence and benevolence trust. In this paper, we will explore these two forms of trust and will examine their role in knowledge sharing and how they can be defined and measured. On the other hand, we will apply ontologies to explore the knowledge context. Ontologies are used in widespread application areas particularly to provide a semantically shared domain knowledge in a declarative formalism for intelligent reasoning. Even ontology enables knowledge sharing; however, the complexity of knowledge being conceptualized in the ontology is critical to the success of knowledge sharing efforts. Other factors like trust in the source of knowledge can also affect knowledge transfer. In this paper, we propose metrics to measure the complexity of ontology for knowledge sharing. Finally, the effectiveness of our proposed knowledge sharing methodology is presented both using a fuzzy-inference engine and a crisp system.               Keywords: competency trust, knowledge complexity, knowledge sharing, knowledge transformability, ontology, tacit knowledge, trust measurement, willingness trust               Categories: I.2.4, I.2.8  
16|6||Entropy Optimization of Social Networks Using an Evolutionary Algorithm|  Maytham Safar (Kuwait University, Kuwait)   Nosayba El-Sayed (Kuwait University, Kuwait)   Khaled Mahdi (Kuwait University, Kuwait)   David Taniar (Monash University, Australia)  Abstract: Recent work on social networks has tackled the   measurement and optimization of these networks robustness and   resilience to both failures and attacks. Different metrics have been   used to quantitatively measure the robustness of a social   network. In this work, we design and apply a Genetic Algorithm that   maximizes the cyclic entropy of a social network model, hence   optimizing its robustness to failures. Our social network model is a   scale-free network created using Barabási and Albert's generative   model, since it has been demonstrated recently that many large   complex networks display a scale-free structure. We compare the   cycles distribution of the optimally robust network generated by our   algorithm to that belonging to a fully connected network. Moreover,   we optimize the robustness of a scale-free network based on the   links-degree entropy, and compare the outcomes to that which is   based on cycles-entropy. We show that both cyclic and degree entropy   optimization are equivalent and provide the same final optimal   distribution. Hence, cyclic entropy optimization is justified in the   search for the optimal network distribution.               Keywords: entropy, evolutionary algorithm, genetic algorithm, social networks               Categories: G.1.6, J.4, K.4.2, L.6.0, L.6.1, L.6.2  
16|7|http://www.jucs.org/jucs_16_7|Collective Intelligence with Visualization and Multimedia|
16|7||Collective Knowledge Engineering with Semantic Wikis|  Grzegorz J. Nalepa (University of Science Technology, Poland)  Abstract: In the paper application of semantic wikis as   knowledge engineering toolin a collaborative environment is   considered. Selected aspects of semantic wikis are discussed. The   main apparent limitation of existing semantic wikis is the lack of   expressiveknowledge representation mechanism. Building a knowledge   base with a semantic wiki becomes complicated because of its   collective nature, where number of users collaboratein the knowledge   engineering process. A need for knowledge evaluation and analysis   facilities become clear. The paper discusses a new semantic wiki   architecture calledPlWiki. The most important concept is to provide   a strong knowledge representation and reasoning with Horn   clauses-based representation. The idea is to use Prolog clauseson   the lower level to represent facts and relations, as well as define   rules on top of them. On the other hand a higher-level Semantic Web   layer using RDF support is provided.This allows for compatibility   with Semantic Media Wiki while offering improved representation and   reasoning capabilities. Another important idea is provide an   extension toalready available flexible wiki solution (DokuWiki)   instead of modifying existing wiki engine. Using the presented   architecture it is possible to analyze rule-based knowledgestored in   the wiki.               Keywords: knowledge engineering, knowledge evaluation, semantic wikis               Categories: H.1.2, H.3, H.5  
16|7||A Semantic Wiki Framework for Reconciling Conflict Collaborations Based on Selecting Consensus Choice|  Dosam Hwang (Yeungnam University, Korea)   Ngoc Thanh Nguyen (Wroclaw University of Technology, Poland)   Jason J. Jung (Yeungnam University, Korea)   Abolghasem Sadeghi-Niaraki (Inha University, Korea)   Kwang-Hyun Baek (Yeungnam University, Korea)   Young-Shin Han (Sungkyunkwan University, Korea)  Abstract: Semantic wikis have been regarded as an   important collaboration tool among a number of experts from multiple   domains. This wiki platform can play a role of collaborative   knowledge management system which can provide an efficient framework   to raise social interactions between remote people   synchronously. However, as these semantic wiki systems allow users   to exploit their own semantics and backgrounds for describing their   knowledge and skills, there are often semantic conflicts between   knowledge (or information) published and provided by the   users. Thereby, the main aims of this work are i) to automatically   detect such conflicts by keeping track on the user semantics, and   ii) to reasonably select consensus choice by analyzing social   collaborations. In this paper, we want to note major patterns of   knowledge dynamics through the social interactions on semantic   wikis, and the semantic conflicts caused by the knowledge   dynamics. The consensus choice has been effectively selected to be   recommended for better understandability about the knowledge   conflicts.               Keywords: conflict resolution, consensus theory, ontology, semantic wiki               Categories: H.1.1, H.3.5, I.2.11  
16|7||Ontology Visualization: Tools and Techniques for Visual Representation of Semi-Structured Meta-Data|  Monika Lanzenberger (Vienna University of Technology, Austria)   Jennifer Sampson (Statoil, Norway)   Markus Rester (Vienna University of Technology, Austria)  Abstract: Ontologies are used to represent a variety of   domain knowledge and data collections, scopes, viewpoints and linked   heterogeneous information sources. They range from simple topologies   to highly structured knowledge bases with complex relations. When   mapping or aligning two or more ontologies an efficient user support   is needed so that the users can understand the prerequisites and the   consequences of the alignments. Information Visualization techniques   can help to facilitate user understanding of the ontology alignment   results. In general, a lot of work in visualization of ontologies   exist. We found an enormous number of ontology visualization tools   by a literature study. Many of them apply graph visualization but   there are other approaches as well. We have identified interesting   solutions for dealing with the complexity of large   ontologies. Ontology engineering, ontology mapping and alignment can   benefit from Information Visualization. Our collection is a starting   point to demonstrate the usefulness of Information Visualization   techniques, however, a detailed evaluation would be the next step to   consolidate this research area and help to boost the adoption of   ontologies in common Web applications.               Keywords: Semantic Web, information visualization techniques, ontology               Categories: H.1.2, I.2.m, I.6.3  
16|8|http://www.jucs.org/jucs_16_8|Methodologies, Technologies and Tools Enabling e-Government|
16|8||From Analog to Digital Television; Strategies to Promote Rapid Adaptation and Awareness|  Manuel J. Fernández Iglesias (Universidade de Vigo, Spain)   Luis M. Álvarez Sabucedo (Universidade de Vigo, Spain)  Abstract: Europe is currently transitioning to digital   terrestrial television and isaimed to replace all analog   infrastructures by 2012. Besides replacing all broadcasting networks   in Europe, the transition requires updating household televisions   andantennas. As with any major change, public administrations must   keep citizens informed and provide support, especially when dealing   with a communication mediumexpected to support a new portfolio of   services and information. State-of-the-art technologies enable   universal coverage in locations where television services are   currentlyunavailable. This paper evaluates the transition to digital   television in several European regions and analyzes novel approaches   and solutions to achieving universal accessto digital television and   citizen awarenes.               Keywords: DTT, change managing, citizen support, migration               Categories: A.1, C.2.m, H.3.5, J.1  
16|8||How is e-Government Progressing?  A Data Driven Approach to E-government Monitoring|  Jeroen Stragier (Ghent University, Belgium)   Pieter Verdegem (Ghent University, Belgium)   Gino Verleye (Ghent University, Belgium)  Abstract: As ICT provide a lot of possibilities, high   expectancies exist towards the electronic public service   provision. All governments are increasingly establishing their   e-strategies. Nevertheless, both in research as among practitioners,   some questions are formulated towards the current   approaches. E-government policy has to deal with two main   challenges: how to offer new and better services for the same (or   lower) budget and how to increase user uptake? The challenges relate   to both the efficiency of e-government, as its effectiveness. In   order to further develop e-government strategies, governments need a   thorough knowledge base to (a) to evaluate their current ways of   working and (b) to found their activities of the future. In this   paper we consider trends in e-government measurement and we discuss   ongoing research towards the development of an e-government monitor   for the Belgian government. This monitor will consist of different   types of information from various sources, providing the necessary   knowledge for all stakeholders involved to underpin their current   and future e-strategies.               Keywords: e-government measurement, e-government monitor, efficiency and effectiveness, indicators, policy               Categories: L.0.0   
16|8||Introducing Living Lab's Method as Knowledge Transfer from one Socio-Institutional Context to another: Evidence from Helsinki-Tallinn Cross-Border Region|  Katri-Liis Lepik (Estonian Business School, Estonia)   Merle Krigul (Estonian Business School, Estonia)   Erik Terk (Tallinn University, Estonia)  Abstract: The present article aims to describe the Living   Labs method as a method innovation in institutional activities and   the problems of taking this innovation into use. Possibilities to   transfer the Living Lab's method from one country, Finland, to   other, Estonia, potential implementation fields and obstacles are   studied. Considerations on the process of utilising the Living Lab's   method in Tallinn are given. Living Lab's is a human-centric   research and development approach in which new technologies are   co-created, tested, and evaluated in the users own private   context. This method is coming into use in several countries among   which Finland is in the forefront but is not yet in use in Tallinn,   Estonia. The empirical part of the research is based on the analyses   of fourteen interviews conducted among Tallinn and Helsinki city   officials, representatives of technology enterprises, experts of the   fields that are internationally most wide-spread Living Labs'   testing grounds, using structured interviews and discussions. The   article concludes by discussing possibilities to use the Living   Lab's method in enhancing Helsinki-Tallinn cross-border co-operation   and thus metropolitan regional integration.               Keywords: Helsinki-Tallinn Euregio, Living Lab, Living Labs method, cross-border co-operation, knowledge transfer, method innovation, open innovation               Categories: M.0  
16|8||Leveraging ICT Deployment and Integration in a Public Organization Aged 176 Years A Greek Case Study|  Melpomeni Hatzikou (Mentoring SA, Greece)   Iraklis-Panagiotis Agiovlasitis (Mentoring SA, Greece)  Abstract: The successful deployment and exploitation of an   Information and Communications Technologies (ICT) project in a   traditional Public Organization involves the proper design and   implementation of the Information System (IS) and a proper   combination of Business Process Re-engineering (BPR) and Change   Management (CM) techniques, specially adapted to meet the   organizations' needs. The current work describes the transformation   of such an organization, the Holy Archdiocese of Athens, earlier   functioning based on a bureaucratic model, into a modern   organization, integrating Information Technology (IT) in core   processes and offering electronic public services to citizens. Over   and above IT expertise, an individual approach of BPR and CM   techniques were used in order to meet the challenges set by the   nature of this project, the outdated processes in a church   organization and the problems caused by elder, unfamiliar with IT   and highly resistant to change personnel.               Keywords: Business Process Reengineering, ICT integration, case study, change management, public services               Categories: H.4.m, K.4.m, K.6.1  
16|8||Locating and Crawling eGovernment Services A Light-weight Semantic Approach|  Luis M. Álvarez Sabucedo (Universidade de Vigo, Spain)   Luis Anido Rifón (Universidade de Vigo, Spain)  Abstract: The application of Web 2.0 tools and   methodologies in the domain of eGov-ernment is not yet a fully   exploited area due to the immaturity of the software support, and   the lack of commitment from Public Administrations. This paper   proposes asolution to locate a service which a citizen may be   interested in. The solution uses particular features from this   environment, such as microformats, metadata and dynamicprocedures on   the Web. The paper describes a semantic model for the domain, and   tools to annotate, publish and crawl services in Public   Administrations are discussedin depth. The paper details the entire   software platform, and it presents conclusions and a number of   proposals for future research efforts.               Keywords: eGovernment, knowledge management, metadata               Categories: H.3.5, H.4, M.1  
16|9|http://www.jucs.org/jucs_16_9|Managing Editor's Column|
16|9||A Trusted Computing Identity Collation Protocol to Simplify Deployment of New Disaster Response Devices|  Peter Danner (Graz University of Technology, Austria)   Daniel Hein (Graz University of Technology, Austria)  Abstract: The use of modern computing equipment by   emergency service units in a disaster area assures increased   efficiency during disaster response. Emergency devices must be easy   to use and secure. Trusted Computing is a promising approach to help   protect the software integrity of commodity emergency devices and   thus increase their security. To efficiently use Trusted Computing   in an emergency scenario it is necessary to establish an initial   trust relationship between the emergency infrastructure providers   and a user, her devices, and the software running on those   devices. Currently, this requires physical presence of the involved   entities. In this paper we propose a remote protocol that employs   electronic identity facilities and Trusted Computing to aggregate   the identity of a user, the identity of her devices and a set of   trusted software states as well as the users facilities and   skills. Such a protocol alleviates the need for physical   presence. Thus, the protocol facilitates deployment of new   electronic emergency equipment, while maintaining a high level of   security. We belief that such a protocol is an important step in the   process of introducing new capabilities for disaster   response.               Keywords: TPM, disaster response, eID, electronic identity, trusted computing               Categories: D.2.9, D.4.6, H.3.2, H.3.4  
16|9||A Multidisciplinary Survey of Computational Techniques for the Modelling, Simulation and Analysis of Biochemical Networks|  James Decraene (Nanyang Technological University, Singapore)   Thomas Hinze (Friedrich-Schiller-Universität Jena, Germany)  Abstract: All processes of life are controlled by networks   of interacting biochemical components. The purpose of modelling   these networks is manifold. From a theoretical point of view it   allows the exploration of network structures and dynamics, to find   emergent properties or to explain the organisation and evolution of   networks. From a practical point of view, in silico experiments can   be performed that would be very expensive or impossible to achieve   in the laboratory, such as hypothesis-testing with regards to   knock-out experiments or overexpression, or checking the validity of   a proposed molecular mechanism. The literature on modelling   biochemical networks is growing rapidly and the motivations behind   different modelling techniques are sometimes quite distant from each   other. To clarify the current context, we review several of the most   popular methods and outline the strengths and weaknesses of   deterministic, stochastic, probabilistic, algebraic and agent-based   approaches. We then present a comparison table which allows one to   identify easily key attributes for each approach such as: the   granularity of representation or formulation of temporal and spatial   behaviour. We describe how through the use of heterogeneous and   bridging tools, it is possible to unify and exploit desirable   features found in differing modelling techniques. This paper   provides a comprehensive survey of the multidisciplinary area of   biochemical networks modelling. By increasing the awareness of   multiple complementary modelling approaches, we aim at offering a   more comprehensive understanding of biochemical networks.               Keywords: analysis, biochemical networks, modelling, simulation, systems biology               Categories: A.1, I.6.4, I.6.5, J.3  
16|9||Classification of Software for the Simulation of Light Scattering and Realization within an Internet Information Portal|  Jens Hellmers (University of Bremen, Germany)   Thomas Wriedt (University of Bremen, Germany)  Abstract: Light scattering studies are done by researchers   of various scientific areas. As the calculation of the scattering   behavior by small particles is rather complex, corresponding   programs usually can be used for specific problems only and   therefore a multitude of programs have been developed over the   years. To enable researchers to find the best fitting one for their   scattering problem a categorization scheme for such software is   presented here. This scheme is used within an actual project to set   up a new internet information portal on the topic of light   scattering. The approach for the integration of the scheme as well   as the implementation of a corresponding search tool is described in   this article.               Keywords: categorization scheme, internet information portal, light scattering, search interface, software               Categories: H.3.1, H.3.3, H.3.4, H.3.5  
16|9||LemmaGen: Multilingual Lemmatisation with Induced Ripple-Down Rules|  Matjaž Juršič (Jožef Stefan Institute, Slovenia)   Igor Mozetič (Jožef Stefan Institute, Slovenia)   Tomaž Erjavec (Jožef Stefan Institute, Slovenia)   Nada Lavrač (Jožef Stefan Institute, Slovenia)  Abstract: Lemmatisation is the process of finding the   normalised forms of words appearing in text. It is a useful   preprocessing step for a number of language engineering and text   mining tasks, and especially important for languages with rich   inflectional morphology. This paper presents a new lemmatisation   system, LemmaGen, which was trained to generate accurate and   efficient lemmatisers for twelve different languages.  Its   evaluation on the corresponding lexicons shows that LemmaGen   outperforms the lemmatisers generated by two alternative approaches,   RDR and CST, both in terms of accuracy and efficiency. To our   knowledge, LemmaGen is the most efficient publicly available   lemmatiser trained on large lexicons of multiple languages, whose   learning engine can be retrained to effectively generate lemmatisers   of other languages.               Keywords: lemmatisation, natural language processing, ripple-down rules, rule induction               Categories: E.1, I.2.6, I.2.7  
16|9||Position-based Routing Protocol for Low Power Wireless Sensor Networks|  Sajjad Ahmad Madani (COMSATS Institute of Information Technology, Pakistan)   Daniel Weber (Vienna University of Technology, Austria)   Stefan Mahlknecht (Vienna University of Technology, Austria)  Abstract: We present a table-less position based routing   scheme for low power data centric wireless sensor networks. Our   proposed scheme is localized, uses greedy forwarding approach, and   does not rely on neighborhood information. These characteristics   reduce the communication overhead (no neighborhood information   exchange), make the protocol highly scalable (no routing tables are   maintained and beacons are not exchanged when a node leaves or   enters a network), and performs better in mobile environments (as   the next hop is non-deterministic and is computed at run time). It   also deals with dead end problem by a recovery strategy in a   distributed and localized way. The proposed protocol is implemented   in the OMNET++ based discrete event simulation environment   PAWiS. The results show that the proposed protocol provides   guaranteed delivery, extended network lifetime, and a mechanism to   route on the basis of end-to-end delay and/or energy   consumption.               Keywords: ad hoc networks, position based routing, routing protocols, wireless sensor networks               Categories: C.2.0, C.2.2  
16|9||Knowledge Authoring with ORE: Testing, Debugging   and Validating Knowledge Rules in a Semantic Web   Framework|  Andres Muñoz Ortega (University of Murcia, Spain)   Jose M. Alcaraz Calero (Hewlett Packard Laboratories, United Kingdom)   Juan A. Botía Blaya (University of Murcia, Spain)   Gregorio Martínez Pérez (University of Murcia, Spain)   Felix J. Garcia Clemente (University of Murcia, Spain)  Abstract: Ontology rule editing, testing, debugging and   validation are still handcrafted and painful tasks. Nowadays, there   is a lack of tools that take these tasks into consideration in order   to ease the work of the developer. This paper is devoted to explain   how we have come to a new tool, ORE (Ontology Rule Editor), which   significantly eases these tasks. It rests on a Semantic Web   framework together with reasoning engines, which operate with   semantic representations. Its design maintains a loosely coupling   from the framework and from rule engines. Collaborative   functionalities have been tackled in order to enable a real   integration of the rule authoring across different tools and/or   users. A practical validation of the approach by instantiating our   tool with Jena and Pellet reasoning engines is presented here. In   order to demonstrate its use, the tool is applied to the task of   rule-based management in a ubiquitous computing scenario.               Keywords: conflict management, knowledge authoring, ontology rule editor, reasoning engines, semantic web               Categories: D.2.2, I.2.1, I.2.4, M.1  
volume|issue|url|title|abstract
17|1|http://www.jucs.org/jucs_17_1|Meeting New Challenges in Document Engineering|
17|1||Document Retrieval Using SIFT Image Features|  Dan Smith (University of East Anglia, United Kingdom)   Richard Harvey (University of East Anglia, United Kingdom)  Abstract: This paper describes a new approach to document classification based on visual features alone. Text-based retrieval systems perform poorly on noisy text. We have conducted series of experiments using cosine distance as our similarity measure, selecting varying numbers local interest points per page, and varying numbers of nearest neighbour points in the similarity calculations. We have found that a distance-based measure of similarity outperforms a rank-based measure except when there are few interest points. We show that using visual features substantially outperforms textbased approaches for noisy text, giving average precision in the range 0.4-0.43 in several experiments retrieving scientific papers.               Keywords: SIFT, document classification               Categories: H.3.1  
17|1||Text Line Detection and Segmentation: Uneven Skew Angles and Hill-and-Dale Writing|  Ergina Kavallieratou (University of the Aegean, Greece)   Fotis Daskas (Greek Open University, Greece)  Abstract: In this paper a line detection and segmentation   technique is presented. The proposed technique is an improved   version of an older one. The experiments have been performed on the   training dataset of the ICDAR 2009 handwriting segmentation contest   in order to be able to compare, objectively, the performance of the   two techniques. The improvement between the older and newer version   is more than 24% while the average extra CPU time cost is less than   200 ms per page.               Keywords: Line detection, OCR, line segmentation               Categories: I.7.5  
17|1||A New Approach to Water Flow Algorithm for Text Line Segmentation|  Darko Brodić (University of Belgrade, Serbia)   Zoran Milivojević (Technical College Nis, Serbia)  Abstract: This paper proposes a new approach to water flow   algorithm for the text line segmentation. Original method assumes   hypothetical water flows under a few specified angles to the   document image frame from left to right and vice versa. As a result,   unwetted image frames are extracted. These areas are of major   importance for text line segmentation. Method modifications mean   extension values of water flow angle and unwetted image frames   function enlargement. Results are encouraging due to text line   segmentation improvement which is the most challenging process stage   in document image processing.               Keywords: bounding box, document image analysis, morphological operation, text line segmentation, water flow algorithm               Categories: I.4, I.4.1, I.4.3, I.4.6, I.7, I.7.2  
17|1||An OCR Free Method for Word Spotting in Printed Documents: the Evaluation of Different Feature Sets|  Israel Rios (Pontifical Catholic University of Parana, Brazil)   Alceu de Souza Britto Jr (Pontifical Catholic University of Parana, Brazil)   Alessandro Lameiras Koerich (Pontifical Catholic University of Parana, Brazil)   Luis Eduardo Soares Oliveira (Federal University of Parana, Brazil)  Abstract: An OCR free word spotting method is developed   and evaluated under a strong experimental protocol. Different   feature sets are evaluated under the same experimental   conditions. In addition, a tuning process in the document   segmentation step is proposed which provides a significant reduction   in terms of processing time. For this purpose, a complete OCR-free   method for word spotting in printed documents was implemented, and a   document database containing document images and their corresponding   ground truth text files was created. A strong experimental protocol   based on 800 document images allows us to compare the results of the   three feature sets used to represent the word image.               Keywords: document retrieval, word recognition, word spotting               Categories: I.5, I.7  
17|1||The Use of Latent Semantic Indexing to Mitigate OCR Effects of Related Document Images|  Renato F. Bulcão-Neto (Innolution Sistemas de Informática Ltda., Brazil)   José A. Camacho-Guerrero (Innolution Sistemas de Informática Ltda., Brazil)   Márcio Dutra (Innolution Sistemas de Informática Ltda., Brazil)   Álvaro Barreiro (University of A Coruña, Spain)   Javier Parapar (University of A Coruña, Spain)   Alessandra A. Macedo (Universidade de Sáo Paulo, Brazil)  Abstract: Due to both the widespread and multipurpose use   of document images and the current availability of a high number of   document images repositories, robust information retrieval   mechanisms and systems have been increasingly demanded. This paper   presents an approach to support the automatic generation of   relationships among document images by exploiting Latent Semantic   Indexing (LSI) and Optical Character Recognition (OCR). We developed   the LinkDI (Linking of   Document Images) service,   which extracts and indexes document images content, computes its   latent semantics, and defines relationships among images as   hyperlinks. LinkDI was experimented with document images   repositories, and its performance was evaluated by comparing the   quality of the relationships created among textual documents as well   as among their respective document images. Considering those same   document images, we ran further experiments in order to compare the   performance of LinkDI when it exploits or not the LSI   technique. Experimental results showed that LSI can mitigate the   effects of usual OCR misrecognition, which reinforces the   feasibility of LinkDI relating OCR output with high degradation.               Keywords: applied computing, document engineering, document image, experimentation, information retrieval, latent semantic, optical character recognition               Categories: H.3, H.3.3, H.5.4  
17|1||Fusion of Complementary Online and Offline Strategies for Recognition of Handwritten Kannada Characters|  Rakesh Rampalli (Indian Institute of Science, India)   Angarai Ganesan Ramakrishnan (Indian Institute of Science, India)  Abstract: This work describes an online handwritten character recognition system working in combination with an offline recognition system. The online input data is also converted into an offline image, and in parallel recognized by both online and offline strategies. Features are proposed for offline recognition and a disambiguation step is employed in the offline system for the samples for which the confidence level of the classier is low. The outputs are then combined probabilistically resulting in a classier out-performing both individual systems. Experiments are performed for Kannada, a South Indian Language, over a database of 295 classes. The accuracy of the online recognizer improves by 11% when the combination with offline system is used.               Keywords: Kannada script, Mahalanobis distance, Pen direction angle, Re-sampling, classifier fusion, directional distance distribution, nearest stroke pixel, offline handwriting recognition, online handwriting recognition, principal component analysis, projection proles, spline curve, support vector machine, transition count               Categories: I.2.1, I.4.9, I.5.4, J.6  
17|1||Choice of Classifiers in Hierarchical Recognition of Online Handwritten Kannada and Tamil Aksharas|  Venkatesh Narasimha Murthy (Tata Consultancy Services Limited, India)   Angarai Ganesan Ramakrishnan (Indian Institute of Science, India)  Abstract: In this paper, we propose a novel dexterous   technique for fast and accurate recognition of online handwritten   Kannada and Tamil characters. Based on the primary classifier output   and prior knowledge, the best classifier is chosen from set of three   classifiers for second stage classification. Prior knowledge is   obtained through analysis of the confusion matrix of primary   classifier which helped in identifying the multiple sets of confused   characters. Further, studies were carried out to check the   performance of secondary classifiers in disambiguating among the   confusion sets. Using this technique we have achieved an average   accuracy of 92.6% for Kannada characters on the MILE lab dataset and   90.2% for Tamil characters on the HP Labs dataset.               Keywords: DTW, Hierarchical Classification, Kannada, PCA, Tamil, handwritten character recognition               Categories: I.5  
17|1||Color Image Restoration Using Neural Network Model|  Satyadhyan Chickerur (M S Ramaiah Institute of Technology, India)   Aswatha Kumar M (M S Ramaiah Institute of Technology, India)  Abstract: Neural network learning approach for color image   restoration has been discussed in this paper and one of the possible   solutions for restoring images has been presented. Here neural   network weights are considered as regularization parameter values   instead of explicitly specifying them. The weights are modified   during the training through the supply of training set data. The   desired response of the network is in the form of estimated value of   the current pixel. This estimated value is used to modify the   network weights such that the restored value produced by the network   for a pixel is as close as to this desired response. One of the   advantages of the proposed approach is that, once the neural network   is trained, images can be restored without having prior information   about the model of noise/blurring with which the image is   corrupted.               Keywords: Ill Posed Problem, Regularization, color image restoration, neural networks               Categories: G.1.8, I.2, I.2.6, I.4, I.4.4  
17|1||Visualizing and Analyzing the Quality of XML Documents|  Daniela da Cruz (Universidade do Minho, Portugal)   Pedro Rangel Henriques (Universidade do Minho, Portugal)  Abstract: In this paper we introduce   eXVisXML, a visual tool to explore documents   annotated with the mark-up language XML, in   order to easily perform over them tasks as knowledge   extraction or document   engineering.  eXVisXML was designed mainly for two   kind of users. Those who want to analyze an annotated document to   explore the information contained-for them a visual inspection tool   can be of great help, and a slicing functionality can be an   effective complement.  The other target group is composed by document engineers who might be interested in assessing the quality of the annotation created. This can be achieved through the measurements of some parameters that will allow to compare the elements and attributes of the DTD/Schema against those effectively used in the document instances.  Both functionalities and the way they were delineated and implemented will be discussed along the paper.               Keywords: document engineering, quality assessment, slicing, visualization               Categories: D.2.8, H.0  
17|1||Nabuco - Two Decades of Document Processing in Latin America|  Rafael Dueire Lins (Federal University of Pernambuco, Brazil)  Abstract: This paper reports on the Joaquim Nabuco   Project, a pioneering work in Latin America on document   digitalization, enhancement, compression, indexing, retrieval and   network transmission of historical document images.               Keywords: back-to-front interference, bleeding, document engineering, historical documents, image processing, show through               Categories: H.3.3  
17|10|http://www.jucs.org/jucs_17_10|Knowledge Work: Knowledge Worker Productivity, Collaboration and User Support|
17|10||What is Productivity in Knowledge Work? - A Cross-Industrial View -|  Rainer Erne (Leeds Metropolitan University, United Kingdom)  Abstract: Experts in specific professional domains form the fastest increasing workforce in OECD countries. Since this fact has been realised by management researchers, they have focussed on the question of how to measure and enhance the productivity of said workforce. According to the author's cross-industrial research undertaken in five different knowledge-intensive organisations, it is, however, not productivity in the traditional meaning of the term which is to be regarded as the crucial performance indicator in expert work. There rather exist multiple performance indicators, each of which is, moreover, differently graded as to its importance by different stakeholders. These findings, firstly, indicate the need for an alternative definition and way of measurement of productivity when the term is applied to knowledge work, and, secondly, they indicate the need for alternative management strategies in order to generate an increase in the productivity of knowledge workers. This paper describes and summarises the key performance indicators for expert work as well as the major 'managing forces' and their general strategies in assessing knowledge workers' performance across five different business segments. It further delineates consequences for the management of knowledge workers - consequences affecting various 'knowledge-intensive' industries.               Keywords: expert, knowledge worker, management, performance, productivity, professional               Categories: A.0, A.1, A.m  
17|10||Representing a Composing Fuzzy-DEA Model to Measure Knowledge Workers Productivity based upon their Efficiency and Cost Effectiveness|"  Ali Abdoli (Amirkabir University of Technology, Iran)   Jamal Shahrabi (Amirkabir University of Technology, Iran)   Jalil Heidary (Amirkabir University of Technology, Iran)  Abstract: By entering the knowledge age and the appearance of knowledge economy, organizations are more dependent on knowledge workers productivity. Productivity means doing the right things right. It shows how a knowledge worker makes use of resources to fulfill the goals of the organization. This definition makes productivity be the result of simultaneous existence of efficiency ""doing the things right"" and effectiveness ""doing the right things"". Since factors influencing knowledge workers productivity cannot be definitely measured, uncertainty theory plays an important role in this area. So in this paper, first, dimensions of productivity will be introduced and then, by the use of linguistic fuzzy approach and DEA, efficiency and effectiveness of knowledge workers will be measured. Next, a model for measuring knowledge workers productivity will be presented on the basis of efficiency and effectiveness. Finally, values of knowledge workers productivities will be ranked. In the last section, the result of this five-step method is examined through a case study.               Keywords: effectiveness, efficiency, fuzzy DEA, knowledge worker, productivity               Categories: M.9  "
17|10||Performance Management in Collaborative Networks: a Methodological Proposal|  Rui Pinto Ferreira (Institute for Systems and Computer Engineering of Porto, Portugal)   Jorge Neves Silva (Institute for Systems and Computer Engineering of Porto, Portugal)   Faimara do Rocio Strauhs (Federal University of Technology - Paraná, Brazil)   Antonio Lucas Soares (University of Porto, Portugal)  Abstract: Performance management in collaborative networks of organisations is a complex process due to the multiplicity of competing perspectives upon it. One of the more sensitive phases of this process is the agreement of the actors in the network regarding the performance evaluation model whose design is considered of great importance in the research literature. This paper proposes a method for the design of performance evaluation systems in collaborative networks through an innovative combination of performance information classification and multi-criteria decision model. The method is implemented in a web-based collaborative platform that enables the members of a collaborative network to efficiently achieve specific performance models that result from a collective and negotiated construction.               Keywords: collaborative networks, constructivist approaches, framework, performance management               Categories: M.0, M.4  
17|10||Assessing the Impact of Visual Facilitation on Inter-Organizational Collaboration: An Experimental Study|  Alice Comi (University of Lugano, Switzerland)   Martin J. Eppler (University of St. Gallen, Switzerland)  Abstract: As suggested by several scholars, inter-organizational collaboration is an important vehicle for innovation, but working across organizational boundaries entails great complexity. In this paper, we argue that visual facilitation may act as a catalyst of inter-organizational teamwork, leading to increased knowledge sharing quality (H1), team performance (H2) and satisfaction (H3). On the other hand, we suggest that the aesthetic beauty of visual representations may exert a manipulatory effect, inducing inter-organizational actors to overestimate the collaboration value potential (H4). We adopt an experimental design (N=145 participants) in order to assess the advantages and disadvantages of visual facilitation in inter-organizational teamwork. In particular, we compare inter-organizational teams working with i) software-based visualization, ii) poster-based visualization, and iii) text-based facilitation (control condition). By comparing results across the two treatment conditions (software and poster), we disentangle the effects of visual facilitation and computer interactivity, therefore making a unique contribution to research on information visualization. The experiment findings show that software-supported teams outperform the control groups in terms of performance (H2), and exhibit greater satisfaction with the inter-organizational meetings (H3). We extend our experimental study by conducting focus groups with 17 experiment participants to gain an in-depth understanding of the users' experience with the different support systems. After discussing relevant implications for both researchers and practitioners, we point out the limitations of our study and suggest directions for future research.               Keywords: experimental research, focus groups, information visualization, inter-organizational collaboration, inter-organizational innovation, inter-organizational teamwork, visual facilitation, visual representations               Categories: H.4.3, H.5.3, J.4, L.2.3, M.0, M.2  
17|10||Caring for Clarity in Knowledge Communication|  Nicole Bischof (St. Gallen, Switzerland)   Martin J. Eppler (St. Gallen, Switzerland)  Abstract: Knowledge communication is an essential mechanism to facilitate intra- and inter-organizational knowledge transfer. In order to improve the efficiency of knowledge communication, organizations need to pay particular attention to the clarity of conveyed knowledge in order not to create confusion, misunderstandings, or misapplication of knowledge. In this contribution, we show where and how the concept of clarity matters for knowledge management in general, and for knowledge communication in particular. We review and operationalize the clarity concept so that it can become the object of a systematic management effort. Furthermore, we show ways of how clarity can be pro-actively and systematically managed. We have tested our conception of clarity in a survey on clarity in knowledge-focused presentations, and we present the results in this article. An outlook on future research on clarity in knowledge management concludes the contribution.               Keywords: PowerPoint presentations, clarity, cognitive load theory, knowledge communication, knowledge transfer               Categories: M.5, M.9  
17|10||Mirroring of Knowledge Practices based on User-defined Patterns|  Ján Paralič (Technical University of Košice, Slovakia)   Christoph Richter (Christian-Albrechts-Universität zu Kiel, Slovakia)   František Babič (Technical University of Košice, Slovakia)   Jozef Wagner (Technical University of Košice, Slovakia)   Michal Raček (PÖYRY Forest Industry Oy Vantaa, Slovakia)  Abstract: Knowledge practices mirroring is one of the   central elements of the Trialogical Learning Approach as it is   supposed to be a driving force in processes of practice   transformation and knowledge creation. The exploitation of   historical logging data holds promise to provide a great deal of   information about group activities without requiring additional   efforts for recording of events by the users. Building on the   Trialogical Learning Approach as well as related work in the fields   of Data Mining and Knowledge Discovery, Computer-Supported   Collaborative Learning, and Information Visualization, this paper   suggests high-level requirements for mirroring tools in support of   practice transformation and introduces a software tool called   Timeline-Based Analyzer (TLBA) that was designed and developed in   response to these requirements. One of the main TLBA features is the   possibility to define patterns as sequences of relevant actions that   resulted into critical moments in investigated practices. Such kind   of patterns might also represent conceptually interesting practices   that emerged within a particular context - either being positive   (a sort of good practices), or negative (bad practices). The   usability of the whole analytical solution has been tested through   the first iteration of several practical experiments and case   studies. One of them is described in this paper and illustrates how   TLBA can be used to support collaborative analysis and   mirroring. The results of these evaluations have been used for   continued improvement of the TLBA in order to provide a stable and   intuitive tool not only for researchers, but for daily use of   teachers or other users.               Keywords: collaborative system, knowledge practices, patterns, timeline-based visualization               Categories: L.0.0, L.3.4, L.3.6  
17|10||The Application of Pattern Repositories for Sharing PLE Practices in Networked Communities|"  Felix Mödritscher (Vienna University of Economics and Business, Austria)   Zinayida Petrushyna (RWTH Aachen University, Germany)   Effie Lai-Chong Law (University of Leicester, United Kingdom)  Abstract: Personal learning environments (PLEs) comprise a new kind of learning technology which aims at putting learners into centre stage, i.e. by empowering them to design and use environments for their learning needs and purposes. Setting a PLE approach into practice, however, is not trivial at all, as the prospective end-users have varying attitudes and experiences in using ICT in general and PLE software in particular. Here, practice sharing could be an enabler for increasing the usefulness and usability of PLE solutions. In this paper we examine the relevant issues of capturing and sharing ""good practices"" of PLE-based, collaborative activities. By good practices we refer to learning experiences provided by learners for a networked community. Moreover, we introduce the concept of a pattern repository as a back-end service for PLEs which should, in the sense of community approaches like Last.fm, support PLE users in selecting and using learning tools for their activities. Finally, we present a prototype and argue for the advantages of such a practice sharing infrastructure with respect to community literature, experiences, and an evaluation study.               Keywords: digital repositories, personal learning environments, practice sharing, virtual communities               Categories: H.3.5, H.3.7, J.4, L.3.6, L.6.1  "
17|10||Task Models for Intention-Aware Systems|  Benedikt Schmidt (SAP Research CEC Darmstadt, Germany)   Todor Stoitsev (SAP Research CEC Darmstadt, Germany)   Max Mühlhäuser (TU Darmstadt, Germany)  Abstract: Intention-aware systems integrate aspects of context-aware and attentionaware systems for the identification and support of intention. Focusing intention is justified by the impact of intention on awareness and interaction with the world. Therefore, proactive user support mechanisms can be improved by including a representation of intention. In this paper, the externalization of intention in task models is discussed: existing task models are reviewed and activity schemes are proposed as task model for intention-aware systems. A framework for intention-aware systems is presented and discussed in detail.               Keywords: attention-aware systems, context-aware systems, intention-aware systems, knowledge work               Categories: H.1.2, H.4.1  
17|11|http://www.jucs.org/jucs_17_11|Managing Editor's Column|
17|11||Expertise Recommender System for Scientific Community|  Muhammad Tanvir Afzal (Mohammad Ali Jinnah University, Pakistan)   Hermann Maurer (Graz University of Technology, Austria)  Abstract: Finding experts in academics as well as in   enterprises is an important practical problem. Both manual and   automated approaches are employed and have their own pros and   cons. On one hand, the manual approaches need extensive human   efforts but the quality of data is good, on the other hand, the   automated approaches normally do not need human efforts but the   quality of service is not as good as in the manual   approaches. Furthermore, the automated approaches normally use only   one metric to measure the expertise of an individual. For example,   for finding experts in academia, the number of publications of an   individual is used to discover and rank experts.  This paper   illustrates both manual and automated approaches for finding experts   and subsequently proposes and implements an automated approach for   measuring expertise profile in academia. The proposed approach   incorporates multiple metrics for measuring an overall expertise   level. To visualize a rank list of experts, an extended hyperbolic   visualization technique is proposed and implemented. Furthermore,   the discovered experts are pushed to users based on their local   context. The research has been implemented for Journal of Universal   Computer Science (J. UCS) and is available online for the users of   J.UCS.               Keywords: digital journals, expertise finding, hyperbolic visualization, multi-faceted expert profile, spiral visualization               Categories: H.3.3, H.5.2  
17|11||RAHIM: Robust Adaptive Approach Based on Hierarchical Monitoring Providing Trust Aggregation for Wireless Sensor Networks|  Nabila Labraoui (STIC University of Tlemcen, Algeria)   Mourad Gueroui (PRISM University of Versailles, France)   Makhlouf Aliouat (Algeria, Algeria)   Jonathan Petit (University of Twente, The Netherlands)  Abstract: In-network data aggregation has a great impact   on the energy consumption in large-scale wireless sensor   networks. However, the resource constraints and vulnerable   deployment environments challenge the application of this technique   in terms of security and efficiency. A compromised node may forge   arbitrary aggregation value and mislead the base station into   trusting a false reading. In this paper, we present RAHIM, a   reactive defense to secure data aggregation scheme in cluster-based   wireless sensor networks. The proposed scheme is based on a novel   application of adaptive hierarchical level of monitoring providing   accuracy of data aggregation result in lightweight manner, even if   all aggregator nodes and a part of sensors are compromised in the   network.               Keywords: accuracy, availability, data aggregation, monitoring mechanism, security, wireless sensor networks               Categories: C.2, C.2.3  
17|11||Time is not Enough: Dealing with Behavior in Real-Time Systems|  Leo Ordinez (Universidad Nacional del Sur - CONICET, Argentina)   David Donari (Universidad Nacional del Sur - CONICET, Argentina)   Rodrigo Santos (Universidad Nacional del Sur - CONICET, Argentina)   Javier Orozco (Universidad Nacional del Sur - CONICET, Argentina)  Abstract: In this paper, the Behavioral Importance Priority Server (BIPS) algorithm is proposed to schedule sets of hard/soft real-time tasks. The mechanism postpones or advances the execution of the next instance of a task according to the value obtained from a function properly associated to the behavior of the task; as a consequence, there is a flexible adaptation of the bandwidth required by each server. A synchronization method is introduced to prevent deadlocks and priority inversions in the case of sets of tasks sharing resources along with the necessary and sufficient conditions for the schedulability analysis. A software framework proposing an abstract architecture of a system based on BIPS is also presented. The BIPS software framework intends to bridge the gap between theoretical scheduling aspects and the actual implementation of them. Since BIPS is capable of managing very different sets of tasks, it covers a wide variety of applications found in the real world.               Keywords: behavior, real-time, scheduling, system development               Categories: C.3, D.1.5, D.4.1  
17|11||Performance Evaluation of Snort under Windows 7 and Windows Server 2008|  Khaled Salah (Khalifa University of Science, United Arab Emirates)   Mojeeb-Al-Rhman Al-Khiaty (King Fahd University of Petroleum and Minerals, Saudi Arabia)   Rashad Ahmed (King Fahd University of Petroleum and Minerals, Saudi Arabia)   Adnan Mahdi (King Fahd University of Petroleum and Minerals, Saudi Arabia)  Abstract: Snort is the most widely deployed network intrusion detection system (NIDS) worldwide, with millions of downloads to date. PC-based Snort typically runs on either Linux or Windows operating systems.  In this paper, we present an experimental evaluation and comparison of the performance of Snort NIDS when running under the two newly released operating systems of Windows 7 and Windows Server 2008. Snort's performance is measured when subjecting a PC host running Snort to both normal and malicious traffic.  Snort's performance is evaluated and compared in terms of throughput and packet loss.  In order to offer sound interpretations and get a better insight into the behaviour of Snort, we also measure the packet loss encountered at the kernel level.  In addition, we study the impact of running Snort under different system configurations which include CPU scheduling priority given to user applications or kernel services, uni and multiprocessor environment, and processor affinity.               Keywords: Experimental Performance Evaluation, Snort, Windows 2008, Windows 7, network security, operating systems               Categories: C.2.0, C.2.1, C.2.3, C.2.6, C.2.m, D.4.0, D.4.6, D.4.8, D.4.9  
17|11||Security Analysis of Three Password Authentication Schemes|  Kyung-Ah Shim (National Institute for Mathematical Sciences, Korea)  Abstract: In this paper, we show that a verifier-based password authentication scheme and two remote user authentication schemes are insecure against several active attacks. These results demonstrate that no more password authentication schemes should be constructed with such ad-hoc methods, i.e, the formal design methodology using provable security should be employed.               Keywords: password-based authentication, remote user authentication, server-compromise attack, smart card, verifier-based password authentication               Categories: D.4.6, E.3  
17|12|http://www.jucs.org/jucs_17_12|Virtual Environments for Collaborative Innovation and Learning|
17|12||Investigating Collaborative Innovation in a Virtual World Task|  Philip Vahey (SRI International, United States)   John Brecht (SRI International, United States)   Charles Patton (SRI International, United States)   Ken Rafanan (SRI International, United States)   Britte Haugan Cheng (SRI International, United States)  Abstract: While much has been written about the importance of innovation, there is still much to learn about the specific behaviours that lead to innovation among groups. In this paper we introduce a framework of innovation based on behaviours identified as being conducive to collaborative innovation. We also report on a study of a task designed to elicit innovation supportive behaviours in a virtual world environment. The task resulted in a variety of solutions and a range of participant behaviours, and specific behaviours were correlated with innovative solutions. Multiple forms of analysis provided unique insights into participant behaviour, and the combined set of analyses led to a richer understanding of participant behaviour than found through any individual analysis. The paper also presents implications for how organizations may scaffold group interactions to increase the chances of successful collaborative innovation.               Keywords: collaboration, innovation, log file analysis, virtual worlds, word-space models               Categories: K.3.1, L.3.0, L.6.1, L.6.2  
17|12||What's in it for me? Recommendation of Peers in Networked Innovation|  Rory L.L. Sie (Open Universiteit in the Netherlands, The Netherlands)   Marlies Bitter-Rijpkema (Open Universiteit in the Netherlands, The Netherlands)   Peter B. Sloep (Open Universiteit in the Netherlands, The Netherlands)  Abstract: Several studies have shown that connecting to people in other networks foster creativity and innovation. However, it is often difficult to tell what the prospective value of such alliances is. Cooperative game theory offers an a priori estimation of the value of future collaborations. We present an agent-based social simulation approach to recommending valuable peers in networked innovation. Results indicate that power as such does not lead to a winning coalition in networked innovation. The recommendation proved to be successful for low-strength agents, which connected to high-strength agents in their network. Future work includes tests in real-life and other recommendation strategies.               Keywords: artificial intelligence, coalition formation, open innovation, recommender systems               Categories: H.1.1, H.1.2, I.6.5, I.6.6, K.4.3  
17|12||360° Open Creativity Support|  Michele Brocco (Technische Universität München, Germany)   Florian Forster (Technische Universität München, Germany)   Marc René Frieß (Technische Universität München, Germany)  Abstract: Open Innovation is a new paradigm that suggests including actors from inside as well as outside a company's boundaries in the innovation process. Open creativity refers to the creative phase in this process. In this article we investigate on open creativity support. We conducted interviews within companies in the German ICT sector to analyze the status quo of open creativity and the tools currently used to support it. In a second step we derive design guidelines and an architecture for IT systems supporting open creativity that lead to a holistic, 360ffi support for open creativity.               Keywords: creativity support systems, open creativity, open innovation               Categories: A.1, H.1, H.5.3  
17|12||Recommending Open Linked Data in Creativity Sessions using Web Portals with Collaborative Real Time Environment|  Peter Dolog (Aalborg University, Denmark)   Frederico Durao (Aalborg University, Denmark)   Karsten Jahn (Aalborg University, Denmark)   Yujian Lin (Aalborg University, Denmark)   Dennis Kjaersgaard Peitersen (Aalborg University, Denmark)  Abstract: In this paper we describe a concept of the recommender system for collaborative real time web based editing in the context of creativity sessions. The collaborative real time editing provides creativity teams of which members are physically distributed with an emulation of the synchronous collaboration where presence of the team members is required simultaneously (e.g., brainstorming, meetings). The concept of recommendation is based on matchmaking the currently performed activities at the user interface and external linked open data provided through SPARQL endpoints. The real time propagation of the changes in editor and recommendation is achieved by reverse AJAX and observer pattern. An experiment in the area of the creativity domain shows that the recommendation in collaborative real time editing activities are useful in task performance, guidance, and inspiration.               Keywords: Web portals, collaborative real time editing, open linked data, portlets, recommender systems               Categories: H.3.3, L.1.0, L.1.2, L.6.2  
17|12||Enhancing the Collective Knowledge for the Engineering of Ontologies in Open and Socially Constructed Learning Spaces|  Konstantinos Kotis (University of the Aegean, Greece)   Andreas Papasalouros (University of the Aegean, Greece)   George Vouros (University of the Aegean, Greece)   Nikolaos Pappas (University of the Aegean, Greece)   Konstantinos Zoumpatianos (University of the Aegean, Greece)  Abstract: The aim of this paper is to present a novel   technological approach for enhancing the collective knowledge of   communities of learners on the engineering of ontologies within a   collaborative, open and socially constructed environment. The   proposed technology aims at shaping information spaces into   ontologies in a collaborative, communicative and learner-centered   way during the ontology development life-cycle. The paper   conjectures that such a collaborative environment can yield   educational benefits, thus there is need to follow principles that   apply in the Computer Supported Collaborative Learning (CSCL)   paradigm. This work is mainly based on a collaborative and   human-centered ontology engineering methodology and on a   meta-ontology framework for developing ontologies, namely HCOME and   HCOME-3O respectively. The integration of key technologies such as   Semantic Wiki and Argumentation models with Ontology Engineering   methodologies and tools serve as an enabler of learning spaces   construction for different domain-specific information spaces in   open settings. Inside these learning spaces innovative   conceptualizations (both domain and development) are conceived,   described by intertwined ontological meta-models following the   HCOME-3O specifications for future reference and tutoring   support. Such learning spaces support two types of ontology   engineering courses: a) courses related to the know-how of shaping   information spaces into ontologies (namely, the development   knowledge) and b) courses related to the analysis of the domain   itself (namely, the domain knowledge). The paper reports on the   evaluation of the approach within a CSCL setting in Ontology   Engineering, using the integrated set of tools and the framework   that have been developed for the collaborative engineering of   ontologies.               Keywords: argumentation models, collaborative knowledge building, ontologies, semantic wiki technology               Categories: H.5.3, I.2.4, K.3.1, K.3.2  
17|12||A Context Aware Recommender System for Creativity Support Tools|  George A. Sielis (University of Cyprus, Cyprus)   Christos Mettouris (University of Cyprus, Cyprus)   George A. Papadopoulos (University of Cyprus, Cyprus)   Aimilia Tzanavari (University of Nicosia, Cyprus)   Roger M.G. Dols (Morpheus Kennistechnologie BV, The Netherlands)   Quintin Siebers (Morpheus Kennistechnologie BV, The Netherlands)  Abstract: The development of methods that can enhance the creativity process is becoming a continuous necessity. Through the years several researchers modelled and defined creativity focusing to the psychological aspect of the topic. More recent researchers approach creativity as a computerized process by simulating it within creativity support tools (CST). This article supports that usage of context aware recommender system, in creativity support tools and more specifically, collaborative creativity support tools (CCST) can enhance creativity process. In this work we focus on the development of a context awareness recommender system and look into how such a system can be useful for the creativity process, through preliminary evaluation results in regards to its usefulness and usability.               Keywords: context awareness, context awareness recommender system, creativity, creativity support tools               Categories: H.3.1, L.1.0, L.2.0, L.3.0, L.6.2  
17|13|http://www.jucs.org/jucs_17_13|Managing Editor's Column|
17|13||Software Process Definition: a Reuse-based Approach|  Ahilton Silva Barreto (COPPE/UFRJ - Universidade Federal do Rio de Janeiro, Brazil)   Leonardo Gresta Paulino Murta (Universidade Federal Fluminense (UFF), Brazil)   Ana Regina Cavalcanti da Rocha (COPPE/UFRJ - Universidade Federal do Rio de Janeiro, Brazil)  Abstract: Software product development has been taking   advantage of reuse techniques for some decades. Concepts like   software components, architectures, and product lines have been   successfully applied in several contexts to develop software   products, although some difficulties are still faced. Software   processes have strong similarities with software products, and some   researchers argue that they are software too.  Therefore, we believe   that software processes may take advantage of some benefits expected   by the use of existing software products reuse techniques, adapted   to software processes. It is also possible that similar difficulties   are faced. This paper presents a software process definition   approach based on reuse techniques, which aims at making some of the   benefits expected by software product reuse available to software   process definition activities. Concepts such as process components,   architectures, process lines and features are described and used. We   describe the proposed approach, tools developed to support it, and   also results of a survey on the expected benefits and difficulties   on software process reuse in the point of view of experienced   software process engineers.               Keywords: software process components, software process definition, software process lines, software process reuse               Categories: D.2.0, D.2.13, D.9, K.6.3  
17|13||Design and Generation of Web Services Choreographies with Time Constraints|  M. Emilia Cambronero (Campus Universitario. ESII, Spain)   Valentín Valero (Campus Universitario. ESII, Spain)   Enrique Martínez (Campus Universitario. ESII, Spain)  Abstract: In this paper we show how UML 2.0 sequence   diagrams can be used for the design of Web service choreographies   with time constraints and how these sequence diagrams can be   extended with frames for the description of Web service   choreographies. We then show how the diagrams can be translated into   WS-CDL documents. This translation is of interest, since non-XML   experts can find it difficult to implement a composite web service   by WS-CDL, i.e. XML code. Graphic models, such as UML sequence   diagrams, are a popular and well-studied framework for a compact   representation of interoperation among participants in a distributed   system and can be used as a starting document for the design of a   composite Web service, from which the corresponding WS-CDL document   can be derived.               Keywords: RealTime systems, UML, WS-CDL, code generation, design, modeling, web services               Categories: D.2.10, D.2.2, D.2.3, H.4.3  
17|13||An Inquiry into the Utilization of Behavior of Users in Personalized Web|  Michal Holub (Slovak University of Technology in Bratislava, Slovakia)   Mária Bieliková (Slovak University of Technology in Bratislava, Slovakia)  Abstract: Nowadays we see successive transformation of the   Web into its personalized form. In order to personalize the content   to suit e ach user's requirements we need to acquire the user's   interests. Utilization of implicit feedback is the most suitable and   unobtrusive way of doing so. In this paper we present various forms   of implicit feedback and their application in the estimation of   user's interests. We propose a method of link recommendation based   on the recorded actions users take while visiting a website. We   employ collaborative filtering to predict user interest to unvisited   pages. We present an evaluation of our method using the web portal   of our faculty where personalized recommendation of links to   interesting events is provided for visitors.               Keywords: implicit feedback, interest estimation, navigational patterns, personal calendar, recommendation, user actions               Categories: H.3.3, H.5.4  
17|13||An Improved FPTAS for Mobile Agent Routing with Time Constraints|  Eugene Levner (Ashkelon Academic College and Bar Ilan University, Israel)   Amir Elalouf (Bar Ilan University, Israel)   T.C. Edwin Cheng (The Hong Kong Polytechnic University, Hong Kong)  Abstract: Camponogara and Shima (2010) developed an   ε-approximation algorithm (FPTAS) for the mobile agent routing   problem in which a benefit function determines how visits to   different sites contribute to the agent's mission. The benefit is   to be maximized under a time constraint. They reduced the problem to   the constrained longest-path problem in a graph. In this note we   present a modified FPTAS that improves on their result by a factor   of , where and  are an upper bound and a lower bound on the maximum   benefit, respectively, n is the number of nodes, and h is the length   of the longest path (in hops) in the graph.               Keywords: FPTAS, approximation algorithm, constrained longest path, constrained routing, mobile agent               Categories: F.2.2, G.2.2, I.2.11, J.7  
17|13||A Relational Approach to Model Transformation with QVT Relations Supporting Model Synchronization|  Kun Ma (University of Jinan, China)   Bo Yang (University of Jinan, China)   Zhenxiang Chen (University of Jinan, China)   Ajith Abraham (Scientific Network for Innovation and Research Excellence, USA)  Abstract: With the help of model transformation, it is possible to generate target models from source models. A possible way to face iterative development process with frequent modifications is to use not only a single transformation but also frequent model synchronization. In this paper, we propose a relational approach to model transformation using Query/View/Transformations (QVT) Relations language that also provides model synchronization mechanism based on the version of the models. The proposed framework uses a Platform-Independent Business Model (PIM-BM) and a Platform-Specific Business Component Model (PSM-BC) via the extension of the UML metamodel and MOF at different levels of abstraction, which sufficiently describe both the structural and behavioral properties of generic Web applications. Also we present the typical model mapping rules between PIM-BMs and PSM-BCs using QVT Relations. Finally the model synchronization based on the version of models is provided for the above model transformation approach.               Keywords: model driven software development, model synchronization, model transformation, model-driven architecture, modeling               Categories: D.2.1, D.2.11, D.2.2, I.6.5  
17|14|http://www.jucs.org/jucs_17_14|CSCWD: New Applications and Challenges|
17|14||Achieving Transparent and Real-time Collaboration in Co-AutoCAD Application|  Liping Gao (University of Shanghai for Science and Technology, PR China)   Tun Lu (Fudan University, PR China)  Abstract: In order to support the real-time collaboration   between geographically distributed designers, the single-user   application AutoCAD is required to be transformed transparently into   groupware system by adopting fully replicated architecture. As the   core issue to maintain the consistency of the distributed replicas,   traditional consistency maintenance algorithms (such as Operation   Transformation and Address Space Transformation algorithms),   however, support only linear data model, and may lead to low   algorithm efficiency and small operation types when adapted to the   collaborative design field. In this paper, a novel layered document   model is proposed to abstract the document model of AutoCAD, and the   AST algorithm is adapted according to the model to achieve   transparent and real-time collaboration. Moreover, the Update   conflicts resolution based on child-precedence strategy, and the   database listening technique used to grasp the semantics of   interface operations to realize operation adaptation are also   presented. Efficiency analysis of the Layer-AST algorithm is given,   showing the improved performance of the algorithm. Finally, the   system architecture of Co-AutoCAD using this strategy is detailed to   guide the application.               Keywords: conflict resolution, consistency maintenance, data model transformation, layered document model, operation adaptation               Categories: J.6  
17|14||Collaboration, Information Seeking and Communication: An Observational Study of Software Developers' Work Practices|  Márcio Kuroki Gonçalves (Federal University of Pará, Brazil)   leidson R. B. de Souza (IBM Research Brazil, Brazil)   Victor M. González (Instituto Tecnológico Autónomo de México, México)  Abstract: Different aspects defining the nature of software engineering work have been analyzed by empirical studies conducted in the last 30 years. However, in recent years, many changes have occurred in the context of software development that impact the way people collaborate, communicate with each other, manage the development process and search for information to create solutions and solve problems. For instance, the generalized adoption of asynchronous and synchronous communication technologies as well as the adoption of quality models to evaluate the work being conducted are some aspects that define modern software development scenarios. Despite this new context, much of the research in the collaborative aspects of software design is based on research that does not reflect these new work environments. Thus, a more up-to-date understanding of the nature of software engineering work with regards to collaboration, information seeking and communication is necessary. The goal of this paper is to present findings of an observational study to understand those aspects. We found that our informants spend 45% of their time collaborating with their colleagues; information seeking consumes 31,90% of developers' time; and low usage of software process tools is observed (9,35%). Our results also indicate a low usage of e-mail as a communication tool (∼1% of the total time spent on collaborative activities), and software developers, of their total time on communication efforts, spending 15% of it looking for information, that helps them to be aware of their colleagues' work, share knowledge, and manage dependencies between their activities. Our results can be used to inform the design of collaborative software development tools as well as to improve team management practices.               Keywords: CSCW, awareness, collaboration,, multi-tasking, observational study, software engineers               Categories: D.2.2, H.5.2, H.5.3  
17|14||Enabling Crowd Participation in  Governmental Decision-making|  Ana Cristina B. Garcia (Universidade Federal Fluminense,, Brazil)   Adriana S. Vivacqua (Universidade Federal do Rio de Janeiro, Brazil)   Thiago C. Tavares (Universidade Federal Fluminense, Brazil)  Abstract: Democratic governments constantly need to make sense of their citizens' needs to make appropriate decisions that reflect the overall wishes and needs of the population. However, except for mandatory voting scenarios, a low rate of citizen participation in government decisions through democratic processes is an aspect that defies democracy itself. Brazil's participatory budget policy emphasizes people's direct guidance regarding certain budget allocations though group meetings. This paper presents mParticipation, an agent-based model for eliciting and answering citizen demands in a participatory government structure using mobile technology. A prototype system applied to the domain of public budget allocation domain demonstrates that it is feasible to provide effective computational support to participatory collective decision-making.               Keywords: collective intelligence, crowdsourcing, m-Democracy, m-Government, mobile interaction, participatory decision-making               Categories: H.1.2, H.5.2, H.5.3, K.4.1, K.5.2, M.0  
17|14||Identifying Workgroups in Brazilian Scientific Social Networks|  Victor Ströele (Federal University of Rio de Janeiro, Brazil)   Ricardo Silva (Federal University of Rio de Janeiro, Brazil)   Moises Ferreira de Souza (Federal University of Rio de Janeiro, Brazil)   Carlos Eduardo R. de Mello (Federal University of Rio de Janeiro, Brazil)   Jano M. Souza (Federal University of Rio de Janeiro, Brazil)   Geraldo Zimbrao (Federal University of Rio de Janeiro, Brazil)   Jonice Oliveira (Federal University of Rio de Janeiro, Brazil)  Abstract: Social networks are social structures consisting of individuals or organizations, usually represented by nodes tied by one or more types of relationships. Although these structures are often complex, analyzing them enables us to detect several inter and intra connections amongst people in and outside their organizations. In this context, we present an approach using data mining techniques in order to identify intra and inter organizational linkages amongst groups of people with similar profiles. Using clustering techniques, we identify groups of people in a way that allows us to evaluate how researchers collaborate in the Brazilian scientific scenario of Computing Science. Besides this, we are able to understand how research flows amongst the best universities and research centres in Brazil. Understanding the Scientific Brazilian scenario can help the development of research in other scenario or even in other Social Network Types.               Keywords: data mining, group detection, scientific collaboration, scientific social networks analysis               Categories: J.1, J.4, K.4.2, K.4.3, L.6, L.6.2  
17|14||Studying the Effects of Information Exchange Channels in Different Communication Modes on Trust Building in Computer-mediated Remote Collaborative Design|  Xiangyu Wang (Curtin University, Australia)   Peter E.D. Love (Curtin University, australia)   Mi Jeong Kim (Kyung Hee University, Republic of Korea)   Lu Wang (The University of Sydney, Australia)  Abstract: The development of information and communication technology (ICT) offers new working styles, where participants in remote locations could communicate and collaborate on projects to achieve a common target. Former studies in different domains have focused on different aspects of trust to help trust building. Our focus is on exploring the effects of communication modes and information exchange channels on trust level in a computer-mediated collaborative remote design team. We describe trust building process in computer-mediated collaborative remote design and demonstrate how the influences were exerted by the combination of communication modes and information exchange channels. The results demonstrate which combination would be best for trust building in a certain condition of the remote settings. The propositions are formulized based on the analysis of the results, which would be critical to trust building in a remote collaborative design team using ICT.               Keywords: collaboration, communication modes, design, information exchange channels, trust               Categories: H.5  
17|14||An Intelligent System for Automated Binary Knowledge Document Classification and Content Analysis|  Tzu-An Chiang (National Taipei College of Business, Taiwan)   Chun-Yi Wu (National Tsing Hua University, Taiwan)   Charles V. Trappey (National Chiao Tung University, Taiwan)   Amy J. C. Trappey (National Tsing Hua University, Taiwan)  Abstract: Many companies rely on patent engineers to search patent documents and offer recommendations and advice to R and D engineers. Given the increasing number of patent documents filed each year, new means to effectively and efficiently identify and manage technology specific patent documents are required. This research applies a back-propagation artificial neural network (BPANN), a hierarchical ontology technique, and a normalized term frequency (NTF) method to develop an intelligent system for binary knowledge document classification and content analysis. The intelligent system minimizes inappropriate patent document classification and reduces the effort required to search and screen patents for analysis. Finally, this paper uses the design of light emitting diode (LED) lamps as a case study to illustrate and verify the efficiency of automated binary knowledge document classification and content analysis.               Keywords: BPANN, document classification, hierarchical ontology, normalized term frequency               Categories: H.3.1, H.3.3  
17|14||A Visited Item Frequency Based Recommender System: Experimental Evaluation and Scenario Description|  Roberto Konow (Universidad Diego Portales, Chile)   Wayman Tan (SkillUpJapan Corporation, Japan)   Luis Loyola (SkillUpJapan Corporation, Japan)   Javier Pereira (Universidad Diego Portales, Chile)   Nelson Baloian (Universidad de Chile, Chile)  Abstract: There has been a continuous development of new clustering and prediction techniques that help customers select products that meet their preferences and/or needs from an overwhelming amount of available choices. Because of the possible huge amount of available data, existing Recommender Systems showing good results might be difficult to implement and may require a lot of computational resources to perform in this scenario. In this paper, we present a more simple recommender system than the traditional ones, easy to implement, and requiring a reasonable amount of resources to perform. This system clusters users according to the frequency an item has been visited by users belonging to the same cluster, performing a collaborative filtering scheme. Experiments were conducted to evaluate the accuracy of this method using the Movielens dataset. Results obtained, as measured by the F-measure value, are comparable to other approaches found in the literature which are far more complex to implement. Following this, we explain the application of this system to an e-content site scenario for advertising. In this context, a filtering tool is shown which has been developed to filter and contextualize recommended items.               Keywords: FMeasure, TF-IDF, advertising,, clustering, collaborative filtering, e-content, recommender system               Categories: H.1.m, H.3.1, H.4.m, J.0  
17|14||An Adaptive Genetic Algorithm and Application in a Luggage Design Center|  Chen-Fang Tsai (Aletheia University, Taiwan R.O.C.)   Weidong Li (Coventry University, United Kingdom)   Anne James (Coventry University, United Kingdom)  Abstract: This paper presents a new methodology for improving the efficiency and generality of Genetic Algorithms (GA). The methodology provides the novel function of adaptive parameter adjustment during each evolution generation of GA. The important characteristics of the methodology are mainly from the following two aspects: (1) superior performance members in GA are preserved and inferior performance members are deteriorated to enhance search efficiency towards optimal solutions; (2) adaptive crossover and mutation management is applied in GA based on the transformation functions to explore wider spaces so as to improve search effectiveness and algorithm robustness. The research was successfully applied for a luggage design chain to generate optimal solutions (minimized lifecycle cost). Experiments were conducted to compare the work with the prior art to demonstrate the characteristics and advantages of the research.               Keywords: genetic algorithm, optimization, search               Categories: F.2.0, G.1.6, I.2.8  
17|14||Web Services Discovery in a Pay-As-You-Go Fashion|  Ying Pan (Guangxi Teachers Education University, P.R. China)   Yong Tang (South China Normal University, P.R. China)   Shu Li (Sun Yat-sen University, P.R. China)  Abstract: Extensive effort has been brought forth to assist in web service discovery. In particular, classic Information Retrieval techniques are exploited to assess the similarity between two web services descriptions, while Semantic Web technologies are proposed to enhance semantic service descriptions. These approaches have greatly improved the quality and accuracy of service discovery. However, these works require hard up-front investment before offering powerful functionalities for service discovery, and they do not study how to discover web services in a pay-as-you-go fashion. In this paper, a framework based on dataspace techniques is proposed to discover web services in a pay-as-you-go fashion. In this framework, a loosely structured data model based on dataspace models is presented to describe web services and the relationships among them, and then keyword-based query is supported on top of this model by using the existing dataspace query language. To support similarity-based service discovery, dataspace techniques are extended to declare the similarity among web services, and a discovery algorithm is presented. In addition, a lightweight way adding semantics to the query processing is also shown in the paper. Finally, the differences between our work and previous works are discussed.               Keywords: Web service discovery, Web service similarity, dataspace               Categories: C.2.4, D.3.m, H.3.m  
17|14||Optimization of Gateway Deployment with Load Balancing and Interference Minimization in Wireless Mesh Networks|  Junzhou Luo (Southeast University, P.R. China)   Wenjia Wu (Southeast University, P.R. China)   Ming Yang (Southeast University, P.R. China)  Abstract: In a wireless mesh network (WMN), gateways act as the bridges between the mesh backbone and the Internet, and significantly affect the performance of the whole network. Hence, how to determine the optimal number and positions of gateways, i.e., gateway deployment, is one of the most important and challenging topics in practical and theoretical research on designing a WMN. Although several approaches have been proposed to address this problem, few of them take load balancing and interference minimization into account. In this paper, we study the Load-balancing and Interference-minimization Gateway Deployment Problem (LIGDP), which aims to achieve four objectives, i.e. minimizing deployment cost, minimizing MR-GW path length, balancing gateway load and minimizing link interference. We formulate it as a multi-objective integer linear program (ILP) issue first, and then propose an efficient gateway deployment approach, called LIGDP Heuristic. The approach joints two heuristic algorithms, i.e., MSC-based location algorithm (MLA) and load-aware and interference-aware association algorithm (LIAA), to determine gateway positions and construct GW-rooted trees. Simulation results not only show that the trade-off between deployment cost and network performance can be achieved by adjusting R-hop, GW throughput and MR throughput constraints, but also demonstrate that, compared with other existing approaches, LIGDP Heuristic performs better on MR-GW path, load balancing and interference minimization without deploying more gateways.               Keywords: gateway deployment, interference minimization, load balancing, wireless mesh networks               Categories: C.2.1, C.2.5, C.2.6, G.1.6  
17|2|http://www.jucs.org/jucs_17_2|CSCWD: Applications and Challenges|
17|2||Developing a Mobile Collaborative Tool for Business Continuity Management|  Claudio Sapateiro (Polytechnic Institute of Setúbal, Portugal)   Nelson Baloian (University of Chile, Chile)   Pedro Antunes (University of Lisbon, Portugal)   Gustavo Zurita (University of Chile, Chile)  Abstract: We describe the design of a mobile collaborative   tool that helps teams managing critical computing infrastructures in   organizations, a task that is usually designated Business Continuity   Management. The design process started with a requirements   definition phase based on interviews with professional teams. The   elicited requirements highlight four main concerns: collaboration   support, knowledge management, team performance, and situation   awareness. Based on these concerns, we developed a data model and   tool supporting the collaborative update of Situation Matrixes. The   matrixes aim to provide an integrated view of the operational and   contextual conditions that frame critical events and inform the   operators responses to events. The paper provides results from our   preliminary experiments with Situation Matrixes.               Keywords: business continuity management, collaboration support, situation awareness               Categories: H.1.2  
17|2||The Iceberg Effect: Behind the User Interface of Mobile Collaborative Systems|  Valeria Herskovic (Pontificia Universidad Católica de Chile, Chile)   Sergio F. Ochoa (Universidad de Chile, Chile)   José A. Pino (Universidad de Chile, Chile)   Andrés Neyem (Pontificia Universidad Católica de Chile, Chile)  Abstract: Advances in mobile technologies are opening new possibilities to support collaborative activities through mobile devices. Unfortunately, mobile collaborative systems have been difficult to conceive, design and implement.  These difficulties are caused in part by their unclear requirements and developers lack of experience with this type of systems. However, several requirements involved in the collaborative back-end of these products are recurrent and should be considered in every development. This paper introduces a characterization of mobile collaboration and a framework that specifies a list of general requirements to be considered during the conception and design of a system in order to increase its probability of success. This framework was used in the development of two mobile collaborative systems, providing developers with a base of back-end requirements to aid system design and implementation. The systems were positively evaluated by their users.               Keywords: equirements for communication and coordination, hidden collaboration requirements, mobile shared workspaces               Categories: D.2.1, D.2.2  
17|2||An Empirical Study on Human and Information Technology Aspects in Collaborative Enterprise Networks|  Naoufel Cheikhrouhou (Ecole Polytechnique Fédérale de Lausanne (EPFL), Switzerland)   Michel Pouly (Ecole Polytechnique Fédérale de Lausanne (EPFL), Switzerland)   Charles Huber (FHNW, Switzerland)   Alok Choudhary (University of Sheffield, United Kingdom)  Abstract: Small and Medium Enterprises (SMEs) face new   challenges in the global market as customers require more complete   and flexible solutions and continue to drastically reduce the number   of suppliers. SMEs are trying to address these challenges through   cooperation within collaborative enterprise networks (CENs). Human   aspects constitute a fundamental issue in these networks as people,   as opposed to organizations or Information Technology (IT) systems,   cooperate. Since there is a lack of empirical studies on the role of   human factors in IT-supported collaborative enterprise networks,   this paper addresses the major human aspects encountered in this   type of organization. These human aspects include trust issues,   knowledge and know-how sharing, coordination and planning   activities, and communication and mutual understanding, as well as   their influence on the business processes of CENs supported by IT   tools. This paper empirically proves that these aspects constitute   key factors for the success or the failure of CENs. Two case studies   performed on two different CENs in Switzerland are presented and the   roles of human factors are identified with respect to the IT support   systems. Results show that specific human factors, namely trust and   communication and mutual understanding have to be well addressed in   order to design and develop adequate software solutions for   CENs.               Keywords: ICT support, collaborative enterprise networks, communication, human aspects, trust issues               Categories: L.3.1, L.6, M.4, M.9  
17|2||Managing Mechanisms for Collaborative New-Product Development in the Ceramic Tile Design Chain|  María-Jesús Agost (Universitat Jaume I, Spain)   Pedro Company (Universitat Jaume I, Spain)   Fernando Romero (Universitat Jaume I, Spain)  Abstract: This paper focuses on improving the management   of New-Product Development (NPD) processes within the particular   context of a cluster of enterprises that cooperate through a network   of intra- and inter-firm relations. Ceramic tile design chains have   certain singularities that condition the NPD process, such as the   lack of a strong hierarchy, fashion pressure or the existence of   different origins for NPD projects. We have studied these particular   circumstances in order to tailor Product Life-cycle Management (PLM)   tools and some other management mechanisms to fit suitable sectoral   reference models. Special emphasis will be placed on PLM templates   for structuring and standardizing projects, and also on the roles   involved in the process.               Keywords: ceramic tile products, collaborative product development, design chain               Categories: H.4.m  
17|2||A Petri Nets based Approach to Specify Individual and Collaborative Interaction in 3D Virtual Environments|  Rafael Rieder (Pontifical Catholic University of Rio Grande do Sul, Brazil)   Márcio S. Pinho (Pontifical Catholic University of Rio Grande do Sul, Brazil)   Alberto B. Raposo (Pontifical Catholic University of Rio de Janeiro, Brazil)  Abstract: This work describes a methodology that supports   the design and implementation of software modules, which represent   the individual and collaborative three-dimensional interaction   process phases. The presented methodology integrates three modeling   approaches: Petri Nets, a collaborative manipulation model based on   the combination of single user interaction techniques taxonomy, and   object-oriented programming concepts. The combination of these   elements allows for the description of interaction tasks, the   sequence of interaction processes being controlled by Petri Nets   with the codes generated automatically. By the integration of these   approaches, the present work addresses not only the entire   development cycle of both individual and collaborative   three-dimensional interaction, but also the reuse of developed   interaction blocks in new virtual environment projects.               Keywords: collaborative interaction, design process, interaction technique specification               Categories: H.5.2, I.3.6, I.3.7, I.6.5  
17|2||LaSca: a Large Scale Group Decision Support System|  Gustavo Carvalho (Federal University of Rio de Janeiro, Brazil)   Adriana S. Vivacqua (Federal University of Rio de Janeiro, Brazil)   Jano M. Souza (Federal University of Rio de Janeiro, Brazil)   Sérgio Palma J. Medeiros (Federal University of Rio de Janeiro, Brazil)  Abstract: Decision-making involves choosing between one ore more alternatives, to achieve one or more goals. To support this process, there are decision support systems that employ different approaches, supporting groups or not. Generally, however, these systems do not have great flexibility; their users have to follow preestablished decision methods. This paper, after exposing some decision-making processes, describes a system, LaSca (from Large Scale), to support decisions in large-scale groups. This system, besides allowing effective achievement of the benefits of deciding in large groups through the proper structuring of the group, also allows its users to define themselves how this structuring will happen, based or not in the existing theories on the subject. So, in addition to facilitate the decision-making process, LaSca also allows its users to decide how to decide.               Keywords: CSCW, decision-making, large groups, participatory design               Categories: H.4.2, K.6.1, M.0, M.1, M.5  
17|2||Let Me Tell You a Story -  On How to Build Process Models|  João Carlos de A. R. Gonçalves (Federal University of the State of Rio de Janeiro (UNIRIO), Brazil)   Flávia Maria Santoro (Federal University of the State of Rio de Janeiro (UNIRIO), Brazil)   Fernanda Araujo Baião (Federal University of the State of Rio de Janeiro (UNIRIO), Brazil)  Abstract: Process Modeling has been a very active research   topic for the last decades. One of its main issues is the   externalization of knowledge and its acquisition for further use, as   this remains deeply related to the quality of the resulting process   models produced by this task. This paper presents a method and a   graphical supporting tool for process elicitation and modeling,   combining the Group Storytelling technique with the advances of Text   Mining and Natural Language Processing. The implemented tool extends   its previous versions with several functionalities to facilitate   group story telling by the users, as well as to improve the results   of the acquired process model from the stories.               Keywords: business process modeling, computer-supported collaborative work, knowledge management, text mining               Categories: H.4, I.2.7, I.7  
17|2||Security and Privacy Preservation for Mobile E-Learning via Digital Identity Attributes|  Jianming Yong (University of Southern Queensland, Australia)  Abstract: This paper systematically discusses the security   and privacy concerns for e-learning systems. A five-layer   architecture of e-learning system is proposed. The security and   privacy concerns are addressed respectively for five layers. This   paper further examines the relationship among the security and privacy   policy, the available security and privacy technology, and the degree   of e-learning privacy and security. The digital identity attributes   are introduced to e-learning portable devices to enhance the   security and privacy of e-learning systems. This will provide   significant contributions to the knowledge of e-learning security and   privacy research communities and will generate more research   interests.               Keywords: E-learning, digital identity, privacy preservation, security, security and privacy architecture               Categories: H.1.2, H.4.2, J.7, K.6.5  
17|2||Realising the Potential of Web 2.0 for Collaborative Learning Using Affordances|  Andreas U. Kuswara (Macquarie University, Australia)   Debbie Richards (Macquarie University, Australia)  Abstract: With the emergence of the Web 2.0 phenomena, technology-assisted social networking has become the norm. The potential of social software for collaborative learning purposes is clear, but as yet there is little evidence of realisation of the benefits. In this paper we consider Information and Communication Technology student attitudes to collaboration and via two case studies the extent to which they exploit the use of wikis for group collaboration. Even when directed to use a particular wiki designed for the type of project they are involved with, we found that groups utilized the wiki in different ways according to the affordances ascribed to the wiki. We propose that the integration of activity theory with an affordances perspective may lead to improved technology, specifically Web 2.0, assisted collaboration.               Keywords: Web 2.0, activity theory, affordances, collaborative learning               Categories: H.4.3, J.1  
17|2||Enhancement of Collaborative Learning Activities using Portable Devices in the Classroom|  Carlos Hurtado (Universidad de Chile, Chile)   Luis A. Guerrero (Universidad de Costa Rica, Costa Rica)  Abstract: Computer Supported Collaborative Learning could   highly impact education around the world if the proper Collaborative   Learning tools are set in place. In this paper we describe the   design of a collaborative learning activity for teaching Chemistry   to Chilean students. We describe a PDA-based software tool that   allows teachers to create workgroups in their classrooms in order to   work on the activity. The developed software tool has three modules:   one module for teachers, which runs on a PC and lets them create the   required pedagogical material; second, there is a PDA module for   students which lets them execute the activity; finally, a third   module allows the teacher set workgroups and monitor each workgroup   during the activity.               Keywords: CSCL, PDAs, learning activities design               Categories: K.3, K.3.0, K.3.1, L.6.2, L.7.0  
17|3|http://www.jucs.org/jucs_17_3|Managing Editor's Column|
17|3||Coordinated System for Real Time Muscle Deformation during Locomotion|  Sandra Baldassarri (University of Zaragoza, Spain)   Francisco Seron (University of Zaragoza, Spain)  Abstract: This paper presents a system that simulates, in   real time, the volumetric deformation of muscles during human   locomotion. We propose a two-layered motion model. The requirements   of realism and real time computation lead to a hybrid locomotion   system that uses a skeleton as first layer. The muscles, represented   by an anatomical surface model, constitute the second layer, whose   deformations are simulated with a finite element method (FEM). The   FEM subsystem is fed by the torques and forces got from the   locomotion system, through a line of action model, and takes into   account the geometry and material properties of the muscles. High   level parameters (like height, weight, physical constitution, step   frequency, step length or speed) allow to customize the individuals   and the locomotion and therefore, the deformation of the persons'   muscles.               Keywords: animation, finite element method, human locomotion, muscle deformation               Categories: G.1.10, I.3, I.6  
17|3||The Architectural Design of a System for Interpreting Multilingual Web Documents in E-speranto|  Grega Jakus (University of Ljubljana, Slovenia)   Jaka Sodnik (University of Ljubljana, Slovenia)   Sašo Tomažič (University of Ljubljana, Slovenia)  Abstract: E-speranto is a formal language for generating   multilingual texts on the World Wide Web. It is currently still   under development. The vocabulary and grammar rules of E-speranto   are based on Esperanto; the syntax of E-speranto, however, is based   on XML (eXtensible Markup Language). The latter enables the   integration of documents generated in E-speranto into web   pages. When a user accesses a web page generated in E-speranto, the   interpreter interprets the document into a chosen natural language,   which enables the user to read the document in any arbitrary   language supported by the interpreter.  The basic parts of the E-speranto interpreting system are the interpreters and information resources, which complies with the principle of separating the interpretation process from the data itself. The architecture of the E-speranto interpreter takes advantage of the resemblance between the languages belonging to the same linguistic group, which consequently results in a lower production cost of the interpreters for the same linguistic group.  We designed a proof-of-concept implementation for interpreting E-speranto in three Slavic languages: Slovenian, Serbian and Russian. These languages share many common features in addition to having a similar syntax and vocabulary. The content of the information resources (vocabulary, lexicon) was limited to the extent that was needed to interpret the test documents. The testing confirmed the applicability of our concept and also indicated the guidelines for future development of both the interpreters and E-speranto itself.               Keywords: E-speranto, World Wide Web, XML, interpretation, multilayered architecture, multilingual documents               Categories: D.2.11, H.5, I.2.7  
17|3||The Synthesis of LSE Classifiers: From Representation to Evaluation|  Fernando López-Colino (Universidad Autónoma de Madrid, Spain)   José Colás (Universidad Autónoma de Madrid, Spain)  Abstract: This work presents a first approach to the   synthesis of Spanish Sign Language's (LSE) Classifier   Constructions (CCs). All current attempts at the automatic   synthesis of LSE simply create the animations corresponding to   sequences of signs. This work, however, includes the synthesis of   the LSE classification phenomena, defining more complex elements   than simple signs, such as Classifier Predicates,   Inflective CCs and Affixal   classifiers. The intelligibility of our synthetic messages   was evaluated by LSE natives, who reported a recognition rate of 93%   correct answers.               Keywords: Automatic Synthesis, Classifier Constructions, Deaf People, Spanish Sign Language               Categories: H.5.2, I.2.7, I.3.7, K.4.2  
17|3||On Compound Purposes and Compound Reasons for Enabling Privacy|  Wynand van Staden (University of Pretoria, South Africa)   Martin S. Olivier (University of Pretoria, South Africa)  Abstract: This paper puts forward a verification method   for compound purposes and compound reasons to be used during purpose   limitation.  When it is absolutely necessary to collect privacy related information, it is essential that privacy enhancing technologies (PETs) protect access to data - in general accomplished by using the concept of purposes bound to data. Compound purposes and reasons are an enhancement of purposes used during purpose limitation and binding and are more expressive than purposes in their general form. Data users specify their access needs by making use of compound reasons which are defined in terms of (compound) purposes. Purposes are organised in a lattice with purposes near the greatest lower bound (GLB) considered weak (less specific) and purposes near the least upper bound (LUB) considered strong (most specific).  Access is granted based on the verification of the statement of intent (from the data user) against the compound purpose bound to the data; however, because purposes are in a lattice, the data user is not limited to a statement of intent that matches the purposes bound to the data exactly - the statement can be a true reflection of their intent with the data. Hence, the verification of compound reasons against compound purposes cannot be accomplished by current published verification algorithms.  Before presenting the verification method, compound purposes and reasons, as well as the structures used to represent them, and the operators that are used to define compounds is presented. Finally, some thoughts on implementation are provided.               Keywords: Compound Purposes, Databases, Privacy Enhancing Technologies, Purpose Lattices, Purposes               Categories: E.m, K.4.m  
17|3||Early Results of Experiments with Responsive Open Learning Environments|  Martin Friedrich (Fraunhofer FIT, Germany)   Martin Wolpers (Fraunhofer FIT, Germany)   Ruimin Shen (Shanghai Jiao Tong University, China)   Carsten Ullrich (Shanghai Jiao Tong University, China)   Ralf Klamma (RWTH Aachen, Germany)   Dominik Renzel (RWTH Aachen, Germany)   Anja Richert (RWTH Aachen, Germany)   Bodo von der Heiden (RWTH Aachen, Germany)  Abstract: Responsive open learning environments (ROLEs) are the next generation of personal learning environments (PLEs). While PLEs rely on the    simple aggregation of existing content and services mainly using Web 2.0 technologies, ROLEs are transforming lifelong learning by introducing a new    infrastructure on a global scale while dealing with existing learning management systems, institutions, and technologies. The requirements engineering process in    highly populated test-beds is as important as the technology development. In this paper, we will describe first experiences deploying ROLEs at two higher learning    institutions in very different cultural settings. The Shanghai Jiao Tong University in China and at the “Center for Learning and Knowledge Management and Department    of Information Management in Mechanical Engineering” (ZLW/IMA) at RWTH Aachen University have exposed ROLEs to theirs students in already established courses. The    results demonstrated to readiness of the technology for large-scale trials and the benefits for the students leading to new insights in the design of ROLEs also    for more informal learning situations.               Keywords: inter-widget communication, language learning, personalized learning environment, responsive open learning environment               Categories: D.2, L.2, L.3, M.5  
17|3||Pragmatic Knowledge Services|  Mikko V. Pohjola (National Institute for Health and Welfare, Finland)   Pasi Pohjola (National Institute for Health and Welfare, Finland)   Sami Paavola (University of Helsinki, Finland)   Merja Bauters (Helsinki Metropolia University of Applied Sciences, Finland)   Jouni T. Tuomisto (National Institute for Health and Welfare, Finland)  Abstract: Knowledge, innovations and their implementation   in effective practices are essential for development in all fields   of societal action, e.g. policy, business, health, education, and   everyday life. However, managing the interrelations between   knowledge, innovation and practice is complicated. Facilitation by   suitable knowledge services is needed. This paper explores the   theory of converging knowledge, innovation, and practice, discusses   some advances in information systems development, and identifies   general requirements for pragmatic knowledge services. A trialogical   approach to knowledge creation and learning is adopted as a viable   theoretical basis. Also three examples of novel knowledge services   Opasnet, Innovillage, and Knowledge Practices Environment (KPE), are   presented. Eventually, it is concluded that pragmatic knowledge   services, as hybrid systems of information technology and its users,   are not only means for creation of practical knowledge, but vehicles   of a cultural change from individualistic perceptions of knowledge   work towards mediated collaboration.               Keywords: Innovillage, KP-Lab, KPE, Opasnet, collaborative knowledge services, collective knowledge, innovation, knowledge practices, open assessment, pragmatism, trialogical approach               Categories:  L.6.0,  L.6.2, L.1.2, L.2.3, L.3.6  
17|3||Rule of Law on the Go: New Developments of Mobile Governance|  Marta Poblet (ICREA, Spain)  Abstract: This paper offers an overview of the emerging   domain of mobile governance as an offspring of the broader landscape   of e-governance. Mobile governance initiatives have been deployed   everywhere in parallel to the development of crowdsourced, open   source software applications that facilitate the collection,   aggregation, and dissemination of both information and data coming   from different sources: citizens, organizations, public bodies,   etc. Ultimately, mobile governance can be seen as a tool to promote   the rule of law from a decentralized, distributed, and bottom-up   perspective.               Keywords: crowdsourcing, governance, mobile governance, mobile technologies, rule of law               Categories: H.2, H.4  
17|4|http://www.jucs.org/jucs_17_4|Web 2.0: Applications and Mechanisms|
17|4||IDEA: A Framework for a Knowledge-based Enterprise 2.0|"  Dada Lin (Technical University Dresden, Germany)   Peter Geißler (expeet|consulting, Germany)   Stefan Ehrlich (T-Systems Multimedia Solutions, Germany)   Eric Schoop (Technical University Dresden, Germany)  Abstract: This paper looks at the convergence of knowledge management and Enterprise 2.0 and describes the possibilities for an over-arching exchange and transfer of knowledge in Enterprise 2.0. This will be underlined by the presentation of the concrete example of T-System Multimedia Solutions (MMS), which describes the establishment of a new enterprise division ""IG eHealth"". This is typified by the decentralised development of common ideas, collaboration and the assistance available to performing responsibilities as provided by Enterprise 2.0 tools. Taking this archetypal example and the derived abstraction of the problem regarding the collaboration of knowledge workers as the basis, a regulatory framework will be developed for knowledge management to serve as a template for the systemisation and definition of specific Enterprise 2.0 activities. The paper will conclude by stating factors of success and supporting Enterprise 2.0 activities, which will facilitate the establishment of a practical knowledge management system for the optimisation of knowledge transfer.               Keywords: Enterprise 2.0, IDEA, enabling factors, expert knowledge, knowledge management, regulatory framework, social software               Categories: M.1, M.2, M.4  "
17|4||Enterprise Microblogging for Advanced Knowledge Sharing: The References@BT Case Study|  Johannes Müller (Siemens Switzerland Ltd., Switzerland)   Alexander Stocker (Joanneum Research, Austria)  Abstract: Siemens is well known for ambitious efforts in knowledge management, providing a series of innovative tools and applications within the intranet. References@BT is such a web-based application with currently more than 7,300 registered users from more than 70 countries. Its goal is to support the sharing of knowledge, experiences and best-practices globally within the Building Technologies division. Launched in 2005, References@BT features structured knowledge references, discussion forums, and a basic social networking service. In response to use demand, a new microblogging service, tightly integrated into References@BT, was implemented in March 2009. More than 500 authors have created around 2,600 microblog postings since then. Following a brief introduction into the community platform References@BT, we comprehensively describe the motivation, experiences and advantages for an organization in providing internal microblogging services. We provide detailed microblog usage statistics, analyzing the top ten users regarding postings and followers as well as the top ten topics. In doing so, we aim to shed light on microblogging usage and adoption within a globally distributed organization.               Keywords: Enterprise 2.0, Web 2.0, enterprise microblogging, knowledge management, knowledge sharing, microblogging, social media               Categories: M.0, M.6  
17|4||Leveraging Web 2.0 in New Product Development: Lessons Learned from a Cross-company Study|  Marco Bertoni (Luleå University of Technology, Sweden)   Koteshwar Chirumalla (Luleå University of Technology, Sweden)  Abstract: The paper explores the application of Web 2.0 technologies to support product development efforts in a global, virtual and cross-functional setting. It analyses the dichotomy between the prevailing hierarchical structure of CAD/PLM/PDM systems and the principles of the Social Web under the light of the emerging product development trends. Further it introduces the concept of Engineering 2.0, intended as a more bottom up and lightweight knowledge sharing approach to support early stage design decisions within virtual and cross-functional product development teams. The lessons learned collected from a cross-company study highlight how to further developblogs, wikis, forums and tags for the benefit of new product development teams, highlighting opportunities, challenges and no-go areas.               Keywords: Cross-functional Teams, Engineering 2.0, Functional Product Development, Product Development, Web 2.0               Categories: K.4.3, L.6.1, L.6.2, M.0, M.1, M.2, M.5, M.7  
17|4||On the Construction of Efficiently Navigable Tag Clouds Using Knowledge from Structured Web Content|  Christoph Trattner (Graz University of Technology, Austria)   Denis Helic (Graz University of Technology, Austria)   Markus Strohmaier (Graz University of Technology, Austria)  Abstract: In this paper we present an approach to improving navigability of a hierarchically structured Web content. The approach is based on an integration of a tagging module and adoption of tag clouds as a navigational aid for such content. The main idea of this approach is to apply tagging for the purpose of a better highlighting of cross-references between information items across the hierarchy. Although in principle tag clouds have the potential to support efficient navigation in tagging systems, recent research identified a number of limitations. In particular, applying tag clouds within pragmatic limits of a typical user interface leads to poor navigational performance as tag clouds are vulnerable to a so-called pagination effect. In this paper, a solution to the pagination problem is discussed, implemented as a part of an Austrian online encyclopedia called Austria-Forum, and analyzed. In addition, a simulation-based evaluation of the new algorithm has been conducted. The first evaluation results are quite promising, as the efficient navigational properties are restored.               Keywords: algorithm, navigability, navigation, online encyclopedia, tag cloud algorithm, tag clouds, tagging, tags               Categories: H.4  
17|4||A Clustering Approach for Collaborative Filtering Recommendation Using Social Network Analysis|  Manh Cuong Pham (RWTH Aachen University, Germany)   Yiwei Cao (RWTH Aachen University, Germany)   Ralf Klamma (RWTH Aachen University, Germany)   Matthias Jarke (RWTH Aachen University, Germany)  Abstract: Collaborative Filtering(CF) is a well-known   technique in recommender systems. CF exploits relationships between   users and recommends items to the active user according to the   ratings of his/her neighbors. CF suffers from the data sparsity   problem, where users only rate a small set of items. That makes the   computation of similarity between users imprecise and consequently   reduces the accuracy of CF algorithms. In this article, we propose a   clustering approach based on the social information of users to   derive the recommendations. We study the application of this   approach in two application scenarios: academic venue recommendation   based on collaboration information and trust-based   recommendation. Using the data from DBLP digital library and   Epinion, the evaluation shows that our clustering technique based CF   performs better than traditional CF algorithms.               Keywords: clustering, collaborative filtering, social network analysis, trust               Categories: H.3.3, H.3.7  
17|4||Markup upon Video - towards Dynamic and Interactive Video Annotations|  Peter Schultes (University of Passau, Germany)   Franz Lehrer (University of Passau, Germany)   Harald Kosch (University of Passau, Germany)  Abstract: Interactive video is increasingly becoming a more and more dominant feature of our media platforms. Especially due to the popular YouTube annotations framework, integrating graphical annotations in a video has become very fashionable these days. However, the current options are limited to a few graphical shapes for which the user can define as good as no dynamic behaviour. Despite the enormous demand for easy-creatable, interactive video there are no such advanced tools available.  In this article we describe an innovative approach, to realize dynamics and interactivity of video annotations. First we explain basic concepts of video-markup like the generic element model and visual descriptors. After that we introduce the event-tree model, which can be used to define event-handling in an interactive video formally as well as visually. By combining these basic concepts, we can give an effective tool to the video community for realizing interactive and dynamic video in a simple, intuitive and focused way.               Keywords: event tree, hypervideo, interactive video, video 2.0, video markup               Categories: D.1.7, H.5.1, H.5.2, H.5.4  
17|4||ODR, Ontologies, and Web 2.0|  Marta Poblet (ICREA, UAB Institute of Law and Technology, Spain)   Pompeu Casanovas (UAB Institute of Law and Technology, Spain)   José-Manuel López-Cobo (playence, Austria)   Núria Casellas (UAB Institute of Law and Technology, Spain)  Abstract: Online communities and institutions create new spaces for interaction, but also open new avenues for the emergence of grievances, claims, and disputes. Consequently, online dispute resolution (ODR) procedures are core to these new online worlds. But can ODR mechanisms provide sufficient levels of reputation, trust, and enforceability for it to become mainstream? This contribution introduces the new approaches to ODR and provides a description of the design and structure of Ontomedia, a web-based platform to facilitate online mediation in different domains.               Keywords: Online Dispute Resolution (ODR), Semantic Web, relational justice, web-based services               Categories: H.2, H.4  
17|5|http://www.jucs.org/jucs_17_5|Software Components, Architectures and Reuse|
17|5||Modeling Quality Attributes with Aspect-Oriented Architectural Templates|  Mónica Pinto (University of Málaga, Spain)   Lidia Fuentes (University of Málaga, Spain)  Abstract: The quality attributes of a software system are,   to a large extent, determined by the decisions taken early in the   development process. Best practices in software engineering   recommend the identification of important quality attributes during   the requirements elicitation process, and the specification of   software architectures to satisfy these requirements. Over the years   the software engineering community has studied the relationship   between quality attributes and the use of particular architectural   styles and patterns. In this paper we study the relationship between   quality attributes and Aspect-Oriented Software Architectures -   which apply the principles of Aspect-Oriented Software Development   (AOSD) at the architectural level. AOSD focuses on identifying,   modeling and composing crosscutting concerns - i.e. concerns that   are tangled and/or scattered with other concerns of the   application. In this paper we propose to use AO-ADL, an   aspect-oriented architectural description language, to specify   quality attributes by means of parameterizable, and thus reusable,   architectural patterns. We particularly focus on quality attributes   that: (1) have major implications on software functionality,   requiring the incorporation of explicit functionality at the   architectural level; (2) are complex enough as to be modeled by a   set of related concerns and the compositions among them, and (3)   crosscut domain specific functionality and are related to more than   one component in the architecture. We illustrate our approach for   usability, a critical quality attribute that satisfies the previous   constraints and that requires special attention at the requirements   and the architecture design stages.               Keywords: AO-ADL, aspect-oriented software architecture, quality attributes, reuse, usability               Categories:  D.2, D.2.11, D.2.13  
17|5||Bio-Inspired Mechanisms for Coordinating Multiple Instances of a Service Feature in Dynamic Software Product Lines|  Jaejoon Lee (Lancaster University, United Kingdom)   Jon Whittle (Lancaster University, United Kingdom)   Oliver Storz (Lancaster University, United Kingdom)  Abstract: One of the challenges in Dynamic Software Product Line (DSPL) is how to support the coordination of multiple instances of a service feature. In particular, there is a need for a decentralized decision-making capability that will be able to seamlessly integrate new instances of a service feature without an omniscient central controller. Because of the need for decentralization, we are investigating principles from self-organization in biological organisms. As an initial proof of concept, we have applied three bio-inspired techniques to a simple smart home scenario: quorum sensing based service activation, a firefly algorithm for synchronization, and a gossiping (epidemic) protocol for information dissemination. In this paper, we first explain why we selected those techniques using a set of motivating scenarios of a smart home and then describe our experiences in adopting them.               Keywords: bio-inspired computing, dynamic software product line, variability mechanism               Categories: D.2.12  
17|5||Automatically Checking Feature Model Refactorings|  Rohit Gheyi (Federal University of Campina Grande, Brazil)   Tiago Massoni (Federal University of Campina Grande, Brazil)   Paulo Borba (Federal University of Pernambuco, Brazil)  Abstract: A feature model (FM) defines the valid combinations of features, whose combinations correspond to a program in a Software Product Line (SPL). FMs may evolve, for instance, during refactoring activities. Developers may use a catalog of refactorings as support. However, the catalog is incomplete in principle. Additionally, it is non-trivial to propose correct refactorings. To our knowledge, no previous analysis technique for FMs is used for checking properties of general FM refactorings (a transformation that can be applied to a number of FMs) containing a representative number of features. We propose an efficient encoding of FMs in the Alloy formal specification language. Based on this encoding, we show how the Alloy Analyzer tool, which performs analysis on Alloy models, can be used to automatically check whether encoded general and specific FM refactorings are correct. Our approach can analyze general transformations automatically to a significant scale in a few seconds. In order to evaluate the analysis performance of our encoding, we evaluated in automatically generated FMs ranging from 500 to 2,000 features. Furthermore, we analyze the soundness of general transformations.               Keywords: Alloy, feature models, refactoring               Categories: D.2.13, D.2.2, D.2.7  
17|5||QoS-based Approach for Dynamic Web Service Composition|  Frederico G. Alvares de Oliveira Jr. (São José dos Campos-SP, Brazil)   José M. Parente de Oliveira (São José dos Campos-SP, Brazil)  Abstract: Web Services have become a standard for integration of systems in distributed environments. By using a set of open interoperability standards, they allow computer-computer interaction, regardless the programming languages and operating systems used. The Semantic Web Services, by its turn, make use of ontologies to describe their functionality in a more structural manner, allowing computers to reason about the information required and provided by them. Such a description also allows dynamic composition of several Web Services, when only one is not able to provide the desired functionality. There are scenarios, however, in which only the functional correctness is not enough to fulfill the user requirements, and a minimum level of quality should be guaranteed by their providers. In this context, this work presents an approach for dynamic Web Service composition that takes into account the composition overall quality. The proposed approach relies on a heuristics to efficiently perform the composition. In order to show the feasibility of the proposed approach, a Web Service composition application prototype was developed and experimented with public test sets, along with another approach that does not consider quality in the composition process. The results have shown that the proposed approach in general finds compositions with more quality, within a reasonable processing time.               Keywords: Quality of Service, Semantic Web Service, Web Service Composition               Categories: H.3, H.3.5  
17|5||An Aspect-Oriented Framework for Weaving Domain-Specific Concerns into Component-Based Systems|  Fréderic Loiret (INRIA Lille, University of Lille 1, France)   Romain Rouvoy (INRIA Lille, University of Lille 1, France)   Lionel Seinturier (INRIA Lille, University of Lille 1, France)   Daniel Romero (INRIA Lille, University of Lille 1, France)   Kévin Sénéchal (INRIA Lille, University of Lille 1, France)   Aleš Plšek (Purdue University, USA)  Abstract: Software components are used in various   application domains, and many component models and frameworks have   been proposed to fulfill domain-specific requirements. The general   trend followed by these approaches is to provide ad-hoc models and   tools for capturing these requirements and for implementing their   support within dedicated runtime platforms, limited to features of   the targeted domain. The challenge is then to propose more flexible   solutions, where components reuse is domain   agnostic. In this article, we present a framework   supporting compositional construction and development of   applications that must meet various extra-functional/domain-specific   requirements. The key points of our contribution are:   i) We target development of component-oriented   applications where extra-functional requirements are expressed as   annotations on the units of composition in the application   architecture. ii) These annotations are   implemented as open and extensible component-based containers,   achieving full separation of functional and extra-functional   concerns. iii) Finally, the full machinery is   implemented using the Aspect-Oriented Programming   paradigm. We validate our approach with two case studies: the first   is related to real-time and embedded applications, while   the                 Categories: D.2.11, D.2.13, D.2.2  
17|5||Context-Aware Composition and Adaptation based on Model Transformation|  Javier Cubo (University of Málaga, Spain)   Carlos Canal (University of Málaga, Spain)   Ernesto Pimentel (University of Málaga, Spain)  Abstract: Using pre-existing software components (COTS) to develop software systems requires the composition and adaptation of the component interfaces to solve mismatch problems. These mismatches may appear at different interoperability levels (signature, behavioural, quality of service and semantic). In this article, we define an approach which supports composition and adaptation of software components based on model transformation by taking into account the four levels. Signature and behavioural levels are addressed by means of transition systems. Context-awareness and semanticbased techniques are used to tackle quality of service and semantic, respectively, but also both consider the signature level. We have implemented and validated our proposal for the design and application of realistic and complex systems. Here, we illustrate the need to support the variability of the adaptation process in a context-aware pervasive system through a real-world case study, where software components are implemented using Windows Workflow Foundation (WF). We apply our model transformation process to extract transition systems (CA-STS specifications) from WF components. These CA-STSs are used to tackle the composition and adaptation. Then, we generate a CASTS adaptor specification, which is transformed into its corresponding WF adaptor component with the purpose of interacting with all the WF components of the system, thereby avoiding mismatch problems.               Keywords: Windows workflow, adaptation, components, composition, context-aware systems, interfaces, model transformation, reusability, transition systems               Categories: D.2, D.2.1, D.2.10, D.2.11, D.2.12, D.2.13, D.2.2  
17|5||An Approach for Feature Modeling of Context-Aware Software Product Line|  Paula Fernandes (Federal University of Rio de Janeiro, Brazil)   Cláudia Werner (Federal University of Rio de Janeiro, Brazil)   Eldânae Teixeira (Federal University of Rio de Janeiro, Brazil)  Abstract: Feature modeling is an approach to represent   commonalities and variabilities among products of a product   line. Context-aware applications use context information to provide   relevant services and information for their users. One of the   challenges to build a context-aware product line is to develop   mechanisms to incorporate context information and adaptation   knowledge in a feature model. This paper presents UbiFEX, an   approach to support feature analysis for context-aware software   product lines, which incorporates a modeling notation and a   mechanism to verify the consistency of product configuration   regarding context variations. Moreover, an experimental study was   performed as a preliminary evaluation, and a prototype was developed   to enable the application of the proposed approach.               Keywords: Context-aware Systems, Domain Engineering, Feature Modeling, Software Product Line               Categories: D.2.1, D.2.13, D.2.2  
17|6|http://www.jucs.org/jucs_17_6|Managing Editor's Column|
17|6||A Framework to Evaluate Interface Suitability for a Given Scenario of Textual Information Retrieval|  Nicolas Bonnel (ThinkCollabs, France)   Max Chevalier (Université de Toulouse, France)   Claude Chrisment (Université de Toulouse, France)   Gilles Hubert (Université de Toulouse, France)  Abstract: Visualization of search results is an essential step in the textual Information Retrieval (IR) process. Indeed, Information Retrieval Interfaces (IRIs) are used as a link between users and IR systems, a simple example being the ranked list proposed by common search engines. Due to the importance that takes visualization of search results, many interfaces have been proposed in the last decade (which can be textual, 2D or 3D IRIs). Two kinds of evaluation methods have been developed: (1) various evaluation methods of these interfaces were proposed aiming at validating ergonomic and cognitive aspects; (2) various evaluation methods were applied on information retrieval systems (IRS) aiming at measuring their effectiveness. However, as far as we know, these two kinds of evaluation methods are disjoint. Indeed, considering a given IRI associated to a given IRS, what happens if we associate this IRI to another IRS not having the same effectiveness. In this context, we propose an IRI evaluation framework aimed at evaluating the suitability of any IRI to different IR scenarios. First of all, we define the notion of IR scenario as a combination of features related to users, IR tasks and IR systems. We have implemented the framework through a specific evaluation platform that enables performing IRI evaluations and that helps end-users (e.g. IRS developers or IRI designers) in choosing the most suitable IRI for a specific IR scenario.               Keywords: interface suitability for IR scenario, textual information retrieval systems, visual information retrieval               Categories: H.3.3  
17|6||Nondeterministic Query Algorithms|  Alina Vasilieva (University of Latvia, Latvia)   Rūsiņš Freivalds (University of Latvia, Latvia)  Abstract: Query algorithms are used to compute Boolean functions. The definition of the function is known, but input is hidden in a black box. The aim is to compute the function value using as few queries to the black box as possible. As in other computational models, different kinds of query algorithms are possible: deterministic, probabilistic, as well as nondeterministic. In this paper, we present a new alternative definition of nondeterministic query algorithms and study algorithm complexity in this model. We demonstrate the power of our model with an example of computing the Fano plane Boolean function. We show that for this function the difference between deterministic and nondeterministic query complexity is 7N versus O(3N).               Keywords: Boolean function, algorithm complexity, decision tree, nondeterministic query algorithm               Categories: F.1.1, F.1.3, F.2.3  
17|6||Descriptional Complexity of Ambiguity in Symmetric Difference NFAs|  Lynette van Zijl (Stellenbosch University, South Africa)   Jaco Geldenhuys (Stellenbosch University, South Africa)  Abstract: We investigate ambiguity for symmetric difference nondeterministic finite automata. We show the existence of unambiguous, finitely ambiguous, polynomially ambiguous and exponentially ambiguous symmetric difference nondeterministic finite automata. We show that, for each of these classes, there is a family of n-state nondeterministic finite automata such that the smallest equivalent deterministic finite automata have O(2n) states.               Keywords: ambiguity, nondeterminism, succinctness               Categories: F.1.1, F.1.2  
17|6||Improving Security Levels of IEEE802.16e Authentication by Involving Diffie-Hellman PKDS|  Yi-Li Huang (TungHai University, Taiwan)   Fang-Yie Leu (TungHai University, Taiwan)   Chao-Hong Chiu (TungHai University, Taiwan)   I-Long Lin (Central Police University, Taiwan)  Abstract: Recently, IEEE 802.16 Worldwide Interoperability for Microwave Access (WiMAX for short) has provided us with low-cost, high efficiency and high bandwidth network services. However, as with the WiFi, the radio wave transmission also makes the WiMAX face the wireless transmission security problem. To solve this problem, the IEEE802.16Std during its development stage defines the Privacy Key Management (PKM for short) authentication process which offers a one-way authentication. However, using a one-way authentication, an SS may connect to a fake BS. Mutual authentication, like that developed for PKMv2, can avoid this problem. Therefore, in this paper, we propose an authentication key management approach, called Diffie-Hellman-PKDS-based authentication method (DiHam for short), which employs a secret door asymmetric one-way function, Public Key Distribution System (PKDS for short), to improve current security level of facility authentication between WiMAXs BS and SS. We further integrate the PKMv1 and the DiHam into a system, called PKM-DiHam (P-DiHam for short), in which the PKMv1 acts as the authentication process, and the DiHam is responsible for key management and delivery. By transmitting securely protected and well-defined parameters for SS and BS, the two stations can mutually authenticate each other. Messages including those conveying user data and authentication parameters can be then more securely delivered.               Keywords: Common secret key, Diffie-Hellman PKDS, IEEE802.16e data security, PKMv1, WiMAX security               Categories: C.2.3, H.4.3, K.6.5  
17|6||Least Slack Time Rate first: an Efficient Scheduling Algorithm for Pervasive Computing Environment|  Myunggwon Hwang (Korea Institute of Science and Technology Information, South Korea)   Dongjin Choi (Chosun University, South Korea)   Pankoo Kim (Chosun University, South Korea)  Abstract: Real-time systems like pervasive computing have to complete executing a task within the predetermined time while ensuring that the execution results are logically correct. Such systems require intelligent scheduling methods that can adequately promptly distribute the given tasks to a processor(s). In this paper, we propose LSTR (Least Slack Time Rate first), a new and simple scheduling algorithm, for a multi-processor environment, and demonstrate its efficient performance through various tests.               Keywords: Least Slack Time Rate First, Multi-processor scheduling, Pervasive computing environment, scheduling algorithm               Categories: C.1, C.2  
17|6||Hierarchical Graph-Grammar Model for Secure and Efficient Handwritten Signatures Classification|  Marcin Piekarczyk (Pedagogical University of Krakow, Poland)   Marek R. Ogiela (AGH University of Science and Technology, Poland)  Abstract: One important subject associated with personal authentication capabilities is the analysis of handwritten signatures. Among the many known techniques, algorithms based on linguistic formalisms are also possible. However, such techniques require a number of algorithms for intelligent image analysis to be applied, allowing the development of new solutions in the field of personal authentication and building modern security systems based on the advanced recognition of such patterns. The article presents the approach based on the usage of syntactic methods for the static analysis of handwritten signatures. The graph linguistic formalisms applied, such as the IE graph and ETPL(k) grammar, are characterised by considerable descriptive strength and a polynomial membership problem of the syntactic analysis. For the purposes of representing the analysed handwritten signatures, new hierarchical (two-layer) HIE graph structures based on IE graphs have been defined. The two-layer graph description makes it possible to take into consideration both local and global features of the signature. The usage of attributed graphs enables the storage of additional semantic information describing the properties of individual signature strokes. The verification and recognition of a signature consists in analysing the affiliation of its graph description to the language describing the specimen database. Initial assessments display a precision of the method at a average level of under 75%.               Keywords: biometric security, handwritten signature verification, hierarchical attributed random graph, intelligent computing, secure verification, signature-based authentication               Categories: F.4.2, F.4.3, I.2.10, I.2.4, I.4.10, I.4.8, I.5.1  
17|6||Cost-Sensitive Spam Detection Using Parameters Optimization and Feature Selection|  Sang Min Lee (Korea Aerospace University, Korea)   Dong Seong Kim (Duke University, USA)   Jong Sou Park (Korea Aerospace University, Korea)  Abstract: E-mail spam is no more garbage but risk since it recently includes virus attachments and spyware agents which make the recipients' system ruined, therefore, there is an emerging need for spam detection. Many spam detection techniques based on machine learning techniques have been proposed. As the amount of spam has been increased tremendously using bulk mailing tools, spam detection techniques should counteract with it. To cope with this, parameters optimization and feature selection have been used to reduce processing overheads while guaranteeing high detection rates. However, previous approaches have not taken into account feature variable importance and optimal number of features. Moreover, to the best of our knowledge, there is no approach which uses both parameters optimization and feature selection together for spam detection. In this paper, we propose a spam detection model enabling both parameters optimization and optimal feature selection; we optimize two parameters of detection models using Random Forests (RF) so as to maximize the detection rates. We provide the variable importance of each feature so that it is easy to eliminate the irrelevant features. Furthermore, we decide an optimal number of selected features using two methods; (i) only one parameters optimization during overall feature selection and (ii) parameters optimization in every feature elimination phase. Finally, we evaluate our spam detection model with cost-sensitive measures to avoid misclassification of legitimate messages, since the cost of classifying a legitimate message as a spam far outweighs the cost of classifying a spam as a legitimate message. We perform experiments on Spambase dataset and show the feasibility of our approaches.               Keywords: Feature Selection, Intrusion Detection, Parameters Optimization, Random Forests, Spam Detection, Spambase               Categories: I.2.6, I.5.1, K.6.5, L.4.0  
17|6||Service Oriented Multimedia Delivery System in Pervasive Environments|  Zhuzhong Qian (State Key Laboratory for Novel Software Technology, P.R. China)   Sheng Zhang (State Key Laboratory for Novel Software Technology, P.R. China)   Kangbin Yim (Soonchunhyang University, Korea)   Sanglu Lu (State Key Laboratory for Novel Software Technology, P.R. China)  Abstract: Service composition is an effective approach for large-scale multimedia delivery. In previous works, user requirement is represented as one fixed functional path which is composed of several functional components in a certain order. Actually, there may be several functional paths (deliver different quality level multimedia data, e.g., image pixel, frame rate) that can meet one request. And due to the diversity of devices and connections in pervasive environment, system should choose a suitable media quality delivery path in accordance with context, instead of one fixed functional path. This paper presents a deep study of multimedia delivery problem and proposes an on-line algorithm LDPath and an off-line centralized algorithm LD/RPath respectively. LDPath aims at delivering multimedia data to end user with lowest delay by choosing services to build delivery paths hop-by-hop, which is adapted to the unstable open environment. And LD/RPath is developed for a relatively stable environment, which generates delivery paths according to the trade-off between delay and reliability metrics, because the service reliability is also an important fact in such scenario. Experimental results show that both algorithms have good performance with low overhead to the system.               Keywords: multimedia delivery, pervasive environment, service composition               Categories: H.3.2  
17|7|http://www.jucs.org/jucs_17_7|Semantic Web: Theory and Applicationsns|
17|7||Knowledge Extraction from RDF Data with Activation Patterns|  Peter Teufl (Graz University of Technology, Austria)   Günther Lackner (studio78.at, Austria)  Abstract: RDF data can be analyzed with various query languages such as SPARQL. However, due to their nature these query languages do not support fuzzy queries that would allow us to extract a broad range of additional information. In this article we present a new method that transforms the information presented by subject-relationobject relations within RDF data into Activation Patterns. These patterns represent a common model that is the basis for a number of sophisticated analysis methods such as semantic relation analysis, semantic search queries, unsupervised clustering, supervised learning or anomaly detection. In this article, we explain the Activation Patterns concept and apply it to an RDF representation of the well known CIA World Factbook.               Keywords: RDF, activation patterns, fuzzy queries, knowledge mining, machine learning, semantic similarity               Categories: M.7  
17|7||Algorithms for the Evaluation of Ontologies for Extended Error Taxonomy and their Application on Large Ontologies|  Najmul Ikram Qazi (Mohammad Ali Jinnah University, Pakistan)   Muhammad Abdul Qadir (Mohammad Ali Jinnah University, Pakistan)  Abstract: Ontology evaluation is an integral and important part of the ontology development process. Errors in ontologies could be catastrophic for the information system based on those ontologies. As per our experiments, the existing ontology evaluation systems were unable to detect many errors (like, circulatory error in class and property hierarchy, common class and property in disjoint decomposition, redundancy of sub class and sub property, redundancy of disjoint relation and disjoint knowledge omission) as defined in the error taxonomy. We have formulated efficient algorithms for the evaluation of these and other errors as per the extended error taxonomy. These algorithms are implemented (named as OntEval) and the implementations are used to evaluate well-known ontologies including Gene Ontology (GO), WordNet Ontology and OntoSem. The ontologies are indexed using a variant of already proposed scheme Ontrel. A number of errors and warnings in these ontologies have been discovered using the OntEval. We have also reported the performance of our implementation, OntEval.               Keywords: information systems applications, knowledge engineering, knowledge modelling, ontological engineering, ontology evaluation, semantic computing               Categories: H.3, H.4, M.1, M.2, M.3  
17|7||Towards Classification of Web Ontologies for the Emerging Semantic Web|  Muhammad Fahad (Université Lumière of Lyon, France)   Nejib Moalla (Université of Lumière Lyon2, France)   Abdelaziz Bouras (Université of Lumière Lyon2, France)   Muhammad Abdul Qadir (Mohammad Ali Jinnah University, Pakistan)   Muhammad Farukh (Université of Lumière Lyon2, France)  Abstract: The massive growth in ontology development has opened new research challenges such as ontology management, search and retrieval for the entire semantic web community. These results in many recent developments, like OntoKhoj, Swoogle, OntoSearch2, that facilitate tasks user have to perform. These semantic web portals mainly treat ontologies as plain texts and use the traditional text classification algorithms for classifying ontologies in directories and assigning predefined labels rather than using the semantic knowledge hidden within the ontologies. These approaches suffer from many types of classification problems and lack of accuracy, especially in the case of overlapping ontologies that share common vocabularies. In this paper, we define an ontology classification problem and categorize it into many sub-problems. We present a new ontological methodology for the classification of web ontologies, which has been guided by the requirements of the emerging Semantic Web applications and by the lessons learnt from previous systems. The proposed framework, OntClassifire, is tested on 34 ontologies with a certain degree of overlapping domain, and effectiveness of the ontological mechanism is verified. It benefits the construction, maintenance or expansion of ontology directories on the semantic web that help to focus on the crawling and improving the quality of search for the software agents and people. We conclude that the use of a context specific knowledge hidden in the structure of ontologies gives more accurate results for the ontology classification.               Keywords: ontology classification and retrieval, ontology searching, semantic matching, semantic web portals, web page classification               Categories: H.3.2, H.3.3, H.3.7, M.3, M.7  
17|7||A Semantic Wiki Based on Spatial Hypertext|  Carlos Solis (University of Limerick, Ireland)   Nour Ali (University of Limerick, Ireland)  Abstract: Spatial Hypertext Wiki (ShyWiki) is a wiki which represents knowledge using notes that are spatially distributed in wiki pages and have visual characteristics such as colour, size, or font type. The use of spatial and visual characteristics in wikis is important to improve human comprehension, creation and organization of knowledge. Another important capability in wikis is to allow machines to process knowledge. Wikis that formally structure knowledge for this purpose are called semantic wikis. This paper describes how ShyWiki can make use of spatial hypertext in order to be a semantic wiki. ShyWiki can represent knowledge at different levels of formality.  Users of ShyWiki can annotate the content and represent semantic relations without being experts of semantic web data description languages. The spatial hypertext features make it suitable for users to represent unstructured knowledge and implicit graphic relations among concepts. In addition, semantic web and spatial hypertext features are combined to represent structured knowledge. The semantic web features of ShyWiki improve navigation and publish the wiki knowledge as RDF resources, including the implicit relations that are analyzed using a spatial parser.               Keywords: Semantic Web, Semantic Wiki, ShyWiki, Spatial Hypertext               Categories: H.5.3, H.5.4  
17|7||A Ranking Tool Exploiting Semantic Descriptions for the Comparison of EQF-based Qualifications|  Valentina Gatteschi (Politecnico di Torino, Italy)   Fabrizio Lamberti (Politecnico di Torino, Italy)   Andrea Sanna (Politecnico di Torino, Italy)   Claudio Demartini (Politecnico di Torino, Italy)  Abstract: Nowadays, one of the main issues discussed at the Community level is represented by the mobility of students and workers across Europe. During the last years, in order to deal with the above picture, several initiatives have been carried out: one of them is the definition of the European Qualification Framework (EQF), a common architecture for the description of qualifications. At the same time, several research activities were established with the aim of finding how semantic technologies could be exploited for qualifications comparison in the field of human resources acquisition. In this paper, the EQF specifications are taken into account and they are applied in a practical scenario to develop a ranking algorithm for the comparison of qualifications expressed in terms of knowledge, skill and competence concepts, potentially aimed at supporting European employers during the recruiting phase.               Keywords: EQF, Semantic Web, matchmaking, ontologies               Categories: H.4.2, I.2.4  
17|7||Ontology-based User Interface Development:  User Experience Elements Pattern|  Syed K. Shahzad (Graz University of Technology, Austria)  Abstract: The user experience of any software or website consists of elements from the conceptual to the concrete level.  These elements of user experience assist in the design and development of user interfaces. On the other hand, ontologies provide a framework for computable representation of user interface elements and underlying data. This paper discusses strategies of introducing ontologies at different user interface layers adapted from user experience elements. These layers range from abstract levels (e.g. User needs/Application Objectives) to concrete levels (e.g. Application User Interface) in terms of data representation. The proposed ontological framework enables device independent, semi-automated GUI construction which we will demonstrate at a personal information management example.               Keywords: GUI, HCI, Knowledge Management, Personal Information Management, User Interface Ontology               Categories: H.1.2, H.5.2, H.5.3, I.2.4, K.6  
17|7||Ontology-based Competency Management:  the Case Study of the Mihajlo Pupin Institute|  Valentina Janev (The Mihajlo Pupin Institute, Serbia)   Sanja Vraneš (The Mihajlo Pupin Institute, Serbia)  Abstract: Semantic-based technologies have been steadily increasing their relevance in recent years in both the research world and business world. Considering this, the present article discusses the process of design and implementation of a competency management system in information and communication technologies domain utilizing the latest Semantic Web tools and technologies including D2RQ server, TopBraid Composer, OWL 2, SPARQL, SPARQL Rules and common human resources related public vocabularies. In particular, the paper discusses the process of building individual and enterprise competence models in a form of ontology database, as well as different ways of meaningful search and retrieval of expertise data on the Semantic Web. The ontological knowledge base aims at storing the extracted and integrated competences from structured, as well as unstructured sources. By using the illustrative case study of deployment of such a system in the Human Resources sector at the Mihajlo Pupin Institute, this paper shows an example of new approaches to data integration and information management. The proposed approach extends the functionalities of existing enterprise information systems and offers possibilities for development of future Internet services. This allows organizations to express their core competences and talents in a standardized, machine processable and understandable format, and hence, facilitates their integration in the European Research Area and beyond.               Keywords: ICT, Semantic Web, case study, competencies, expertise, human resources               Categories: H.4, M.0, M.3, M.4, M.7, M.8  
17|7||A Comparison of Different Retrieval Strategies Working on Medical Free Texts|  Markus Kreuzthaler (Medical University of Graz, Austria)   Marcus D. Bloice (Medical University of Graz, Austria)   Lukas Faulstich (KGaA (ID), Germany)   Klaus-Martin Simonic (Medical University of Graz, Austria)   Andreas Holzinger (Medical University of Graz, Austria)  Abstract: Patient information in health care systems mostly consists of textual data, and free text in particular makes up a significant amount of it. Information retrieval systems that concentrate on these text types have to deal with the different challenges these medical free texts pose to achieve an acceptable performance. This paper describes the evaluation of four different types of information retrieval strategies: keyword search, search performed by a medical domain expert, a semantic based information retrieval tool, and a purely statistical information retrieval method. The different methods are evaluated and compared with respect to its appliance in medical health care systems.               Keywords: evaluation, health care, information retrieval, medicine, text mining               Categories: H.3.3, I.1.3, I.2.7, J.3  
17|8|http://www.jucs.org/jucs_17_8|Cloud Computing|
17|8||An Ontology based Agent Generation for Information Retrieval on Cloud Environment|  Yue-Shan Chang (National Taipei University, Taiwan)   Chao-Tung Yang (Tunghai University, Taiwan)   Yu-Cheng Luo (National Taipei University, Taiwan)  Abstract: Retrieving information or discovering knowledge from a well organized data center in general is requested to be familiar with its schema, structure, and architecture, which against the inherent concept and characteristics of cloud environment. An effective approach to retrieve desired information or to extract useful knowledge is an important issue in the emerging information/knowledge cloud. In this paper, we propose an ontology-based agent generation framework for information retrieval in a flexible, transparent, and easy way on cloud environment. While user submitting a flat-text based request for retrieving information on a cloud environment, the request will be automatically deduced by a Reasoning Agent (RA) based on predefined ontology and reasoning rule, and then be translated to a Mobile Information Retrieving Agent Description File (MIRADF) that is formatted in a proposed Mobile Agent Description Language (MADF). A generating agent, named MIRA-GA, is also implemented to generate a MIRA according to the MIRADF. We also design and implement a prototype to integrate these agents and show an interesting example to demonstrate the feasibility of the architecture.               Keywords: agent generation, cloud computing, information retrieval, ontology               Categories: D.2.2, H.3.3, H.3.4, H.4.1, M.8  
17|8||ORPMS: An Ontology-based Real-time Project Monitoring System in the Cloud|  Hai Dong (Curtin University of Technology, Australia)   Farookh Khadeer Hussain (Curtin University of Technology, Australia)   Elizabeth Chang (Curtin University of Technology, Australia)  Abstract: Project monitoring plays a crucial role in   project management, which is a part of every stage of a project's   life-cycle. Nevertheless, along with the increasing ratio of   outsourcing in many companies' strategic plans, project monitoring   has been challenged by geographically dispersed project teams and   culturally diverse team members. Furthermore, because of the lack of   a uniform standard, data exchange between various project monitoring   software becomes an impossible mission. These factors together lead   to the issue of ambiguity in project monitoring processes. Ontology   is a form of knowledge representation with the purpose of   disambiguation. Consequently, in this paper, we propose the   framework of an ontology-based real-time project monitoring system   (ORPSM), in order to, by means of ontologies, solve the ambiguity   issue in project monitoring processes caused by multiple   factors. The framework incorporates a series of ontologies for   knowledge capture, storage, sharing and term disambiguation in   project monitoring processes, and a series of metrics for assisting   management of project organizations to better monitor projects. We   propose to configure the ORPMS framework in a cloud environment,   aiming at providing the project monitoring service to geographically   distributed and dynamic project members with great flexibility,   scalability and security. A case study is conducted on a prototype   of the ORPMS in order to evaluate the framework.               Keywords: ontology, product quality evaluation, project management, project monitoring, project progress assessment               Categories: D.2.8, D.4.7, I.2.4  
17|8||Cloud Warehousing|"  Hui Ma (Victoria University of Wellington, New Zealand)   Klaus-Dieter Schewe (Software Competence Center Hagenberg, Austria)   Bernhard Thalheim (University of Kiel, Germany)   Qing Wang (University of Otago, New Zealand)  Abstract: Data warehouses integrate and aggregate data from various sources to support decision making within an enterprise. Usually, it is assumed that data are extracted from operational databases used by the enterprise. Cloud warehousing relaxes this view permitting data sources to be located anywhere on the world-wide web in a so-called ""cloud"", which is understood as a registry of services. Thus, we need a model of dataintensive web services, for which we adopt the view of the recently introduced model of abstract state services (AS2s). An AS2 combines a hidden database layer with an operation-equipped view layer, and thus provides an abstraction of web services that can be made available for use by other systems. In this paper we extend this model to an abstract model of clouds by means of an ontology for service description. The ontology can be specified using description logics, where the ABox contains the set of services, and the TBox can be queried to find suitable services. Consequently, AS2 composition can be used for cloud warehousing.               Keywords: cloud computing, data warehouse, service composition, service ontology, service-oriented computing, tenants               Categories:  E.m, D.2.10  "
17|8||Cooperation as a Service in VANETs|  Hajar Mousannif (Cadi Ayyad University, Morocco)   Ismail Khalil (Johannes Kepler University, Austria)   Hassan Al Moatassime (Cadi Ayyad University, Morocco)  Abstract: Vehicular Networks, including Vehicular Adhoc Networks (VANETs) and Vehicular Sensor Networks (VSNs), stimulate a brand new variety of services, ranging from driver safety services, traffic information and warnings regarding traffic jams and accidents, to providing weather or road condition, parking availability, and advertisement. 3G networks and sophisticated Intelligent Transportation Systems (ITS), including deploying costly roadside base stations, can indeed be used to offer such services, but these come with a cost, both at network and hardware levels. In this paper we introduce Cooperation as a service (CaaS): A novel architecture that will allow providing a set of services for free and without any additional infrastructure, by taking advantage of Vehicle-to-Vehicle communications. CaaS uses a hybrid publish/subscribe mechanism where the driver (or subscriber) expresses his interests regarding a service (or a set of services) and where cars having subscribed to the same service will cooperate to provide the subscriber with the necessary information regarding the service he subscribed to, by publishing this information in the network. CaaS structures the network into clusters, and uses Content Based Routing (CBR) for intra-cluster communications and geographic routing for inter-cluster communications.               Keywords: CBR, VANETs, cluster, geographic routing, publish/subscribe, service               Categories: C.2.1, C.2.2  
17|9|http://www.jucs.org/jucs_17_9|Software Technologies in Knowledge Society|
17|9||Opening Learning Management Systems to Personal Learning Environments|  Francisco J. García-Peñalvo (University of Salamanca, Spain)   Miguel Á. Conde (University of Salamanca, Spain)   Marc Alier (Polytechnic University of Catalonia - UPC, Spain)   María J. Casany (Polytechnic University of Catalonia - UPC, Spain)  Abstract: New ICT technologies are continuously introducing changes in the way in which society generates, shares and access information. This is changing what society expects and requires of education. eLearning is acting as a vector of this change, introducing pervasive transformations in and out of the classroom. But with Learning Management Systems (LMS) users have reached a plateau of productivity and stability. At the same time outside the walled garden of the LMS new transformative tools, services and ways of learning are already in use, within the PLE and PLN paradigms.  The stability and maturity of the LMS may become yet another resistance factor working against the introduction of innovations. New tools and trends cannot be ignored, and this is the reason why learning platforms should become open and flexible environments. In the course of this article the reasons for this change and how it may be addressed will be discussed, together with a proposal for architecture based on Moodle.               Keywords: Learning Management System, Moodle 2.0, Personal Learning Environment, SOA, eLearning, widgets               Categories: L.2.0, L.2.1, L.2.2, L.2.3, L.3.0, L.3.6  
17|9||Modelling Knowledge and Game Based Learning: Model Driven Approach|  Miroslav Minović (Belgrade University, Serbia)   Miloš Milovanović (Belgrade University, Serbia)   Dušan Starčević (Belgrade University, Serbia)  Abstract: Research in game based learning area is moving from traditional web-based Learning Management Systems (LMS) towards game-based learning environments, with the intention of integrating advantages of using games in university education. Important issue that requires attention is proper integration of knowledge in to game environments with the focus on reusing existing units of knowledge. This is why main topic of this paper is knowledge modelling in educational games. In our work we proposed a Model Driven Approach (MDA) to educational game development that focuses on models rather than on implementation. This provides many opportunities to primarily reuse existing resources especially when it comes to knowledge. Our work enables reusing Learning Objects between web-based LMSs and game-based learning environments. We used a two-step process defined as the Model Driven Approach to Learning Objects repurposing whereby a Web based Learning Object (LO) is transformed into a more abstract model and then returned, enhanced with game specific attributes to a platform specific model. For that purpose, a new term is proposed: Educational Game Learning Object (EGLO). In order to ensure full reusability of the EGLO the authors of this paper suggested separation of style and content. This enables the designer to adapt presentational aspects of the Learning Object according to the content within as well as to the limitations and needs of the specific platform.               Keywords: Game-Based Learning, MDA, educational games, knowledge modelling, learning objects, reusability               Categories: K.3.1, L.1.2, L.2.0, L.3.0, L.3.6, L.5.1  
17|9||Application of Systems Modeling Language (SySML) for Cognitive Work Analysis in Systems Engineering Design Process|  Wilfred H. Wells (University of Central Florida, USA)   Waldemar Karwowski (University of Central Florida, USA)   Serge Sala-Diakanda (University of Central Florida, USA)   Kent Williams (University of Central Florida, USA)   Tareq Ahram (University of Central Florida, USA)   James A. Pharmer (Naval Air Warfare Center Training Systems Division, USA)  Abstract: At present time most system engineers do not have access to cognitive work analysis knowledge or training in terms that they could understand and apply in the system design process. This may lead to specifying systems requirements that do not account for cognitive strengths and limitations of the prospective users. This paper proposes integration of cognitive work demands in the systems engineering process through development of a Cognitive Work Analysis (CWA) framework and a Tutorial using Systems Modeling Language (SysML). The CWA framework provides a structured approach for defining, managing, organizing, and modeling cognitive work requirements in systems engineering process.               Keywords: Systems Modeling Language, cognitive work analysis, systems engineering, design, tutorial               Categories: J.2, J.4, L.3.0, M.4  
17|9||Using the Affect Grid to Measure Emotions in Software Requirements Engineering|  Ricardo Colomo-Palacios (Universidad Carlos III de Madrid, Spain)   Cristina Casado-Lumbreras (Universidad Complutense de Madrid, Spain)   Pedro Soto-Acosta (University of Murcia, Spain)   Angel Garcia-Crespo (Universidad Carlos III de Madrid, Spain)  Abstract: Computer systems are designed and used by humans. And human being is characterized, among other things, by emotions. Giving this fact, the process of designing and developing computer systems is, like any other facet in our lives, driven by emotions. Requirements engineering is one of the main phases in software development. In Requirements engineering, several tasks include acceptance and negotiation activities in which the emotional factor represents a key role. This paper presents a study based on the application of affect grid by Russell in requirements engineering main stakeholders: developers and users. Results show that high arousal and low pleasure levels in the process are predictors of conflictive requirements.               Keywords: emotions, software engineering, software psychology, software requirements               Categories:  D.m,  K.6.1, D.2.1  
17|9||Usability Evaluation of a Visual Modelling Tool for OWL Ontologies|  Juan García (University of Salamanca, Spain)   Francisco J. García-Peñalvo (University of Salamanca, Spain)   Roberto Therón (University of Salamanca, Spain)   Patricia Ordóñez de Pablos (University of Oviedo, Spain)  Abstract: Usability is generally regarded as ensuring that software products are effective and efficient to use from the user's perspective. Diverse aspects that ensure the usability of a software product should be assessed during the different phases in its life cycle. The goal of usability testing is to evaluate whether or not a tool that is being developed will be usable by the end user in order to achieve the tasks for which it is being designed. This paper is targeted at describing the evaluation and the usability of OWL-VisMod, a visual modelling tool for OWL ontologies, from the point of view of the human-computer interaction. This evaluation is based on a user-centred approach and the use of questionnaires. The whole usability evaluation process is described and the results are discussed.               Keywords: OWL ontologies, evaluating usability, modelling OWL, user-centred design               Categories: H.0, H.1.1, H.5.2  
17|9||Exploring the Attitudes and Intentions of Non-shoppers in the Acceptance of e-Commerce|  Ángel Hernández-García (Universidad Politécnica de Madrid, Spain)   Santiago Iglesías-Pradas (Universidad Politécnica de Madrid, Spain)   Julián Chaparro-Peláez (Universidad Politécnica de Madrid, Spain)   Félix Pascual-Miguel (Universidad Politécnica de Madrid, Spain)  Abstract: Acceptance of online shopping adoption by individuals has been a concerning issue for researchers in the past decade. However, most research has focused in evaluating the attitudes and intention to use electronic commerce from the shoppers' perspective, neglecting to analyze the behavior and attitudes of those who have not adopted e-commerce yet: the non-shoppers. The objective of this study is to explore and evaluate the behavior and attitudes of the non-shoppers' segment towards the acceptance of business-to-consumer electronic commerce (B2C-EC). The theoretical foundations of the study are provided by the Technology Acceptance Model (TAM) and the Innovations Diffusion Theory (IDT), with the addition of a specific factor related to the nature of B2C-EC: product offering of the e-commerce channel. This framework leads to an attitudinal/behavioral model which seeks to identify the factors perceived by non-shoppers as the most important for the adoption of B2C-EC.   The model has been validated with data from 995 Spanish non-shoppers using the partial least squares (PLS) technique. Findings from the analysis results show that perceived usefulness, perceived compatibility and product offering affect positively the attitude of non-shoppers towards the adoption of B2C-EC and their intention to use it. Among these factors, perceived compatibility stands out as the most relevant factor to foster the adoption of B2C-EC among non-shoppers. Other implications for theory and practice are discussed in the final section.               Keywords: B2C, TAM, acceptance models, consumer behaviour, electronic commerce, non-shoppers, perceived compatibility, product offering               Categories: H.4.0, J.4, K.4.2, K.4.4  
17|9||Positioning Theory, Roles and the Design and Implementation of Learning Technology|  Mark Johnson (University of Bolton, United Kingdom)   Dai Griffiths (University of Bolton, United Kingdom)   Mi Wang (East China Normal University, China)  Abstract: The concept of social role is a fundamental underpinning of the design and implementation of a wide range of learning technologies. However, the roles that are designed into technologies often ill-fit the real roles of teachers, learners and other stakeholders in educational institutions. This can exacerbate problems in adoption as stakeholders do not recognise the roles described for them in the technology. In this paper, Positioning Theory is used to explore the relationship between role, social context and communication drawing on specific examples of IMS Learning Design, Virtual Learning Environments, and Personal Learning Environments. With insights gained from this analysis, recommendations are made for theoretical focus on understanding the particulars of practice and identification of specific technical issues of interoperability rather than designing technologies based on idealisations of the roles of stakeholders within institutions.               Keywords: interoperability standards, learning technology design, positioning theory, social role               Categories: D.2.1, D.2.12, D.2.2, K.3.0, K.4.3  
17|9||Multimedia Modules and Virtual Organization Website for Collaborative Research Experience for Teachers in STEM|  Magdy F. Iskander (University of Hawaii at Manoa Honolulu, USA)   James Baker (University of Hawaii at Manoa Honolulu, USA)   Jill Kobashigawa Nakatsu (University of Hawaii at Manoa Honolulu, USA)   Soo Yong Lim (University of Hawaii at Manoa Honolulu, USA)   Nuri Celik (University of Hawaii at Manoa Honolulu, USA)  Abstract: Wireless enabled cyber physical systems and applications, highly interactive multimedia modules, and virtual organization tools and capabilities provide attractive avenues for boosting interest and improving teaching effectiveness of STEM courses in schools.  In this paper we describe the Research Experience for Teachers (RET)Hawaii program and present features of some of the developed multimedia modules for middle schools.  It is shown that with the production of highly interactive modules that include virtual labs, virtual instruments, and virtual participation in practical applications, the RET-Hawaii program has grown and is presently being used in 28 schools across the islands of Hawaii. To help maintain teachers connectivity, and facilitate exchange of information and sharing of implementation experiences, a virtual organization website was developed and is being used throughout the program. Features of the developed multimedia modules are described and capabilities of the developed virtual organization website are discussed. Outcomes from the RET-Hawaii program are highlighted to demonstrate some of the gained benefits from the program.               Keywords: STEM, cyber physical systems, education, multimedia modules, virtual instruments, virtual labs               Categories: L.1.5, L.2, L.2.3, L.3, L.3.6, L.6  
volume|issue|url|title|abstract
18|1|http://www.jucs.org/jucs_18_1|Outcomes of International Research Projects on Technology Applied to Education|
18|1||Exploiting Semantics for Constructing and Comparing Occupational and Educational-driven Qualifications: the TIPTOE Project|  Valentina Gatteschi (Politecnico di Torino, Italy)   Fabrizio Lamberti (Politecnico di Torino, Italy)   Claudio Demartini (Politecnico di Torino, Italy)   Rob van Wezel (KCH International, The Netherlands)   Simonetta Bettiol (Ufficio Scolastico Regionale per il Veneto, Italy)  Abstract: In recent years, mobility of students and workers started to be considered as a way for answering skill shortages in the European labor world. However, in order to implement effective mobility practices, suitable instruments supporting transparency and readability of the outcomes of learning processes as well as of the needs of companies and employers in general have to be developed. In fact, though some instruments have been introduced (like, for instance, the European Qualification Framework, EQF, the European Credit system for Vocational Education and Training, ECVET, etc.), they are often seen as theoretical tools rather than a practical help for involved stakeholders. In this work, the results of the TIPTOE project, a transnational initiative funded by the European Commission under the Lifelong Learning Programme are illustrated. In particular, the semantic-based methodology for the construction of a European-wide profile mixing education and labor worlds perspectives in the trade sector is discussed. Furthermore, a number of tools allowing end-users to compare owned qualifications to the reference one and supporting stakeholders in the reading of national educational and occupational profiles in the EQF dimension are presented.               Keywords: lifelong learning, ontology, qualifications, semantic engine, taxonomy               Categories: I.2.1, I.2.4  
18|1||CC-LO: Embedding Interactivity, Challenge and Empowerment into Collaborative Learning Sessions|  Santi Caballe (Open University of Catalonia, Spain)   David Ganan (Open University of Catalonia, Spain)   Ian Dunwell (Coventry University, United Kingdom)   Anna Pierri (Modelli Matematici e Applicazioni (MoMA, SpA), Italy)   Thanasis Daradoumis (University of the Aegean, Greece)  Abstract: Despite their demonstrated potential through a range of early studies, on-line collaborative learning systems do not yet have the impact that many believe is possible. In particular, collaborative learning approaches cannot be readily applied to every e-learning experience, since they require a degree of presence and/or collaboration which may be difficult to achieve. In addition, collaborative learning systems often lack the challenging resources and tools required to fully support collaborations, making the experience unattractive to end-users and discouraging progression. Whilst the learner might expect to control the collaborative experience, often it is the collaborative experience that controls and limits the learner. As a result, collaborative learning resources can lack authentic interactivity, user empowerment and balanced levels of challenge, thus having a negative effect in learner motivation and engagement. To overcome these deficiencies, we propose a new paradigm named Collaborative Complex Learning Objects (CC-LO): a special type of Learning Object which aims to leverage the knowledge elicited during live sessions of collaborative learning, augmented with author-generated information, to produce interactive and attractive resources to be experienced and played by learners. During CC-LO execution, learners can observe how avatars discuss and collaborate, how discussion threads grow, and how knowledge is constructed, refined and consolidated. Furthermore, learners can interact with the CC-LO in order to modify some parameters observing the consequences and assessing their understanding. The research reported in this paper was undertaken within the European Framework 7 project ALICE (Adaptive Learning via Intuitive/Interactive, Collaborative and Emotional Systems).               Keywords: collaborative complex learning objects, collaborative learning, on-line discussions, virtualized collaborative sessions               Categories: K.3.1, L.1.2, L.3.0, L.3.6  
18|1||Educational Innovation with Learning Networks: Tools and Developments|  Peter B. Sloep (Open Universiteit Nederland, The Netherlands)   Adriana J. Berlanga (Open Universiteit Nederland, The Netherlands)   Wolfgang Greller (Open Universiteit Nederland, The Netherlands)   Slavi Stoyanov (Open Universiteit Nederland, The Netherlands)   Marcel van der Klink (Open Universiteit Nederland, The Netherlands)   Symeon Retalis (University of Piraeus, Greece)   Jan Hensgens (Aurus KTS, The Netherlands)  Abstract: Professional Development is ill served by traditional ways of learning. It can profit from a Learning Networks approach, which emphasizes logistic, content and didactic flexibility. Learning Networks are online, social networks that have been designed and tooled to foster informal learning. Three European projects are discussed - idSpace, LTfLL, Handover - which have developed tools befitting networked learning. Each in its own way, the projects illustrate the benefits of a networked learning approach. This goes for all three flexibilities but in particular for the need to be didactically flexible. Finally, it is argued that formal education could profit from the tools discussed.               Keywords: FP7, Handover, LTfLL, idSpace, innovation, language technologies, learning network, networked learning               Categories: H.5.0, H.5.1, H.5.2, I.2.7, K.3.1, L.2, L.3  
18|1||Accessible Lifelong Learning at Higher Education: Outcomes and Lessons Learned at two Different Pilot Sites in the EU4ALL Project|"  Jesus G. Boticario (aDeNu Research Group, Spain)   Alejandro Rodriguez-Ascaso (aDeNu Research Group, Spain)   Olga C. Santos (aDeNu Research Group, Spain)   Emmanuelle Raffenne (Madrid, Spain)   Lydia Montandon (Atos GIBS (Global Innovation and Business Strategy), Spain)   David Roldán (Universidad Politécnica de Valencia, Spain)   Félix Buendía (Universidad Politécnica de Valencia, Spain)  Abstract: The EU4ALL project (IST-FP6-034778) has developed a general framework to address the needs of accessible lifelong learning at Higher Education level consisting of several standards-based interoperable components integrated into an open web service architecture aimed at supporting adapted interaction to guarantee students' accessibility needs. Its flexibility has supported the project implementation at several sites with different settings and various learning management systems. Large-scale evaluations involving hundreds of users, considering diverse disability types, and key staff roles have allowed obtaining valuable lessons with respect to ""how to adopt or enhance eLearning accessibility"" at university. The project was evaluated at four higher education institutions, two of the largest in Europe and two medium-sized. In this paper, we focus on describing the implementation and main conclusions at the largest project evaluation site (UNED), which was involved in the project from the beginning, and thus, in the design process, and a medium-sized university that adopted the EU4ALL approach (UPV). This implies dealing with two well-known open source learning environments (i.e. dotLRN and Sakai), and considering a wide variety of stakeholders and requirements. Thus the results of this evaluation serve to illustrate the coverage of both the approach and developments.               Keywords: adaptive learning, educational standards, learning objects, metadata and learning, service oriented architecture, user modelling, user-centred design, web accessibility               Categories: H.1.2, H.3.5, H.4.2, H.5.2, H.5.4, J.7  "
18|1||PLAYER - a European Project and a Game to Foster Entrepreneurship Education for Young People|  Benjamim Fonseca (University of Trás-os-Montes e Alto Douro, Portugal)   Ângela Pereira (Instituto Politécnico de Leiria, Portugal)   Robert Sanders (EBN - European BIC Network, Belgium)   Vera Barracho (EBN - European BIC Network, Belgium)   Urban Lapajne (University of Maribor, Slovenia)   Matej Rus (University of Maribor, Slovenia)   Martin Rahe (EADA - Escuela de Alta Dirección y Administración, Spain)   Andre Mostert (University of East London, United Kingdom)   Thorsten Klein (University of East London, United Kingdom)   Viktorija Bojovic (University of Novi Sad, Serbia)   Saa Bonjak (University of Novi Sad, Serbia)   Leonel Morgado, (University of Trás-os-Montes e Alto Douro, Portugal)   Zita Bonjak (University of Novi Sad, Serbia)   João Carvalho (CIEBI - Centro de Inovação Empresarial da Beira Interior, Portugal)   Isabel Duarte (CIEBI - Centro de Inovação Empresarial da Beira Interior, Portugal)   Andreana Casaramona (Innova BIC - Business Innovation Centre, Italy)   Alberto Soraci (Innova BIC - Business Innovation Centre, Italy)   Hugo Paredes (University of Trás-os-Montes e Alto Douro, Portugal)   Paulo Martins (University of Trás-os-Montes e Alto Douro, Portugal)   Ramiro Gonçalves (University of Trás-os-Montes e Alto Douro, Portugal)   Pedro Neves (University of Trás-os-Montes e Alto Douro, Portugal)   Ricardo Rodrigues Nunes (University of Trás-os-Montes e Alto Douro, Portugal)   Jorge Lima (University of Trás-os-Montes e Alto Douro, Portugal)   João Varajão (University of Trás-os-Montes e Alto Douro, Portugal)  Abstract: Entrepreneurship is widely recognized as one of the basic skills to be acquired through a life-long learning. The European Union, under the guidance of the Oslo Agenda, promotes several initiatives to develop entrepreneurship culture in Europe. Education can make a significant contribution to entrepreneurship, encouraging the development of entrepreneurial attitudes and skills in young people. Serious Games are presently recognised as having an important role and potential in education and social networks emerged in the last years as the platform preferred by many, especially young people, to socialize, play games and even learn. This paper presents the PLAYER project, in which a game was developed and implemented as a Facebook application, to enable learning entrepreneurial skills progressively, by guiding users to develop a business idea in the form of a business plan.               Keywords: EU project, Facebook, business education, computers in education, entrepreneurship, entrepreneurship education, game based learning, serious games, technology enhanced learning               Categories: J.4, K.3.1, K.3.2, L.3.5, L.5.1, L.6.2  
18|1||Clustering Projects for eLearning Interoperability|  Marc Alier (Universitat Politècnica de Catalunya - Barcelona Tech, Spain)   Enric Mayol (Universitat Politècnica de Catalunya - Barcelona Tech, Spain)   Maria Jose Casañ (Universitat Politècnica de Catalunya - Barcelona Tech, Spain)   Jordi Piguillem (Universitat Politècnica de Catalunya - Barcelona Tech, Spain)   Jeffrey W. Merriman (Massachusetts Institute of Technology, USA)   Miguel Ángel Conde (University of Salamanca, Spain)   Francisco J. García-Peñalvo (University of Salamanca, Spain)   Wouter Tebben (Free Knowledge Institute, The Netherlands)   Charles Severance (University of Michigan, USA)  Abstract: Since the beginning of the discipline, eLearning has been about innovation. New software, systems, contents and tools are being created and experimented with and in constant evolution. But when systems, contents and tools become successful and part of the regular infrastructure of educational institutions, interoperability becomes an issue. Systems that are consolidated and regularly used need to be able to interoperate with new ones. And the new tendencies need to fit within the current infrastructure. This paper states how several research and development projects with heterogeneous funding sources and locations worldwide, gathered together to find a solution to this common problem, providing open specifications and standards, plus Free/Libre, Open Source reference implementations.               Keywords: E-Learning, IMS LTI, LMS, Moodle, OKI, SOA, Sakai, free software, interoperability, open source, open standards, software as a service               Categories:  L.3.6, D.0, D.2.12, K.3.1, L.2.0, L.2.3, L.3.0, L.3.5  
18|1||OER Development and Promotion.  Outcomes of an International Research Projecton the OpenCourseWare Model|  Edmundo Tovar (Universidad Politecnica de Madrid, Spain)   Nelson Piedra (Universidad Tecnica Particular de Loja, Ecuador)   Janneth Chicaiza (Universidad Tecnica Particular de Loja, Ecuador)   Jorge Lopez (Universidad Tecnica Particular de Loja, Ecuador)   Oscar Martinez-Bonastre (Miguel Hernandez University, Spain)  Abstract: In this paper, we describe the successful results of an international research project focused on the use of Web technology in the educational context. The article explains how this international project, funded by public organizations and developed over the last two academic years, focuses on the area of open educational resources (OER) and particularly the educational content of the OpenCourseWare (OCW) model. This initiative has been developed by a research group composed of researchers from three countries. The project was enabled by the Universidad Politécnica de Madrid OCW Offices leadership of the Consortium of Latin American Universities and the distance education know-how of the Universidad Técnica Particular de Loja (UTPL, Ecuador). We give a full account of the project, methodology, main outcomes and validation. The project results have further consolidated the group, and increased the maturity of group members and networking with other groups in the area. The group is now participating in other research projects that continue the lines developed here.               Keywords: OCW, OER, OpenCourseWare, SNA, linked data, open educational resources, semantic web, social networks analysis               Categories: L.1.2, L.1.4, L.3.0, L.3.2, L.6.0  
18|10|http://www.jucs.org/jucs_18_10|Managing Editor's Column|
18|10||The Method of Logistic Optimization in E-commerce|  Robert Bucki (The College of Informatics and Management in Bielsko-Biała, Poland)   Petr Suchanek (Silesian University in Opava, Czech Republic)  Abstract: Rapidly changing business environment requires new approaches and methods for supporting management systems in all types of companies. Modern companies doing business use e-commerce systems by default. One of the key areas of e-commerce systems is logistics and the supply chain. The optimal way to ensure the success of logistics and supply chains is to use the methods of modeling and simulation based on appropriate models and especially its mathematical representation. In this paper, authors highlight the customer-oriented model of the e-commerce system and deal with logistic optimization and simulations. As an example, a sample logistic structure which requires the adequate control approach is presented. This is realized by means of heuristic algorithms which are responsible for meeting the set criterion. Moreover, the criteria to either maximize the production output or minimize the lost flow capacity of the logistic system or minimize the tool replacement criterion are introduced. Equations of state are given in order to represent the flow of material through the logistic system.                 Categories: C.4, H.1.1, H.4.2, I.6.8  
18|10||Web-based Environment for Learning Discrete Event Simulation|  Marijana Despotović-Zrakić (University of Belgrade, Serbia)   Dusan Barać (University of Belgrade, Serbia)   Zorica Bogdanović (University of Belgrade, Serbia)   Branislav Jovanić (University of Belgrade, Serbia)   Božidar Radenković (University of Belgrade, Serbia)  Abstract: This paper describes a web-based environment for learning discrete simulation. The main goal of the paper is to foster the process of e-learning simulation by providing students and teachers with effective and comprehensive tools for creating, storing and executing discrete system simulation models. For these purposes the FONWEBGPSS application was developed and integrated into the e-learning system Moodle. The integration is implemented on three levels: users, processes and learning resources. The integration of users and processes is performed by synchronizing data in both systems. The integration of learning resources is performed by adjusting and implementing the IEEE LOM profile for learning simulation. In order to evaluate the impact of the proposed solution on the learning simulation outcome, research has been performed within the undergraduate course Simulation and simulation languages at the University of Belgrade. Research results indicate that students achieve better results in learning simulation when using FONWEBGPSS application integrated into the e-learning system than learning in a traditional way.               Keywords: Moodle, Web-based simulation, discrete event simulation, e-learning system, learning simulation, simulation model web repository               Categories: K.3.1, K.3.2, L.3  
18|10||Automating the Analysis of Problem-solving Activities in Learning Environments: the Co-Lab Case Study|  Rafael Duque (University of Cantabria, Spain)   Lars Bollen (University of Twente, The Netherlands)   Anjo Anjewierden (University of Twente, The Netherlands)   Crescencio Bravo (University of Castilla-La Mancha, Spain)  Abstract: The analysis of problem-solving activities carried out by students in learning settings involves studying the students' actions and assessing the solutions they have created. This analysis constitutes an ideal starting point to support an automatic intervention in the student activity by means of feedback or other means to help students build their own knowledge. In this paper, we present a model-driven framework to facilitate the automation of this problem-solving analysis and of providing feedback. This framework includes a set of authoring tools that enable software developers to specify the analysis process and its intervention mechanisms by means of visual languages. The models specified in this way are computed by the framework in order to create technological support to automate the problem-solving analysis. The use of the framework is illustrated thanks to a case study in the field of System Dynamics where problem-solving practices are analysed.               Keywords: analysis of problem-solving activities, computer-supported learning environments, model-driven development, visual languages               Categories: L.0.0, L.3.4  
18|10||Usability Evaluation Methods for a Scientific Internet Information Portal|  Jens Hellmers (University of Bremen, Germany)   Jörg Thomaschewski (University of Applied Sciences Emden/Leer, Germany)   Eva-Maria Holt ((SEVEN PRINCIPLES, Germany)   Thomas Wriedt (University of Bremen, Germany)  Abstract: Sharing information is important for the scientific community. Over the years the internet became the main information source due to its actuality, interactivity and flexibility. While the amount of available data grows, especially non-profit scientific internet pages often lack the user friendliness known from commercial offers, sometimes they also fail to focus on the users needs. To analyze and improve the attractiveness of internet pages it became common to apply methods of usability engineering. But as it requires a certain amount of work it is usually done in 'big scale' for commercial offers. In this paper we would like to demonstrate the evaluation of a non-commercial scientific information internet portal using methods of usability engineering. For this an online User Experience Questionnaire (UEQ) in combination with web traffic analysis was used. We also would like to outline the experience made during the evaluation process, as well as some of the results.               Keywords: Kano model, usability engineering, user experience questionnaire UEQ               Categories: H.5.2  
18|10||Product Presentation Strategy for Online Customers|  Marija Jovic (University of Belgrade, Serbia)   Dusan Milutinovic (Hemofarm Group, Serbia)   Anton Kos (University of Ljubljana, Slovenia)   Saso Tomazic (University of Ljubljana, Slovenia)  Abstract: This paper deals with customers' behavior in an   online environment. The major hypothesis of this paper is that   different online product presentation strategies have a different   impact on the customer's choice and that this impact can be   measured. The research was conducted using an experimental method   based on 6 product groups of 8 products per group. The products were   presented with different combinations of several audio and visual   elements: text, picture, video, animation, speech, special sound,   and background music. The impact of each combination on the   customer's choice was tested on a customer sample of 46   examinees. The most important conclusion is that besides text and a   picture of the product, it is highly recommendable to include a   video of the product in the product's online presentation. Regarding   the number of multimedia elements, it is better to include more than   less elements in a product presentation on the Internet, in contrast   to some findings in connection with e-Learning.               Keywords: e-commerce, multimedia presentation, online product presentation               Categories: H.4.0, J.4, K.4.2, K.4.4  
18|10||A General Qualitative Spatio-Temporal Model Based on Intervals|  Ester Martínez-Martín (Jaume-I University, Spain)   M. Teresa Escrig (Jaume-I University, Spain)   Angel P. del Pobil (Jaume-I University, Spain)  Abstract: Many real-world problems involve qualitative   reasoning about space and/or time. Actually, it is an adequate tool   for dealing with situations in which information is not sufficiently   precise. However, despite its numerous applications, it is difficult   for people from outside the field to incorporate the required   reasoning techniques into their methods. In this paper, we present a   general, easy-to-use framework that integrates and solves the   reasoning process of all qualitative models based on intervals. This   framework has been divided into: (1) a representation magnitude and   (2) the resolution of the reasoning process. Mainly, the developed   method for solving the reasoning process is based on the definition   of two algorithms: the qualitative sum and the qualitative   difference. In addition, here, different instances of the model as   well as some practical applications of them are   presented.               Keywords: comonsense reasoning, qualitative models, spatial reasoning               Categories: I.2  
18|10||BDI Agent Architecture for Multi-Strategy Selection in Automated Negotiation|  Cao Mukun (Xiamen University, China)   Melody Y. Kiang (California State University, USA)  Abstract: Research in automated negotiation has traditionally been focusing on the negotiation protocol and strategy design, but little on the implementation related issues such as how to select the best negotiation strategy, especially for problems involving multi-strategy selection. The strategy selection is very important for agent to take risk to achieve better negotiation outcomes. The lack of such study has hampered the development in applying automated negotiation to real world problems.  This research focuses on operationalizing risk taking agent's independent decision-making process through the design of a negotiation decision-making model and the software architecture, based on an abstract architecture model that can support both goal-directed reasoning and reactive response. We formally define the automated negotiation agent's abstract architecture model and propose an algorithm for the architecture and the decision-making model. Grounded on the theory of Belief-Desire-Intention, the model can support the agent's multi-strategy negotiation.  A prototype of the model is built and applied to an aircraft purchase negotiation process to demonstrate the effectiveness of our model.               Keywords: agent architecture, automated negotiation, belief-desire-intention model, multi-agent system, negotiation agent, risk taking               Categories: I.2.11, K.4.4  
18|11|http://www.jucs.org/jucs_18_11|Some Reflections about Service Oriented Architectures, Cloud Computing Applications, Services and Interoperability|
18|11||A Simple Model Based on Web Services to Exchange Context Information between Web Browsers and Web Applications|  Jordán Pascual Espada (University of Oviedo, Spain)   Oscar Sanjuán Martínez (University Carlos III of Madrid, Spain)   B. Cristina Pelayo G-Bustelo (University of Oviedo, Spain)   Juan Manuel Cueva Lovelle (University of Oviedo, Spain)   Patricia Ordóñez de Pablos (University of Oviedo, Spain)  Abstract: Nowadays mobile devices are equipped with sensors and hardware elements capable of capturing many types of information from the real world, location, orientation, light level, temperature, etc. This information is known in some areas as context information. For years many mobile native applications use context information to support specific tasks. Most of the applications developed with traditional technologies dont have mechanisms to use most types of context information. This paper presents a lightweight approach to use context information in conventional web applications. The proposal defines a set of highly customizable XML tags, and included web applications that can express specific requests for context information. A web browser designed following the proposed specification is responsible for processing the XML tags and send the context information to the web application using web services. In this paper we present the proposed architecture, then develop and evaluate a GPS navigator application based on this proposal.               Keywords: Mobile devices, Web applications, Web browser, Web services, smartphone               Categories: H.3.5, H.4.0, H.5.4  
18|11||The Wookie Widget Server: a Case Study of Piecemeal Integration of Tools and Services|  David Griffiths (University of Bolton, United Kingdom)   Mark Johnson (University of Bolton, United Kingdom)   Kris Popat (University of Bolton, United Kingdom)   Paul Sharples (University of Bolton, United Kingdom)   Scott Wilson (University of Bolton, United Kingdom)  Abstract: Apache Wookie (incubating) has generated considerable interest within the context of Technology Enhanced Learning where it was developed, as well as in mobile applications. The origins of the system in providing services for IMS Learning Design are described, together with an introduction to the system's design and functionality.  However, the areas where it has had success are distinct from the application area for which it was designed and developed.  The implications of this for understanding user needs is analysed by using ideas drawn from sociology. The complexity of the relationship between the context of use and user needs, and the feedback loops between them is discussed, and the role of technological interventions as an element in a discourse is considered. It is proposed that this understanding of users needs, together with the experience of the development and use of Wookie, argues in favour of an interoperability strategy which focuses on relatively small sets of functional requirements, and avoidance where possible of specifications developed for particular application domains: an approach which may be characterised as piecemeal rather than Utopian.               Keywords: Apache, IMS Learning Design, Interoperability, Mash-up, Mobile, W3C, Widget, Wookie, personal learning environment, specification               Categories: H.1.2, H.3.3, H.4.1, H.4.2  
18|11||Orchestration of E-Learning Services for Automatic Evaluation of Programming Exercises|  Ricardo Queirós (CRACS & INESC-Porto LA & DI-ESEIG/IPP, Portugal)   José Paulo Leal (University of Porto, Portugal)  Abstract: Managing programming exercises require several   heterogeneous systems such as evaluation engines, learning objects   repositories and exercise resolution environments. The coordination   of networks of such disparate systems is rather complex. These tools   would be too specific to incorporate in an e-Learning platform. Even   if they could be provided as pluggable components, the burden of   maintaining them would be prohibitive to institutions with few   courses in those domains. This work presents a standard based   approach for the coordination of a network of e-Learning systems   participating on the automatic evaluation of programming   exercises. The proposed approach uses a pivot component to   orchestrate the interaction among all the systems using   communication standards. This approach was validated through its   effective use on classroom and we present some preliminary results.               Keywords: e-Learning, interoperability, service oriented architectures               Categories: D.3, L.1.2, L.3.0, L.3.6  
18|11||Docs4Learning: Getting Google Docs to work within the LMS with IMS BLTI|  Marc Alier Forment (UPC Universitat Politècnica de Catalunya Barcelona-Tech, Spain)   María José Casany (UPC Universitat Politècnica de Catalunya Barcelona-Tech, Spain)   Enric Mayol (UPC Universitat Politècnica de Catalunya Barcelona-Tech, Spain)   Jordi Piguillem (UPC Universitat Politècnica de Catalunya Barcelona-Tech, Spain)   Nikolas Galanis (UPC Universitat Politècnica de Catalunya Barcelona-Tech, Spain)   Francisco J. García-Peñalvo    Miguel Ángel Conde ((USAL Universidad de Salamanca, Spain)  Abstract: Google Docs is a well-known suite of online   collaborative tools for document processing, spreadsheets, online   presentations, drawing and even forms. The last versions of the   major open source LMS Moodle, offers weak integrations with Google   Docs treating it as a content repository. But these integrations are   neglecting the collaborative qualities of the Google Docs suite and   its potential as a learning activity within the LMS course. This   paper presents an integration proposal that using the IMS Basic   Learning Tools Interoperability (IMS BLTI) standard turns Google   Docs into an engine that powers collaborative learning activities   within the LMS Moodle.               Keywords: Google Docs, LMS, PLE, VLE, cloud computing, eLearning, interoperability, software as a service               Categories: D.0, D.2.11, D.2.12, D.2.2, K.3.1, L.2.0, L.2.3, L.3.0, L.3.5, L.3.6  
18|11||Design Choices Underlying the Software as a Service (SaaS) Business Model from the User Perspective: Exploring the Fourth Wave of Outsourcing|  Anton Joha (EquaTerra, United Kingdom)   Marijn Janssen (Delft University of Technology, The Netherlands)  Abstract: Software as a Service (SaaS) can be viewed as   the fourth wave of outsourcing. SaaS is a relatively new type of   service delivery model in which a service provider delivers its   services over the web to many users on a pay per use or period   basis. In the scarce literature available, the SaaS business model   is almost always analyzed from the perspective of the service   provider perspective, and rarely from the user organization. Using   the unified business model conceptual framework, two case studies   are investigated to understand the design choices underlying the   SaaS business model from the user organization perspective. The   analyses on the business model dimensions provided insight into the   differences between the case studies and helped to identify eight   discriminating design choices that are important when designing SaaS   business models. These include the (1) SaaS service characteristics,   (2) SaaS value source, (3) SaaS user target group, (4) data   architecture configuration and tenancy model, (5) SaaS governance   and demand/supply management core competencies, (6) cloud deployment   model, (7) SaaS integration and provider strategy and the (8) SaaS   pricing structure. An appeal is made for more research into the   impact of cloud business models.               Keywords: SaaS, business model, cloud computing, design choices, software as a Service, sourcing               Categories: H.0, H.1, H.4  
18|11||Utilization-level and Serviceability of a Social Name-card Portal for QoS in a Cloud Social Networking Service|  Yung Bok Kim (Sejong University, Korea)  Abstract: Various mobile-web services have expanded with   the evolution of mobile Internet technologies and with the   increasing variety of smart phones in the proliferating cloud   computing environment. Web services for the integration of cloud   applications/services can be evaluated at the utilization-level as   well as the serviceability of the service on the server side in the   management for cloud computing. In web activity, a web server can be   a unified hub for web interactions as well as for the real-time   estimation model of service-based parameters,   i.e. utilization-level/serviceability for service monitoring. With   the real-time estimation/analysis of the parameters in a web server   for service-based contents delivery, the utilization-level and   serviceability of a social-web name-card portal are   presented. Empirical results are presented on the basis of the   implementation of the real-time estimation scheme in a social-web   name-card portal server for a cloud SNS.               Keywords: QoS, SNS, Social Web, cloud, name card, serviceability, utilization level               Categories: H.1, H.3, H.4, H.5  
18|11||Human and Intellectual Capital Management in the Cloud: Software Vendor Perspective|  Ricardo Colomo-Palacios (Universidad Carlos III de Madrid, Spain)   Eduardo Fernandes    Marc Sabbagh (Meta4, France)   Antonio de Amescua Seco (Universidad Carlos III de Madrid, Spain)  Abstract: Cloud systems have shifted traditional   on-premise software products towards new and service oriented   solutions. In order to adapt to this new trend, traditional software   vendors are facing a necessary evolution towards service oriented   software products. This software evolution is quite complex and full   of problems. This paper presents lessons learned and the issues that   emerged in a project aimed to adapt Meta 4' PeopleNet solution to   adopt a cloud computing approach. This project, designed as a   two-step approach, presents a set of issues that are analyzed in   this paper, namely: Software evolution, Software processes and   Technology and Personnel issues. The resultant conclusions, that   highlight the importance of people in this software evolution, are   useful for companies facing a product evolution process towards   cloud oriented environments.               Keywords: cloud computing, information systems development, software as a service, software vendors               Categories: C.3, D.2.11, D.2.12, H.4.1, K.6.1, K.6.3  
18|11||Interoperability Framework for Multimodal Biometry: Open Source in Action|  Miloš Milovanović (University of Belgrade, Serbia)   Miroslav Minović (University of Belgrade, Serbia)   Starčević Dušan (University of Belgrade, Serbia)  Abstract: In recent years identity management systems significantly increased the use of biometry. This process shifted this research area towards academia that in turn resulted with the rise of available biometric solutions, especially open source ones. Most of these solutions deal with only one biometric modality. The problem is that the price of the solution affects the precision and performances of the system. Open source solutions usually struggle with this issue since the funds for development are very limited. Possible solution can be found in using the multimodal approach that involves using several biometric modalities to improve preciseness and performances of the system. Unfortunately this opens another issue of interoperability among existing biometric solutions, acquisition devices and databases. This paper focuses on solving this issue, by proposing the interoperability framework for this purpose. Efficiency of the proposed framework was evaluated by using it as a development platform for developing a multimodal biometric application that combined three separate biometric modalities: fingerprint, face and voice. Proposed framework should further accelerate future development of biometric solutions.               Keywords: framework, interoperability, multimodal biometry, open source, security               Categories:  K.6.5, D.2.11, D.2.12, D.2.13  
18|11||Towards a Practical Solution for Data Grounding in a Semantic Web Services Environment|  Miguel García Rodríguez (University of Oviedo, Spain)   Jose María Alvarez Rodríguez (University of Oviedo, Spain)   Diego Berrueta Muñoz (Fundacion CTIC, Spain)   Luis Polo Paredes (Fundacion CTIC, Spain)   Jose Emilio Labra Gayo (University of Oviedo, Spain)   Patricia Ordóñez de Pablos (University of Oviedo, Spain)  Abstract: Grounding is the process in charge of linking   requests and responses of web services with the semantic web   services execution platform, and it is the key activity to automate   their execution in a real business environment. In this paper, the   authors introduce a practical solution for data grounding. On the   one hand, we need a mapping language to relate data structures from   services definition in WSDL documents to concepts, properties and   instances of a business domain. On the other hand, two functions   that perform the lowering and lifting processes using these mapping   specifications are also presented.               Keywords: cloud computing, data grounding, interoperability, mapping languages, ontologies, semantic web, semantic web services, service-oriented architectures, web services               Categories: G.2.2, H.3.5, I.2.4  
18|12|http://www.jucs.org/jucs_18_12|An Overview of Current Information Systems Security Challenges and Innovations|
18|12||Aligning Security and Privacy to Support the Development of Secure Information Systems|  Haralambos Mouratidis (University of East London, United Kingdom)   Christos Kalloniatis (University of the Aegean, Greece)   Shareeful Islam (University of East London, United Kingdom)   Marc-Philippe Huget (University of Savoie, France)   Stefanos Gritzalis (University of the Aegean, Greece)  Abstract: The increasing dependency on information systems   to process and manage sensitive information requires the usage of   development methods that support the development of secure and   private information systems. The literature provides examples of   methods that focus on security and privacy individually but fail to   provide evidence of information systems development methods that   consider security and privacy in a unified framework. Security and   privacy are very much related, in particular certain security   properties and mechanisms support the achievement of privacy   goals. Without a development framework to support developers to   explicitly model that relationship, conflicts and vulnerabilities   can be introduced to a system design that might endanger its   security. In this paper, we present our work in developing a   framework that supports the unified analysis of privacy and   security. In particular, we present a meta-model that combines   concepts from security and privacy requirements methods, such as   security and privacy goals, properties, constraints, and actor and   process patterns within a social context. A real case study is   employed to demonstrate the applicability of our work.               Keywords: constraints, goal modelling, meta-model, privacy, security               Categories: D.2.1, D.2.2, H.1, K.6.5  
18|12||Information Security Service Culture - Information Security for End-users|  Rahul Rastogi (Nelson Mandela Metropolitan University, South Africa)   Rossouw von Solms (Nelson Mandela Metropolitan University, South Africa)  Abstract: Information security culture has been found to   have a profound influence on the compliance of end-users to   information security policies and controls in their   organization. Similarly, a complementary aspect of information   security is the culture of information security managers and   developers in the organization. This paper calls this is as the   'information security service culture' (ISSC). ISSC shapes and   guides the behaviour of information security managers and developers   as they formulate information security policies and controls. Thus,   ISSC has profound influence on the nature of these policies and   controls and thereby on the interaction of end-users with these   artefacts. ISSC is useful in transforming information security   managers and developers from their present-day technology-focused   approach to an end-user centric approach.               Keywords: ISSC, Information security culture, culture, information security management, information security service culture               Categories: H.3.1, H.3.2, H.3.3, H.3.7, H.5.1  
18|12||A Novel Identity-based Network Architecture for Next Generation Internet|  Pedro Martinez-Julia (University of Murcia, Spain)   Antonio F. Gómez-Skarmeta (University of Murcia, Spain)  Abstract: In this paper we show a network architecture for   Next Generation Internet (NGI) that prevents operation traceability   and protects the privacy of communication parties while raising   their identity to be a central element of the network. As a side   effect, our architecture inherently supports authentication and   mobility of the entities involved in the communication. Moreover, it   is designed to be agnostic to any underlying network infrastructure   and can be used to enhance them with reduced penalty, which makes it   a perfect component to take its features to existing networks   without defining a brand new transport layer. We also show the   successful verification of the protocol security and demonstrate its   feasibility and scalability showing its behavior when instantiated   on top of two different architectures.               Keywords: Next Generation Internet, identity, overlay networks, privacy               Categories: C.2.1, C.2.2, C.2.6, K.6.5  
18|12||Analysing the Security Risks of Cloud Adoption Using the SeCA Model: A Case Study|  Thijs Baars (Utrecht University, The Netherlands)   Marco Spruit (Utrecht University, The Netherlands)  Abstract: When IS/IT needs to be replaced, cloud systems   might provide a feasible solution. However, the adoption process   thus far has gone undocumented and enterprise architects are   troubled with proper hands-on tools missing, until very   recently. This single case study describes a large Dutch utility   provider in their effort to understand the facets of the cloud and   identifying the risks associated with it. In an action research   setting, the SeCA model was used to analyse the cloud solutions and   identify the risks with specific data classifications in mind. The   results show how decision makers can use the SeCA model in various   ways to identify the security risks associated with each cloud   solution analysed. The analysis assumes that data classifications   are in place. This research concludes that by using the SeCA model,   a full understanding of the security risks can be gained on an   objective and structural level; this is a further validation of   prior empirical research that the SeCA model is a proper hands-on   tool for cloud security analysis.               Keywords: SeCA model, case study, cloud computing, cloud security, information security               Categories: H.2, H.3.7, H.5.4  
18|12||Risk-Driven Security Metrics in Agile Software Development - An Industrial Pilot Study|  Reijo M. Savola (VTT Technical Research Centre of Finland, Finland)   Christian Frühwirth (Aalto University, Finland)   Ari Pietikäinen (Ericsson Finland, Finland)  Abstract: The need for effective and efficient information security solutions is steadily increasing in the software industry. Software and system developers require practical and systematic approaches to obtain sufficient and credible evidence of the security level in the system under development in order to guide their efforts and ensure the efficient use of resources. We present experiences of developing and using hierarchical security metrics and measurements in an industrial pilot study at Ericsson Finland. The pilot focused on risk-driven security design and implementation in the context of an Agile software development process. The pilot target was a well-established telecommunications product of Ericsson and a core component in modern mobile networks. The results of the study demonstrate the practical potential of risk-driven security metrics, particularly in offering some early visibility of security effectiveness and efficiency. Hierarchical metrics models enable the linking of security objectives with detailed measurements. Security metrics visualization was found to play a crucial role in increasing the manageability of metrics. We also found that the practical means of managing larger collections of metrics and measurements are more essential than individual security metrics. A major challenge in the use of risk-driven security metrics is the lack of evidence for security effectiveness evidence in the early phases of product development and Risk Analysis, when the needs for it are at their greatest.               Keywords: agile SW development, risk analysis, security metrics               Categories: D.2.2, D.2.8, D.2.9  
18|12||HC+: Towards a Framework for Improving Processes in Health Organizations by Means of Security and Data Quality Management|  Ismael Caballero (University of Castilla-La Mancha, Spain)   Luis Enrique Sánchez (SICAMAN NT., Spain)   Alberto Freitas (Universidade do Porto, Portugal)   Eduardo Fernández-Medina (University of Castilla-La Mancha, Spain)  Abstract: There is currently a need to optimize the levels of perceived quality in most public services. Some of the most critical services are those related to Health, since health and welfare are fundamental to the population as a whole. Both public and private Health organizations are therefore interested in quantifying how good their services are, and to what extent the population is satisfied with their usage. These services can be classified into two main groups: health management and clinical. The performance of both kinds of processes is being assessed through the development of certain indicators. However, as these processes are intended to be supported by Health Management Information Systems (HMIS), some legal and technical concerns must be addressed when an HMIS is developed. These HMIS commonly manage personal data which is highly sensitive, and some mechanisms to ensure both security and data quality should therefore be also implemented. But the assurance of security and data quality goes beyond the HMIS, to the overall processes. This paper introduces a framework, HC+, whose objective is to assess and improve the level of perceived quality for services by paying special attention to the way in which the processes manage the levels of security and data quality. This will be achieved by studying the dependence of indicators that are able to describe the levels of perceived quality from the levels of security and data quality. HC+ is composed of three main components: a common Information Model with which to better represent the elements of the processes involved in the study, a set of selected Indicators to measure the levels of quality, and a Methodology to assess and improve the processes so that they can obtain better values for the chosen indicators. In addition, all the changes and decisions made should be consistent with the Quality Management System (e.g. ISO 9000) of the Organization.               Keywords: ElectroniccHealth Record (EHR), HIS, Health Management Information System (HMIS or HIS), Personal Health Record (PHR), quality, quality health information, security, security health information, software engineering               Categories: K.6.5, L.4  
18|12||The Modelling of a Digital Forensic Readiness Approach for Wireless Local Area Networks|  Sipho Ngobeni (Council for Scientific and Industrial Research, South Africa)   Hein Venter (University of Pretoria, South Africa)   Ivan Burke (Council for Scientific and Industrial Research, South Africa)  Abstract: Over the past decade, wireless mobile communication technology based on the IEEE 802.11 Wireless Local Area Networks (WLANs) has been adopted worldwide on a massive scale. However, as the number of wireless users has soared, so has the possibility of cybercrime. WLAN digital forensics is seen as not only a response to cybercrime in wireless networks, but also a means to stem the increase of cybercrime in WLANs.  The challenge in WLAN digital forensics is to intercept and preserve all the communications generated by the mobile stations and to conduct a proper digital forensic investigation. This paper attempts to address this issue by proposing a wireless digital forensic readiness model designed to monitor, log and preserve wireless network traffic for digital forensic investigations. Thus, the information needed by the digital forensic experts is rendered readily available, should it be necessary to conduct a digital forensic investigation. The availability of this digital information can maximise the chances of using it as digital evidence and it reduces the cost of conducting the entire digital forensic investigation process.               Keywords: access point, cyber forensic experts, digital evidence, digital forensic process, digital forensic readiness, digital forensics, hash value, traffic, wireless local area network               Categories: H.3.1, H.3.2, H.3.3, H.3.7, H.5.1  
18|12||New Results of Related-key Attacks on All Py-Family of Stream Ciphers|  Lin Ding (Information Science and Technology Institute, China)   Jie Guan (Information Science and Technology Institute, China)   Wen-long Sun (Information Science and Technology Institute, China)  Abstract: The stream cipher TPypy has been designed by Biham and Seberry in January 2007 as the strongest member of the Py-family of stream ciphers. At Indocrypt 2007, Sekar, Paul and Preneel showed related-key weaknesses in the Py-family of stream ciphers including the strongest member TPypy. Furthermore, they modified the stream ciphers TPypy and TPy to generate two fast ciphers, namely RCR-32 and RCR-64, in an attempt to rule out all the attacks against the Py-family of stream ciphers. So far there exists no attack on RCR-32 and RCR-64. In this paper, we show that the related-key weaknesses can be still used to construct related-key distinguishing attacks on all Py-family of stream ciphers including the modified versions RCR-32 and RCR-64. Under related keys, we show distinguishing attacks on RCR-32 and RCR-64 with data complexity 2139.3 and advantage greater than 0.5. We also show that the data complexity of the distinguishing attacks on Py-family of stream ciphers proposed by Sekar et al. can be reduced fromto. These results constitute the best attacks on the strongest members of the Py-family of stream ciphers Tpypy, RCR-32 and RCR-64. By modifying the key setup algorithm, we propose two new stream ciphers TRCR-32 and TRCR-64 which are derived from RCR-32 and RCR-64 respectively. Based on our security analysis, we conjecture that no attacks lower than brute force are possible on TRCR-32 and TRCR-64 stream ciphers.               Keywords: Py-family of stream ciphers, TRCR-32, TRCR-64, cryptanalysis, distinguishing attack, related-key attack               Categories: D.4.6, E.3, K.6.5  
18|13|http://www.jucs.org/jucs_18_13|Recent Advances in Bio-Inspired Computing: Theory and Applications|
18|13||A Variant of Distributed P Systems for Real Time Cross Layer Optimization|  Susan Elias (Sri Venkateswara College of Engineering, India)   Vanaja Gokul (Sri Venkateswara College of Engineering, India)   Kamala Krithivasan (Indian Institute of Technology Madras, India)   Marian Gheorghe (University of Sheffield, United Kingdom)   Gexiang Zhang (Southwest Jiaotong University, China)  Abstract: Membrane computing models (also known as P Systems) that solve optimisation problems using genetic algorithms, ant colony optimisation, quantum-inspired evolutionary algorithm and particle swarm optimisation have been defined and are efficiently used in several applications. This paper describes the design of a variant of the existing Distributed P system (dP system) that is augmented with new features that enable centralised monitoring and communication with all the other components of the distributed system. This proposed model is titled Monitored Distributed P System (MDP System) and its innovative application in performing Cross Layer Optimisation in wireless adhoc networks is also presented. In the proposed MDP System each node in the network is represented by a P system that can independently perform Cross Layer Optimisation using particle swarm optimisation. Discussions on the communication complexity of the proposed model and the experimental results presented are also suggestive of the fact that the proposed Monitored Distributed P System is suitable for real time optimisation in a dynamic and distributed environment.               Keywords: cross layer optimisation, distributed P systems, membrane computing, particle swarm optimisation               Categories: H.1  
18|13||P Systems with Shuffle Operation and Catalytic-Like Rules|  Yunyun Niu (Huazhong University of Science and Technology, China)   Jinbang Xu (Huazhong University of Science and Technology, China)   K.G. Subramanian (Universiti Sains Malaysia, Malaysia)   Rosni Abdullah (Universiti Sains Malaysia, Malaysia)  Abstract: Shuffle operation on trajectories is useful in modeling parallel composition of wordsand languages. In this work, a new class of P systems with shuffle operation and catalytic-like rules is presented. Such a system has a membrane structure, where language-objects and shuffle-operation rules are placed in its regions. It can be used as a language generator. In this study, we propose a variant P system with shuffle operation on string-language objects. Some comparisonresults are obtained, which show that the power of shuffle operation is enlarged in the framework of P systems. Moreover, string-language objects are extended to array-language objects, and an-other variant P system with shuffle operation on picture-language objects is introduced. We also illustrate how to generate picture languages by using this kind of devices.               Keywords: P system, membrane computing, picture language, shuffle on trajectories               Categories: F.1.1, F.4.3, I.7.0  
18|13||Array P System with Shuffle on Trajectories|  A.S. Prasanna Venkatesan (B.S. Abdur Rahman University, India)   D.G. Thomas (Madras Christian College)   T. Robinson (Madras Christian College, India)   Atulya K. Nagar (Liverpool Hope University, United Kingdom)  Abstract: In this paper, we introduce a new concept of trajectory array P system which consists of a membrane structure in which the objects are arrays and the evolutionary rules are given in terms of trajectories. We present some properties of trajectory array P system and compare with certain families of picture languages. We consider a variant of trajectory array P system and show that the languages generated by the trajectory P system and its variant have common intersection.               Keywords: P system, array languages, membrane computing, shuffle on trajectories               Categories: F.4.3  
18|13||A Novel Membrane Algorithm Based on Particle Swarm Optimization for Solving Broadcasting Problems|  Gexiang Zhang (Southwest Jiaotong University)   Fen Zhou (Southwest Jiaotong University, China)   Xiaoli Huang (Southwest Jiaotong University, China)   Jixiang Cheng (Southwest Jiaotong University, China)   Marian Gheorghe (University of Sheffield, United Kingdom)   Florentin Ipate (University of Pitesti, Romania)   Raluca Lefticaru (University of Pitesti, Romania)  Abstract: This paper presents the application of membrane   algorithms to broadcasting problems, which are regarded as NP-hard   combinatorial optimization problems. A membrane algorithm, called   HPSOPS, is proposed by appropriately combining membrane systems and   a hybrid particle swarm optimization with wavelet mutation   (HPSOWM). HPSOPS is designed with the hierarchical membrane   structure and transformation/communication-like rules of membrane   systems, the representation of individuals and the evolutionary   mechanism of HPSOWM. Experimental results from various broadcasting   problems show that HPSOPS performs better than its counterpart   HPSOWM and genetic algorithms reported in the literature, in terms   of search capability, efficiency, solution stability and   precision.               Keywords: broadcasting problem, membrane algorithm, membrane computing, membrane systems, particle swarm optimization               Categories: F.1.1, F.2.1, I.2.11, I.2.8  
18|13||Solving Economic Dispatch Problems with Valve-point Effects using Particle Swarm Optimization|  Kusum Deep (Indian Institute of Technology Roorkee, India)   Jagdish Chand Bansal (ABV-Indian Institute of Information Technology and Management Gwalior, India)  Abstract: Particle Swarm Optimization (PSO) is a swarm   intelligence optimization method inspired from birds' flocking or   fish schooling. Many improved versions of PSO are reported in   literature, including some by the authors. Original as well as   improved versions of PSO have proven their applicability to various   fields like science, engineering and industries. Economic dispatch   (ED) problem is one of the fundamental issues in power system   operations. This problem turns out to be a non linear continuous   optimization problem. In this paper, economic dispatch problem is   solved using original PSO and two of its improved variants, namely,   Laplace Crossover PSO (LXPSO) and Quadratic Approximation PSO   (qPSO), in order to find better results than reported in the   literature. Results are also compared with the earlier published   results.               Keywords: Laplace Crossover, Particle Swarm optimization, Quadratic Approximation Particle Swarm optimization, economic dispatch               Categories: G.1.6, I.1.2  
18|13||Two Local Search Strategies for Differential Evolution|  Musrrat Ali (Sungkyunkwan University, Republic of Korea)   Millie Pant (Indian Institute of Technology Roorkee, India)   Atulya K. Nagar (Liverpool Hope University, United Kingdom)   Chang Wook Ahn (Sungkyunkwan University, Republic of Korea)  Abstract: Insertion of a local search technique is often considered an effective mechanism to increase the efficiency of a global optimization algorithm. In this paper we propose and analyze the effect of two local searches namely; Trigonometric Local Search (TLS) and Interpolated Local Search (ILS) on the working of basic Differential Evolution (DE). The corresponding algorithms are named as DETLS and DEILS. The performances of proposed algorithms are investigated and compared with basic DE, modified versions of DE and some other evolutionary algorithms. It is found that the proposed schemes improve the performance of DE in terms of quality of solution without compromising with the convergence rate.               Keywords: differential evolution, global optimization, local search, quadratic interpolation, trigonometric mutation               Categories: C.2.m, F.2, G.1.10, G.1.6, I.6, J.0  
18|13||Real-time Implementation of a Class of Optimised Multirate Quadrature Mirror Filter Bank Using Genetic Algorithms|  Gurvinder Singh Baicher (University of Wales Newport, United Kingdom)  Abstract: This paper considers theoretical issues concerning reconstruction errors and conditions for perfect reconstruction (PR) of the input signal for a 2-channel multirate quadrature mirror filter (QMF) bank.  The main emphasis is on the optimisation of a new design of a perfect reconstruction QMF bank using infinite impulse response (IIR) filters based on transformation of variables technique.  The genetic algorithm (GA) optimisation is used for the initial design of the QMF bank and for the IIR filters using finite word length coefficients.  The optimised results are then applied to a real time digital signal processing kit.  Finally, some test results for data compression achievable using different values of encoded bits are included.               Keywords: IIR filters, genetic algorithms, multirate filter bank, optimization, polyphase decomposition, pulse code modulation, quadrature mirror filter bank, real-time implementation               Categories: I.6.3, I.6.6, J.2  
18|13||Assessing Alpha Band Event-related Synchronisation/Desynchronisation Using a Bio-Inspired Computational Model|  Basabdatta Sen Bhattacharya ((University of Lincoln, United Kingdom)   Damien Coyle (University of Ulster, United Kingdom)   Liam P. Maguire (University of Ulster, United Kingdom)  Abstract: This paper describes a study of the effects of variation of synaptic connectivity in a thalamo-cortical circuitry using a neural mass model. The oscillatory behaviour of the model output is assessed within the alpha frequency band. The model presented here is a modification of an existing model involving the introduction of biologically plausible synaptic connectivities as well as synaptic structure. Our goal is to study altered event related desynchronisation/synchronisation (ERD/ERS) patterns within the alpha band in Alzheimers disease as observed in experimental studies. ERD is an amplitude attenuation of certain EEG rhythms when an event is initiated or while a certain event is taking place in the brain. ERS is an amplitude enhancement of a certain EEG rhythm when cortical areas are not specifically engaged in a given mode of activity at a certain instant of time. EEG desynchronisation normally blocks alpha rhythms in the EEG due to sensory processing or behaviour. The results show that a decrease in synaptic connectivity induces a time lag in both ERD and ERS peaks in the model output. Furthermore, a deficiency induced in the inhibitory cholinergic pathway results in a distinct effect on time to peak in the ERD/ERS response. These observations are consistent with experimental findings in AD. Variation of the level of interconnectivity has a pronounced effect on the ERS behaviour of the model while the excitatory connectivity in the retino-geniculate pathway during the resting state is more influential on the ERD behaviour.               Keywords: Alpha rhythm, Alzheimer's disease, Event-related-(de)synchronisation, thalamo-cortical model               Categories: I.6  
18|14|http://www.jucs.org/jucs_18_14|Managing Editor's Column|
18|14||A Hybrid Metaheuristic Strategy for Covering with Wireless Devices|  Antonio L. Bajuelos (University of Aveiro, Portugal)   Santiago Canales (Universidad Pontifícia Comillas de Madrid, Spain)   Gregorio Hernández (Universidad Politécnica de Madrid, Spain)   Mafalda Martins (University of Aveiro, Portugal)  Abstract: In this paper we focus on approximate solutions   to solve a new class of Art Gallery Problems inspired by wireless   localization. Instead of the usual guards we consider wireless   devices whose signal can cross a certain number, k, of walls. These   devices are called k-transmitters. We propose an algorithm for   constructing the visibility region of a k-transmitter located on a   point of a simple polygon. Then we apply a hybrid metaheuristic   strategy to tackle the problem of minimizing the number of   k-transmitters, located at vertices, that cover a given simple   polygon, and compare its performance with two pure   metaheuristics. We conclude that the approximate solutions obtained   with the hybrid strategy, for 2-transmitters and 4-transmitters, on   simple polygons, monotone polygons, orthogonal polygons and monotone   orthogonal polygons, are better than the solutions obtained with the   pure strategies.               Keywords: art gallery problems, computational geometry, hybrid metaheuristics and approximation algorithms, visibility and coverage problems               Categories: G.1.6, I.2.8  
18|14||An Exploratory Study of Game-based M-learning for Software Project Management|  Alton Y.K. Chua (Nanyang Technological University, Singapore)   Radhika Shenoy Balkunje (Nanyang Technological University, Singapore)  Abstract: Given that the virtues of m-learning have not   yet been fully exploited in teaching Software Project Management   (SPM), this paper embarks on a timely endeavour to explore the use   of game-based m-learning for SPM by introducing a game called Mobile   Application for Project management LEarning (MAPLE). A total of 55   graduate students were invited to participate in the evaluation   study carried out for the MAPLE application. The evaluation was   based on three design principles derived from the literature,   namely, motivation, gaming and learning. Based on the preliminary   evaluation, three major observations could be culled. One,   game-based m-learning is a useful and an entertaining augmentation   to traditional learning. Two, design principles namely motivation,   gaming and learning and their appropriate blending is necessary to   develop an effective m-learning game. Finally, appealing features in   MAPLE are risk alerts, avatar creation and feedback.               Keywords: gaming, m-learning, motivation, software project management               Categories: L.5.1  
18|14||Behavioral and Temporal Pattern Detection within Financial Data with Hidden Information|  Doron Drusinsky (Naval Postgraduate School, USA)  Abstract: This paper describes a technique for behavioral   and temporal pattern detection within financial data, such as credit   card and bank account data, where the required information is only   partially visible.  Typically, transaction amount, transaction date, merchant name and type, and location of transaction are all visible data items, i.e., they are readily available in the financial institutions database. In contrast, the transaction status as a business transaction (using a personal card), a personal transaction, an investment related transaction, or perhaps a suspicious transaction, is information not explicitly available in the database. Our behavioral pattern detection technique combines well-known Hidden Markov Model (HMM) techniques for learning and subsequent identification of hidden artifacts, with run-time pattern detection of probabilistic UML-based formal specifications. The proposed approach entails a process in which the end-user first develops his or her deterministic patterns, s/he then identifies hidden artifacts in those patterns. Those artifacts induce the state set of the identifying HMM, whose remaining parameters are learned using standard frequency analysis techniques. In the run-time pattern detection phase, the system emits visible information, used by the HMM to deduce invisible information, and sequences thereof; both types of information are then used by a probabilistic pattern detector to monitor the pattern.               Keywords: Hidden Markov Models, UML, hidden data, monitoring, patterns, statecharts               Categories: D.2.4, F.1.1, F.4.1  
18|14||Multilevel Steganography: Improving Hidden Communication in Networks|  Wojciech Frączek (Warsaw University of Technology, Poland)   Wojciech Mazurczyk (Warsaw University of Technology, Poland)   Krzysztof Szczypiorski (Warsaw University of Technology, Poland)  Abstract: This paper presents multilevel steganography (MLS), which defines a new concept for hidden communication in telecommunication networks. In MLS, at least two steganographic methods are utilised simultaneously in such a way that one method's (the upper-level) network traffic serves as a carrier for the second method (the lower-level). Such a relationship between two (or more) information-hiding solutions has several potential benefits. The most important is that the lower-level method's steganographic bandwidth can be utilised to make the secret data unreadable even after the detection of the upper-level method, e.g., it can carry a cryptographic key that deciphers the steganogram carried by the upper-level method. It can also be used to provide the steganogram with integrity. Another important benefit is that the lower-level method may be used as a signalling channel to exchange information that affects the way that the upper-level method functions, thus possibly making the steganographic communication harder to detect. A prototype of MLS for IP networks was also developed, and the experimental results are included in this paper.               Keywords: MLS, information hiding, multilevel steganography, network steganography               Categories: C.2.0  
18|14||Optimized On-Chip-Pipelining for Memory-Intensive Computations on Multi-Core Processors with Explicit Memory Hierarchy|  Jörg Keller (FernUniversität in Hagen, Germany)   Christoph W. Kessler (Linköping Universitet, Sweden)   Rikard Hultén (Linköping Universitet, Sweden)  Abstract: Limited bandwidth to off-chip main memory tends to be a performance bottleneck in chip multiprocessors, and this will become even more problematic with an increasing number of cores. Especially for streaming computations where the ratio between computational work and memory transfer is low, transforming the program into more memory-efficient code is an important program optimization.  On-chip pipelining reorganizes the computation so that partial results of subtasks are forwarded immediately between the cores over the high-bandwidth internal network, in order to reduce the volume of main memory accesses, and thereby improves the throughput for memory-intensive computations. At the same time, throughput is also constrained by the limited amount of on-chip memory available for buffering forwarded data. By optimizing the mapping of tasks to cores, balancing a trade-off between load balancing, buffer memory consumption, and communication load on the on-chip network, a larger buffer size can be applied, resulting in less DMA communication and scheduling overhead.  In this article, we consider parallel mergesort as a representative memory-intensive application in detail, and focus on the global merging phase, which is dominating the overall sorting time for larger data sets. We work out the technical issues of applying the on-chip pipelining technique, and present several algorithms for optimized mapping of merge trees to the multiprocessor cores. We also demonstrate how some of these algorithms can be used for mapping of other streaming task graphs.  We describe an implementation of pipelined parallel mergesort for the Cell Broadband Engine, which serves as an exemplary target. We evaluate experimentally the influence of buffer sizes and mapping optimizations, and show that optimized on-chip pipelining indeed speeds up, for realistic problem sizes, merging times by up to 70% on QS20 and 143% on PS3 compared to the merge phase of CellSort, which was by now the fastest merge sort implementation on Cell.               Keywords: multicore computing, on-chip pipelining, parallel merge sort, streaming computations, task mapping               Categories: C.1.4, D.1.3, D.3.4, F.1.2, F.2.2  
18|14||Controlled Pure Grammar Systems|  Alexander Meduna (Brno University of Technology, Czech Republic)   Petr Zemek (Brno University of Technology, Czech Republic)  Abstract: This paper discusses grammar systems that have   only terminals, work in the leftmost way, and generate their   languages under the regulation by control languages over rule   labels. It establishes three results concerning their generative   power. First, without any control languages, these systems are not   even able to generate all context-free languages. Second, with   regular control languages, these systems, having no more than two   components, characterize the family of recursively enumerable   languages. Finally, with control languages that are themselves   generated by regularcontrolled context-free grammars, these systems   over unary alphabets generate nothing but regular languages. In its   introductory section, the paper gives a motivation for introducing   these systems, and in the concluding section, it formulates several   open problems.               Keywords: controlled derivations, formal languages, pure grammar systems               Categories: F.1.1, F.4.2, F.4.3  
18|14||Software Cost Modelling and Estimation Using Artificial Neural Networks Enhanced by Input Sensitivity Analysis|  Efi Papatheocharous (University of Cyprus, Cyprus)   Andreas S. Andreou (Cyprus University of Technology, Cyprus)  Abstract: This paper addresses the issue of Software Cost   Estimation (SCE) providing an alternative approach to modelling and   prediction using Artificial Neural Networks (ANN) and Input   Sensitivity Analysis (ISA). The overall aim is to identify and   investigate the effect of the leading factors in SCE, through   ISA. The factors identified decisively influence software effort in   the models examined and their ability to provide sufficiently   accurate SCEs is examined. ANN of variable topologies are trained to   predict effort devoted to software development based on past   (finished) projects recorded in two publicly available historical   datasets. The main difference with relevant studies is that the   proposed approach extracts the most influential cost drivers that   describe best the effort devoted to development activities using the   weights of the network connections. The approach is validated on   known software cost data and the results obtained are assessed and   compared. The ANN constructed generalise efficiently the knowledge   acquired during training providing accurate effort predictions. The   validation process included predictions with only the most highly   ranked attributes among the original cost attributes of the datasets   and revealed that accuracy performance was maintained at same   levels. The results showed that the combination of ANN and ISA is an   effective method for evaluating the contribution of cost factors,   whereas the subsets of factors selected did not compromise the   accuracy of the prediction results.               Keywords: artificial neural networks, input sensitivity analysis, software cost estimation               Categories: D.2.8, D.2.9  
18|14||Modeling the Value of End-to-End Multipath Protocols|  Henna Suomi (Aalto University, Finland)   Kalevi Kilkki (Aalto University, Finland)   Heikki Hämmäinen (Aalto University, Finland)  Abstract: Recently, adding multipath capability in the   Internet protocol suite has attracted increasing interest. By   letting end hosts discover several paths to communicate, end-to-end   multipath protocols aim to improve utilization rate of Internet   resources. Although many proposals for end-to-end multipath   communication exist, they have not reached significant   deployment. Since the multipath protocols are mainly designed for   open multi-stakeholder environments, understanding their economic   impact is important. This paper introduces a model for assessing the   value of the end-to-end multipath protocols from the end user   perspective. Without a net benefit of the end user, the end-to-end   multipath communication only results in the reallocation of costs   and benefits in the Internet connectivity market. The model   indicates that wireless devices having access to multiple   independent access operators via similar or dissimilar access   technologies are crucial in achieving end user value out of   multipath communication. Initially, the end user value seems higher   when the radio interfaces to access operators are active one at a   time but later on, along with higher-energy batteries and   lower-energy protocols, full benefit of multipath communication can   be achieved. The value of multipath protocols depends on the   effective path diversity and available capacity on the Internet.               Keywords: end user, multipath communication, net benefit, path diversity               Categories: D.4.4, H.1.0  
18|15|http://www.jucs.org/jucs_18_15|Technology for Learning across Physical and Virtual Spaces|
18|15||Design-Oriented Pedagogy for Technology-Enhanced Learning to Cross Over the Borders between Formal and Informal Environments|  Henriikka Vartiainen (University of Eastern Finland, Finland)   Anu Liljeström (University of Eastern Finland, Finland)   Jorma Enkenberg (University of Eastern Finland, Finland)  Abstract: In this paper, we introduce an instructional   model for technology-enhanced learning in the framework of a   design-oriented pedagogy. The model is based on the collaborative   designing of learning objects representing real objects in nature   and culture environments. Project-based learning, whole task   approach, object-oriented learning, multiple perspectives and   semantically rich objects constitute the framework for a   collaborative design process to articulate, build and share   knowledge constructed in a community of learners, teacher and   experts with the support of social media and mobile   technologies. The co-development process supported by socially   shared tools will provide possibilities for working with knowledge   objects related to the physical, conceptual or cultural artefacts,   so that the constructed learning objects can serve as starting   points for others to adapt, integrate and develop them further to   represent the phenomenon in question. In the paper, the theoretical   background of the pedagogy, the instructional model designed and the   development of the model will be introduced. Four design experiments   demonstrate the applicability of the model in different educational   contexts.               Keywords: design-oriented pedagogy, learning by collaborative designing, learning object, pedagogical model, project-based learning               Categories: L.0, L.2  
18|15||A Review of Mobile Location-based Games for Learning across Physical and Virtual Spaces|  Nikolaos Avouris (University of Patras, Greece)   Nikoleta Yiannoutsou (University of Patras, Greece)  Abstract: In this paper we review mobile location-based   games for learning. These games are played in physical space, but at   the same time, they are supported by actions and events in an   interconnected virtual space. Learning in these games is related to   issues like the narrative structure, space and game rules and   content that define the virtual game space. First, we introduce the   theoretical and empirical considerations of mobile location based   games, and then we discuss an analytical framework of their main   characteristics through typical examples. In particular, we focus on   their narrative structure, the interaction modes that they afford,   their use of physical space as prop for action, the way this is   linked to virtual space and the possible learning impact the game   activities have. Finally we conclude with an outline of future   trends and possibilities that these kinds of playful activities can   have on learning, especially outside school, like in environmental   studies and visits in museums and other sites of cultural and   historical value.               Keywords: game-based learning, informal learning, location based games, mobile games, mobile learning               Categories: H.3.1, H.3.2, H.3.3, H.3.7, H.5.1  
18|15||ARLearn: Augmented Reality Meets Augmented Virtuality|  Stefaan Ternier (Open University of the Netherlands, The Netherlands)   Roland Klemke (Open University of the Netherlands, The Netherlands)   Marco Kalz (Open University of the Netherlands, The Netherlands)   Patricia van Ulzen (Open University of the Netherlands, The Netherlands)   Marcus Specht (Open University of the Netherlands, The Netherlands)  Abstract: This article deals with educational   opportunities for mixed reality games and related scenarios for   learning. It discusses several issues and educational challenges to   be tackled when linking augmented reality and augmented   virtuality. Second, the paper describes the architecture of the   ARLearn system which offers highly flexible support for different   educational settings. Three prototypical use cases implemented based   on the underlying ARLearn framework are discussed, which are a field   trip system, an augmented Google StreetView client called   StreetLearn, and a real time crisis intervention game. ARLearn   combines real time notification and mixed reality games across   Mobile Augmented Reality and Virtual Reality and the authors aim to   use the underlying (open source) framework for further case studies   and mixed reality applications for learning support.               Keywords: augmented reality, augmented virtuality, immersive learning games               Categories: L.5.1  
18|15||SOS: Orchestrating Collaborative Activities across Digital and Physical Spaces Using Wearable Signaling Devices|  Davinia Hernández-Leo (Universitat Pompeu Fabra, Spain)   Raul Nieves (Universitat Pompeu Fabra, Spain)   Ernesto Arroyo (Universitat Pompeu Fabra, Spain)   Andrea Rosales (Universitat Pompeu Fabra, Spain)   Javier Melero (Universitat Pompeu Fabra, Spain)   Josep Blat (Universitat Pompeu Fabra, Spain)  Abstract: Carrying out collaborative learning activities   (supported by technologies or not) typically involves the   coordination of multiple participants, in their dynamic assignment   to groups and roles and in the distribution of resources and tools   to specific group or individuals. While the mechanisms required to   address these coordination aspects in digital educational spaces   have been largely studied, less research has been conducted on   orchestration support for facilitating this coordination in   (technology-enhanced) physical spaces, such as the classroom or the   playground. This paper presents the Signal Orchestration System   (SOS), a system that augments the physical environment with digital   signals indicating orchestration aspects. The SOS facilitates its   integration with digital educational spaces to allow transitioning   activities from digital to physical spaces. The paper describes the   SOS system and its underlying architecture through a functional   prototype that has been developed to show its feasibility and to   enable its evaluation in authentic situations. The main components   of the prototype include a Manager, where orchestration visual and   auditory signals are configured, changed on the fly and transmitted,   and three different designs of Wearable Signaling Devices, which are   carried by participants and render the orchestration signals. The   prototype has been used in two different experiments in the context   of a real course applying adaptations of the well-known Jigsaw   collaborative learning flow pattern. The results show that the SOS   enables a flexible dynamic orchestration of the collaborative   activities.               Keywords: CSCL, activities across spaces, augmented physical spaces, classroom orchestration, collaborative learning flows, wearable devices               Categories:  L.6.2, K.3, K.3.0, K.3.1, L.7.0  
18|15||Architecture for Collaborative Learning Activities in Hybrid Learning Environments|  María Blanca Ibáñez (Universidad Carlos III de Madrid, Spain)   David Maroto (Universidad Carlos III de Madrid, Spain)   José Jesús García Rueda (Universidad Carlos III de Madrid, Spain)   Derick Leony (Universidad Carlos III de Madrid, Spain)   Carlos Delgado Kloos (Universidad Carlos III de Madrid, Spain)  Abstract: 3D virtual worlds are recognized as   collaborative learning environments. However, the underlying   technology is not sufficiently mature and the virtual worlds look   cartoonish, unlinked to reality. Thus, it is important to enrich   them with elements from the real world to enhance student engagement   in learning activities. Our approach is to build learning   environments where participants can either be in the real world or   in its mirror world while sharing the same hybrid space in a   collaborative learning experience. This paper focuses on the system   architecture and a usability study of a proof-of-concept for these   hybrid learning environments. The architecture allows the   integration of the real world and its 3D virtual mirror; the   exchange and geolocalization of multimodal information, and also the   orchestration of learning activities. The results of the usability   evaluation show positive engagement effects on participants in the   mirror world and, to a lesser extent, on those in the real   world.               Keywords: 3D virtual worlds, architecture for virtual learning environments, augmented reality, augmented virtuality, hybrid learning environments, mirror worlds               Categories: H.4.2, H.4.3, H.5.2, H.5.3, L.2.3  
18|16|http://www.jucs.org/jucs_18_16|Managing Editor's Column|
18|16||Constructor-based Logics|  Daniel Găină (Japan Advanced Institute of Science and Technology, Japan)   Kokichi Futatsugi (Japan Advanced Institute of Science and Technology, Japan)   Kazuhiro Ogata (Japan Advanced Institute of Science and Technology, Japan)  Abstract: Many computer science applications concern   properties that are true for a restricted class of models. In this   paper, a couple of constructor-based institutions   are presented. These institutions are defined on top of some base   institutions, roughly speaking, by enhancing the syntax with   constructor symbols and restricting the semantics   to models with elements that are reachable by constructors. The   proof rules for the constructor-based Horn   logics, formalized asinstitutions, are defined in this   paper, and a proof of completeness is provided in the abstract   framework of institutions..               Keywords: Horn logic, completeness, constructor, induction, institution, proof theory               Categories: F.3, F.4  
18|16||Enriching Ontology Concepts Based on Texts from WWW and Corpus|  Tarek F. Gharib (King Abdulaziz University, Saudi Arabia)   Nagwa Badr (Ain Shams University, Egypt)   Shaimaa Haridy (Ain Shams University, Egypt)   Ajith Abraham (Machine Intelligence Research Labs (MIR Labs), USA)  Abstract: In spite of the growing of ontological   engineering tools, ontology knowledge acquisition remains a highly   manual, time-consuming and complex task. Automatic ontology learning   is a well-established research field whose goal is to support the   semi-automatic construction of ontologies starting from available   digital resources (e.g., A corpus, web pages, dictionaries,   semi-structured and structured sources) in order to reduce the time   and effort in the ontology development process. This paper proposes   an enhanced methodology for enriching Lexical Ontologies such as the   popular open-domain vocabulary WordNet. Ontologies like WordNet   can be semantically enriched to obtain extensions and enhancements   to its lexical database. The proliferation of senses in WordNet is   considered as one of its main shortcomings for practical   applications. Therefore, the presented methodology depends on the   Coarse-Grained word senses. These senses are generated from applying   WordNet Fine-Grained word senses to a Merging Sense algorithm. This   algorithm merges only semantically similar word senses instead of   applying traditional clustering techniques. A performance comparison   is illustrated between two different data sources (Web, Corpus) used   in the Enrichment process. The results obtained from using   Coarse-Grained word senses in both cases yields better precision   than Fine-Grained word senses in the Word Sense Disambiguation   task.               Keywords: coarse-grained word senses, corpus, ontology, semantic web, word sense disambiguation (WSD), word senses               Categories:  M.7  
18|16||The Educational Affordances of Widgets and Application Stores|  David Griffiths (The University of Bolton, United Kingdom)   Mark William Johnson (The University of Bolton, United Kingdom)   Kris Popat (The University of Bolton, United Kingdom)   Paul Sharples (The University of Bolton, United Kingdom)   Scott Wilson (The University of Bolton, United Kingdom)  Abstract: In order to provide interoperable services to a   range of applications, platforms and devices a number of open source   applications have been developed, many of them within the Apache   Software Foundation. We analyse the way that these relate to   research and development in education, which has also informed the   functionality which they offer, providing a case study of the   relationship between generic open source infrastructure development,   and the discourse around pedagogy. The functionality foreseen for   Personal Learning Environments and for the learning design approach   to face-to-face learning is identified. The capabilities of Apache   Wookie (incubating) W3C Widget Server are compared with this desired   functionality, and the unfulfilled functionality identified with a   particular focus on the need to support teachers control over their   technological environment in response to emerging conditions in the   classroom. The application store ('app store') is identified as a   key software paradigm for meeting the unfulfilled functionality, and   the ways in which it can support teaching practice are explored. A   number of current software projects, and collaborations between   them, are described which are contributing to providing a coherent   infrastructure for building app stores. Finally some areas of   functionality which remain pending future research and development   are identified.               Keywords: Apache, EDUKapp, Omelette, Personal Learning Environment, ROLE, Rave, W3C, Widget, Wookie, affordance, app store, iCamp, iTEC, learning design               Categories: L.2.1, L.2.2, L.3.0, L.3.6  
18|16||Digital Learning Resources in Higher Education: Designing for Large-scale Use|  Rob J.M. Hartog (Wageningen University, The Netherlands)   Adrie J.M. Beulens (Wageningen University, The Netherlands)   Johannes Tramper (Wageningen University, The Netherlands)  Abstract: In a series of faculty-based projects on design,   realization, implementation, use and evaluation of digital learning   resources for higher education, many design requirements emerged and   were evaluated. This paper focuses on those requirements that are   related with large-scale use. It is argued that sustainable quality   of design and realization of digital learning resources will only be   possible when these resources are used by many students and   teachers.  Design requirements of digital learning resources should   therefore be consistent with one or more scenarios for large-scale   use. This paper discusses eight large-scale use scenarios that can   be useful reference scenarios for design of digital learning   resources in higher education. It is argued that different   large-scale use scenarios imply different sets of design   requirements. Vice versa, certain design requirements are relevant   in some reference scenarios and irrelevant in other reference   scenarios.               Keywords: activating digital learning resources, design-oriented research, large-scale use, learning objects, requirements engineering               Categories: K.3.0, K.3.1  
18|16||Weaving Scholarly Legacy Data into Web of Data|  Atif Latif (Leibniz Information Center for Economics, Germany)   Muhammad Tanvir Afzal (Mohammad Ali Jinnah University, Pakistan)   Hermann Maurer (Graz University of Technology, Austria)  Abstract: The Linked Open Data project provides a new   publishing paradigm for creating machine readable and structured   data on the Web. Currently, the significant presence of data sets   describing scholarly publications in the Linked Data cloud underpins   the importance of Linked Data for the scientific community and for   the open access movement. However, these semantically rich datasets   need to be exploited and linked with real time applications. In the   project we report on this. We have exploited numerous scholarly   datasets and have created semantic links to papers in an online   journal, particularly Journal of Universal Computer Science   (J.UCS). The J. UCS plays an important part in the computer science   publishing community and provides a number of innovative features   and datasets to its web users. However, the legacy HTML format in   which these features are made available makes it difficult for   machines to understand and query. Keeping in mind the impressive   benefits of the Linked Open Data project, this paper presents an   approach to convert J.UCS legacy HTML data from its current form to   machine understandable format (RDF). It also interlinks this data   with other important Linked Data resources. The approach developed   has successfully disambiguated and interlinked J.UCS authors and   publications datasets with DBpedia, DBLP, CiteULike and faceted   DBLP. Additionally, triplified and interlinked datasets are made   available to the scientific and semantic web community for   downloading and posing SPARQL queries. This semantically linked   dataset can further be used by researchers and semantic agents to   identify semantic associations, to build inferencing systems, and to   extract useful knowledge.                 Categories: H.3.3, L.1.4, M.0  
18|16||Learning to Classify Neutral Examples from Positive and Negative Opinions|  María-Teresa Martín-Valdivia (University of Jaén, Spain)   Arturo Montejo-Ráez (University of Jaén, Spain)   Alfonso Ureña-López (University of Jaén, Spain)   Mohammed Rushdi Saleh (University of Jaén, Spain)  Abstract: Sentiment analysis is a challenging research   area due to the rapid increase of subjective texts populating the   web. There are several studies which focus on classifying opinions   into positive or negative. Corpora are usually labeled with a   star-rating scale. However, most of the studies neglect to consider   neutral examples. In this paper we study the effect of using neutral   sample reviews found in an opinion corpus in order to improve a   sentiment polarity classification system. We have performed   different experiments using several machine learning algorithms in   order to demonstrate the advantage of taking the neutral examples   into account. In addition we propose a model to divide neutral   samples into positive and negative ones, in order to incorporate   this information into the construction of the final opinion polarity   classification system. Moreover, we have generated a corpus from   Amazon in order to prove the convenience of the system. The results   obtained are very promising and encourage us to continue researching   along this line and consider neutral examples as relevant   information in opinion mining tasks.               Keywords: NLP, neutral examples, opinion mining, sentiment polarity               Categories: H.3.3, I.2.1, I.2.7, I.7, L.3.2  
18|16||A Review of Constructivist Learning Methods with Supporting Tooling in ICT Higher Education: Defining Different Types of Scaffolding|  Javier Melero (Universitat Pompeu Fabra, Spain)   Davinia Hernández-Leo (Universitat Pompeu Fabra, Spain)   Josep Blat (Universitat Pompeu Fabra, Spain)  Abstract: Information and Communication Technology (ICT)   engineering education is facing a decreasing interest by   students. To deal with this issue, a need for shifting from   traditional learning approaches to constructivist methods has been   identified. Several pedagogical methodologies based on social and   constructivist theories are being applied to engage students in ICT   education. This paper presents a literature review of studies   carried out from 2000 to 2010 that have applied constructivist   learning methods with supportive tools to specific ICT areas. From   the analysis of the literature review this paper identifies the most   representative constructivist learning methods within the field of   ICT education. In particular, we pay attention to the educational   tooling used to support the learning process and the learning   benefits of applying such methods. The analysis also reveals that   different combinations of guidance approaches and tooling   implementations are often adopted to scaffold the learning   process. With the aim of understanding to what extent and how   scaffolding is present in the studied learning scenarios, this   document proposes a definition of different types of scaffolding   techniques. Namely: social-guidance and system-guidance scaffolding,   depending on whether an individual or a tool is the responsible for   providing support to students; macro-scaffolding when pedagogical   methods define activity flows, or micro-scaffolding when the support   is provided to perform specific actions within activities; and   tool-enveloped scaffolding, when a generic tool such a learning   management system scaffolds the learning process by the integration   of different supportive tools, and tool-embedded scaffolding when   the scaffolding is applied within a specific-purpose   tooling.               Keywords: ICT Engineering Education, constructivism, literature review, scaffolding, teaching and learning strategies               Categories: A.1, J.0, L.3  
18|17|http://www.jucs.org/jucs_18_17|Conceptual Modelling of Services|
18|17||Towards Model-Driven Engineering Support for Service Evolution|  Juan M. Vara (Rey Juan Carlos University, Spain)   Vasilios Andrikopoulos (University of Stuttgart, Germany)   Michael P. Papazoglou (Tilburg University, The Netherlands)   Esperanza Marcos (Rey Juan Carlos University, Spain)  Abstract: In the field of Service-Oriented Architecture (SOA) evolution is a key issue given the non-trivial nature of updating widely distributed and heterogeneous systems. With this in mind, in this work we used some of the technologies developed in the context of the Eclipse Modeling Framework (EMF) to provide a proof of concept of the possible synergy between Model-Driven Engineering (MDE) and Service Orientation. In particular, we present a DSL toolkit for modeling the structural part of Abstract Service Descriptions (ASDs) and the reasoning mechanism that assesses whether two versions of a service are compatible with respect to its consumers.               Keywords: compatibility, model-driven engineering, service evolution, type theory               Categories: D.2.1, D.2.2, D.2.6, D.3.1, F.4.3, H.1.1  
18|17||Behavior Alignment and Control Flow Verification of Process and Service Choreographies|  Jorge Roa (Universidad Tecnológica Nacional, Argentina)   Pablo Villarreal (Universidad Tecnológica Nacional, Argentina)   Omar Chiotti (INGAR-CONICET, Argentina)  Abstract: The representation of process and service   choreographies has been recognized as an important requirement in   service-oriented methodologies. The guarantee of alignment between   process and service choreographies and the verification of the   behavior of choreographies represent an important improvement for   such methodologies, since they enable the automatic generation of   choreography service specifications from well-defined choreography   process models. To deal with these issues, we propose a   transformation pattern that guarantees behavior alignment between   process and service choreographies, and a verification method for   the control flow of choreographies, which can be applied to any   choreography language. These approaches make use of the Global   Interaction Nets (GI-Nets) language to formalize the behavior of   process and service choreographies. This formal representation can   then be used to conclude on the behavioral aspects of   choreographies. In addition, we present a tool for the modeling,   automatic generation and verification of GI-Nets, and apply the   proposed approaches to the UP-ColBPIP and WS-CDL choreography   languages.               Keywords: Web service, business process, choreography, verification               Categories: D.2.10, D.2.2  
18|17||A Metadirectory of Web Components for Mashup Composition|  Jose Ignacio Fernández-Villamor (Universidad Politécnica de Madrid, Spain)   Carlos Á. Iglesias (Universidad Politécnica de Madrid, Spain)   Mercedes Garijo (Universidad Politécnica de Madrid, Spain)  Abstract: Because of the growing availability of third-party APIs, services, widgets and any other reusable web component, mashup developers now face a vast amount of candidate components for their developments. Moreover, these components quite often are scattered in many different repositories and web sites, which makes difficult their selection or discovery. In this paper, we discuss the problem of component selection in Service-Oriented Architectures (SOA) and Mashup-Driven Development, and introduce the Linked Mashups Ontology (LiMOn), a model that allows describing mashups and their components for integrating and sharing mashup information such as categorization or dependencies. The model has allowed the building of an integrated, centralized metadirectory of web components for query and selection, which has served to evaluate the model. The metadirectory allows accessing various heterogeneous repositories of mashups and web components while using external information from the Linked Data cloud, helping mashup development.               Keywords: components, discovery, integration, mashups, services, widgets               Categories: H.3.4, H.3.5  
18|17||A Formal Approach for Risk Assessment in RBAC Systems|  Ji Ma (Software Competence Center Hagenberg, Austria)  Abstract: Risk assessment and access control are   important issues in cloud computing. In this paper, we propose a   formal approach to risk assessment for RBAC Systems, in which access   control decisions are taken after consideration of risk   assessment. The risk assessment method considers partial orderings   on objects and actions, which allow us to effectively capture the   notions of importance of objects and criticality of actions and then   to determine the risk of assigning a specific role to a specific   user. We in particular consider the cases of permission assignment   and delegation assignment.               Keywords: RBAC, access control, poset, risk assessment, security classification               Categories: H.1.0  
18|17||A Conceptual Model for IT Service Systems|  Ajantha Dahanayake (Prince Sultan University, Kingdom of Saudi Arabia)   Bernhard Thalheim ((Christian-Albrechts University of Kiel, Germany)  Abstract: Although services are developed, used, applied and intensively discussed in nowadays IT practice, the concept of an IT service has not yet been introduced.  Services are IT artifacts that can be used by many users in different context at different points of time in different locations and serve a certain purpose. They provide the data and functionality at the best point of time, in the agreed format and quality for the right user with the right location and context.  We generalize some of the introduced notions such as the REA framework (resource-event-agent) and introduce a framework for conceptual modeling of IT service systems that is based on the classical rhetorical frame introduced by Hermagoras of Temnos (Quis, quid, quando, ubi, cur, quem ad modum, quibus adminiculis (W7: Who, what, when, where, why, in what way, by what means)). Services are primarily characterized by W4: wherefore (end), whereof (source), wherewith (supporting means), and worthiness ((surplus) value). Additionally, the purpose can be characterized by answering the why, whereto, when, and for which reason W4 questions. The secondary characterization W14H is given by characterizing user or stakeholder (by whom, to whom, whichever), the application domain (wherein, where, for what, wherefrom, whence, what), the solution they are providing (how, why, whereto, when, for which reason), and the additional context (whereat, whereabout, whither, when).               Keywords: Hermagoras of Temnos, IT service systems, Web-based services, classical rhetorical frame, conceptual model for services, conceptual modelling, service systems               Categories: H.1.1, H.2.3, H.2.4, H.4.2, H.4.3, J.4, J.7  
18|17||Service-Oriented Development of Web Information Systems|  Valeria de Castro (Rey Juan Carlos University, Spain)   Juan Manuel Vara (Rey Juan Carlos University, Spain)   Esperanza Marcos (Rey Juan Carlos University, Spain)  Abstract: During the last years, Web Information Systems   have evolved from simple information sources to systems offering   services to end-users. The development of this kind of systems   presents different challenges, such as the alignment between   business services and their implementation, and the way business   processes are placed in the system. To address this type of   challenges this paper presents a methodological and technical   proposal for Service-Oriented development of Web Information   Systems. It follows a model-driven approach, defining a set of   models at different levels of abstraction and the model   transformations needed to connect them. Besides, the development of   a conference management system is used as case study to illustrate   the proposal.               Keywords: Web information systems, model-driven development, service-oriented               Categories: D.2.2, H.5.0, H.5.2, H.5.4  
18|17||A Conceptual Ontology-based Resource Meta-Model towards Business-driven Information System Implementation|  Hongming Cai (Shanghai Jiao Tong University, China)   Boyi Xu (Shanghai Jiao Tong University, China)   Fenglin Bu (Shanghai Jiao Tong University, China)  Abstract: Enterprises need a flexible and configurable IT   architecture to meet complex business requirements agilely. For the   purpose of bridging business modelling in build-time and application   configuration in runtime seamlessly, a Conceptual Ontology-based   Resource meta-Model (CORM) is proposed. Firstly, a resource   meta-model is built as a referred model to describe business   elements and relationships. Then, by means of ontology, these   business elements are transformed into IT service-oriented   components such as SOAP services, RESTful services and BPEL   files. Referring to Model-View-Controller pattern, these service   components are then configured in a runtime supported   environment. Next, a state space defined by a resource array is   built as the control mechanism to realize a completed IT   system. Finally, a CORM-based supported Platform is built to support   business modelling, service transformation and system   configuration. The research indicates a new approach to develop and   implement enterprise information systems in a more flexible and   configurable way.               Keywords: business process, conceptual model, information systems, ontology, resource oriented architecture, service composition, software engineering               Categories: D.2.11, H.1.1, H.4.0  
18|18|http://www.jucs.org/jucs_18_18|Trends in Immersive Education Research|
18|18||A Proposal to Create Learning Environments in Virtual Worlds Integrating Advanced Educative Resources|"  David Griol (Carlos III University of Madrid, Spain)   José Manuel Molina (Carlos III University of Madrid, Spain)   Araceli Sanchis de Miguel (Carlos III University of Madrid, Spain)   Zoraida Callejas (University of Granada, Spain)  Abstract: Social Networking has been a global consumer   phenomenon during the last few years. Online communities are   changing the way people behave, share and interact within their   daily lives. Most of such communities are mainly focused on sharing   contents and communicating using a traditional web   interface. However, social virtual worlds are computer-simulated   environments that the users can ""inhabit"" and in which they can   interact and create objects. Education is one of the most   interesting applications of virtual worlds, as their flexibility can   be exploited in order to create heterogeneous groups from all over   the world who can collaborate synchronously in different virtual   spaces. In this paper, we highlight the potential of virtual worlds   as an educative tool and propose a model to create learning   environments within Second Life or OpenSimulator combining the   Moodle learning management system, embodied conversational metabots,   and programmable 3D objects. We have implemented the proposal in a   learning system for several subjects of the Computer Science degree   in our university and show that it fostered engagement and   collaboration and helped the students to better understand complex   concepts.               Keywords: E-learning, OpenSimulator, Second Life, Sloodle, Virtual Worlds, speech interaction               Categories: H.5.1, H.5.2, H.5.4, J.6, L.3.0, L.3.1, L.3.6, L.6.1  "
18|18||The ShanghAI Lectures: A Global Education Project on Artificial Intelligence|"  Nathan Labhart (University of Zurich, Switzerland)   Béatrice S. Hasler (Interdisciplinary Center Herzliya, Israel)   Andy Zbinden (SWITCH, Switzerland)   Andreas Schmeil (University of Lugano, Switzerland)  Abstract: We present a global education project in   Artificial Intelligence (AI) called the ""ShanghAI Lectures"": A   lecture series held annually via videoconference among 15 to 20   universities around the globe. The lectures are complemented by a   novel three-dimensional collaborative virtual environment for   international student teamwork, and a web-based resource designed as   a knowledge base and for community building. This paper summarizes   the lessons learned from the first edition of the ShanghAI Lectures,   which may guide future global teaching and learning projects of this   kind.               Keywords: 3D collaborative virtual environments, global teaching, intercultural learning, videoconference               Categories: L.2.7, L.3.0, L.3.5, L.3.6, L.5.0, L.6.1, L.6.2  "
18|18||Creating Test Questions for 3D Collaborative Virtual Worlds: the WorldOfQuestions Authoring Environment|  María Blanca Ibáñez (Universidad Carlos III de Madrid, Spain)   José Jesús Garcia Rueda (Universidad Carlos III de Madrid, Spain)   Diego Morillo (Universidad Carlos III de Madrid, Spain)   Carlos Delgado Kloos (Universidad Carlos III de Madrid, Spain)  Abstract: In this paper we introduce, describe and   evaluate WorldOfQuestions, an authoring environment for the creation   and delivery of tests in 3D Collaborative Virtual Worlds. This   environment is composed of an extended, customized version of the   Open Wonderland platform and a form-based editor. Its aim is to make   the most of 3D world features, such as immersion and interactivity,   when implementing multiple choice, ordering and essay questions   enriched with multimedia elements and 3D objects. A group of   teaching professionals was asked to work with the environment, in   order to evaluate its usefulness and ease of use. A Technology   Acceptance Model (TAM) based framework was used for this   evaluation. According to the educators interviewed, the most   important aspects to consider regarding the behavioral intention to   use the tool were the academic subject being taught, the student   profiles, the environment learning curve and the time   requirements.               Keywords: 3D collaborative virtual worlds, TAM, authoring tools, computer based assessment               Categories: L.3.0  
18|18||MareMonstrum: a Contribution to Empirical Research about How the Use of MUVEs May Improve Students' Motivation|  Pilar Sancho (Complutense University of Madrid, Spain)   Javier Torrente (Complutense University of Madrid, Spain)   Baltasar Fernández-Manjón (Complutense University of Madrid, Spain)  Abstract: The use of Multi-User Virtual Environments (MUVEs) is a trend topic in virtual education and e-learning. A number of research papers and literature reviews addresses how digital natives learn in a different way than the previous generation and how these kinds of highly interactive environments may positively affect their motivation. But actual efficacy of MUVEs to enhance students' motivation has not been deeply backed up yet by empirical research. This paper contributes with a small experiment conducted on an elective programming course for engineering students. The hypothesis was that the use of a MUVE would improve students' motivation towards learning. To evaluate the veracity of this hypothesis, the dropout rates of the course were compared alongside four academic years, assuming that lower dropout rates imply a motivation increase. The first two years (Y1 and Y2) a traditional approach based on lectures, weekly assignments and a final exam was used. The last two years (Y3 and Y4), the NUCLEO approach was used. NUCLEO is a pedagogical strategy that combines game mechanics (including collaboration and competition), problem-based learning and a fantastic narrative metaphor. In Y3 the NUCLEO approach was implemented having a flat classical interface provided by the standard Moodle Learning Management System (LMS), while in Y4 a ·3D MUVE was used as interface. Dropouts during the traditional teaching period (Y1-2) fell dramatically during the NUCLEO teaching period (Y3-4). However, dropouts were higher in Y4 when a MUVE was used as interface (16.66%) compared to Y3 (9.09%). These data suggest that just using a MUVE or a 3D environment can enhance motivation but to achieve maximum effectiveness if they are combined with elements like game mechanics. These data were also backed up by satisfaction questionnaires fulfilled by teachers and students.               Keywords: computer supported collaborative learning, learning in multi-user virtual environments, problem based learning               Categories:  H.5.1, J.2, L.5.1, L.6.1  
18|19|http://www.jucs.org/jucs_18_19|Distributed Development of Information System|
18|19||Obtaining Requirements for Designing a Tool to Support Distributed Development|  José Luis Hernández (University of Castilla-La Mancha, Spain)   Aurora Vizcaíno (University of Castilla-La Mancha, Spain)   Ismael Caballero (University of Castilla-La Mancha, Spain)   Gabriela Aranda (National University of Comahue, Argentina)  Abstract: The Distributed Software Development involves various challenges, many of which are related to the lack of trust experienced by team members since they often do not know each other personally. Other problems which are already considered to be classic are related to communication, coordination and collaboration. Bearing in mind that providing information about co-workers may increase both the team spirit and the team members' confidence in each other, we have carried out surveys to discover what information might be useful in attaining this objective, and to reduce those problems related to the three 'c's. The results of the questionnaires have been analyzed from different points of view, first by differentiating the respondents' roles and then by analyzing their specific use in communication, coordination and control activities. The results of this analysis have allowed us to obtain the requirements needed to design a tool with which to support global software development. The implementation of this tool is also described in this paper.               Keywords: distributed software sevelopment (DSD), global software development (GSD), tools for GSD, trust               Categories: D.2.2, D.4.4  
18|19||Division of Effort, Productivity, Quality, and Relationships in FLOSS Virtual Teams: Evidence from the FreeBSD Project|  George M. Giaglis (Athens University of Economics and Business, Greece)   Diomidis Spinellis (Athens University of Economics and Business, Greece)  Abstract: Research in virtual teams and distributed work   argues that the lack of collocation places an overhead on the   performance potential of large, globally distributed teams. In this   paper, we revisit this tenet through a case study of Free/Libre Open   Source Software (FLOSS) development to demonstrate how globally   dispersed FLOSS communities manage to overcome the problem of   geographic separation of their members. Our results show that   successful FLOSS teams demonstrate a truly global distribution of   members, who perform different types of work so as to achieve   consistent round-the-clock development, without any apparent ill   effects on team productivity and the quality of the resulting   outcomes. Cooperation between team members is abundant, especially   at more complex work items, and does not seem to be affected by   distance; only mentoring relationships appear in some cases to be   easier to cultivate between individuals living closer   together. These findings challenge the conventional wisdom of   research in distributed work, in cases where virtual teams consist   of highly skilled and motivated individuals, who leverage the power   of communication technologies to overcome problems associated with   physical distance.               Keywords: FLOSS, FreeBSD, distributed work, open source development, virtual teams               Categories: D.2.9, K.4.3, K.6.1, K.6.3  
18|19||A Study of the Impact of Global Software Development in Packaged Software Release Planning|"  Ricardo Colomo-Palacios (Universidad Carlos III de Madrid, Spain)   Pedro Soto-Acosta (Universidad de Murcia, Spain)   Francisco J. García-Peñalvo (Universidad de Salamanca, Spain)   Ángel García-Crespo (Universidad Carlos III de Madrid, Spain)  Abstract: Today's globalization of software development   has its advantages, but also its drawbacks. Software project   managers often lead the production of new software versions and   their release on the market. This paper analyses the main challenges   faced by software product managers in release planning with regard   to the adoption of Global Software Development (GSD) practices for   developing packaged software. To achieve this objective, two   qualitative techniques are used in this study, namely, Focus Group   and Delphi Study. The experiment produced two lists, ranking   challenges in software release planning. One list was made   considering the adoption of GSD practices and the other did not take   into account the adoption of these practices. Results show that   there are some, apparently solved, challenges for packaged software   release planning like ""Project monitoring & control"" or ""Quality   management"" that become crucial when facing GSD scenarios, while   there are other important challenges in traditional software release   planning such as ""Requirements prioritisation"" and ""Stakeholders   Management"" that apparently do not add extra pressure in GSD   environments. In sum, GSD is found to be highly influenced by issues   concerning personnel and human resources management.               Keywords: Delphi study, focus group, global software development, product manager, release planning               Categories: D.2.9  "
18|19||Metamodeling the Structure and Interaction Behavior of Cooperative Component-based User Interfaces|  Luis Iribarne (University of Almeria, Spain)   Nicolas Padilla (University of Almeria, Spain)   Javier Criado (University of Almeria, Spain)   Cristina Vicente-Chicote (Technical University of Cartagena, Spain)  Abstract: In Web-based Cooperative Information   Systems (WCIS), user groups with different roles cooperate   through specialized interfaces. Cooperative interaction and user   interface structures are usually rather complicated, and modeling   has an important part in them. Model-Driven   Engineering (MDE) is a software engineering discipline   which assists engineers in abstracting system implementations by   means of models and metamodels. This article describes an   interactive, structural metamodel for user interfaces based on   component architectures as a way to abstract, model, simplify and   facilitate implementation. The paper also presents a case study   based on an Environmental Management Information   Systems (EMIS), where three actors (a politician, a GIS   expert, and a technician) cooperate in assessing natural   disasters.               Keywords: MDE, component-based development, cooperative systems, user interaction, user interfaces               Categories: D.2, H.4, H.5  
18|19||An Integrated Approach of Software Development and Test Processes to Distributed Teams|  Gislaine Camila Lapasini Leal (State University of Maringa, Brazil)   Ana Paula Chaves (Federal Technological University of Parana, Brazil)   Elisa Hatsue Moriya Huzita (State University of Maringa, Brazil)   Marcio Eduardo Delamaro (University of Sao Paulo, Brazil)  Abstract: The Distributed Software Development (DSD) is a   development strategy that meets the globalization needs concerned   with the increase productivity and cost reduction.  However, the   temporal distance, geographical dispersion and the socio-cultural   di_erences, increased some challenges and, especially, added new   requirements related with the communication, coordination and   control of projects. Among these new demands there is the necessity   of a software process that provides adequate support to the   distributed software development. This paper presents an integrated   approach of software development and test that considers distributed   teams peculiarities. The approach purpose is to o_er support to DSD,   providing a better project visibility, improving the communication   between the development and test teams, minimizing the ambiguity and   di_culty to understand the artifacts and activities. This integrated   approach was conceived based on four pillars: (i) to identify the   DSD peculiarities concerned with development and test processes,   (ii) to de_ne the necessary elements to compose the integrated   approach of development and test to support the distributed teams,   (iii) to describe and specify the workows, artifacts, and roles of   the approach, and (iv) to represent appropriately the approach to   enable the e_ective communication and understanding of   it.               Keywords: global software development, software process, test               Categories: H.2, H.3.7, H.5.4  
18|19||Knowledge Management Initiatives in Offshore Software Development: Vendors' Perspectives|  Anuradha Mathrani (Massey University, New Zealand)   David Parsons (Massey University, New Zealand)   Sanjay Mathrani (Massey University, New Zealand)  Abstract: Offshore software development (OSD) is a leading business sector in the global IT marketplace, and vendors in different countries are opening software development centres to take advantage of new business opportunities. However, software development is both a technical and a social process in which various software modules are integrated, requiring ongoing interaction and synchronisation of activities between distributed stakeholders. Knowledge management (KM) strategies are applied to create knowledge consistent with client requirements, project specific features and chosen design methodologies. Building on existing KM theories with empirical evidence from ten case studies in the Asia Pacific region, within two country contexts (New Zealand and India), this research reveals the KM initiatives for enabling knowledge transfer in the OSD process at the operational, design and strategic level. The paper offers insights on how software vendors build organisational knowledge repositories as they streamline distributed tasks in different country contexts. Country-specific contexts reveal that New Zealand vendors are engaged more in project and product management and have further outsourced software development tasks to other low cost countries. The Indian vendors are involved in software construction, development of technical specialist skills and use of more formal processes. These findings emphasise implications of various sociological, cultural and technical perspectives of KM initiatives in OSD.               Keywords: Experience Capture, Explicit, Software Development, Tacit, distributed knowledge management               Categories: D.2.7, D.2.9, M.8, M.9  
18|19||A Global Software Inspection Process for Distributed Software Development|  Deepti Mishra (Atilim University Incek, Turkey)   Alok Mishra (Atilim University Incek, Turkey)  Abstract: Globally distributed software development is an   established trend towards delivering high-quality software to global   users at lower costs. The main expected benefits from distributed   software development are improvements in development time   efficiency, being close to the customers and having flexible access   to greater and less costly resources. Organizations require to use   their existing resources as effectively as possible, and also need   to employ resources on a global scale from different sites within   the organization and from partner organization throughout the   world. However, distributed software development particularly face   communication and coordination problems due to spatial, temporal and   cultural separation between team members. Ensuring quality issues in   such projects is a significant issue. This paper presents global   software inspection process in the distributed software development   environment towards quality assurance and management.               Keywords: distributed software development, global software development, software inspection, software quality, tool               Categories: D.2.2, D.2.4  
18|2|http://www.jucs.org/jucs_18_2|Managing Editor's Column|
18|2||Supporting End-User Development through a New Composition Model: An Empirical Study|  David Lizcano (Universidad Politécnica de Madrid, Spain)   Fernando Alonso (Universidad Politécnica de Madrid, Spain)   Javier Soriano (Universidad Politécnica de Madrid, Spain)   Genoveva López (Universidad Politécnica de Madrid, Spain)  Abstract: End-user development (EUD) is much hyped, and its impact has outstripped even the most optimistic forecasts. Even so, the vision of end users programming their own solutions has not yet materialized.  This will continue to be so  unless we in both industry and the research community set ourselves the ambitious challenge of devising end to end an end-user application development model for developing a new age of EUD tools. We have embarked on this venture, and this paper presents the main insights and outcomes of our research and development efforts as part of a number of successful EU research projects.  Our proposal not only aims to reshape software engineering to meet the needs of EUD but also to refashion its components as solution building blocks instead of programs and software developments. This way, end users will really be empowered to build solutions based on artefacts akin to their expertise and understanding of ideal solutions.               Keywords: domain experts, domain-specific software development, ecologies of participation, end-user development, end-user software engineering               Categories:  H.5.2, C.2.4, D.1.7, D.2.2, D.3, H.4.m  
18|2||Generic Temporal and Fuzzy Ontological Framework (GTFOF) for Developing Temporal-Fuzzy Database Model for Managing Patient's Data|  Nadeem Mahmood (University of Karachi, Pakistan)   S. M. Aqil Burney (University of Karachi, Pakistan)   Kamran Ahsan (Staffordshire University, United Kingdom)  Abstract: A generic temporal and fuzzy ontological framework (GTFOF) is presented, specific to the task of designing temporal and fuzzy database system. The framework includes both time and fuzzy dimension in deigning patient information  system in a hospital environment. The proposed framework is essential for developing knowledge management systems (KMS) in healthcare environments. The importance of ontological models in the development of patient information system is well established and it provides the logical and formal mechanism for building KMS. Healthcare information systems may include complex data such as time stamped data and fuzzy data about patients. This paper highlights the importance of identifying the key concepts for building an ontological framework to manage both temporal and fuzzy information content. The proposed generic framework is capable of integrating and mapping the proposed ontological model into an effective database design for implementation.               Keywords: healthcare systems, knowledge management systems, patient information system, temporal and fuzzy database system, temporal and fuzzy ontological framework               Categories: I.2.4  
18|2||MaF: An Ontology Matching Framework|  Jorge Martinez-Gil (University of Málaga, Spain)   Ismael Navas-Delgado (University of Málaga, Spain)   Jose F. Aldana-Montes (University of Málaga, Spain)  Abstract: In this work, we present our experience when developing the Matching Framework (MaF), a framework for matching ontologies that allows users to configure their own ontology matching algorithms and it allows developers to perform research on new complex algorithms. MaF provides numerical results instead of logic results provided by other kinds of algorithms. The framework can be configured by selecting the simple algorithms which will be used from a set of 136 basic algorithms, indicating exactly how many and how these algorithms will be composed and selecting the thresholds for retrieving the most promising mappings. Output results are provided in a standard format so that they can be used in many existing tools (evaluators, mediators, viewers, and so on) which follow this standard. The main goal of our work is not to better the existing solutions for ontology matching, but to help research new ways of combining algorithms in order to meet specific needs. In fact, the system can test more than 6 * 136! possible combinations of algorithms, but the graphical interface is designed to simplify the matching process.               Keywords: knowledge integration, ontology matching, software tools               Categories: M.1, M.3  
18|2||Performance Evaluation of Recent Windows Operating Systems|  Goran Martinovic (Josip Juraj Strossmayer University of Osijek, Croatia)   Josip Balen (Josip Juraj Strossmayer University of Osijek, Croatia)   Bojan Cukic (West Virginia University, USA)  Abstract: The primary goal of most OSs (Operating Systems) is the efficient use of computer systems software and hardware  resources. Since Windows OSs are most widely used OS for personal computers, they need to satisfy needs of all different kind  of computer systems users. In comparison with Windows XP, new versions of the Windows OS; namely Windows Vista and Windows 7,  introduce a number of new features and enhancements. Furthermore, performance improvement was imposed as one of the key design  goals for both Windows Vista and Windows 7. This paper presents a performance evaluation of three latest versions of the Microsoft OS for personal computers; namely Windows XP, Windows Vista and Windows 7. OS performance measurement is done by means of a set of benchmark applications in the controlled environment. To ensure accurate, reliable and repeatable performance measurement results, we have created a performance measurement process and a performance evaluation model. Special emphasis is placed on evaluation areas with the greatest impact on the performance: CPU cheduling, memory management, graphic subsystem management, hard disk drive management and network performance. To determine the Windows OSs performance in different environments, performance measurement is done in three experiments. Experimental results indicate that Windows Vista and Windows 7 have several performance improvements on the stand-alone high-end computer system, but Windows XP outperforms Windows Vista and Windows 7 on the stand-alone low-end computer system. Furthermore, on network computer system Windows Vista and Windows 7 show network performance improvements mostly for the traffic with medium-sized packets.               Keywords: Windows 7, Windows Vista, Windows XP, benchmark, operating system, performance evaluation, performance measurement               Categories: D.4, D.4.8, K.6.2  
18|2||Reconfigurable VBSME Architecture Using RBSAD|  Joaquin Olivares (University of Cordoba, Spain)  Abstract: This paper presents an architecture which is capable of processing variable block size motion estimation (VBSME) and which is able to apply pixel precision reduction techniques in a reconfigurable way. The design has been carried out by using online arithmetic, which allows to process all motion vectors of a block in just one iteration. The system has been implemented on FPGA and just requires 7724 slices, reaching a performance of 55 4CIF frames per second (fps) in full precision and of 72 with 4 bit precision. Results for different search areas 31 x 31, 32 x 32, and 46 x 46 are presented. Using 4bit precision real time processing for HDTVp is achieved. Thanks to the reduced cost and high performance, this architecture is perfect for mobile devices.               Keywords: high-speed arithmetics, parallel architectures, special-purpose and application-based systems, video               Categories: B.2.4, C.1.4, C.3, H.5.1  
18|2||RESTifying a Legacy Semantic Search System: Experience and Lessons Learned|  Guillermo Vega-Gorgojo (University of Valladolid, Spain)   Eduardo Gómez-Sánchez (University of Valladolid, Spain)   Miguel L. Bote-Lorenzo (University of Valladolid, Spain)   Juan I. Asensio-Pérez (University of Valladolid, Spain)  Abstract: The REST architectural style pursues scalability and decoupling of application components on target architectures,  as opposed to the focus on distribution transparency of RPC-based middleware infrastructures. Ongoing debate between REST and RPC proponents evidences the need of comparisons of both approaches, as well as case studies showing the implications in the development of RESTful applications. With this aim, this paper presents a revamped RESTful version of a legacy RPC-based search system of educational tools named Ontoolsearch. The former version suffers from reduced interoperability with third-party clients, limited visibility of interactions and has some scalability issues due to the use of an RPC-based middleware. These limitations are addressed in the RESTful application as a result of applying REST constraints and using the Atom data format. Further, a benchmarking experiment showed that scalability of the RESTful prototype is superior, measuring a ∼3 times increase of peak throughput. In addition, some lessons learned on RESTful design and implementation have been derived from this work that may be of interest for future developments.               Keywords: C.2.4, H.3.3, K.3.1               Categories: RESTful web services, educational tools, remote procedure call, semantic search  
18|20|http://www.jucs.org/jucs_18_20|Managing Editor's Column|
18|20||The Forum for Negative Results (FNR)Guest Editorial|"  Lutz Prechelt (Freie Universität Berlin, Germany)  Abstract: In September 1997, J.UCS published an article   titled ""Why we Need an Explicit Forum for Negative Results""   [Prechelt, 1997]. It argued that when a plausible approach for   solving a computer science or software engineering problem had   failed to work out, it was silly for the scientific system not to   publish the attempt iff a useful insight had been gained along the   way nevertheless. Due to the strong bias of essentially all Computer   Science publication venues towards ""successful"" research results, it   was thus required to call for such negative results explicitly in   order to avoid that those results would either be misleadingly   disguised as successes or disappear in some closet. The article   declared that J.UCS had thus agreed to create the ""Forum for   Negative Results (FNR)"" as a permanent special section of   J.UCS.               Keywords: FNR, failures, forum, negative results               Categories: A.m, B.6.3, C.1.3, I.2.6, I.2.7, K.4.m, K.7.m  "
18|20||Computational Analysis of Medieval Manuscripts: A New Tool for Analysis and Mapping of Medieval Documents to Modern Orthography|  Mushtaq Ahmad (University of Pretoria, South Africa)   Stefan Gruner (University of Pretoria, South Africa)   Muhammad Tanvir Afzal   Abstract: Medieval manuscripts or other written documents from that period contain valuable information about people, religion, and politics of the medieval period, making the study of medieval documents a necessary pre-requisite to gaining in-depth knowledge of medieval history. Although tool-less study of such documents is possible and has been ongoing for centuries, much subtle information remains locked such manuscripts unless it gets revealed by effective means of computational analysis. Automatic analysis of medieval manuscripts is a non-trivial task mainly due to non-conforming styles, spelling peculiarities, or lack of relational structures (hyper-links), which could be used to answer meaningful queries. Natural Language Processing (NLP) tools and algorithms are used to carry out computational analysis of text data. However due to high percentage of spelling variations in medieval manuscripts, NLP tools and algorithms cannot be applied directly for computational analysis. If the spelling variations are mapped to standard dictionary words, then application of standard NLP tools and algorithms becomes possible. In this paper we describe a web-based software tool CAMM (Computational Analysis of Medieval Manuscripts) that maps medieval spelling variations to a modern German dictionary. Here we describe the steps taken to acquire, reformat, and analyze data, produce putative mappings as well as the steps taken to evaluate the findings. At the time of the writing of this paper, CAMM provides access to 11275 manuscripts organized into 54 collections containing a total of 242446 distinctly spelled words. CAMM accurately corrects spelling of 55% percent of the verifiable words. CAMM is freely available at http://researchworks.cs.athabascau.ca/.               Keywords: MPEG spelling variations, mapping, phonetic algorithms               Categories: I.7.1, I.7.2, I.7.m, J.5  
18|20||Distributed Load Balancing Algorithms for Heterogeneous Players in Asynchronous Networks|  Luiz F. Bittencourt (University of Campinas, Brazil)   Flávio K. Miyazawa (University of Campinas, Brazil)   André L. Vignatti (University of Campinas, Brazil)  Abstract: In highly scalable networks, such as grid and   cloud computing environments and the Internet itself, the   implementation of centralized policies is not feasible. Thus, nodes   in such networks act according to their interests. One problem with   these networks is load balancing. This paper   considers load balancing in networks with   heterogeneous nodes, that is, nodes with   different processing power, and asynchronous   actions, where there is no centralized clock and thus one or more   nodes can perform their actions simultaneously. We show that if the   nodes want to balance the load without complying with certain rules,   then load balancing is never achieved. Thus, it is necessary to   implement some rules that need to be distributed (i.e., so that they   run locally on each node) due to the unfeasibility of centralized   implementation. Due to the game-theoretic nature of the nodes, the   concept of solution is when all nodes are satisfied with the load   assigned to them, a Nash equilibrium   state. Moreover, we discuss how the rules can be created and present   three sets of rules for the nodes to reach a Nash equilibrium. For   each set of rules, we prove its correctness and, through   simulations, evaluate the number of steps needed to reach the   network's Nash equilibrium.               Keywords: Nash equilibrium, game theory, load balancing               Categories: F.2.0, I.2.11  
18|20||Crossing the Undecidability Border with Extensions of Propositional Neighborhood Logic over Natural Numbers|  Dario Della Monica (Reykjavik University, Iceland)   Valentin Goranko (Technical Institute of Denmark, Denmark)   Angelo Montanari (University of Udine, Italy)   Guido Sciavicco (University of Murcia, Spain)  Abstract: Propositional Neighborhood Logic (PNL) is an   interval temporal logic featuring two modalities corresponding to   the relations of right and left neighborhood between two intervals   on a linear order (in terms of Allen's relations,   meets/ and met by). Recently,   it has been shown that PNL interpreted over several classes of   linear orders, including natural numbers, is decidable   (NEXPTIME-complete) and that some of its natural extensions preserve   decidability. Most notably, this is the case with PNL over natural   numbers extended with a limited form of metric constraints and with   the future fragment of PNL extended with modal operators   corresponding to Allen's relations begins,   begun by, and before/. This paper aims   at demonstrating that PNL and its metric version MPNL, interpreted   over natural numbers, are indeed very close to the border with   undecidability, and even relatively weak extensions of them become   undecidable. In particular, we show that (i) the addition of binders   on integer variables ranging over interval lengths makes the   resulting hybrid extension of MPNL undecidable, and (ii) a very weak   first-order extension of the future fragment of PNL, obtained by   replacing proposition letters by a restricted subclass of   first-order formulae where only one variable is allowed, is   undecidable (in contrast with the decidability of similar   first-order extensions of point-based temporal logics).               Keywords: first-order logic, hybrid logics, interval length binders, interval neighborhood logics, undecidability               Categories: F.2, F.4.1, F.4.3  
18|20||Non-Marker based Mobile Augmented Reality and its Applications using Object Recognition|  Daewon Kim (Dankook University, South Korea)   Doosung Hwang (Dankook University, South Korea)  Abstract: As the augmented reality technology has become   more pervasive and applicable, it is easily seen in our daily lives   regardless of fields and scopes. Existing camera vision based   augmented reality techniques depend on marker based approaches   rather than real world information. The augmented reality technology   using marker recognition has limitations in its applicability and   provision of proper environment to guarantee user's immersiveness to   relevant service application programs. This study aims to implement   a smart mobile terminal based augmented reality technology by using   a camera built in a terminal device and image and video processing   technology without any markers so that users can recognize   multimedia objects from real world images and build an augmented   reality service, where 3D content connected to objects and relevant   information are added to the real world image. Object recognition   from a real world image is involved in a process of comparison   against preregistered reference information, where operation to   measure similarity is reduced for faster running of the application,   considering the characteristics of smart mobile   devices. Furthermore, the design allows users to interact through   touch events on the smart device after 3D content is output onto the   terminal screen. Afterward, users can browse object related   information on the web. The augmented reality technology appropriate   for the smart mobile environment is proposed and tested through   several experiments and showed reliable performances in the results.               Keywords: augmented reality, image, mobile, object, recognition               Categories: I.0, I.4.9, I.5.4, J.0  
18|20||Points-to Analysis: A Fine-Grained Evaluation|  Jonas Lundberg (Linnaeus University, Sweden)   Welf Lowe (Linnaeus University, Sweden)  Abstract: Points-to analysis is a static program analysis   that extracts reference information from programs, e.g., possible   targets of a call and possible objects referenced by a   field. Previous works evaluating different approaches to   context-sensitive Pointsto analyses use coarse-grained precision   metrics focusing on references between source code entities like   methods and classes. Two typical examples of such metrics are the   number of nodes and edges in a call-graph. These works indicate that   context-sensitive analysis with a call-depth k = 1 only provides   slightly better precision than contextinsensitive   analysis. Moreover, these works could not find a substantial   precision improvement when using the more expensive analyses with   call-depth k     The hypothesis in the present paper is that substantial differences between the contextsensitive approaches show if (and only if) the precision is measured by more fine-grained metrics focusing on individual objects (rather than methods and classes) and references between them. These metrics are justified by the many applications requiring such detailed object reference information.  In order to experimentally validate our hypothesis we make a systematic comparison of ten different variants of context-sensitive Points-to analysis using different call-depths k     The main results show that the differences between different context-sensitive analysis techniques are substantial, also the differences between the context-insensitive and the context-sensitive analyses with call-depth k = 1 are substantial. The major surprise was that increasing the call-depth k               Keywords: context sensitivity, points-to analysis, static program analysis               Categories: D.2.3, D.3.4, F.3.2  
18|20||The Contrapositive of Countable Choice for Inhabited Sets of Naturals|  Iosif Petrakis (Ludwig-Maximilians Universität München, Germany)  Abstract: Within a fairly weak formal theory of numbers   and number-theoretic sequences we give a direct proof of the   contrapositive of countable finite choice for decidable   predicates. Our proof is at the same time a proof of a stronger form   of it. In that way we think that we improve a proof given by Diener   and Schuster. Within the same theory we prove properties of   inhabited sets of naturals satisfying the general contrapositive of   countable choice. Extending our base theory with the continuity   principle, we prove that each such set is finite. In that way we   generalize a result of Veldman, who proved, actually within the same   extension, the finiteness of these sets, supposing additionally   their decidability.               Keywords: constructive mathematics, countable choice               Categories: G.0  
18|20||Ontology-based Approach to Competence Profile Management|  Vladimir Tarasov (Jönköping University, Sweden)  Abstract: Competence management has received much   attention during recent years because it contributes to achieving   organizational goals and solving problems such as improvement of   information flow or competence supply. Many approaches were proposed   to modelling competence and using competence models but there is   still a lack of research into structures and utilisation of   competence profiles in a competence management system. This article   addresses this problem by proposing a formal approach to competence   profile management. Four project cases are first analysed to elicit   requirements of competence profile management, including competence   profile operations. After that, an abstract model of competence   profile management is formally defined based on the   requirements. Finally, an ontology-based implementation of the   abstract model is presented including a software architecture of a   competence profile management system. The main contribution of this   work is formalization of operations on competence profiles and   ontology-based implementation of these operations. The proposed   implementation architecture can facilitate construction of a   competence profile management system.               Keywords: Jena, OWL, competence, competence managemen, competence profile, formalisation, ontology-based profile               Categories: H.1, H.4, M.4  
18|20||Engineering Security into Distributed Systems: A Survey of Methodologies|  Anton V. Uzunov (University of Adelaide, Australia)   Eduardo B. Fernandez (Florida Atlantic University, USA)   Katrina Falkner (University of Adelaide, Australia)  Abstract: Rapid technological advances in recent years have precipitated a general shift towards software distribution as a central computing paradigm. This has been accompanied by a corresponding increase in the dangers of security breaches, often causing security attributes to become an inhibiting factor for use and adoption. Despite the acknowledged importance of security, especially in the context of open and collaborative environments, there is a growing gap in the survey literature relating to systematic approaches (methodologies) for engineering secure distributed systems. In this paper, we attempt to fill the aforementioned gap by surveying and critically analyzing the state-of-the-art in security methodologies based on some form of abstract modeling (i.e. model-based methodologies) for, or applicable to, distributed systems. Our detailed reviews can be seen as a step towards increasing awareness and appreciation of a range of methodologies, allowing researchers and industry stakeholders to gain a comprehensive view of the field and make informed decisions. Following the comprehensive survey we propose a number of criteria reflecting the characteristics security methodologies should possess to be adopted in real-life industry scenarios, and evaluate each methodology accordingly. Our results highlight a number of areas for improvement, help to qualify adoption risks, and indicate future research directions.               Keywords: computer security, distributed systems, model driven security, model-based development, secure software architectures, secure software engineering, security engineering, security methodologies, security patterns, survey               Categories: C.2.0, C.2.4, D.2.0, D.2.1, D.2.2, D.4.6, K.6.5, L.4  
18|3|http://www.jucs.org/jucs_18_3|Rethinking Education in the Knowledge Society|
18|3||Computer Generated Voice-Over in a Medical E-Learning Application: The Impact on Factual Learning Outcome|"  Stefan Minder (University of Bern, Switzerland)   Michele Notari (University of Bern, Switzerland)   Felix Schmitz (University of Bern, Switzerland)   Rainer Hofer (University of Bern, Switzerland)   Ulrich Woermann (University of Bern, Switzerland)  Abstract: The Medical Faculty of the University of Bern uses voice-over in picture driven e-learning modules to avoid split attention induced by the modality effect. To lower production costs, professional narrators have been replaced by computer-generated voices. The e-learning modules are produced with a content management system (CMS) offering text-to-speech functionality. 107 Swiss high school students passed a 20-minute e-learning sequence on cystic fibrosis. In a nested between-group design with four learning content presentation modalities (written text vs. human voice-over vs. artificial voice-over plus 15""-laptop-screens vs. 2,8""smart-phone screens), the learning outcome was assessed at three points in time: before, just after, and six weeks after the learning phase. All modalities led to significant short-term and long-term increase in factual knowledge about cystic fibrosis. Our two hypotheses are supported: (1) presenting pictures with both human and artificial voice-over leads to the same factual learning outcome, and (2) the e-learning module leads to the same learning outcome and acceptance independent of devices and their screen sizes. Furthermore, the image-voice-over modality on mobile devices (small screens) turned out to be a setting with no significant difference in effectiveness.               Keywords: TTS, e-learning, modality effect, split attention, text-to-speech               Categories:  H.5.1, H.5.2, H.5.4, K.3.1  "
18|3||Co-Designing Collaborative Smart Classroom Curriculum for Secondary School Science|"  Mike Tissenbaum (Ontario Institute for Studies in Education, Canada)   Michelle Lui (Ontario Institute for Studies in Education, Canada)   James D. Slotta (Ontario Institute for Studies in Education, Canada)  Abstract: This paper introduces a series of iterative designs that investigate how the aggregation and visualization of student-contributed work can support collaborative problem solving in the domain of physics. We investigate how new technologies can enable students to contribute to a shared knowledge base, working across contexts: in class, at home, and in a specialized ""smart classroom"" environment. We explore how student data can be provided to the teacher before class, in support of planning the next day's lesson, and during class, to help the teacher orchestrate class activities and respond to student needs. Our work builds upon the research tradition of knowledge communities and inquiry learning to inform its design of materials and activities that support productive collaborative interactions for learners. We are also guided by the recent literature on scripting and orchestration to define curricular activities that bridge home and school environments, leveraging a digital platform that includes Web 2.0 features to guide structured collaborations. This paper reports on a design-based research program in which the development of the curriculum and technology platform is informed by successive cycles of design, enactment, analysis, and re-design. The paper will review our efforts through three successive design cycles, exploring the evolution of our own ""smart classroom curriculum"" for high school physics.  For each iteration, we present our design goals, the resulting curriculum and technology, the student learning outcomes, and our evaluation that informs the next iteration. We end with a description of our current design, and discuss the goals and directions of our future efforts.               Keywords: future classrooms, science education               Categories: L.1.0, L.2.3, L.3.0, L.3.6, L.6.2  "
18|3||Boys are like Girls: Insights in the Gender Digital Divide in Higher Education in Switzerland and Europe|  Luca Botturi (University of Applied Sciences of Southern Switzerland, Switzerland)   Chiara Bramani (University of Lugano, Switzerland)   Sean McCusker (Durham University, United Kingdom)  Abstract: This paper explores the differences between boys and girls in their approach to ICT. Data were gathered from students in the final grades of high school in the Swiss Canton Ticino as part of a wider European project, with a particular focus on the potential uptake of a study or professional career in ICT. Preliminary focus groups with teachers and interviews with women with a job in ICT were followed by a quali-quantitative study which involved 539 students. Results indicate that there are no big gender differences when it comes to ICT use and perception. Small differences are found in the perception of the gender digital divide, while relevant differences were found in the perception and values attached to future professional or academic careers in ICT.               Keywords: Switzerland, college, digital divide, gender               Categories: K.4.2, K.7.0, L.3.3, L.3.7  
18|3||University Students and Social Media: Reflections from an Empirical Research|"  Paolo Ferri (University of Milan, Italy)   Andrea Pozzali (University of Milan, Italy)  Abstract: The current debate on the potential for change that the development of social media can bring to education seems to be based more on general and theoretical considerations than on systematic data. In order to contribute to the development of a more informed perspective, in this paper we present empirical evidence gathered from a 2008 and 2009 survey on undergraduate students at the University of Milan-Bicocca, concerning students' attitudes toward traditional and new media. In particular, we focus here on data concerning the diffusion of some specific tools and services that are commonly meant to represent the most important features of the ""collaborative web"". The comparison of the results obtained in the two surveys allows us to make some reflections on the path of diffusion of social media among young university students and to critically review their actual significance in an educational perspective.               Keywords: Web 2.0, digital natives, personal learning environments, social networks               Categories: A.0, A.1, L.3.5, L.3.6  "
18|3||Pedagogical Design of an eTandem Chinese-French Writing Course|"  Jue Wang (University of Geneva, Switzerland)   Claudia Berger (University of Geneva, Switzerland)   Nicolas Szilas (University of Geneva, Switzerland)  Abstract: Based on previous research conducted concerning eTandem or telecollaboration Foreign Language education, especially a detailed analysis of the ""failed"" experiences of related courses, an original pedagogical design of an eTandem course is proposed. This small-scale pilot design-based research project involved 6 students from two very different languages and cultures: Chinese/China and French/Switzerland. The eTandem Chinese-French writing course included theme-based oral communication and writing activities, peer-corrections by native speakers, and tutoring. Despite the cultural and language differences, most of the pedagogical purposes of the project have been achieved and it has proved that most potential ""failures"" in telecollaboration projects could be possibly avoided. The result of this pilot research has been taken into consideration for the design of a larger-scale eTandem project between Switzerland and China, following an iterative design methodology.               Keywords: design-based research, foreign language teaching and learning, intercultural competence, peer-to-peer correction, tandem language learning, telecollaboration, tutoring               Categories: L.3.5, L.3.6, L.6.2  "
18|3||Measuring Primary Schools Teachers' Perception of ICT through Self-Efficacy: A Case Study|  Isabella Rega (Università della Svizzera italiana, Switzerland)   Francesca Fanni (Università della Svizzera italiana, Switzerland)  Abstract: The case study proposed in this article is the MELISSA project - Measuring E-Learning Impact in primary Schools in South African disadvantaged areas. MELISSA measures the impact of exposure to ICTs in teacher training/learning applying the Self-Efficacy construct. The intention is here to understand and analyse changes in attitudes to and uses of ICTs in term of Computer and Teacher Self-Efficacy. To accomplish this goal, the MELISSA team applied a mixed investigative method, merging quantitative and qualitative methodologies.               Keywords: ICT, ICT4E, disadvantaged contexts, qualitative methods, quantitative methods, self-efficacy, teacher training               Categories: L.0.0, L.3.0, L.3.4, L.3.6, L.3.7  
18|3||AT-HOME 2.0 - An Educational Framework for Home-based Healthcare|"  Izak van Zyl (Università della svizzera italiana, Switzerland)   Retha de la Harpe (Cape Peninsula University of Technology, South Africa)  Abstract: This paper intends to describe some of the primary social and cultural dynamics in South African home-based healthcare, using ethnographic case study material and design methodology. This constitutes a detailed narrative of the ""care experience"" in a poor community, emphasising the needs of and barriers to educational information, particularly concerning caregivers. In reaction to this context, a collaborative training model - AT-HOME 2.0 - emerges through design intervention. This is foreseen as a basic framework whereby caregivers (are encouraged to) develop educational content via information and communication technologies (e.g. mobile phones and social media). Such content can and may include experiences, suggestions, and guidelines that are relevant to the practice of caregiving. AT-HOME 2.0 will conceptually - and in some cases practically - demonstrate how educational content may be generated, published, and disseminated in the sphere of home-based healthcare.               Keywords: digital technologies, home-based healthcare, informal learning, socio-cultural dynamics               Categories: L.2.1, L.3.0, L.3.6, L.6.0, L.6.2  "
18|4|http://www.jucs.org/jucs_18_4|Advances on Social Network Applications|
18|4||Fuzziness and Overlapping Communities in Large-Scale Networks|  Qinna Wang (Université de Lyon, France)   Eric Fleury (Université de Lyon, France)  Abstract: Overlapping community detection is a popular topic in complex networks. As compared to disjoint community structure, overlapping community structure is more suitable to describe networks at a macroscopic level. Overlaps shared by communities play an important role in combining different communities. In this paper, two methods are proposed to detect overlapping community structure. One is called clique optimization, and the other is named fuzzy detection. Clique optimization detects granular overlaps which are nodes have high togetherness with different communities. Fuzzy detection identified modular overlaps which are groups of nodes shared by several communities. Experimental studies in synthetic networks and real networks show that both methods provide good performances in detecting overlapping nodes but in different views. In addition, a new extension of modularity is introduced for measuring the quality of overlapping community structure.               Keywords: community detection, fuzzy community detection, large-scale networks, modularity, overlapping community detection               Categories: L.3, L.6  
18|4||Uncovering the Social Dynamics of Online Elections|  John Boaz Lee (University of the Philippines, Philippines)   Gerard Cabunducan (University of the Philippines, Philippines)   Francis George C. Cabarle (University of the Philippines, Philippines)   Raphael Castillo (University of the Philippines, Philippines)   Jasmine A. Malinao (University of the Philippines, Philippines)  Abstract: Past work analysing elections in online domains has largely ignored the underlying social networks present in such environments. Here, the Wikipedia Request for Adminship (RfA) process is studied within the context of a social network and several factors influencing different stages of the voting process are pinpointed. Machine-learning problems were formulated to test the identified factors. The different facets explored are: election participation, decision making in elections, and election outcome. Our results show that voters tend to participate in elections that their contacts have participated in. Furthermore, there is evidence showing that an individual's decision-making is influenced by his contacts' actions. The properties of voters within the social graph were also studied; results reveal that candidates who gain the support of an influential coalition tend to succeed in elections. Additionally, detailed analyses on different classes of voters and candidates were made. Finally, the structural properties corresponding to networks of election participants were analysed and these networks were found to exhibit higher degrees of community structure versus graphs of participants selected at random.               Keywords: election analysis, logistic regression, social influence, social network analysis, social voter               Categories: H.3.0, J.1, J.4, M.7  
18|4||The Unification and Assessment of Multi-Objective Clustering Results of Categorical Datasets with H-Confidence Metric|  Onur C. Sert (TOBB Economics and Technology University, Turkey)   Kayhan Dursun (TOBB Economics and Technology University, Turkey)   Tansel Özyer (TOBB Economics and Technology University, Turkey)   Jamal Jida (Lebanese University, Lebanon)   Reda Alhajj (University of Calgary, Canada)  Abstract: Multi objective clustering is one focused area of multi objective optimization. Multi objective optimization attracted many researchers in several areas over a decade. Utilizing multi objective clustering mainly considers multiple objectives simultaneously and results with several natural clustering solutions. Obtained result set suggests different point of views for solving the clustering problem. This paper assumes all potential solutions belong to different experts and in overall; ensemble of solutions finally has been utilized for finding the final natural clustering. We have tested on categorical datasets and compared them against single objective clustering result in terms of purity and distance measure of k-modes clustering. Our clustering results have been assessed to find the most natural clustering. Our results get hold of existing classes decided by human experts.               Keywords: NSGA-II, h-confidence, multi-objective clustering               Categories: I.5.1, I.5.3, I.5.4, I.5.5, J.4  
18|4||Social Network Based Reputation Computation and Document Classification|  Joo Young Lee (Syracuse University, USA)   Yue Duan (Syracuse University, USA)   Jae C. Oh (Syracuse University, USA)   Wenliang Du (Syracuse University, USA)   Howard Blair (Syracuse University, USA)   Lusha Wang (Syracuse University, USA)   Xing Jin (Syracuse University, USA)  Abstract: We develop two social network based algorithms that automatically compute author reputation from a collection of textual documents. We first extract keyword reference behaviors of the authors to construct a social network, which represents relationships among the authors in terms of information reference behavior. With this network, we apply the two algorithms: the first computes each author's reputation value considering only direct reference and the second utilizes indirect reference recursively. We compare the reputation values computed by the two algorithms and reputation ratings given by a human domain expert. We further evaluate the algorithms in email categorization tasks by comparing them with machine learning techniques. Finally, we analyse the social network through a community detection algorithm and other analysis techniques. We observed several interesting phenomena including the network being scale-free and having a negative assortativity.               Keywords: community analysis, computer security, reputation management, social network               Categories: H.2, H.3.7, H.5.4  
18|4||Understanding Microblog Users for Social Recommendation Based on Social Networks Analysis|  I-Hsing Ting (National University of Kaohsiung, Taiwan)   Pei Shan Chang (National University of Kaohsiung, Taiwan)   Shyue-Liang Wang (National University of Kaohsiung, Taiwan)  Abstract: With the rapid growth of Internet and social networking websites, various services are provided in these platforms. For instance, Facebook focuses on social activities, Twitter and Plurk (which are called microblogs) are both focusing on the interaction of users through short messages. Millions of users enjoy services from these websites which are full of marketing possibilities. Understanding the users can assist companies to enhance the accuracy and efficiency of the target market. In this paper, a social recommendation system based on the data from microblogs is proposed. This social recommendation system is built according to the messages and social structure of target users. The similarity of the discovered features of users and products will then be calculated as the essence of the recommendation engine. A case study included in the paper presents how the recommendation system works based on real data from Plurk.               Keywords: microblogs, social networks analysis, social recommendation system, target marketing               Categories: H.3.5  
18|4||Key Person Analysis in Social Communities within  the Blogosphere|  Anna Zygmunt (AGH University of Science and Technology, Poland)   Piotr Bródka (Wrocław University of Technology, Poland)   Przemysław Kazienko (Wrocław University of Technology, Poland)   Jarosław Koźlak (AGH University of Science and Technology, Poland)  Abstract: Identifying key persons active in social groups in the blogosphere is performed by means of social network analysis. Two main independent approaches are considered in the paper: (i) discovery of the most important individuals in persistent social communities and (ii) regular centrality measures applied either to social groups or the entire network. A new method for separating of groups stable over time, fulfilling given conditions of activity level of their members is proposed. Furthermore, a new concept for extracting user roles and key persons in such groups is also presented. This new approach was compared to the typical clustering method and the structural node position measure applied to rank users. The experimental studies have been carried out on real two-year blogosphere data.               Keywords: CPM, SNA, blogosphere, fast modularity optimization, key person, node position, persistent group, role identification, social community extraction, social group, social network, social network analysis, stable social group               Categories: E.m, F.2.m, G.2.2, G.2.3, H.3.1, H.3.5, H.4.3, I.5.1, I.5.3, I.5.4, I.7.4, I.7.5, J.4, K.4.2, L.6.1, L.6.2, M.0  
18|5|http://www.jucs.org/jucs_18_5|Managing Editor's Column|
18|5||Decision Strategies for a P2P Computing System|  Grzegorz Chmaj (Wrocław University of Technology, Poland)   Krzysztof Walkowiak (Wrocław University of Technology, Poland)  Abstract: Peer-to-Peer (P2P) computing (also called   'public-resource computing') is an effective approach to perform   computation of large tasks. Currently used P2P computing systems   (e.g., BOINC) are most often centrally managed, i.e., the final   result of computations is created at a central node using partial   results - what may be not efficient in the case when numerous   participants are willing to download the final result. In this   paper, we propose a novel approach to P2P computing systems. We   assume that results can be delivered to all peers in a distributed   way using three types of network flows: unicast, Peer-to-Peer and   anycast. We describe our concept of the system architecture with a   special focus on the decision strategies developed for system   participants. Using our discrete realtime simulator we evaluate the   proposed strategies in various scenarios and present a comprehensive   analysis of obtained results. According to obtained results, the   Peer-to-Peer flow provides lower operational cost of the computing   system compared to unicast and anycast flows. Moreover, an   appropriate selection of decision strategy can significantly reduce   the operational cost.               Keywords: P2P, anycast, computing systems, networks, simulation, unicast               Categories:  C.2.1, C.2.3, C.2.4  
18|5||Improving the Extraction of Text in PDFs by Simulating the Human Reading Order|  Ismael Hasan (University of a Coruña, Spain)   Javier Parapar (University of a Coruña, Spain)   Álvaro Barreiro (University of a Coruña, Spain)  Abstract: Text preprocessing and segmentation are critical tasks in search and text mining applications. Due to the huge amount of documents that are exclusively presented in PDF format, most of the Data Mining (DM) and Information Retrieval (IR) systems must extract content from the PDF files. In some occasions this is a difficult task: the result of the extraction process from a PDF file is plain text, and it should be returned in the same order as a human would read the original PDF file. However, current tools for PDF text extraction fail in this objective when working with complex documents with multiple columns. For instance, this is the case of official government bulletins with legal information. In this task, it is mandatory to get correct and ordered text as a result of the application of the PDF extractor. It is very usual that a legal article in a document refers to a previous article and they should be offered in the right sequential order. To overcome these difficulties we have designed a new method for extraction of text in PDFs that simulates the human reading order. We evaluated our method and compared it against other PDF extraction tools and algorithms. Evaluation of our approach shows that it significantly outperforms the results of the existing tools and algorithms.               Keywords: PDF, evaluation, ordered text extraction, text extraction, text mining, text preprocessing               Categories: I.7.4, I.7.5, J.1  
18|5||Wikipedia-Based Semantic Interpreter Using Approximate Top-k Processing and Its Application|  Jong Wook Kim (Teradata Corporation, USA)   Ashwin Kashyap (Technicolor, USA)   Sandilya Bhamidipati (Technicolor, USA)  Abstract: Proper representation of the meaning of texts is crucial for enhancing many data mining and information retrieval tasks, including clustering, computing semantic relatedness between texts, and searching. Representing of texts in the concept-space derived from Wikipedia has received growing attention recently. This concept-based representation is capable of extracting semantic relatedness between texts that cannot be deduced with the bag of words model. A key obstacle, however, for using Wikipedia as a semantic interpreter is that the sheer size of the concepts derived from Wikipedia makes it hard to efficiently map texts into concept-space. In this paper, we develop an efficient and effective algorithm which is able to represent the meaning of a text by using the concepts that best match it. In particular, our approach first computes the approximate top-k Wikipedia concepts that are most relevant to the given text. We then leverage these concepts for representing the meaning of the given text. The experimental results show that the proposed technique provides significant gains in execution time without causing significant reduction in precision. We then explore the effectiveness of the proposed algorithm on a real world problem. In particular, we show that this novel scheme could be leveraged to boost the effectiveness in finding topic boundaries in a news video.               Keywords: Wikipedia, concept, semantic interpretation               Categories: H.3.1, H.3.3, M.4  
18|5||Modeling and Performance Evaluation of a Contract-based Electronic Signature Process|  Ahmed Nait-Sidi-Moh (Université de Picardie Jules Verne, France)   Mohamed Bakhouya (Aalto University, Finland)   Wafaa Ait-Cheik-Bihi (Université de Strasbourg, France)   Jaafar Gaber (Université de Technologie de Belfort Montbéliard, France)  Abstract: Distributed systems become ubiquitous by allowing users access to a wide range of services at any time, anywhere, and from a variety of devices. In these open environments where there are many opportunities for both fraudulent services and misbehaving clients, service discovery systems are subject to security challenges. Controlling services' access is one of the fundamental issues that must be faced in the context of service discovery in distributed and open environments. Therefore, secure accesses and utilization of available services must be ensured for users. In our previous work, a contract-based approach for controlling the service access in a distributed computing context was presented. In this paper, we address the purpose and the usage of digital signature on negotiated electronic queries between a server and clients in service discovery systems and web service composition. The paper discusses the combined use of Timed Event Graphs and (max, +)- algebra to model, evaluate and optimize the performance of the signature process and client requests validation by a service provider (server). Based on an optimization resource allocation algorithm, an improvement study of the quality of service offered to the clients, in terms of waiting times and validation of their requests, is proposed. The results are reported and show the efficiency of the use of the proposed formal tools for performance analysis, evaluation and tuning of the considered process.               Keywords: Petri nets and (max, +)-algebra, dimensioning and improvement, electronic exchanges, evaluation and simulation, modeling, web service access control               Categories: E.3, F.4.3, G.1.3, G.2.1, H.4.0, H.5.1  
18|5||Applying a Modular Framework to Develop Mobile Applications and Services|  Mabel Vazquez-Briseno (UABC, Mexico)   Pierre Vincent (MobKit, France)   Juan Ivan Nieto-Hipolito (UABC, Mexico)   Juan de Dios Sanchez-Lopez (UABC, Mexico)  Abstract: The development of mobile applications and   services has led to new challenges for software programmers. One of   the main differences from standard PC programming is that the mobile   environment is still limited in several aspects. Thus, there are   many applications for mobile devices that share similarities, and   implementing new applications may result in duplicated code within   the same project or in similar projects. Moreover, current mobile   development is still an error-prone task that may produce   difficult-to-maintain applications. As a result, developers need new   tools to help them to develop mobile software efficiently. This work   focuses on a new framework for generating mobile applications and   services, MobAppGen. The framework provides a set of components   called modules that can be used to construct new applications using   a Web interface. The architecture and functionalities of the   framework are delineated, and several tests were conducted to   evaluate the performance of the framework. For the tests, we created   a number of projects using the available modules. In addition, a   survey was conducted to estimate the acceptance and usefulness of   the framework.               Keywords: mobile computing, mobile devices, mobile information systems, multimedia, software               Categories: D.2.11, H.3.4, H.4.3, H.5.1  
18|6|http://www.jucs.org/jucs_18_6|Security in Information Systems: New Challenges and Opportunities|
18|6||Success Rate of Remote Code Execution Attacks - Expert Assessments and Observations|  Hannes Holm (Royal Institute of Technology, Sweden)   Teodor Sommestad (Royal Institute of Technology, Sweden)   Ulrik Franke (Royal Institute of Technology, Sweden)   Mathias Ekstedt (Royal Institute of Technology, Sweden)  Abstract: This paper describes a study on how cyber   security experts assess the importance of three variables related to   the probability of successful remote code execution attacks: (i)   non-executable memory, (ii) access and (iii) exploits for High or   Medium vulnerabilities as defined by the Common Vulnerability   Scoring System. The rest of the relevant variables were fixed by the   environment of a cyber defense exercise where the respondents   participated. The questionnaire was fully completed by fifteen   experts. These experts perceived access as the most important   variable and availability of exploits for High vulnerabilities as   more important than Medium vulnerabilities. Non-executable memory   was not seen as significant. Estimates by the experts are compared   to observations of actual attacks carried out during the cyber   defense exercise. These comparisons show that experts' in general   provide fairly inaccurate advice on an abstraction level such as in   the present study. However, results also show a prediction model   constructed through expert judgment likely is of better quality if   the experts' estimates are weighted according to their   expertise.               Keywords: cyber security, remote code execution, software vulnerabilities               Categories: D.2.9, K.6.3, K.6.5  
18|6||Combating Mobile Spam through Botnet Detection using Artificial Immune Systems|  Ickin Vural (University of Pretoria, Republic of South Africa)   Hein S. Venter (University of Pretoria, Republic of South Africa)  Abstract: Malicious software (malware) infects large   numbers of mobile devices. Once infected these mobile devices may be   involved in many kinds of online criminal activity, including   identity theft, unsolicited commercial SMS messages, scams and   massive coordinated attacks. Until recently, mobile networks have   been relatively isolated from the Internet, so there has been little   need to protect them against Botnets. Mobile networks are now well   integrated with the internet, so threats on the internet, such as   Botnets, have started to migrate to mobile networks. This paper   studies the potential threat of Botnets based on mobile networks,   and proposes the use of computational intelligence techniques to   detect Botnets. We then simulate mobile Bot detection by detecting   anomalies using an artificial immune system implementation on an   Android device.               Keywords: Botnet, artificial immune system, computational intelligence, malware, mobile               Categories: J.0  
18|6||Qos-Security Metrics Based on ITIL and COBIT Standard for Measurement Web Services|  Pattama Charuenporn (King Mongkut's Institute of Technology Ladkrabang, Thailand)   Sarun Intakosum (King Mongkut's Institute of Technology Ladkrabang, Thailand)  Abstract: Web Services have been widely adopted in   business projects, and almost all Web Service developers agree that   security factors are the principal components that must be taken   into consideration. A large number of security metrics and   measurements is available for specific business needs, and the best   practice for different business demands is therefore needed if the   quality of service security metrics (Qos-SM) is to be   developed. This research proposes a new way of developing Qos-SM   using Qos ontology mapping with two information system standards,   COBIT and ITIL, as a result of which new Qos-SM are developed. In   order to prove the correctness and precision of the metrics, the   researchers have used the metrics to measure the level of security   quality from Web service data sets. The experimental results, based   on vector analysis, show that the same level of security quality is   attained with both of the metrics developed and the metrics from   previous research. This research also represents the metrics in the   form of a class diagram, thus facilitating its application in the   organization.               Keywords: COBIT, ITIL, quality of service, security for web service, security metrics and measurement               Categories: D.2.4, D.2.8, D.2.m  
18|6||A Systematic Review of Information Security Governance Frameworks in the Cloud Computing Environment|  Oscar Rebollo (Ministry of Labour and Immigration, Spain)   Daniel Mellado (University of Castilla-La Mancha, Spain)   Eduardo Fernández-Medina (University of Castilla-La Mancha, Spain)  Abstract: The senior management of any enterprise that   plans to start using Cloud Computing services needs to define a   clear governance strategy with regard to the security of its   information assets. This paper presents a systematic literature   review whose objective is to seek existing Information Security   Governance frameworks that may assist companies with these   functions. The analysis of the frameworks extracted is complemented   with a set of comparative criteria that consider the particularities   of Cloud Computing when dealing with security governance   issues.               Keywords: cloud computing, information security governance, systematic literature review               Categories: C.2.4, K.6, K.6.5  
18|6||Syntactic and Semantic Extensions to Secure Tropos to Support Security Risk Management|  Raimundas Matulevičius (University of Tartu, Estonia)   Haralambos Mouratidis (University of East London, United Kingdom)   Nicolas Mayer (CRP Henri Tudor, Luxembourg)   Eric Dubois (CRP Henri Tudor, Luxembourg)   Patrick Heymans (University of Namur, Belgium)  Abstract: The need to consider security from the early   stages of the development process of information systems has been   argued by academics and industrialists alike, and security risk   management has been recognised as one of the most prominent   techniques for eliciting security requirements. However, although   existing security modelling languages provide some means to model   security aspects, they do not contain concrete constructs to address   vulnerable system assets, their risks, and risk   treatments. Furthermore, security languages do not provide a   crosscutting viewpoint relating all three - assets, risks and risk   treatments - together. This is problematic since, for a security   analyst, it is difficult to detect what the potential security flaws   could be, and how they need to be fixed. In this paper, we extend   the Secure Tropos language, an agentand goal-oriented security   modelling language to support modelling of security risks. Based on   previous work, where we had observed some inadequacies of this   language to model security risks, this paper suggests improvements   of Secure Tropos semantics and syntax. On the syntax level we extend   the concrete and abstract syntax of the language, so that it covers   the security risk management domain. On the semantic level, we   illustrate how language constructs need to be improved to address   the three different levels of security risk management. The   suggested improvements are illustrated with the aid of a running   example, called eSAP, from the healthcare domain.               Keywords: information system, risk management, secure tropos, security, syntax and semantics of modelling language               Categories: D.2.1, D.2.2, H.1, H.4.2, J.6  
18|6||A Framework for the Comparison of Best Practice Recommendations and Legal Requirements for South African Banks|  Carla-Lee Botha (University of South Africa, South Africa)   Elmarie Kritzinger (University of South Africa, South Africa)   Marianne Loock (University of South Africa, South Africa)  Abstract: South African home users of the Internet use it   to perform various everyday functions. These functions include, but   are not limited to, online shopping, online gaming, social   networking and online banking. Home users of online banking face   multiple threats, such as phishing and social engineering. These   threats come from hackers attempting to obtain confidential   information, such as online banking authentication credentials, from   home users. It is, thus, essential that home users of online banking   be made aware of these threats, how to identify them and what   countermeasures to implement to protect themselves from hackers. In   this respect, information security awareness (ISA) programmes are an   effective way of making the home users of online banking aware of   both the threats they face and the countermeasures available to   protect themselves from these threats. South African banks have to   comply with certain legal requirements when implementing information   security awareness initiatives. Non-compliance or failure to   demonstrate due care and due diligence, should a security incident   occur, will result in financial penalties for the bank as well as   possible brand damage and loss of customers. Banks implement   international best practice recommendations in an effort to comply   with legislation. These include recommendations for information   security awareness. This research proposes a framework which,   predominantly, can be applied when determining and comparing   information security best practice recommendations and information   security legal requirements for online banking. The primarily aim of   this paper is to investigate whether the implementation of best   practices are sufficient to comply with legal requirements. A   selected list of information security best practices was   investigated for best practice recommendations while a selected list   of information security legislation was also investigated for legal   requirements imposed on South African banks. A gap analysis was   performed on both these recommendations and requirements to   determine whether the implementation of best practice   recommendations results in compliance with legal requirements. The   gap analysis found that the implementation of best practice   recommendations does not result in compliance with legal   requirements. Accordingly, the outcome of this research highlights   the importance of applying such a framework in a comprehensive   fashion to understand the legal requirements imposed and ensure that   adequate controls are in place for achieving compliance.               Keywords: South Africa, best practice, home users, information security awareness, legislation, online banking               Categories: H.3.5, K.3.2, K.6.5  
18|6||Countermeasures to Prevent Misbehaviour in VANETs|  Jezabel Molina-Gil (University of La Laguna, Spain)   Pino Caballero-Gil (University of La Laguna, Spain)   Cándido Caballero-Gil (University of La Laguna, Spain)  Abstract: A key aspect to ensure that Vehicular Ad-hoc NETworks (VANETS) work properly is the provision of reliable and real time information to users. In order to achieve this goal, on the one hand, nodes must cooperate actively in relaying the messages to reach as many users as possible to warn them about possible hazards. On the other hand, users should be able to rely on the received information, so they should be able to verify that the relayed network data are true. As distributed and decentralized networks, security problems such as prevention of false information injection, and detection of misbehaviour could be solved through cooperation among nodes. In this work we propose a set of countermeasures to prevent selfish behaviour and malicious attacks, making use of node revocation through cooperation enforcement mechanisms and isolation of malicious nodes from the network. The proper performance of the proposed techniques has been evaluated with many simulations, and the results show that the countermeasures described in this work increase not only efficiency but also security of communications.               Keywords: ITS, VANETs, cooperation, misbehaviour, security, self-management               Categories: C.2.0, C.2.1, C.2.2, C.2.3, C.2.4  
18|6||Adaptive Group Key Management Protocol for Wireless Communications|  Saïd Gharout (Orange Labs - France Telecom, France)   Abdelmadjid Bouabdallah (University of Technology of Compiègne, France)   Yacine Challal (University of Technology of Compiègne, France)   Mohammed Achemlal (Orange Labs - France Telecom, France)  Abstract: Group-oriented services and wireless   communication networks are among the emerging technologies of the   last few years. Group key management, which is an important building   bloc in securing group communication, has received a particular   attention in both academic and industry research communities. This   is due to the economical relevance of group-based applications, such   as video on demand, videoconferencing, collaborative work. The key   management concerns the distribution and updates of the key material   each time a member joins or leaves the group. The dynamic aspect of   group applications due to free membership joins and leaves in   addition to members' mobility makes difficult the design of   efficient and scalable key management protocols. Indeed, to secure   group communication in mobile environment, the protocol must deal   not only with dynamic group membership but also with dynamic member   location. Thus, the challenges in designing secure and scalable key   management protocols are: the dynamic updates of the key caused by   frequent joins and leaves, the large size of the group and the   mobility of group members. Many academic researches have addressed   the first and the third challenges. However the mobility challenge   has not been widely addressed. In this paper, we present our   solution for group key management with a mobility support. Our   protocol focuses on the above three challenges. It is highly   scalable to dynamic groups and treats the nodes' mobility with a   null re-keying cost and keeps perfect backward and forward   secrecies. Our simulation studies show that our protocol makes   better performance compared to other protocols while reducing the   overall overhead and the number of re-keying messages and has no   security failures.               Keywords: confidentiality, group communication, key management, mobility               Categories: C.2.0  
18|7|http://www.jucs.org/jucs_18_7|Adaptive Methodologies and Designs for Network-on-Chip based Systems|
18|7||Mapping and Scheduling in Heterogeneous NoC through Population-Based Incremental Learning|  Freddy Bolanos (Universidad Nacional de Colombia, Colombia)   Jose Edison Aedo (Universidad de Antioquia, Colombia)   Fredy Rivera (Universidad de Antioquia, Colombia)   Nader Bagherzadeh (University of California, Irvine, USA)  Abstract: Network-on-Chip (NoC) is a growing and promising communication paradigm for Multiprocessor-System-On-Chip (MPSoC) design, because of its scalability and performance features. In designing such systems, mapping and scheduling are becoming critical stages, because of the increase of both size of the network and application's complexity. Some reported solutions solve each issue independently. However, a conjoint approach for solving mapping and scheduling allows to take into account both computation and communication objectives simultaneously. This paper shows a mapping and scheduling solution, which is based on a Population-Based Incremental Learning (PBIL) algorithm. The simulation results suggest that our PBIL approach is able to find optimal mapping and scheduling, in a multi-objective fashion. A 2-D heterogeneous mesh was used as target architecture for implementation, although the PBIL representation is suited to deal with more complex architectures, such as 3-D meshes.               Keywords: computer-aided design (CAD), multiprocessor-system-on-chip (MPSoC), network-on-chip (NoC), population-based incremental learning (PBIL)               Categories: C.1.2, I.2.6, J.6  
18|7||ACO-based Algorithms for Search and Optimization of Routes in NoC Platform|  Luneque Silva Junior (State University of Rio de Janeiro, Brazil)   Nadia Nedjah (State University of Rio de Janeiro, Brazil)   Luiza de Macedo Mourelle (State University of Rio de Janeiro, Brazil)  Abstract: Network-on-Chip (NoC) have been used as an interesting option in design of communication infrastructures for embedded systems, providing a scalable structure and balancing the communication between cores. Because several data packets can be transmitted simultaneously through the network, an efficient routing strategy must be used in order to avoid congestion delays. In this paper, ant colony algorithms were used to find and optimize routes in a mesh-based NoC. The routing optimization is driven by the minimization of total latency in packets transmission. The simulation results show the effectiveness of the ant colony inspired routing by comparing it with general purpose algorithms for deadlock free routing under different traffic patterns.               Keywords: ant colony optimization, network-on-chip, packet routing               Categories: B.4.3, I.2.8, I.6.3  
18|7||Designing Robust Routing Algorithms and Mapping Cores in Networks-on-Chip: A Multi-objective Evolutionary-based Approach|  Maurizio Palesi (Kore University, Italy)   Rafael Tornero (Universidad de Valencia, Spain)   Juan Manuel Orduñna (Universidad de Valencia, Spain)   Vincenzo Catania (University of Catania, Italy)   Daniela Panno (University of Catania, Italy)  Abstract: Mainstream electronic designs are realized by Systems-on-Chips (SoCs) that push the limits of integration. The advancement of manufacturing technologies in terms of integration leads us to SoCs with many (e.g., 10-1000) digital units (e.g., processor cores, controllers, storage, application-specific units) that need to be interconnected in an efficient and reliable way. The Network-on-Chip (NoC) design paradigm emerged recently as a promising alternative to classical bus-based communication architectures. Aside from better predictability and lower power consumption, the NoC approach offers greater scalability compared to previous solutions for on-chip communication. The design flow of NoCs include several key issues. Among other parameters, the decision of where cores have to be topologically mapped and also the routing algorithm represent two highly correlated design problems that must be carefully solved for any given application in order to optimize different performance metrics. The strong correlation between the different parameters often makes that the optimization of a given performance metric has a negative effect on a different performance metric. In this paper we propose a new strategy that simultaneously refines the mapping and the routing function to determine the Pareto optimal configurations which optimize average communication delay and routing robustness. The proposed strategy has been applied on both synthetic and real traffic scenarios. The obtained results show how the solutions found by the proposed approach outperforms those provided by other approaches proposed in literature, in terms of both performance and fault tolerance.               Keywords: fault-tolerance, genetic algorithm, multi-objective optimization, networks-on-chip, performance analysis, routing algorithm, topological mapping               Categories: B.4.3, J.6  
18|8|http://www.jucs.org/jucs_18_8|Understanding Online Social Networking Services|
18|8||Discovering Consumer Insight from Twitter via Sentiment Analysis|  Wilas Chamlertwat (Chulalongkorn University, Thailand)   Pattarasinee Bhattarakosol (Chulalongkorn University, Thailand)   Tippakorn Rungkasiri (Chulalongkorn University, Thailand)   Choochart Haruechaiyasak (National Electronics and Computer Technology Center, Thailand)  Abstract: Traditional approaches for studying consumer behavior, such as marketing survey and focus group, require a large amount of time and resources. Moreover, some products, such as smartphones, have a short product life cycle. As an alternative solution, we propose a system, the Micro-blog Sentiment Analysis System (MSAS), based on sentiment analysis to automatically analyze customer opinions from the Twitter micro-blog service. The MSAS consists of five main functions to (1) collect Twitter posts, (2) filter for opinionated posts, (3) detect polarity in each post, (4) categorize product features and (5) summarize and visualize the overall results. We used the product domain of smartphone as our case study. The experiments on 100,000 collected posts related to smartphones showed that the system could help indicating the customers' sentiments towards the product features, such as Application, Screen, and Camera. Further evaluation by experts in smartphone industry confirmed that the system yielded some valid results.               Keywords: information extraction, information visualization, micro-blog, natural language processing, sentiment analysis               Categories: H.3.5, H.4.3, M.0  
18|8||Establishing Knowledge Networks via Analysis of Research Abstracts|  Mahalakshmi G. Suryanarayanan (Anna University, India)   Dilip S. Sam (Anna University, India)   Sendhilkumar Selvaraju (Anna University, India)  Abstract: The extraction and propagation of knowledge   inherent in a social network environment is demanding higher   significance in research. The knowledge hidden within a social   network would be easier to be comprehended if provided in a   collective form. In the field of scientific research, such   presentation of appreciated knowledge evolved from research   communities would aid researchers. In this paper, we propose the   evolution of a knowledge network from the information available in   digital bibliographic repositories like DBLP [DBLP]. The most   important characteristic of this knowledge network would be the   comprehension of the proficiency of the scientist in the perspective   of an area of research. This is achieved by categorizing the   research articles published by an author into specific domains. The   quality of the research articles are ascertained by analysing the   abstracts within the domain. This analysis is used to determine the   quality of the research article in terms of originality, relevancy   and thereby, the impact of the article with respect to a research   area. This quality measure provides knowledge on the impact of the   scientist on the research community is arrived at as a cumulative   entity. This knowledge helps in the evolution of the knowledge   network from the social network of a research community.               Keywords: fuzzy cognitive maps, knowledge networks               Categories: H.3.3, H.3.7  
18|8||Beating Social Pulse: Understanding Information Propagation via Online Social Tagging Systems|  Xuan Hau Pham (Yeungnam University, Korea)   Jason J. Jung (Yeungnam University, Korea)   Dosam Hwang (Yeungnam University, Korea)  Abstract: Social media (e.g., Twitter and FaceBook) have   been one of the most popular online communication channels to share   information among users. It means the users can give (and have)   cognitive influences to (and from) the others. Thus, it is important   for many online collaborative applications to understand how the   information can be propagated via such social media. In this paper,   we focus on a social tagging system where users can easily exchange   resources as well as their tags with other users. Given a certain   tag from a temporal folksonomy, the social pulse can be established   by counting the number of users (or resources). Particularly, we can   discover meaningful relationship between tags by computing   inducibility. To conduct experimentation, a tag search system has   been implemented to collect a dataset from Flickr.               Keywords: inducibility, information propagation, social pulse, social tagging               Categories: H.1.1, H.3.5, I.2.11  
18|8||Automatic Tag Attachment Scheme based on Text Clustering for Efficient File Search in Unstructured Peer-to-Peer File Sharing Systems|  Ting Ting Qin (Hiroshima University, Japan)   Satoshi Fujita (Hiroshima University, Japan)  Abstract: In this paper, the authors address the issue of automatic tag attachment to the documents distributed over a P2P network aiming at improving the efficiency of file search in such networks. The proposed scheme combines text clustering with a modified tag extraction algorithm, and is executed in a fully distributed manner. Meanwhile, the optimal cluster number can also be fixed automatically through a distance cost function. We have conducted experiments to evaluate the accuracy of the proposed scheme. The result of experiments indicates that the proposed approach is capable of making effective and efficient tag attachment in real scenarios; i.e., for more than 90% of documents, it attaches the same tags as the ones attached by human reviewers. Moreover, it proofs by the experiments that the optimal cluster number is almost the same as the number of topics from the website.               Keywords: K-DMeans, P2P system, TFIDCF, automatic tag attachment, text clustering               Categories: H.3.1, H.3.2, H.3.3  
18|8||Modeling, Mining and Analysis of Multi-Relational Scientific Social Network|  Victor Ströele (Federal University of Rio de Janeiro, Brazil)   Geraldo Zimbrão (Federal University of Rio de Janeiro, Brazil)   Jano M. Souza (Federal University of Rio de Janeiro, Brazil)  Abstract: Social networks are dynamic social structures   consisting of individuals or organizations, usually represented by   nodes tied by one or more relationship type. Analyzing these   structures enables us to detect several inter and intra connections   between people in and outside their organizations. In this context,   we construct a multi-relational scientific social network where   researchers may have four different types of relationships with each   other. We adopt some criteria such as relationship age in order to   assign a weight to relationships and to enable the modeling of a   scientific social network as close as possible to reality. Using   clustering techniques with maximum flow measure, we identify the   social structure and research communities in a way that allows us to   evaluate the knowledge flow in the Brazilian scientific   community.               Keywords: Max Flow Grouping Algorithm, Multi-relational Scientific Social Network  Analysis, knowledge flow, weighted relationships               Categories: J.1, J.4, K.4.2, K.4.3, L.1.0, L.6.0, L.6.2  
18|9|http://www.jucs.org/jucs_18_9|Internet of Things|
18|9||A Metropolitan Taxi Mobility Model from Real GPS Traces|  Hongyu Huang (Chongqing University, China)   Daqiang Zhang (Nanjing Normal University, China)   Yanmin Zhu (Shanghai Jiao Tong University, China)   Minglu Li (Shanghai Jiao Tong University, China)   Min-You Wu (Shanghai Jiao Tong University, China)  Abstract: The past few years have witnessed the growing interest in vehicular ad hoc networks(VANETs) and their potential applications for Internet of Things (IoT). Since the mobility model is crucial to simulation based researches of VANET, using a realistic mobility model can ensurethe consistency between simulation results and real deployments. Although there are many mobility models characterizing the movement of mobile nodes, none of them consider the behaviorof vehicles in a metropolitan scenario. In this paper, we present our study of extracting a mobility model for VANET from a large amount of real taxi GPS trace data. In order to capture charac-teristics of the urban vehicle network from microscopic to macroscopic aspects, we design three parameters and extract their values from the GPS trace data. Using this mobility model, we cangenerate the synthetic trace to simulate the movement of taxis in the urban area of a metropolis. The validation is carried through extensive comparisons between the synthetic trace and the realtrace. The results show that our mobility model has a good approximation with the real scenario.               Keywords: Mobility Model, Taxi GPS Data, Vehicular Ad Hoc Network               Categories: C.2,, C.2.m  
18|9||Context-based Ontology Matching: Concept and Application Cases|"  Feiyu Lin (Changzhou University, P.R.China)   Kurt Sandkuhl (Rostock University, Germany)   Shoukun Xu (Changzhou University, P.R.China)  Abstract: The Internet of Things (IoT) aims at linking smart objects that are relevant to the user and embedding intelligence into the environment. It is more and more accepted in the scientific community and expected by end users, that pervasive services should be able to adapt to the circumstances or situation in which a computing task takes place, and maybe even detect all relevant parameters for this purpose. Work presented in this paper addresses the challenge of bringing together concepts and experiences from two different areas: context modeling and ontology matching. Current work in the field of automatic ontology matching does not sufficiently take into account the context of the user during the matching process. The main contributions of this paper are (1) the introduction of the concept of ""context"" in the ontology matching process, (2) an approach for context-based semantic matching, which is building on different (weighted) levels of overlap for a better ranking of alignment elements depending on user's context, (3) an evaluation of the context-based matching in experiments and from user's perspectives.               Keywords: Internet of Things, context-aware computing, ontology matching               Categories: H.3.2, H.3.3, M.4, M.5, M.7  "
18|9||Directed Path Based Authentication Scheme for the Internet of Things|  Huansheng Ning (Beihang University, China)   Hong Liu (Beihang University, China)   Qing Liu (Nanjing Normal University, China)   Genlin Ji (Nanjing Normal University, China)  Abstract: The Internet of Things (IoT) is emerging as an attractive paradigm, and several IoT models and related security issues have received widespread attentions. In this paper, we focus on an existing U2IoT architecture (i.e., Unit IoT and Ubiquitous IoT), and propose a directed path based authentication scheme (DPAS) to realize security protection for the U2IoT architecture. Particularly, the directed path descriptor is introduced for the secret key distribution and cross-network authentication, and the proof mapping is applied to establish tri-dimensional equivalence relations among diverse nodes for achieving mutual authentication. Moreover, security analysis shows that DPAS achieves data confidentiality and integrity, authentication, anonymity and forward security, and performance analysis indicates that DPAS with moderate communication overhead and computation load is suitable for the IoT applications.               Keywords: Internet of things, authentication protocol, directed path, security               Categories: C.2.2, K.6.5  
18|9||Goal-Driven Process Navigation for Individualized Learning Activities in Ubiquitous Networking and IoT Environments|  Jian Chen (Waseda University, Japan)   Qun Jin (Waseda University, Japan)   Runhe Huang (Hosei University, Japan)  Abstract: In the study, we propose an integrated adaptive   framework to support and facilitate individualized learning through   sharing the successful process of learning activities based on   similar learning patterns in the ubiquitous learning environments   empowered by Internet of Things (IoT). This framework is based on a   dynamic Bayesian network that gradually adapts to a target   students needs and information access behaviours. By analysing   the log data of learning activities and extracting students'   learning patterns, our analysis results show that most of students   often use their preferred learning patterns in their learning   activities, and the learning achievement is affected by the learning   process. Based on these findings, we try to optimise the process of   learning activities using the extracted learning patterns, infer the   learning goal of target students, and provide a goal-driven   navigation of individualized learning process according to the   similarity of the extracted learning patterns.                 Categories:  H.3.3, H.3.1, H.3.5, L.2.0  
18|9||Localized Processing and Analysis of Accelerometer Data in Detecting Traffic Events and Driver Behaviour|  Bratislav Predic (University of Nis, Serbia)   Dragan Stojanovic (University of Nis, Serbia)  Abstract: Recent advancements in sensor technologies   resulted in the development of sensors with small dimensions and   with power consumption that is low enough to be embedded in various   mobile devices and which is widely integrated in vehicles. Such   sensors can be extensively used to detect real-time traffic events   and situations of user/vehicle in context-aware mobile   applications. This paper explores the usage of a large number of   anonymous mobile devices already involved in the road navigation   function as mobile sources of traffic information. Apart from   collecting location and speed data, which is extensively used today   to calculate average trip time per road segment, we are exploring   possibility of using an acceleration sensor integrated with a mobile   device in order to efficiently and timely detect critical traffic   events and redistribute this information to other drivers through   proactive traffic information system. Such a system would be capable   of warning drivers of 'near-accident' situations enhancing their   situational awareness and general safety.               Keywords: accelerometer data, extended floating car data, traffic information systems, vehicle tracking               Categories:  H.4.3, H.1.2, H.3.5  
18|9||Low Complexity H.264/AVC Intraframe Coding for Wireless Multimedia Sensor Network|  Xingang Liu (University of Electronic Science and Technology of China, China)   Jiantan Liu (Yeungnam University, South Korea)   Kook-Yeol Yoo (Yeungnam University, South Korea)   Haengrae Cho (Yeungnam University, South Korea)  Abstract: For the Wireless Multimedia Sensor Network (WMSN), the intraframe video coding is widely used for the robust transmission and computation complexity. Though the intraframe algorithm requires much smaller computational complexity than the interframe coding, the amount of computation of the intraframe should be reduced to use WMSN application. In this paper, we propose an intra mode decision algorithm to reduce the computation complexity of intraframe H.264/AVC encoders. The proposed algorithm determines the candidate modes and skips the remaining modes based on the smoothness and directional similarity of MB. The simulation results show that the proposed algorithm achieves 18% to 70% reduction in the computational complexity, compared with the various conventional methods.               Keywords: H.264/AVC, complexity, intraframe coding, wireless multimedia sensor               Categories: E.4, H.5.1, I.4.2, I.4.9, I.6.6  
18|9||Network Planning for WiMAX-R Networks|  Qiang Liu (Beijing Jiaotong University, China)   Min Chen (Seoul National University, Korea)   Jie Zhang (Beijing Jiaotong University, China)   Bingwen Shen (Beijing Jiaotong University, China)   Zhong Chu (Beijing Jiaotong University, China)  Abstract: In this paper, a novel network planning process   of the Mobile WiMAX for Railway (WiMAX-R) network is proposed. We   first analyze the factors need considered in network planning. After   introducing the WiMAX-R network architecture, the WiMAX-R network   planning process is presented in detail. The process comprises   application analysis, capacity prediction, network parameters   configuring, coverage planning, handover planning and network   simulation validation. In each step, Mobile WiMAX technical features   and railway environment characters are both take into   consideration. Finally, we simulated a WiMAX-R planning example   based on OPNET platform. The simulation results showed that the   designed WiMAX-R network can perfectly satisfy the applications   QoS requirements.               Keywords: IEEE 802.16e, mobile WiMAX, network planning, railway               Categories: C.2.1, C.2.5  
18|9||Security-enhanced Search Engine Design in Internet of Things|  Xiaojun Qian (Nanjing Normal University, China)   Xiaoping Che (Evry University, France)  Abstract: This paper elaborates the challenges in   searching imposed by the burgeoning fieldof Internet of Things   (IoT). Firstly it overviews the evolution of the new field to its   predecessors: searching in the mobile computing, ubiquitous   computing and information retrieve. Then,it identifies five research   thrusts: architecture design, search locality, real-time,   scalability and divulging information. It also sketches several   presumptive IoT scenarios, and uses them to iden-tify key   capabilities missing in today's systems. On top of these challenging   issues, we report our undertaking work -- a security-enhanced search   engine for Internet of Things based on El-liptic Curve Cryptography   (ECC) security protocol. We also report our preliminary experimental   results.               Keywords: Internet of Things, elliptic curve cryptography, mobile computing, security               Categories: H.3.1, H.3.3, J.6  
volume|issue|url|title|abstract
19|1|http://www.jucs.org/jucs_19_1|Managing Editor's Column|
19|1||From a Solution Model to a B Model for Verification of Safety Properties|  Philippe Bon (Université Lille Nord de France, France)   Simon Collart-Dutilleul (Université Lille Nord de France, France)  Abstract: In the context of safety requirement   engineering, model transformation is a task of interest. Indeed, it   allows us to keep all the requirements while switching from one   point of view to another. The presented work assumes that a valid   solution has been found and proposes an approach in order to build a   valid implementation. As some fine dynamic properties are integrated   into the specification, high-level Petri nets are used to specify   and verify the solution. Then, considering an industrial railway   context, the transformation of the Petri net model in order to   provide an input to a B process is   considered. This last consideration leads to a proposition of a   systematic direct transformation of the Petri net model into   abstract B machines. The approach is illustrated   by a theoretical railway example. The limitations of this approach   are discussed at the end of the paper and some prospects are   detailed.               Keywords: B formal method, Petri nets, modelling languages translation, railway transport, safety critical system               Categories: J.6, J.7  
19|1||Systematic Evaluation of Software Product Line Architectures|  Edson A. Oliveira Junior (State University of Maringa, Brazil)   Itana M. S. Gimenes (State University of Maringa, Brazil)   José C. Maldonado (University of Sãao Paulo, Brazil)   Paulo C. Masiero (University of Sãao Paulo, Brazil)   Leonor Barroca (The Open University, United Kingdom)  Abstract: The architecture of a software product line is   one of its most important artifacts as it represents an abstraction   of the products that can be generated. It is crucial to evaluate the   quality attributes of a product line architecture in order to:   increase the productivity of the product line process and the   quality of the products; provide a means to understand the potential   behavior of the products and, consequently, decrease their time to   market; and, improve the handling of the product line   variability. The evaluation of product line architecture can serve   as a basis to analyze the managerial and economical values of a   product line for software managers and architects. Most of the   current research on the evaluation of product line architecture does   not take into account metrics directly obtained from UML models and   their variabilities; the metrics used instead are difficult to be   applied in general and to be used for quantitative analysis. This   paper presents a Systematic Evaluation Method for UML-based Software   Product Line Architecture, the SystEM-PLA. SystEM-PLA differs from   current research as it provides stakeholders with a means to: (i)   estimate and analyze potential products; (ii) use predefined basic   UML-based metrics to compose quality attribute metrics; (iii)   perform feasibility and trade-off analysis of a product line   architecture with respect to its quality attributes; and, (iv) make   the evaluation of product line architecture more flexible. An   example using the SEI's Arcade Game Maker (AGM) product line is   presented as a proof of concept, illustrating SystEM-PLA   activities. Metrics for complexity and extensibility quality   attributes are defined and used to perform a trade-off   analysis.               Keywords: UML, metrics, product line architecture evaluation, quality attributes, tradeoff analysis, variability               Categories: D.2, D.2.11  
19|1||Deriving System Behavior from UML State Machine Diagram: Applied to Missile Project|  Hyun-Seok Min (Korea University, Korea)   Sang-Mun Chung (Agency for Defense Development, Korea)   Jin-Young Choi (Korea University, Korea)  Abstract: Traditionally, System Analysis and Software   Design are treated as separate processes. Software Design is based   on System Analysis but they have little direct relationship to each   other. UML (Unified Modeling Language) is widely accepted by   industry as the de facto standard for System Analysis and Software   Design. The primary tool for System Analysis is the Use Case Diagram   and its Scenarios, while the primary tools for Software Design are   the Class Diagram and Sequence Diagram. State Machine Diagram is   also very useful for behavioral modeling. Our aim is to derive   system behavior from software design, so that separate processes can   work together. This paper suggests how to make a system-wide State   Machine Diagram by gathering State Machine Diagrams in the system   using predefined Stereotypes and   Synchronization/Externalization. The resulting system-wide State   Machine Diagram can be used for various things, such as automatic   test case generation for the system, deadlock detection, and Use   Case scenario consistency checking. The proposed method is applied   to the Missile project of ADD (Agency for Defense Development) in   South Korea. The result is very promising. It is expected to be   applied to more projects.               Keywords: State Machine Diagram, UML, consistency, deadlock, system, test               Categories: D.2.4, D.2.5, F.3.1, F.3.2, I.6.4  
19|1||Model-Driven Framework for Design and Production of Low-Budget Stereoscopic TV Content|  Aleksandar Spasić (College of Professional Studies for Pre-School Teachers, Serbia)   Dragan Janković (University of Nis, Serbia)  Abstract: Three-dimensional television (3D TV) is expected   by many to be the next step in the advancement of television. Due to   significant financial exhaustion during the process of transition   from analogue to digital production, low-budget broadcasters are not   in the position to invest in a new 3D system. This paper proposes   one model-driven framework approach to 3D TV production system   applicable to and suitable for low-budget broadcasters. The target   of the project is to define one of the possible scenarios for   applying stereoscopic 3D technologies to low-budget TV   production. 3D TV content production chain is described in the first   step of the project. 3D TV production workflow is proposed in the   second step. This step has two parts: the analyses of the production   stages and their integral processes, and the definition of a problem   space model which is suitable for low-budget 3D TV production. The   preproduction, production and postproduction phases of a low-budget   3D TV production are described during the analyses of 3D TV content   production workflow. The UML is used as a modelling tool. The   behavioural description of a program production is modelled by the   Use Case diagram. A state machine diagram is used to describe the   dynamic behavioral representation and the life cycle of a 3D   content. The flow and dependencies in 3D workflow are modelled by   using the activity diagrams. The structural static representation   (domain model) is presented by a class diagram.               Keywords: 3D TV production, Computing Independent Model (CIM), Model of Problem Space (MOPS), Software Intensive System of 3D Television Production               Categories: D.2.1, D.2.9, H.1.0, H.4.0, K.6.1, K.6.4  
19|1||An Aspect-Oriented Approach for Spatial Concerns in Web Applications|"  Matias Urbieta (UNLP, Argentina)   Gustavo Rossi (UNLP, Argentina)   Silvia E. Gordillo (UNLP, Argentina)   Armanda Rodrigues (Universidade Nova de Lisboa, Portugal)   Joao Araujo (Universidade Nova de Lisboa, Portugal)   Ana Moreira (Universidade Nova de Lisboa, Portugal)  Abstract: The growing availability of on-line geographical   information, since the advent of open map servers in the 2000s,   originated a new generation of Web applications, those which combine   ""conventional"" Web functionality with typical features of   traditional Geographic Application System (GIS). The rapid growth in   number and complexity of Web applications with geo-referenced data   together with the need to support fast requirements change, demands   for increased modularity. The volatility of some of these changing   requirements, both in the scope of their geographic nature or in the   period of time in which they are valid, stresses the importance of   the applications"" modularity. A solution is to take into   consideration the crosscutting nature of these requirements and   decouple their realization from ""conventional"" requirements in   separate software modules.  This paper proposes an   end-to-end Aspect-Oriented approach to deal with spatial   requirements from the early stages of applications development   throughout to implementation. A significant contribution of this   approach is the characterization of the most common spatial   requirements in Web-GIS applications. The result is the improvement   of               Keywords: Web application, aspect-oriented software development, spatial concerns               Categories: D.2.1, D.2.10, D.2.13, D.2.2  "
19|1||Gyrolayout: A Hyperbolic Level-of-Detail Tree Layout|  Dana K. Urribarri (Universidad Nacional del Sur, Argentina)   Silvia M. Castro (Universidad Nacional del Sur, Argentina)   Sergio R. Martig (Universidad Nacional del Sur, Argentina)  Abstract: Many large datasets can be represented as   hierarchical structures,introducing not only the necessity of   specialized tree visualization techniques, but also the requirements   of handling large amounts of data and offering the user a useful   insightinto them. Many two-dimensional techniques have been   developed, but 3-dimensional ones, together with navigational   interactions, present a promising appropriate tool todeal with large   trees.  In this paper we present a hyperbolic tree   layout extended to support different level-of-detail techniques and   suitable for large tree representation and visualization. This   layout permits the visualization of large trees with different level   of detail in anenclosed 3-dimensional volume. As a significant part   of the layout, we also present a Weighted Spherical Centroidal   Voronoi Tessellation, an extension of planar Weighted Centroidal   Voronoi Tessellations, in order to find an appropriate distribution   of nodes on a spherical surface.               Keywords: Einstein gyrovector space, centroidal Voronoi tessellation, hyperbolic layout, level of detail, tree visualization               Categories: H.5.0, I.3.5, I.3.6  
19|1||A Catalog of Aspect Refactorings for Spring/AOP|  Santiago A. Vidal (UNICEN, Argentina)   Claudia Marcos (UNICEN, Argentina)  Abstract: The importance of enterprise applications in   current organizations makes it necessary to facilitate their   maintenance and evolution along their life. These kind of systems   are very complex and they have several requirements that   orthogonally crosscut the system structure (called crosscutting   concerns). Since many of the enterprise systems are developed with   the Spring framework, can be taken advantage of the benefit provided   by the aspect-oriented module of Spring in order to encapsulate the   crosscutting concerns into aspects. In this way, the maintenance and   evolution of the enterprise systems will be improved. However, most   of the aspect refactorings presented in the literature are not   directly applicable to Spring systems. Along this line, in this work   we present an adaptation of a catalog of aspect refactorings,   initially presented for AspectJ, to be used with Spring/AOP. Also,   we conduct a case study in which two enterprise applications   developed with the Spring framework are refactored in order to   encapsulate their crosscutting concerns into aspects.               Keywords: aspect-oriented programming, refactoring, separation of concerns               Categories: D.2.3, D.3.3  
19|10|http://www.jucs.org/jucs_19_10|Managing Editor's Column|
19|10||Key-Insulated Signcryption|  Jia Fan (Science and Technology on Communication Security Laboratory, China)   Yuliang Zheng (University of North Carolina at Charlotte, USA)   Xiaohu Tang (Southwest Jiaotong University, China)  Abstract: Signcryption is a public key cryptographic   technique that is particularly suited for mobile communications   thanks to its light computational and communication overhead. The   wide spread use of signcryption in a mobile computing environment,   however, is accompanied by an increased risk of private key   exposure. This paper addresses the issue of key exposure by   proposing a key-insulated signcryption technique. We define a   security model for key-insulated signcryption and prove that the   keyinsulated signcryption technique is provably secure in the   security model.               Keywords: key exposure, key insulation, signcryption               Categories: H.2, H.3.7, H.5.4  
19|10||Term Satisfiability Problem for Two-Element Algebras is in QL or is NQL-Complete|  Tomasz A. Gorazd (Jagiellonian University, Poland)   Jacek Krzaczkowski (Maria Curie-Sklodowska University, Poland)  Abstract: We show that the term satisfiability problem for   finite algebras is in NQL. Moreover we present a complete   classification of the computational complexity of the term   satisfiability problem for two-element algebras. We show that for   any fixed twoelement algebra the problem is either in QL or   NQL-complete.  We show that the complexity of the considered problem, parameterized by an algebra, is determined by the clone of term operations of the algebra.               Keywords: SAT, algebra, clones, computational complexity, solving equations               Categories: F.1.3, F.2.2  
19|10||An Algebraic Theory of Epistemic Processes|  Hamid Reza Mahrooghi (Sharif University of Technology, Iran)   Rasool Jalili (Sharif University of Technology, Iran)  Abstract: In the past few years, several process-algebraic   frameworks have been proposed that incorporate the notion of   epistemic knowledge. These frameworks allow for reasoning about   knowledge-related properties, such as anonymity, secrecy and   authentication, in the operational specifications given in   process-algebraic languages. Hitherto, no sound and   (ground-)complete axiomatization has been given for the   abovementioned process-algebraic frameworks. In this paper, we   define notions of bisimulation that are suitable for such process   algebras with histories and give a sound and ground-complete   axiomatization for the theory of CryptoPAi, which   is a process algebra based on Milner's Calculus of Communicating   Systems (CCS) extended with cryptographic terms and   identities. Moreover, we show that one of our defined notions of   bisimulation is precisely characterized by the extension of the   Hennessy-Milner logic with epistemic constructs.               Keywords: axiomatization, cryptography, epistemic logic, process algebra, security protocols               Categories: F.4, F.4.1, F.4.3  
19|10||Model-Driven Development of Aspect-Oriented Software Architectures|  Jennifer Pérez (Technical University of Madrid (UPM), Spain)   Isidro Ramos (Universidad Politecnica de Valencia, Spain)   Jose A. Carsí (Universidad Politecnica de Valencia, Spain)   Cristóbal Costa-Soria (Paterna Technological Science Park, Spain)  Abstract: The Model-Driven Development (MDD) paradigm has   become widely spread in the last few years due to being based on   models instead of source code, and using automatic generation   techniques to obtain the final software product. Until now, the most   mature methodologies that have been proposed to develop software   following MDD are mainly based on functional requirements by   following the Object-Oriented Paradigm. Therefore, mature MDD   methodologies are required for supporting the code generation from   models that specify non-functional requirements. The Aspect-Oriented   Software Development (AOSD) approach was created to provide explicit   mechanisms for developing non-functional requirements through   reusable elements called aspects. Aspect-Oriented Software   Architectures (AOSA) emerged to deal with the design of both,   functional requirements and non-functional requirements, which   opened an important challenge in the software engineering field: the   definition of a methodology for supporting the development of AOSAs   following the MDD paradigm. This new methodology should allow the   code generation from models which specify functional and   non-functional requirements. This paper presents a mature approach,   called PRISMA, which deals with this challenge. Therefore, this   contribution takes a step forward in the area presenting in detail   the PRISMA MDD process, which has been applied to generate the code   of several real applications of the tele-operated robotics   domain. PRISMA MDD approach provides complete support for the   development of technology-independent AOSAs, which can be compiled   from high-level, aspect-oriented architectural models into different   technology platforms and languages following an MDD process. This   contribution illustrates how to apply the PRISMA MDD approach   through the modelling framework that has been developed to support   it, and a case study of a tele-operated robot that has been   completely developed using this approach. Finally, the results   obtained from the application of PRISMA MDD process to develop   applications of the tele-operation domain are analyzed in terms of   code generation.               Keywords: aspect-oriented software architectures, aspect-oriented software development (AOSD), code generation, model-driven development (MDD), software architecture               Categories: D.2.10, D.2.11, D.2.13, D.2.2  
19|10||A Team Formation and Project-based Learning Support Service for Social Learning Networks|"  Howard Spoelstra (Open University of the Netherlands, The Netherlands)   Peter van Rosmalen (Open University of the Netherlands, The Netherlands)   Evert van de Vrie (Open University of the Netherlands, The Netherlands)   Matija Obreza (Open University of the Netherlands, The Netherlands)   Peter Sloep (Open University of the Netherlands, The Netherlands)  Abstract: The Internet affords new approaches to   learning. Geographically dispersed self-directed learners can learn   in computer-supported communities, forming social learning   networks. However, self-directed learners can suffer from a lack of   continuous motivation. And surprisingly, social learning networks do   not readily support effective, coherence-creating and motivating   learning settings. It is argued that providing project-based   learning opportunities and team formation services can help overcome   these shortcomings. A review of existing team formation tools   evidences that a new design for team formation and the initiation of   project-based learning is required before these can be supported in   social learning networks. A design is proposed which identifies   ""knowledge"", ""personality"" and ""preferences"" as categories in which   data is needed to form teams, and it specifies how the required data   are gathered and assessed. The design defines rules deduced from   team formation principles from prior team formation research to   optimise team formations towards increased productivity, creative   solutions or higher learning outcomes. The rules are implemented in   three team formation expressions each calculating one of the desired   team formations. The expressions are deployed on a set of test data,   demonstrating the effectiveness of the team formation service   design. The article includes a discussion of the results and   provides indications for future research.               Keywords: project team formation, project-based learning, self-directed learning, social learning networks, team formation expressions, team formation rules, team formation service               Categories: L.3.6, L.6.0, L.6.1, L.6.2  "
19|11|http://www.jucs.org/jucs_19_11|Outcomes of International Research Projects on Technology Applied to Education|
19|11||Teaching Innova Project: the Incorporation of Adaptable Outcomes in Order to Grade Training Adaptability|  Ángel Fidalgo (Universidad Politécnica de Madrid, Spain)   María Luisa Sein-Echaluce ((Universidad de Zaragoza, Spain)   Dolores Lerís ((Universidad de Zaragoza, Spain)   Oscar Castañeda (Universidad de La Guajira, Colombia)  Abstract: The education project presented in this paper   endeavors to study the feasibility of incorporating adaptive systems   into LMS systems, by using them both in training & learning process   and at work. This case study is aimed at employability and job post   improvement. For this purpose, we have created a process that is   flexible both to the student pattern (and to the job pattern. The   developed process is adaptable both to the student (via the   incorporation of an adaptable system with an LMS system) and to the   job model (via an adaptable system to the knowledge management). The   evaluation was qualitative and measured the process (feasibility to   apply adaptive systems) and the efficiency of the method   (applicability and employability). The functionality of the specific   developed tools allowed us to grade the degree of adaptability in   the training process, to dynamically vary the training plan from the   student's actions and to identify the resources that best met the   job needs.               Keywords: LMS, adaptable hypermedia system, knowledge management system, lifelong learning, personalized learning, repository               Categories: H.3.3, H.3.5, I.7.3, K.3, K.4.3, L.1.3, L.2.0, L.2.1, L.2.3, L.3.0, L.3.2, L.3.3, L.3.4, L.3.5, L.3.6, M.7  
19|11||Discovering Learner Styles in Adaptive e-Learning Hypermedia Systems|  Mahnane Lamia (University of Badji Moktar, Algeria)   Laskri Mohamed Tayeb (University of Badji Moktar, Algeria)  Abstract: A distinct feature of an adaptive e-learning   hypermedia system (AEHS) is the learner model it employs, that is, a   representation of information about an individual learner. Learner   modeling and adaptation are strongly correlated, in the sense that   the amount and nature of the information represented in the learner   model depend largely on the kind of adaptation effect that the   system has to deliver. In fact, we see a problem arising when   teachers assume similar learning styles, thinking styles, levels of   knowledge and abilities for learners. This is because learners that   are less able will feel that it is too difficult for them to follow   and those that are more capable will feel as though the learning   method is too easy. Teachers can adjust the standards; however,   there may be conflicts between learners with varied styles. Thinking   style, learning style, level of knowledge, preferences and ability   of learner are part of learners characteristics, which have   significant influence on the activity of learners in the learning   process. In this paper we have focused our attention on the learner   model, which allows for the discovery of preferences, needs and   interests of users that have access to an AEHS. In order to observe   the psychological and pedagogical characteristics of a learner, a   quantitative and qualitative research is conducted based on a   questionnaire. The thinking style of a learner is analyzed. Based on   the statistical results, we figure out the rules about pedagogical   activity decision-making. This study presents two subsequent   experiments. The first experiment explores the relationship of   thinking style and pedagogical activities to validate this specific   psychological construct in the context of an AEHS. The second   experiment reduces the questionnaire to 60 questions, using a   filtering principle keeping the validity of the original   questionnaire.               Keywords: E-learning, adaptation, learner model, pedagogical activities, thinking style               Categories: K.3, L.1.5, L.2.0, L.3.3  
19|11||Socio-semantic Integration of Educational Resources  - the Case of the mEducator Project|  Stefan Dietze (Leibniz University, Germany)   Eleni Kaldoudi (Democritus University of Thrace, Greece)   Nikolas Dovrolis (Democritus University of Thrace, Greece)   Daniela Giordano (University of Catania, Italy)   Concetto Spampinato (University of Catania, Italy)   Maurice Hendrix (Coventry University, United Kingdom)   Aristidis Protopsaltis (Coventry University, United Kingdom)   Davide Taibi (Italian National Research Council, Italy)   Hong Qing Yu (The Open University, United Kingdom)  Abstract: Research in technology-enhanced learning (TEL)   throughout the last decade has largely focused on sharing and   reusing educational resources and data. This effort has led to a   fragmented landscape of competing metadata schemas, such as IEEE LOM   or ADL SCORM, and interface mechanisms, such as OAI-PMH, SQI and   REST-ful services in general. More recently, semantic technologies   were taken into account to improve interoperability. However, so far   Web-scale integration of resources is not facilitated, mainly due to   the lack of take-up of shared principles, datasets and schemas. On   the other hand, the Linked Data approach has emerged as the de facto   standard for sharing data on the Web and is fundamentally based on   established W3C standards. This paper presents results of the   European Commission-funded project mEducator, which exploits Linked   Data principles for (1) semantic integration and (2) social   interconnecting of educational data, resources and actors. We   describe a general approach to exploit the wealth of already   existing educational data on the Web by allowing its exposure as   Linked Data and by taking into account automated enrichment and   interlinking techniques to provide a rich and well-interlinked graph   for the educational domain. Additionally, the paper presents an   evaluation of our work with respect to a set of socio-semantic   dimensions. Experimental results demonstrate improved   interoperability and retrievability of the resulting resource   descriptions as part of an interlinked resource graph.               Keywords: SOA, clustering, linked data, semantic web, technology-enhanced learning               Categories: H.3, H.4, H.5, M.1, M.4, M.7, M.8, M.9  
19|11||Proof Assistant Based on Didactic Considerations|  Jorge Pais (Universidad ORT Uruguay, Uruguay)   Alvaro Tasistro (Universidad ORT Uruguay, Uruguay)  Abstract: We consider some issues concerning the role of   Formal Logic in Software Engineering education, which lead us to   promote the learning of formal proof through extensive,   appropriately guided practice. To this end, we propose to adopt   Natural Deduction as proof system and to make use of an adequate   proof assistant to carry out formal proof on machine. We discuss   some necessary characteristics of such proof assistant and   subsequently present the design and implementation of our own   version of it. This incorporates several novel features, such as the   display and edition of derivations as trees, the use of   meta-theorems (derived rules) as lemmas, and the possibility of   maintaining a set of draft trees that can be inserted into the main   derivation as needed. The assistant checks the validity of each   edition operation as performed. So far, it has been implemented for   propositional logic and (quite satisfactorily) put into practice in   courses of Logic for Software Engineering and Information Systems   programs.               Keywords: educational software, formal proof, teaching logic               Categories: L.3.0, L.3.1, L.3.6, L.3.8  
19|11||One Computer per Student City - Total UCA An All Inclusive Totality under Discussion|  Lucila Maria Costi Santarosa (Universidade Federal do Rio Grande do Sul, Brasil)   Débora Conforto (Universidade Federal do Rio Grande do Sul, Brasil)   Fernanda Chagas Schneider (Universidade Federal do Rio Grande do Sul, Brasil)  Abstract: This paper discusses the National Policy of the   Inclusive Education and the distribution of Laptops - PROUCA. Both   operate under the logic of inclusion in the context of education,   the first aiming at school inclusion and the other at digital   inclusion. In order to observe how the inclusive process of people   with disabilities mediated by laptops occurs, a qualitative   descriptive research was performed, focusing on the TOTAL UCA   reality in Tiradentes, Minas Gerais. The results of the research   project showed that the distribution of laptops, labeling the   offered tool under the concept of technological homogeneity and   uniformity, imposes barriers to the care for diversity in a   socio-digital inclusion scenario.               Keywords: PROUCA, accessibility, socio-digital inclusion               Categories: L.3.1, L.3.6, L.3.8  
19|11||Language Learning in Educational Virtual Worlds  - a TAM Based Assessment|  Carlos-Miguel Lorenzo (University of Alcalá Madrid, Spain)   Leonardo Lezcano (University of Alcalá Madrid, Spain)   Salvador Sánchez-Alonso (University of Alcalá Madrid, Spain)  Abstract: We are currently experiencing a boom in the   presence of Spanish language in the world, which is reflected in its   inclusion as a second language in the educational system of   countries like Brazil and the emergence of language in the U.S. and   China. To confront this situation there is a wide variety of courses   for learning Spanish. However, specific initiatives combining proven   teaching methods in university classroom experiences with the   creation of new multidisciplinary content displayed on 3D virtual   sets have not been detected. This study proposes the establishment   of a learner's role-play to improve learner's skills. Foreign   languages' learning is the focus of the report because can serve as   an appropriate context to analyze self-directed learning strategies   and the culture of Lifelong Learning. The goal of this research is   the creation of an integrated Massively Multiuser Online Learning   (MMOL) platform that enables the creation, development and   deployment of contents and activities for teaching Spanish in an ad   hoc educational virtual world named SLRoute. Such environment   promotes an immersive, creative and collaborative experience in the   process of learning a foreign language. In order to assess the   validity and reliability of this technology we used the Technology   Acceptance Model (TAM). The ultimate intention is to measure the   acceptability of MMOL platforms for educational issues.               Keywords: 3D learning, AIML, Artificial Intelligence, Chatbot, MMOG, MMOL platform, MOO, Non Player Character, educational virtual world, immersive context, learning objects               Categories: L.3.0, L.3.6, L.5.0, L.5.1, L.6.1  
19|11||A Dual-Modal System that Evaluates User's Emotions in Virtual Learning Environments and Responds Affectively|  Michalis Feidakis (University of Aegean, Greece)   Thanasis Daradoumis (University of Aegean, Greece)   Santi Caballe (Open University of Catalonia, Spain)   Jordi Conesa (Open University of Catalonia, Spain)   David Gañán (Open University of Catalonia, Spain)  Abstract: Endowing learning systems with emotion awareness   features (capture user's affective state and provide affective   feedback), seems quite promising. This paper describes a system   implementation that provides emotion awareness, both explicitly, by   self-reporting of emotions through a usable web tool, and   implicitly, via sentiment analysis. Prominent theories, models and   techniques of emotion, emotion learning, emotion detection and   affective feedback are reviewed. We also present findings from our   experiment with university students, validating the explicit   mechanism in real education settings. Finally, we set open issues   for future experimentation, contributing to the research   agenda.               Keywords: Affect, CSCL, affective Computing, collaborative Learning, detection, emotion, emotion Awareness, feedback, mood, opinion Mining, recognition, reporting, Measurement, sentiment Analysis               Categories: K.3.1, L.1.3, L.1.4, L.2.0, L.3.0, L.3.1, L.3.5, L.3.6, L.6.2  
19|11||TRAILER Project (Tagging, Recognition, Acknowledgment of Informal Learning Experiences) A Methodology to Make Learners' Informal Learning Activities Visible to the Institutions|  Francisco J. García-Peñalvo (University of Salamanca, Spain)   Miguel Á. Conde (University of Salamanca, Spain)   Valentina Zangrando (University of Salamanca, Spain)   Alicia García-Holgado (University of Salamanca, Spain)   Anton M. Seoane (University of Salamanca, Spain)   Marc Alier (UPC - BarcelonaTech, Spain)   Nikolas Galanis (UPC - BarcelonaTech, Spain)   Francis Brouns (Open Universiteit Netherlands, The Netherlands)   Hubert Vogten (Open Universiteit Netherlands, The Netherlands)   David Griffiths (Institute of Educational Cybernetics, United Kingdom)   Aleksandra Mykowska (Dom Szkolen i Doradztwa Mykowska Aleksandra, Poland)   Gustavo Ribeiro-Alves (Instituto Superior de Engenharia do Porto, Portugal)   Miroslav Minović (University of Belgrade, Serbia)  Abstract: The application of information technologies   (specially the Internet, Web 2.0 and social tools) make informal   learning more visible. This kind of learning is not linked to an   institution or a period of time, but it is important enough to be   taken into account. On the one hand, learners should be able to   communicate to the institutions they are related to, what skills   they possess, whether they were achieved in a formal or informal   way. On the other hand the companies and educational institutions   need to have a deeper knowledge about the competencies of their   staff. The TRAILER project provides a methodology supported by a   technological framework to facilitate communication about informal   learning between businesses, employees and learners. The paper   presents the project and some of the work carried out, an   exploratory analysis about how informal learning is considered and   the technological framework proposed. Whilst challenges remain in   terms of establishing the meaningfulness of technological engagement   for employees and businesses, the continuing transformation of the   social, technological and educational environment is likely to lead   to greater emphasis for the effective exploitation of informal   learning.               Keywords: decision making, informal learning, personal learning network, service-based framework               Categories: L.2.0, L.2.1, L.2.2, L.2.3, L.3.0, L.3.6, M.0  
19|11||Support Platform for Learning about Multimodal Biometrics|"  Uroš Šošević (University of Belgrade, Serbia)   Ivan Milenković (University of Belgrade, Serbia)   Miloš Milovanović (University of Belgrade, Serbia)   Miroslav Minović (University of Belgrade, Serbia)  Abstract: Lately, there is an increasing interest in   multimodal biometric systems. Faculty of organizational sciences and   Ministry of Education and Science of Serbia have recognized   importance of biometrics, and started an international project named   ""Multimodal biometry in identity management"". As a part of our   project, we have developed a support platform for learning about   multimodal biometrics. Platform is used as part of biometric course   in order to improve student's learning experience and to increase   their interest in biometrics. A research study was conducted to   compare traditional learning method and learning method based on our   support platform. Results of our research study speak in favour of   using elBio support platform as a teaching tool.               Keywords: biometrics, learning tool, support platform               Categories: K.3, L.2, L.3.6  "
19|12|http://www.jucs.org/jucs_19_12|Managing Editor's Column|
19|12||Applying Professional Solutions within the Educational Environments by Means of Cloud Computing: Coaching for Teachers|"  Habib M. Fardoun (King Abdulaziz University (KAU), Saudi Arabia)   Abdulfattah Mashat (King Abdulaziz University (KAU), Saudi Arabia)   Sebastián Romero López (University of Castilla-La Mancha (UCLM), Spain)  Abstract: In a world where the most used sentences is: ""I   haven't got the time..."" Information Technologies (IT) plays an   important role in supporting our daily work, including in everyday   educational settings. Such technologies can aid a complete   educational system to function successfully so to help the whole   school educational life. For this to prove, we present the ""Coaching   for Teacher"" system, a personal technological conversational coach;   it aims to provide solutions to overcome difficulties that teachers   face during their teaching and learning process. In real time, a   teacher can appeal and seek advice rapidly by comfortably talking to   an agent. In this paper, we present the steps we followed to design   and develop this agent-based application, and a case study conducted   in an educational centre for proof that the concept works in an   authentic educational environment.               Keywords: cloud computing, coaching, education, educational environments, information and communication technologies, learning/teaching process, social networks               Categories: D.2.10, D.2.2, D.4.6, D.4.7, H.3.4, H.4.3, H.5.2, K.3.1, K.4.3, L.2.0, L.2.1, L.2.2, L.2.3, L.3.0, L.3.6  "
19|12||An Investigation into the Relationship Between Perceived Quality-of-Experience and Virtual Acoustic Environments: the Case of 3D Audio Telephony|"  Khalil ur Rehman Laghari (Institut National de la Recherche Scientifique (EMT-INRS), Canada)   Tiago H. Falk (Institut National de la Recherche Scientifique (EMT-INRS), Canada)   Mansoor Hyder (Sindh Agriculture University, Pakistan)   Michael Haun (Eberhard Karls Universität Tübingen, Germany)   Christian Hoene (Eberhard Karls Universität Tübingen, Germany)   Noel Crespi (Institut Telecom SudParis, France)  Abstract: Quality of Experience (QoE) is a human centric   quality evaluation method which provides the blue print of human   needs, perceptions, feelings and experiences with respect to a   multimedia service. In a communications ecosystem, human interaction   takes place alongside technological, contextual, and business   domains, thus producing a holistic view on QoE formation. In this   paper, we investigate the relationship between human perceived QoE   and ""context"" for burgeoning 3-dimensional (3D) audio   teleconferencing services. 3D audio teleconferencing applications   are customizable by generating different virtual acoustic   environments (VAE), where parameters such as virtual room size and   competing talker conditions can be adjusted for a particular   application. The impact of different VAE characteristics on   perceived QoE, however, is still unknown. In this study, four QoE   factors were investigated across different VAE scenarios. It was   found that a) medium-size virtual rooms produce optimal perceived   QoE, b) competing talkers of mixed gender could be easily located in   the virtual space, and c) competing speaker gender had no   significant effect on perceived audio quality.               Keywords: 3D Audio, communication ecosystem, quality of experience, teleconferencing, virtual acoustic environment               Categories: H.1, H.5, H.5.4, L.2.7  "
19|12||The Analysis of the Users' Response to the Linear Internet Video Advertising by Using QoE Methods|  Miloš Ljubojević (Academic and Research Network of Republic of Srpska, Bosnia and Herzegovina)   Vojkan Vasković (University of Belgrade, Republic of Serbia)   Dušan Starčević (University of Belgrade, Republic of Serbia)  Abstract: Internet video advertising is a sensitive   application regarding the quality of the multimedia content,   efficiency of displayed advertisement and user's   attention. Therefore, video advertising have to be described with   respect to Quality of Experience (QoE). Important issue represents   trade-off between the Quality of Experience and ad efficiency. The   analysis of payment which takes into account the duration of video   ad is one of the aspects in this research. This paper analyzes   influences of the format of the video ad to user's attention in   order to achieve optimum ratio between the efficiency of the ad and   QoE.  We investigated impact of the position of the video ad in   video content, ad duration and transition effects in merging video   contents to the user's attention and ad efficiency. The model for   estimation of QoE, taking into account improvement efficiency of   video ad, was presented and metrics which are necessary for the   evaluation of the QoE are introduced. The results show that it is   possible to design video ad to achieve optimal ratio between the   efficiency of ad and QoE. The improvement of the efficiency of an ad   may be achieved while retaining the maximum QoE at the same time.               Keywords: content adaptation, nternet video advertisement modelling, quality of experience, subjective quality assessment, user's attention               Categories: H.3.5, H.5.1, H.5.2, M.6  
19|12||Towards Self-Service Government - A Study on the Computability of Legal Eligibilities|  Alois Paulin (Vienna University of Technology, Austria)  Abstract: In this paper we present a novel model for   governing societies based on modern information technology, which   neither relies on manual bureaucratic labour, nor depends on   process-based e-government services. We analyse the flaws of the   latter and argue that e-government is not feasible for sustainable   governance due to permanently changing regulation; instead we   propose a model in which people can govern themselves in a   self-service manner by relying on constellations of data stored in a   network of governmental databases to which citizens and government   agents have read- and write access under conditions defined by   then-valid regulation.               Keywords: e-government, relational algebra, self-service government               Categories: H.1, H.m, J.1  
19|12||A Framework to Develop Web Applications Based on RFID Panels|  Pedro G. Villanueva (University of Castilla-La Mancha, Spain)   Ricardo Tesoriero (University of Castilla-La Mancha, Spain)   José A. Gallud (University of Castilla-La Mancha, Spain)   Abdulrahman H. Altalhi (King Abdulaziz University (KAU), Saudi Arabia)  Abstract: The pervasiveness of the Web, and the emergence   of new technologies such as the RFID, allow users to interact with   the physical environment. This fact has caused the conception of new   types of applications, for instance, the Web applications based on   RFID panels that allow users to retrieve and store resources from   and to the Web through RFID panels. The development of these   applications is defined by three main concepts: the Tool that   performs domain model functionality, the Command that represents an   action to be performed by the tool, and finally, the Resource   representing the result of the command on the tool.  Thus, this work   presents a framework that enables developers to model Web   applications based on RFID panels in terms of these concepts. The   paper also exposes how to extend the framework to build four   applications that belong to absolutely different domains.               Keywords: Human-Computer Interaction (HCI), RFID, Web applications, framework development, models development               Categories: D.2.11, H.1.2, I.2.5  
19|12||A Method for Collaborative Argumentation in Merging Individual Ontologies|  Josiane Michalak Hauagge Dall Agnol (Paraná Federal University of Technology (UTFPR), Brazil)   Cesar Augusto Tacla (Paraná Federal University of Technology (UTFPR), Brazil)  Abstract: This paper proposes a framework of the   negotiation process for solving divergences in the collaborative   ontology development. Such framework is obtained through the use of   philosophical principles deriving from the theories of essence,   identity, unity and dependence (preconized by the OntoClean   methodology) as to justify part of the argumentation used in the   negotiation process among the participants, besides helping reach a   consensus and reduce the conceptual gap among models. The evaluation   of the experiments conducted with the use of the proposed method   suggests the feasibility and implementability of our approach in   practice.               Keywords: OntoClean, argumentation, collaborative ontology development, conceptual gap, negotiation process               Categories: M.0, M.4, M.9  
19|12||Initializing Matrix Factorization Methods on Implicit Feedback Databases|  Balazs Hidasi (Gravity R&D, Hungary)   Domonkos Tikk (Gravity R&D, Hungary)  Abstract: The implicit feedback based recommendation   problem--when only the user history is available but there are no   ratings--is a much harder task than the explicit feedback based   recommendation problem, due to the inherent uncertainty of the   interpretation of such user feedbacks. Recently, implicit feedback   problem is being received more attention, as application oriented   research gets more attractive within the field. This paper focuses   on a common matrix factorization method for the implicit problem and   investigates if recommendation performance can be improved by   appropriate initialization of the feature vectors before   training. We present a general initialization framework that   preserves the similarity between entities (users/items) when   creating the initial feature vectors, where similarity is defined   using e.g. context or metadata information. We demonstrate how the   proposed initialization framework can be coupled with MF   algorithms. We experiment with various similarity functions,   different context and metadata based similarity concepts. The   evaluation is performed on two implicit variants of the MovieLens   10M dataset and four real life implicit databases. We show that the   initialization significantly improves the performance of the MF   algorithms by most ranking measures.               Keywords: contextual information, implicit feedback, initialization, recommender systems, similarity               Categories: I.2.6  
19|12||Promoting International Interoperability of Research Information Systems: VIVO and CERIF|  Leonardo Lezcano (University of Alcalá, Spain)   Brigitte Jörg (University of Bath, United Kingdom)   Brian Lowe (Cornell University, USA)   Jon Corson-Rikert (Cornell University, USA)  Abstract: Institutional repositories (IR) and Current   Research Information Systems (CRIS) store and manage information on   the context in which research activity takes place. Several models,   standards and ontologies have been proposed to date as solutions to   provide coherent semantic descriptions of research   information. These present a large degree of overlap but also   present very different approaches to modelling. This paper   introduces a contrast of two of the more widespread models, the VIVO   ontology and the CERIF standards, and provides guidance for mapping   them in a way that enables clients to integrate data coming from   heterogeneous sources. The majority of mapping challenges have risen   from the representation of VIVO sub-hierarchies in CERIF as well as   from the representation of CERIF attributes in VIVO. In addition,   the paper illustrates features for linking data across the Web, for   querying of geographically distributed data stores and for   aggregating data described using different data models in a common   store. These features are supported by semantic web technologies   including RDF, OWL and SWRL.               Keywords: CERIF, CRIS, OWL, SPARQL, VIVO, knowledge representation, linked data, mapping, ontologies, research information, scientific information, semantic interoperability               Categories: H.1.0, H.2.5, H.4.2  
19|13|http://www.jucs.org/jucs_19_13|Industrial and Business Applications of Semantic Web Technologies|
19|13||Web Resource Sense Disambiguation in Web of Data|  Farzam Matinfar (University of Isfahan, Iran)   Mohammadali Nematbakhsh (University of Isfahan, Iran)   Georg Lausen (Albert-Ludwigs-Universität, Germany)  Abstract: This paper introduces the use of WordNet as a   resource for RDF web resources sense disambiguation in Web of Data   and shows the role of designed system in interlinking datasets in   Web of Data and word sense disambiguation scope. We specify the core   labelling properties in semantic web to identify the name of   entities which are described in web resources and use them to   identify the candidate senses for a web resource. Moreover, we   define the web resource's context to identify the most   appropriate sense for each of the input web resources. Evaluation of   the system shows the high coverage of the core labelling properties   and the high performance of the sense disambiguation algorithm.               Keywords: interlinking, linked data, semantic web, word sense disambiguation               Categories: H.3.1, H.3.3, M.7  
19|13||Business Process Management Applications based on Semantic Process Models: the ProcessGene Suite Case-Study|  Avi Wasser (University of Haifa, Israel)   Maya Lincoln (University of Haifa, Israel)  Abstract: In recent years, Business Process Management (BPM) applications have become central enablers for the generation, customization and utilization of business processes within and between organizations. One of the central techniques for extending the span of BPM applications is Natural Language Processing (NLP). This work aggregates and reviews previous works on NLP standardization for BPM. Based on these works, we present a set of BPM applications, aiming at extending the utilization of the knowledge embedded in business process repositories. To verify the industrial deployment, we then present an extended case study that examines the feasibility of the suggested applications in real life scenarios using the ProcessGene BPM suite.               Keywords: BPM applications, business process model standardization, business process repositories, natural language processing               Categories: H.4  
19|13||A Semantic based Platform for Research and Development Projects Management in the ICT Domain|  Carlos García-Moreno (Indra Software Labs, Spain)   Yolanda Hernández-González (Indra Software Labs, Spain)   Miguel Ángel Rodríguez-García (Universidad de Murcia, Spain)   José Antonio Miñarro-Giménez (Universidad de Murcia, Spain)   Rafael Valencia-García (Universidad de Murcia, Spain)   Angela Almela (Universidad Catolica San Antonio de Murcia, Spain)  Abstract: Innovation is one of the keys to success in business and industry world, especially within the current economic context. R&D projects are a building-block in the innovation process, hence the importance of managing them efficiently. Ontologies and semantic technologies have proven highly effective at this task. Within this context, the present study explores the use of ontologies to model R&D related data and the application of semantic technologies to the building of an enhanced management system. Findings confirm the success of the system proposed, and reveal that it may bring considerable benefits to project management, such as the definition of a completely explicit information model and improved management capabilities.               Keywords: knowledge management, ontology, research and development, semantic annotation, semantic web               Categories: M.0, M.3, M.4, M.7, M.8  
19|13||A Tool-based Semantic Framework for Security Requirements Specification|  Olawande Daramola (Covenant University, Nigeria)   Guttorm Sindre (Norwegian University of Science and Technology (NTNU), Norway)   Thomas Moser (Vienna University of Technology, Austria)  Abstract: Attaining high quality in security requirements   specification requires first-rate professional expertise, which is   scarce. In fact, most organisations do not include core security   experts in their software team. This scenario motivates the need for   adequate tool support for security requirements specification so   that the human requirements analyst can be assisted to specify   security requirements of acceptable quality with minimum   effort. This paper presents a tool-based semantic framework that   uses ontology and requirements boilerplates to facilitate the   formulation and specification of security requirements. A two-phased   evaluation of the semantic framework suggests that it is usable,   leads to reduction of effort, aids the quick discovery of hidden   security threats, and improves the quality of security requirements.               Keywords: information extraction, misuse cases, ontology, requirements boilerplates, security requirements, security threat               Categories: D.2.1, M.4, M.8  
19|13||Ontology Combined Structural and Operational Semantics for Resource-Oriented Service Composition|  Cheng Xie (Shanghai Jiao Tong University, China)   Hongming Cai (Shanghai Jiao Tong University, China)   Lihong Jiang (Shanghai Jiao Tong University, China)  Abstract: Resource-oriented Services recently become an   enabling technology to integrate and configure information from   different heterogeneous systems so as to meet ever-changing   environment which not only need the concepts for entities but also   require the semantics for operations. By the aim of combining   structural and operational semantics agilely, a Semantic Resource   Service Model (SRSM) is proposed. Firstly, SRSM describes   Entity-Oriented and Transition-Oriented Resource by semantic   meta-model which contains data structures and operation   semantics. Secondly, by describing structural semantics for   Entity-Oriented Resource, heterogonous inputs/outputs of a service   can be automatically matched. Thirdly, by describing operational   semantics for Transition-Oriented Resource, the service composition   sequence can be inferred after ontology reasoning. Then, both   Entity-Oriented and Transition-Oriented Resources are encapsulated   into composited RESTful service. At last, a case study and several   comparisons are applied in a prototype system. The result shows that   the proposed approach provides a flexible way for resource-oriented   service composition.               Keywords: RESTful service, entity-oriented resource, ontology, operational semantic, resource-oriented architecture, structural semantic, transition-oriented resource               Categories: D.2.11, H.1.1, H.4.0  
19|13||Semantic Integration of Heterogeneous Data Sources in the MOMIS Data Transformation System|  Maurizio Vincini (University of Modena and Reggio Emilia, Italy)   Domenico Beneventano (University of Modena and Reggio Emilia, Italy)   Sonia Bergamaschi (University of Modena and Reggio Emilia, Italy)  Abstract: In the last twenty years, many data integration   systems following a classical wrapper/mediator architecture and   providing a Global Virtual Schema (a.k.a. Global Virtual View - GVV)   have been proposed by the research community. The main issues faced   by these approaches range from system-level heterogeneities, to   structural syntax level heterogeneities at the semantic   level. Despite the research effort, all the approaches proposed   require a lot of user intervention for customizing and managing the   data integration and reconciliation tasks.  In some cases, the   effort and the complexity of the task is huge, since it requires the   development of specific programming codes. Unfortunately, due to the   specificity to be addressed, application codes and solutions are not   frequently reusable in other domains.  For this reason, the Lowell   Report 2005 has provided the guideline for the definition of a   public benchmark for information integration problem. The proposal,   called THALIA (Test Harness for the Assessment of Legacy information   Integration Approaches), focuses on how the data integration systems   manage syntactic and semantic heterogeneities, which definitely are   the greatest technical challenges in the field. We developed a Data   Transformation System (DTS) that supports data transformation   functions and produces query translation in order to push down to   the sources the execution. Our DTS is based on MOMIS, a   mediator-based data integration system that our research group is   developing and supporting since 1999. In this paper, we show how the   DTS is able to solve all the twelve queries of the THALIA benchmark   by using a simple combination of declarative translation functions   already available in the standard SQL language. We think that this   is a remarkable result, mainly for two reasons: firstly to the best   of our knowledge there is no system that has provided a complete   answer to the benchmark, secondly, our queries does not require any   overhead of new code.               Keywords: XML, ontology matching, semantic annotations, semantic integration, semantic web               Categories: H.3.1, H.3.2, H.3.3, H.3.7, H.5.1  
19|13||An Item based Geo-Recommender System Inspired by Artificial Immune Algorithms|  Antonio Cabanas-Abascal (University Carlos III Madrid, Spain)   Eduardo García-Machicado (University Carlos III Madrid, Spain)   Lisardo Prieto-González (University Carlos III Madrid, Spain)   Antonio de Amescua Seco (University Carlos III Madrid, Spain)  Abstract: Nowadays, one of the most relevant features   provided by in almost every web site is a recommender   system. However, they are usually focused on the common   characteristics of several items which are shared among the users   without taking into account that there are other very important   features, such as geo-position. To face this lack of such relevant   factors, authors propose the usage of a useful system that will aid   in tasks related to pattern detection and fast adaptability to   changes: Artificial Immune System. A combination of both systems and   the addition of a geographic component will provide a new solution   to this problem, which will solve as well these issues as other ones   like comparison tasks in big data.               Keywords: artificial immune systems, big data, geo-localization, item, recommender systems               Categories: H.1.1, H.1.2, H.3.1, H.3.2, H.3.3, H.3.5  
19|14|http://www.jucs.org/jucs_19_14|Cloud Education Environment|
19|14||Using Cloud Services to Develop Learning Scenarios from a Software Engineering Perspective|"  Marc Jansen ((Ruhr-West University of Applied Sciences, Germany)   Lars Bollen (University of Twente, The Netherlands)   Nelson Baloian (Universidad de Chile, Chile)   H. Ulrich Hoppe (University of Duisburg-Essen, Germany)  Abstract: The term ""Cloud Computing"" does not primarily   specify new types of core technologies but rather addresses features   to do with integration, inter-operability and   accessibility. Although not new, virtualization and automation are   core features that characterize Cloud Computing. In this paper, we   intend to explore the possibility of integrating cloud services with   educational scenarios without re-defining neither the technology nor   the usage scenarios from scratch. Our suggestion is based on certain   solutions that have already been implemented and tested for specific   cases.               Keywords: cloud computing, cloud services, learning scenarios               Categories: C.2.4, K.3.1  "
19|14||Cloud Services, Interoperability and Analytics within a ROLE-enabled Personal Learning Environment|  Rocael Hernandez Rizzardini (Galileo University, Guatemala)   Byron H. Linares (Galileo University, Guatemala)   Alexander Mikroyannidis (The Open University Milton Keynes, United Kingdom)   Hans-Christian Schmitz (Institut für Deutsche Sprache, Germany)  Abstract: The ROLE project (Responsive Open Learning   Environments, EU 7th Framework Programme, grant agreement no.:   231396, 2009-2013) was focused on the next generation of Personal   Learning Environments (PLEs). A ROLE PLE is a bundle of   interoperating widgets - often realised as cloud services - used for   teaching and learning. In this paper, we first describe the creation   of new ROLE widgets and widget bundles at Galileo University,   Guatemala, within a cloud-based infrastructure. We introduce an   initial architecture for cloud interoperability services including   the means for collecting interaction data as needed for learning   analytics. Furthermore, we describe the newly implemented widgets,   namely a social networking tool, a mind-mapping tool and an online   document editor, as well as the modification of existing   widgets. The newly created and modified widgets have been combined   in two different bundles that have been evaluated in two web-based   courses at Galileo University, with participants from three   different Latin-American countries. We measured emotional aspects,   motivation, usability and attitudes towards the environment. The   results demonstrated the readiness of cloud-based education   solutions, and how ROLE can bring together such an environment from   a PLE perspective.               Keywords: cloud education environments, cloud learning activities, cloud-based tools, personal learning environment, responsive open learning environments, widget bundles               Categories: L.2.2, L.2.3, L.3.0, L.3.5, L.3.6  
19|14||A Generic Architecture for Emotion-based Recommender Systems in Cloud Learning Environments|  Derick Leony (Universidad Carlos III de Madrid, Spain)   Hugo A. Parada Gélvez (Universidad Carlos III de Madrid, Spain)   Pedro J. Muñoz-Merino (Universidad Carlos III de Madrid, Spain)   Abelardo Pardo (The University of Sydney, Australia)   Carlos Delgado Kloos (Universidad Carlos III de Madrid, Spain)  Abstract: Cloud technology has provided a set of tools to   learners and tutors to create a virtual personal learning   environment. As these tools only support basic tasks, users of   learning environments are looking for specialized tools to exploit   the uncountable learning elements available on the internet. Thus,   one of the most common functionalities in cloud-based learning   environments is the recommendation of learning elements and several   approaches have been proposed to deploy recommender systems into an   educational environment. Currently, there is an increasing interest   in including affective information into the process to generate the   recommendations for the learner; and services offering this   functionality on cloud environments are scarce. Hence in this paper,   we propose a generic cloud-based architecture for a system that   recommends learning elements according to the affective state of the   learner. Furthermore, we provide the description of some use cases   along with the details of the implementation of one of them. We also   provide a discussion on the advantages and disadvantages of the   proposal.               Keywords: affective computing, cloud learning environments, recommender systems, software architecture               Categories: D.2.11, H.3.3, L.3.2  
19|14||weSPOT: A Personal and Social Approach to Inquiry-Based Learning|  Alexander Mikroyannidis (The Open University, United Kingdom)   Alexandra Okada (The Open University, United Kingdom)   Peter Scott (The Open University, United Kingdom)   Ellen Rusman (Open Universiteit, The Netherlands)   Marcus Specht (Open Universiteit, The Netherlands)   Krassen Stefanov (Sofia University, Bulgaria)   Pavel Boytchev (Sofia University, Bulgaria)   Aristidis Protopsaltis (Friedrich-Alexander-Universität, Germany)   Paul Held (Friedrich-Alexander-Universität, Germany)   Sonia Hetzner (Friedrich-Alexander-Universität, Germany)   Kathy Kikis-Papadakis (Foundation for Research and Technology-Hellas, Greece)   Foteini Chaimala (Foundation for Research and Technology-Hellas, Greece)  Abstract: weweSPOT is a new European initiative proposing   a novel approach for personal and social inquiry-based learning in   secondary and higher education. weSPOT aims at enabling students to   create their mash-ups out of cloud-based tools and services in order   to perform scientific investigations. Students will also be able to   share their inquiry accomplishments in social networks and receive   feedback from the learning environment and their peers. This paper   presents the research framework of the weSPOT project, as well as   the initial inquiry-based learning scenarios that will be piloted by   the project in real-life educational settings.SPOT is a new European   initiative proposing a novel approach for personal and social   inquiry-based learning in secondary and higher education. weSPOT   aims at enabling students to create their mash-ups out of   cloud-based tools and services in order to perform scientific   investigations. Students will also be able to share their inquiry   accomplishments in social networks and receive feedback from the   learning environment and their peers. This paper presents the   research framework of the weSPOT project, as well as the initial   inquiry-based learning scenarios that will be piloted by the project   in real-life educational settings.               Keywords: cloud learning environment, inquiry-based learning, personal learning environment, scientific inquiry, social learning               Categories: L.2.2, L.3.0, L.3.4, L.3.6, L.6.2  
19|14||Laboratories as a Service (LaaS): Using Cloud Technologies in the Field of Education|  Rafael Pastor (National Spanish Distance University of Spain, Spain)   Agustín Carlos Caminero (National Spanish Distance University of Spain, Spain)   Daniel Sánchez (National Spanish Distance University of Spain, Spain)   Roberto Hernández (National Spanish Distance University of Spain, Spain)   Salvador Ros (National Spanish Distance University of Spain, Spain)   Antonio Robles-Gómez (National Spanish Distance University of Spain, Spain)   Llanos Tobarra (National Spanish Distance University of Spain, Spain)  Abstract: Society has evolved in such a way that individuals are required to embrace constant improvements in order to be able to perform their jobs properly. Distance education is a solution to this problem, as it allows students to obtain practical knowledge without the space and time constraints of classical face-to-face education, thus allowing them to fit their studies into possibly tight schedules. In order to obtain practical distance education on technical topics, the use of remote laboratories becomes more of a necessity rather than just being an option. To this end, the RELATED framework has been developed in order to permit the structural development of remote laboratories. It presents a structured methodology of remote/virtual lab development and also provides common facilities, such as user management, booking, or basic visualization. In the case that a high number of laboratories and students use RELATED, handling such information becomes a major issue for the proper functionality of RELATED. These issues can be efficiently tackled using cloud technologies. This paper proposes the use of cloud technologies to enhance RELATED and describes the cloud-based architecture that is under development at UNED, including details on its software components and the algorithms needed for resource provisioning.               Keywords: cloud computing, on-line education, remote laboratories, web-based services               Categories: C.2.4, H.3.5, J.6, K.3, K.6, L.3.0, L.3.5, L.3.6  
19|14||Ensemble - an E-Learning Framework|  Ricardo Queirós (University of Porto, Portugal)   José Paulo Leal (University of Porto, Portugal)  Abstract: E-Learning frameworks are conceptual tools to   organize networks of elearning services. Most frameworks cover areas   that go beyond the scope of e-learning, from course to financial   management, and neglects the typical activities in everyday life of   teachers and students at schools such as the creation, delivery,   resolution and evaluation of assignments. This paper presents the   Ensemble framework - an e-learning framework exclusively focused on   the teaching-learning process through the coordination of   pedagogical services. The framework presents an abstract data,   integration and evaluation model based on content and communications   specifications. These specifications must base the implementation of   networks in specialized domains with complex evaluations. In this   paper we specialize the framework for two domains with complex   evaluation: computer programming and computer-aided design   (CAD). For each domain we highlight two Ensemble hotspots: data and   evaluations procedures. In the former we formally describe the   exercise and present possible extensions. In the latter, we describe   the automatic evaluation procedures.               Keywords: automatic evaluation, e-learning, interoperability, standards               Categories: D.2.11, D.2.12, D.3.0  
19|14||Evaluation on Students' and Teachers' Acceptance of Widget- and Cloud-based Personal Learning Environments|  Sylvana Kroop (Centre for Social Innovation, Austria)  Abstract: Instead of using traditional learning   environments which contain tools and content of a single provider   that are often owned by one specific educational organization, the   presented idea of Widget- and Cloud-based Personal Learning   Environments (PLEs) exploits a variety of existing and developing   open educational sources including popular Web2.0 resources such as   YouTube, Flickr or Wikipedia. The main contribution of this paper is   the analysis of teachers and students attitudes and reasons   for acceptance of widget- and cloud-computing based PLE   technology. A quantitative and qualitative comparison of three   widget-based PLE scenarios reveals the benefits as well as barriers   of the new PLE technology regarding a) learning outcome and b)   (cognitive, technical, time-wise) ease of the personal learning   process. Findings show that a systematic cloud computing approach -   software as a service (SaaS) where users do not need to install and   run tools locally - is preferred. It saves time and meets the needs   to keep the personal environment flexible and up to date. But while   users have to manage a broad range of tools and content their most   essential request is to be efficiently supported by the system in   regard to their individual learning needs, e.g. in the decision   making process of selecting and evaluating relevant   tools.               Keywords: cloud computing, evaluation results, open educational resources, participatory research design, personal learning environments, self-regulated learning, widgets               Categories: D.2, D.2.1, D.2.10, J.4, L.0, L.1.1, L.1.2, L.1.3, L.2, L.3.4, L.3.5, L.3.6, L.3.7, L.3.8, L.6, M.5  
19|15|http://www.jucs.org/jucs_19_15|Managing Editor's Column|
19|15||An Algorithm for Peer Review Matching in Massive Courses for Minimising Students' Frustration|  Iria Estévez-Ayres (Universidad Carlos III de Madrid, Spain)   Raquel M. Crespo-García (Universidad Carlos III de Madrid, Spain)   Jesús A. Fisteus (Universidad Carlos III de Madrid, Spain)   Carlos Delgado Kloos (Universidad Carlos III de Madrid, Spain)  Abstract: Traditional pedagogical approaches are no longer   sufficient to cope with the increasing challenges of Massive Open   On-line Courses (MOOCs). Consequently, it is necessary to explore   new paradigms. This paper describes an exploration of the adaptation   of the peer review methodology for its application to MOOCs. Its   main goal is to minimise the students' frustration through the   reduction of the number of committed students that receive no   feedback from their peers. In order to achieve this objective, we   propose two algorithms for the peer review matching in MOOCs. Both   reward committed students by prioritising the review of their   submissions. The first algorithm uses sliding deadlines to minimise   the probability of a submission not being reviewed. Our experiments   show that it reduces dramatically the number of submissions from   committed students that do not receive any review. The second   algorithm is a simplification of the former. It is easier to   implement and, despite performing worse than the first one, it also   improves with respect to the baseline.               Keywords: Massive Open Online Courses, assessment, evaluation, peer assessment, peer evaluation, peer review, quality               Categories: K.3, K.3.1  
19|15||Behavioral and Temporal Rule Checking for Gaussian Random Process  a Kalman Filter Example|  Doron Drusinsky (Naval Postgraduate School, USA)  Abstract: This paper describes a behavioral and temporal pattern detection technique for state-space systems whose state is a random variable such as the state estimated using a Kalman filter. Our novel behavioral and temporal pattern detection technique uses diagrammatic, intuitive, yet formal specifications based on a dialect of the UML of the kind used to monitor or formally verify the correctness of deterministic systems. Combining these formal specifications with a special code generator, extends the deterministic pattern detection technique to the domain of stochastic processes.   We demonstrate the technique using a Ballistic trajectory Kalman filter tracking example in which a pattern-rule of interest is not flagged when observing the sequence of mean track position values but is flagged with a reasonable probability using the proposed technique.               Keywords: Kalman Filter, UML, monitoring, patterns, random process, statecharts               Categories: D.2.4, F.1.1, F.4.1  
19|15||Cluster Perturbation Simulated Annealing for Protein Folding Problem|  Juan Frausto-Solís (UPEMOR, Mexico)   Mishael Sánchez-Pérez (UNAM, Mexico)   Ernesto Liñan-García (UADEC, Mexico)   Juan Paulo Sánchez-Hernández (ITESM Campus Cuernavaca, Mexico)   Manoj Ramachandran (Toc H Institute of Science and Technology, India)  Abstract: In this paper, an improved Simulated Annealing   algorithm for Protein Folding Problem (PFP) is presented. This   algorithm called Cluster Perturbation Simulated Annealing (CPSA) is   based on a brand new scheme to generate new solutions using a   cluster perturbation. The algorithm is divided into two phases:   Cluster Perturbation Phase and the Reheat Phase. The first phase   obtains a good solution in a small amount of time, and it is applied   at very high temperatures. The second phase starts with a threshold   temperature and reheats the system for a better exploration. CPSA   reduces the execution time of the Simulated Annealing Algorithm   without sacrificing quality to find a native structure in PFP in   Ab-Initio approaches.               Keywords: cluster perturbation simulated annealing, protein folding, simulated annealing, tuned SA               Categories: J.0, J.3, J.7  
19|15||A Personalized Recommender System Based on a Hybrid Model|  Wedad Hussein (Ain Shams University, Egypt)   Rasha M. Ismail (Ain Shams University, Egypt)   Tarek F. Gharib (King Abdulaziz University, Saudi Arabia)   Mostafa G. M. Mostafa (Ain Shams University, Egypt)  Abstract: Recommender systems are means for web   personalization and tailoring the browsing experience to the users'   specific needs. There are two categories of recommender systems;   memory-based and model-based systems. In this paper we propose a   personalized recommender system for the next page prediction that is   based on a hybrid model from both categories. The generalized   patterns generated by a model based techniques are tailored to   specific users by integrating user profiles generated from the   traditional memory-based system's user-item matrix. The suggested   system offered a significant improvement in prediction speed over   traditional model-based usage mining systems, while also offering an   average improvement in the system accuracy and system precision by   0.27% and 2.35%, respectively.               Keywords: next page prediction, recommender systems, web usage mining               Categories: I.5.1, I.5.3, I.5.4, L.2.2  
19|15||Toward a Module-centralized and Aspect-oriented Monitoring Framework in Clouds|  Kun Ma (University of Jinan, China)   Runyuan Sun (University of Jinan, China)   Ajith Abraham (Scientific Network for Innovation and Research Excellence, USA)  Abstract: Currently, monitoring plays an important role in   managing the Cloud computing environment. However, the Cloud   computing owners and tenants often lack the management and   monitoring tools to ensure the performance, robustness,   dependability, and security. To address this limitation, this paper   describes the development of a lightweight module-centralized and   aspect-oriented monitoring framework. This frame-work performs   end-to-end measurements at virtual and physical machine instances,   software and Web service in the Cloud. It monitors the quality of   service (QoS) pa- rameters of the IaaS and SaaS layer in the forms   of plug-in bundles. In addition, we discuss the manager-agent   monitoring of entity objects and aspect-oriented Cloud service   monitoring in detail. All the modules constitute the entire proposed   framework to improve the performance in hybrid Clouds.               Keywords: Cloud computing, aspect-oriented programming, cloud monitoring, performance evaluation               Categories: K.6, K.6.3, K.6.4, K.6.5  
19|15||NIKVision: Developing a Tangible Application for and with Children|  Javier Marco (Universidad de Zaragoza, Spain)   Sandra Baldassarri (Universidad de Zaragoza, Spain)   Eva Cerezo (Universidad de Zaragoza, Spain)  Abstract: In this paper, the design process of a tangible   game for a tabletop device (NIKVision) is presented. NIKVision is   intended to give leisure and fun while reinforcing physical   manipulation and co-located gaming for 3-6 year old   children. Interaction is provided by the handling of conventional   toys and computer augmentation on a table surface. The presence of   an additional vertical monitor that complements table surface output   is a distinguishing feature of NIKVision. By following a engineering   design lifecycle, the paper describes the complete process of   designing a Farm Game for the tabletop. Children have been involved,   for the very starting point, through continuous test sessions in   schools and nurseries. The data recovered from these sessions have   been essential, not only to detect problems, but to take the more   adequate design decisions. Different children-centred design methods   have been used, depending on the question to be evaluated or   designed, ranging from observation notes to Wizard of Oz, or   video-analysis.  The paper exposes the results of a final summative   evaluation that summarizes the performance of the game in relation   to Usability, User Experience and physical and co-located   gaming. The experience obtained by the authors from this process has   crystalized in a set of reflections about the feasibility of   designing with very young children and about the value of the data   obtained from them.               Keywords: children-centred design, evaluation, tabletop, tangible, usability, user experience               Categories: H.1.2 , H.5.2  
19|15||Self-Aware Trader: A New Approach to Safer Trading|  Javier Martínez Fernández (Hochschule Konstanz, Germany)   Juan Carlos Augusto (Middlesex University, United Kingdom)   Giuseppe Trombino (School of Computing and Mathematics, United Kingdom)   Ralf Seepold (Hochschule Konstanz, Germany)   Natividad Martinez Madrid (University of Reutlingen, Germany)  Abstract: Traders are required to work in the financial   market with highly complex information and to perform efficiently   under high levels of psychological pressure. Multiple disciplines,   from programs with artificial intelligence to complex mathematical   functions, are used to help traders in their effort to maximize   profits. However, an essential problem not yet considered in this   rapidly evolving environment is that traders are not supported to   adequately manage how stress influences their decisions. This paper   takes into consideration the negative influences of stress on   individuals and proposes a system designed to support traders by   providing them with information that can reduce the likelihood of   poor decision-making. The system has been designed considering both   technical and physiological aspects to make information available in   a suitable way. Biometric sensors are used to collect data   associated with stress, a software platform then analyses this   information and displays it to the trader.  The resulting system is   capable of making individual traders, as well as teams of traders,   self-aware of their levels of stress.  The system has been tested in   real environments and the results provide evidence that self-aware   traders benefit from the system by reducing risky decision-making.               Keywords: decision making, sensors, stress, stress measurement, trader               Categories: B.4.m, C.3, H.1.2, H.4.3, H.5.3, I.2.1, J.3, J.4, J.7  
19|15||Web Search Results Exploration via Cluster-Based Viewes and Zoom-Based Navigation|  Karol Rástočný (Slovak University of Technology in Bratislava, Slovakia)   Michal Tvarožek (Slovak University of Technology in Bratislava, Slovakia)   Maria Bielikova (Slovak University of Technology in Bratislava, Slovakia)  Abstract: Information seeking on the Web has become   day-to-day routine for more than two billion human beings most of   who use traditional keyword-based search engines. Developers of   these search engines stress personalization, prediction of users'   next actions and mistake correction. But they are still struggling   with results presentation and support for users, who make atypical   queries or who do not exactly know what they are looking for. We   address these issues via a novel approach for exploring web   repositories, which naturally combines user search activities - look   up, learning and investigation. We achieve this via view-based   navigation in hierarchical clusters and two-dimensional graphs of   search results.               Keywords: Semantic Web, Web, adaptive views, exploratory search, graph visualization, navigation, results clustering               Categories: H.1.2, H.3.3, H.5.1, H.5.2, H.5.4  
19|16|http://www.jucs.org/jucs_19_16|Information Security|
19|16||An Efficient Ciphertext-Policy Attribute-Based Access Control towards Revocation in Cloud Computing|  Xingxing Xie (Xidian University, P.R.China)   Hua Ma (Xidian University, P.R.China)   Jin Li (Guangzhou University, P.R.China)   Xiaofeng Chen (Xidian University, P.R.China)  Abstract: Attribute-Based Encryption (ABE) is one of the   new visions for finegrained access control in cloud   computing. Plenty of research work has been done in both academic   and industrial communities. However, before ABE can be deployed in   data outsourcing systems, efficient enforcement of authorization   policies and policy updates are the main obstacles. Therefore, in   order to solve this problem, efficient and secure attribute and user   revocation should be proposed in original ABE scheme, which is still   a challenge in existing work. In this paper, we propose a new   ciphertext-policy ABE (CP-ABE) construction with efficient attribute   and user revocation, which largely eliminates the overhead   computation at data service manager and data owner. Besides, we   present an efficient access control mechanism based on the CP-ABE   construction with one outsourcing computation service provider.               Keywords: attribute-based encryption, outsourcing, re-encryption, revocation               Categories: E.3  
19|16||Multiplication and Squaring with Shifting Primes on OpenRISC Processors with Hardware Multiplier|  Leandro Marin (University of Murcia, Spain)   Antonio J. Jara (University of Murcia, Spain)   Antonio F. Skarmeta (University of Murcia, Spain)  Abstract: Cryptographic primitives are the key component   in the security protocols to support the authentication, key   management and secure communication establishment. For that reason,   this work presents the optimization of the Elliptic Curve   Cryptography through the usage of Shifting Primes for constrained   devices. Specifically, this presents the optimization for the   chipsets JN51XX from NXP/Jennic, which are based on OpenRISC   architecture and offer a class-2 constrained device. In details,   Shifting Primes features have allowed to optimize the multiplication   and squaring through a double accumulator and shifting   reduction. This work is ancillary to the previous works about   optimization of Shifting Primes for class-1 constrained devices. The   optimization of the Elliptic Curve Cryptography for the class-2   constrained devices brings several opportunities for realistic   scenarios, where the security interoperability between a gateway   (class-2 device) and end-nodes (class 1 devices) is a major   requirement.               Keywords: Internet of Things, OpenRISC, Security GT, Shifting Primes,, lliptic Curve Cryptography               Categories: B.2.1, B.4.1, E.3, G.1.1  
19|16||A Privacy Preserving Message Delivery Protocol Using Identity-Hidden Index in VDTNs|  Youngho Park (Pukyong National University, Republic of Korea)   Chul Sur (Pukyong National University, Republic of Korea)   Sanguk Shin (Pukyong National University, Republic of Korea)   Kyung-Hyune Rhee (Pukyong National University, Republic of Korea)   Changho Seo (Kongju National University, Republic of Korea)  Abstract: Vehicular Delay Tolerant Networks (VDTNs) are   characterized model of Vehicular Ad Hoc Networks where vehicles   disseminate messages through fixed relay nodes placed on roadside by   utilizing a store-carry-forward method. In this paper, we propose a   secure message delivery protocol for protecting receiver-location   privacy in socialspot-based VDTN because location privacy is one of   the most important security requirements. To design a simplified   protocol, we eliminate the use of conventional pseudonym-based   vehicle identification accompanied with a complex pseudonymous   certificate management. Instead, we introduce an identity-hidden   message indexing which enables a receiver vehicle to query a message   whose destination is itself to the socialspot RSU without revealing   its identity, and we make use of non-interactive key agreement   scheme to establish a secure communication channel between message   source and destination vehicles. Furthermore, we demonstrate   experimental results to confirm the reduced cryptographic overhead   and the effectiveness of privacy preservation for the proposed   protocol.               Keywords: ID-hidden index, VANET, VDTN, authentication, privacy preservation               Categories: C.2.0, L.7  
19|16||Graph-based KNN Algorithm for Spam SMS Detection|  Tran Phuc Ho (Konkuk University, Republic of Korea)   Ho-Seok Kang (Konkuk University, Republic of Korea)   Sung-Ryul Kim (Konkuk University, Republic of Korea)  Abstract: In the modern life, SMS (Short Message Service)   is one of the most necessary services on mobile devices. Because of   its popularity, many companies use SMS as an effective marketing and   advertising tool. Also, the popularity gives hackers chances to   abuse SMS to cheat mobile users and steal personal information in   their mobile phones, for example. In this paper, we propose a method   to detect spam SMS on mobile devices and smart phones. Our approach   is based on improving a graph-based algorithm and utilizing the KNN   Algorithm - one of the simplest and most effective classification   algorithms. The experimentation is carried out on SMS message   collections and the results ensures the efficiency of the proposed   method, with high accuracy and small processing time enough for   detecting spam messages directly on mobile phones in real   time.               Keywords: classification, data mining, graph-based KNN, mobile security, smartphone, spam SMS detection               Categories: E.1, E.2, H.3.0, I.2, L.7  
19|16||A Security Real-time Privacy Amplification Scheme in QKD System|"  Bo Liu (National University of Defense Technology, China)   Baokang Zhao (National University of Defense Technology, China)   Bo Liu (National University of Defense Technology, China)   Chunqing Wu (National University of Defense Technology, China)  Abstract: Quantum Key Distribution (QKD) technology, based   on the laws of physics, can create unconditional security keys   between communication parties. In recent years, researchers draw   more and more attention to the QKD technology. Privacy amplification   is a very significant procedure in QKD system. In this paper, we   propose the real-time privacy amplification (RTPA) scheme which   converts the weak secret string to a uniform key that is fully   secret from Eve. Our detailed proofs show the security of our RTPA   scheme. In order to prevent the potential man-in-middle attacks, we   employ an authentication procedure to RTPA scheme (ARTPA) with the   ""-XOR almost universal hash functions. We implement our ARTPA scheme   based on CLIP system, which is connected to the quantum   communication system. Considering the privacy amplification and   authentication overhead and the finite size effect on the security   of final keys, we set the secret key length be 256k before privacy   amplification and the authentication tag length be 60. Our   experimental results show the efficiency of the proposed ARTPA   scheme.               Keywords: authentication, privacy amplification, quantum key distribution, security               Categories: E.4, H.1.0, H.1.1  "
19|16||Security Issues and Attacks on the GSM Standard: a Review|"  Giuseppe Cattaneo (Università di Salerno, Italy)   Giancarlo De Maio (Università di Salerno, Italy)   Umberto Ferraro Petrillo (Università di Roma ""La Sapienza"", Italy)  Abstract: The Global Systems for Mobile communications   (GSM) is actually the most widespread mobile communication   technology existing nowadays. Despite being a mature technology, its   introduction dates back to the late eighties, it suffers from   several security vulnerabilities, which have been targeted by many   attacks aimed to break the underlying communication protocol. Most   of these attacks focuses on the A5/1 algorithm used to protect   over-the-air communication between the two parties of a phone   call. This algorithm has been superseded by new and more secure   algorithms. However, it is still in use in the GSM networks as a   fallback option, thus still putting at risk the security of the GSM   based conversations. The objective of this work is to review some of   the most relevant results in this field and discuss their practical   feasibility. To this end, we consider not only the contributions   coming from the canonical scientific literature but also those that   have been proposed in a more informal context, such as during hacker   conferences.               Keywords: GSM, encryption, mobile security, security attacks               Categories: C.2, C.2.0, C.2.1  "
19|16||Observations of Skipjack-like Structure with SP/SPS Round Function|  Ting Cui (Information Science and Technology Institute, China)   Chenhui Jin (Information Science and Technology Institute, China)   Guoshuang Zhang (Science and Technology on Information Assurance Laboratory, China)  Abstract: Impossible differential cryptanalysis is an   important tool for evaluating the security level of a block cipher,   and the key step of this cryptanalysis is to find the longest   impossible differential. This paper focuses on retrieving impossible   differentials for m-cell Skipjack-like structure with SP/SPS round   function (named SkipjackSP   and SkipjackSPS resp.). Up   to now, known longest impossible differentials in m-cell   Skipjack-like structures is   m2 rounds. In this paper,   we provide some new m2   rounds impossible differentials for these two structures. Further,   we prove that if P layer is chosen from binary   matrices, we can always retrieve   m2 + 1 rounds impossible   differentials for these two structures, and   m2 + 2 rounds impossible   differentials for   SkipjackSP. Moreover, if P   layer satisfies some satiable conditions, we may further obtain   m2 + 2 rounds impossible   differential for   SkipjackSPS. Our results   show that we should choose P layer carefully when   employing these two structures.               Keywords: block cipher, impossible differential, permutation layer, skipjack-like structure               Categories: C.2.0, D.4.6, E.3  
19|16||Text Analysis for Monitoring Personal Information Leakage on Twitter|"  Dongjin Choi (Chosun University, Republic of Korea)   Jeongin Kim (Chosun University, Republic of Korea)   Xeufeng Piao (School of Computer Science and Technology, China)   Pankoo Kim (Chosun University, Republic of Korea)  Abstract: Social networking services (SNSs) such as   Twitter and Facebook can be considered as new forms of   media. Information spreads much faster through social media than any   other forms of traditional news media because people can upload   information with no time and location constraints. For this reason,   people have embraced SNSs and allowed them to become an integral   part of their everyday lives. People express their emotional status   to let others know how they feel about certain information or   events. However, they are likely not only to share information with   others but also to unintentionally expose personal information such   as their place of residence, phone number, and date of birth. If   such information is provided to users with inappropriate intentions,   there may be serious consequences such as online and offline   stalking. To prevent information leakages and detect spam, many   researchers have monitored e-mail systems and web blogs. This paper   considers text messages on Twitter, which is one of the most popular   SNSs in the world, to reveal various hidden patterns by using   several coefficient approaches. This paper focuses on users who   exchange Tweets and examines the types of information that they   reciprocate other's Tweets by monitoring samples of 50 million   Tweets which were collected by Stanford University in November   2009. We chose an active Twitter user based on ""happy birthday"" rule   and detecting their information related to place to live and   personal names by using proposed coefficient method and compared   with other coefficient approaches. As a result of this research, we   can conclude that the proposed coefficient method is able to detect   and recommend the standard English words for non-standard words in   few conditions. Eventually, we detected 88,882 (24.287%) more name   included Tweets and 14,054 (3.84%) location related Tweets compared   by using only standard word matching method.               Keywords: Personal Identifiable Information, Twitter, personal information leakage, social network services, text analysis               Categories: H.3.1, H.3.2, H.3.3, H.3.7, H.5.1  "
19|17|http://www.jucs.org/jucs_19_17|Towards Sustainable Computing through Ambient Intelligence|
19|17||Enabling User Access Control in Energy-constrained Wireless Smart Environments|  Juan Álvaro Muñoz Naranjo (University of Almería, Spain)   Pablo Orduña (University of Deusto, Spain)   Aitor Gómez-Goiri (University of Deusto, Spain)   Diego López-de-Ipiña (University of Deusto, Spain)   Leocadio González Casado (University of Almería, Spain)  Abstract: This work introduces a novel access control   solution for wireless network services in Internet of Things   scenarios. We focus on a minimal use of computation, energy and   storage resources at wireless sensors so as to address constrained   devices: the proposed methods for key distribution and access   control rely on extremely fast key derivation functions and, for the   same reason, memory usage is reduced since keys are computed on the   fly when needed. Our solution achieves privacy, authentication,   semantic security, low energy, low computational demand and impacts   mitigation of compromised devices on a simple manner. The access   control provided is based on user identity and time intervals. We   discuss these properties, compare our proposal to previous related   work and provide experimental results that confirm its viability.               Keywords: access control, internet of things, sustainability, wireless network services               Categories: C.2.4, E.3  
19|17||MECCANO: a Mobile-Enabled Configuration Framework to Coordinate and Augment Networks of Smart Objects|  Ana M. Bernardos (Universidad Politécnica de Madrid, Spain)   Luca Bergesio (Universidad Politécnica de Madrid, Spain)   Josue Iglesias (Universidad Politécnica de Madrid, Spain)   José R. Casar (Universidad Politécnica de Madrid, Spain)  Abstract: In this paper, we exploit the capabilities of   mobile devices as instruments to facilitate interaction in spaces   populated with smart objects. We do this through MECCANO, a   framework that supports an interaction method for a user to perform   physical discovery and versatile configuration of behaviors   involving a network of smart objects. Additionally, MECCANO guides   the developer to easily integrate new augmented objects in the smart   ecosystem. Behaviors are rule-based micro-services composed by a   combination of events, conditions and actions that one or more smart   objects can trigger, detect or perform. Each object owns and   publishes its capabilities in a software module; this module becomes   available when a user physically lies in the area of influence of   the smart object. The capabilities provided by a specific object can   be merged with those in other objects (including those in the user's   mobile device itself) to configure a behavior involving several   objects, adapted to the user's needs. On operation, the behavior is   run within the mobile device, serving the device as orchestrator of   the involved objects. The framework also facilitates sharing   micro-services in such a way that users can act as prosumers by   generating their self-made behaviors. New behaviors are associated   to the classes of objects that are needed to execute them, becoming   ready for other users to download. The proposed interaction method   and its tools are demonstrated both from the developer's and the   end-user's points of view, through practical implementations.               Keywords: interaction, mobile technologies, reasoning, recommendation, smart objects, ubiquitous computing, user generated services               Categories: H.1.2, H.5.1  
19|17||Design Considerations for Application Selection and Control in Multi-user Public Displays|  Constantin Taivan (University of Minho, Portugal)   Rui José (University of Minho, Portugal)   Bruno Silva (University of Minho, Portugal)   Ivan Elhart (University of Lugano, Switzerland)   Jorge Cardoso (Universidade Católica Portuguesa, Portugal)  Abstract: Urban spaces are increasingly embedded with   various types of public digital displays. Many of these displays can   be subject to multi-user interactions and support a broad range of   applications.  A fundamental implication emerging from the   interactive nature of those applications is that users should have   access to appropriate selection and control techniques that would   allow them to drive the way applications are shown and used in the   respective environment. Such techniques should enable each user to   reason and express intentions about the system behavior, while also   dealing with concurrent requests from multiple users in a way that   is fair and clear. In this study, we aim to inform the definition of   novel techniques for application selection and control in pervasive   display environments that can address the above challenges. Drawing   inspiration from traditional GUI interaction concepts we developed   and deployed a public display system that supports multiple   applications and is able to receive explicit content presentation   requests from multiple viewers. Based on the experiment observations   and interviews with the participants, we reached a set of design   considerations for future pervasive displays environments that are   open to third party applications providers and allow the audience to   influence content presentation.               Keywords: mixed initiative approach, multi-application displays, multi-user interaction, public displays               Categories: D.2.1, D.2.10, H.1.2, I.2.0, K.4.2  
19|17||Implementation of a Building Automation System Based on Semantic Modeling|  Jaime Caffarel (Universidad Politécnica de Madrid, Spain)   Song Jie (Universidad Politécnica de Madrid, Spain)   Jorge Olloqui (Universidad Politécnica de Madrid, Spain)   Rocío Martínez (Universidad Politécnica de Madrid, Spain)   Asunción Santamaría (Universidad Politécnica de Madrid, Spain)  Abstract: This paper presents an Ontology-Based   multi-technology platform designed to avoid some issues of Building   Automation Systems. The platform allows the integration of several   building automation protocols, eases the development and   implementation of different kinds of services and allows sharing   information related to the infrastructure and facilities within a   building. The system has been implemented and tested in the Energy   Efficiency Research Facility at CeDInt-UPM.               Keywords: OSGi, RDF, building automation, ontology               Categories: H.1.2, M.4  
19|17||Assessing the Impact of the homeML Format and the homeML Suite within the Research Community|  Heather McDonald (University of Ulster, United Kingdom)   Chris Nugent (University of Ulster, United Kingdom)   Dewar Finlay (University of Ulster, United Kingdom)   George Moore (University of Ulster, United Kingdom)   William Burns (University of Ulster, United Kingdom)   Josef Hallberg (University of Technology, Sweden)  Abstract: The lack of a standard format to store data   generated within the smart environments research domain is limiting   the opportunity for researchers to share and reuse datasets.  The   opportunity to exchange datasets is further hampered due to the lack   of an online resource to facilitate this.  In our current work we   have attempted to resolve these issues through the development of   homeML, a proposed format to support the storage and exchange of   data generated within a smart environment and the homeML suite, an   online tool to support data exchange and reuse.  A usability and   functionality study performed by 8 unbiased members of the research   community is presented and discussed.  All participants in the study   agreed that the homeML format could address the need for a standard   format within this domain.  Participants also agreed that the homeML   suite would be a useful tool to be available to researchers as they   perform experiments in the area of smart environments.               Keywords: heterogeneous data, homeML, repository and XML, smart environments, standard format               Categories: E.1, E.2  
19|17||An Agent-mediated Ontology-based Approach for Composite Activity Recognition in Smart Homes|  George Okeyo (University of Ulster, United Kingdom)   Liming Chen (De Montfort University, United Kingdom)   Hui Wang (University of Ulster, United Kingdom)  Abstract: Activity recognition enables ambient assisted   living applications to provide activity-aware services to users in   smart homes. Despite significant progress being made in activity   recognition research, the focus has been on simple activity   recognition leaving composite activity recognition an open   problem. For instance, knowledge-driven activity recognition has   recently attracted increasing attention but mainly focused on simple   activities. This paper extends previous work by introducing a   knowledge-driven approach to recognition of composite activities   such as interleaved and concurrent activities. The approach combines   the recognition of single and composite activities into a unified   framework.  To support composite activity modelling, it combines   ontological and temporal knowledge modelling formalisms. In   addition, it exploits ontological reasoning for simple activity   recognition and qualitative temporal inference to support composite   activity recognition. The approach is organized as a multi-agent   system to enable multiple activities to be simultaneously monitored   and tracked. The presented approach has been implemented in a   prototype system and evaluated in a number of experiments. The   experimental results have shown that average recognition accuracy   for composite activities is 88.26%.               Keywords: activity recognition, agents, composite activities, concurrent activities, interleaved activities, ontology, temporal knowledge               Categories: H.1.2  
19|17||CUBICA: An Example of Mixed Reality|"  Juan Mateu (Universidad Autonoma de Madrid, Spain)   Xavier Alaman (Universidad Autonoma de Madrid, Spain)  Abstract: Nowadays, one of the hot issues in the agenda   is, undoubtedly, the concept of Sustainable Computing. There are   several technologies in the intersection of Sustainable Computing   and Ambient Intelligence. Among them we may mention ""Human-Centric   Interfaces for Ambient Intelligence"" and ""Collaborative Smart   Objects"" technologies. In this paper we present our efforts in   developing these technologies for ""Mixed Reality"", a paradigm where   Virtual Reality and Ambient Intelligence meet. Cubica is a mixed   reality educational application that integrates virtual worlds with   tangible interfaces. The application is focused on teaching computer   science, in particular ""sorting algorithms"". The tangible interface   is used to simplify the abstract concept of array, while the virtual   world is used for delivering explanations. This educational   application has been tested with students at different educational   levels in secondary education, having obtained promising results in   terms of increased motivation for learning and better understanding   of abstract concepts.               Keywords: collaborative smart objects, human-centric interfaces for AmI environments, ubiquitous and ambient displays environments               Categories: H.1.2, H.5.2, K.3.1, L.3.1, L.7.0  "
19|17||A Multimodal Ambient Intelligence Environment for Playful Learning|"  Haris Papagiannakis (Foundation of Research and Technology, Hellas - FORTH, Greece)   Margherita Antona (Foundation of Research and Technology, Hellas - FORTH, Greece)   Stavroula Ntoa (Foundation of Research and Technology, Hellas - FORTH, Greece)   Constantine Stephanidis (Foundation of Research and Technology, Hellas - FORTH, Greece)  Abstract: This paper reports the design, development and   evaluation of a technological framework for learning applications,   named AmI Playfield, aimed at creating challenging learning   conditions through play and entertainment. AmI Playfield is an   educative Ambient Intelligent (AmI) environment which emphasizes the   use of kinesthetic and collaborative technology in a natural playful   learning context and embodies performance measurement techniques.   In order to test and assess AmI Playfield, the ""Apple Hunt""   application was developed, which engages (young) learners in   arithmetic thinking through kinesthetic and collaborative play,   observed by unobtrusive AmI technology behind the scene. ""Apple   Hunt"" has been evaluated according to a combination of methodologies   suitable for young testers, whereas Children Committees are   introduced as a promising approach to evaluation with children. The   obtained results demonstrate the system's high potential to generate   thinking and fun, deriving from the learners' full-body kinesthetic   play and team work.               Keywords: ambient intelligence, child computer interaction, evaluation with children, multimodal systems, pervasive gaming, playful learning               Categories: H.5.1, H.5.2  "
19|18|http://www.jucs.org/jucs_19_18|Technologies for Enhancing Accessibility and Fighting Info-exclusion|
19|18||Can I Access my School Website? Auditing Accessibility of the Portuguese Teaching Institutions Websites|  Ramiro Gonçalves (University of Trás-os-Montes e Alto Douro, Portugal)   José Martins (University of Trás-os-Montes e Alto Douro, Portugal)   Jorge Pereira (University of Trás-os-Montes e Alto Douro, Portugal)   Vitor Santos (Nova School of Statistics and Information Management, Portugal)   Manuel Pérez Cota (University of Vigo, Spain)  Abstract: Web accessibility is becoming a current topic in   social and scientific discussions. With the advances in technology,   a need for access to all Web resources is becoming more and more   recurrent due to the several advantages that the Web brings to those   with some sort of disability, allowing them accessing and   integrating in society.  With this document we aim to present indicators regarding the lower accessibility levels of the Portuguese teaching institutions websites. A set of background and theoretical considerations is made alongside the article, as well as the results of an accessibility evaluation made to the Portuguese secondary schools websites using a specialized software tool and according to WCAG 2.0.  The present document also contains a proposal for a model that aims on improving Web accessibility Levels in Portugal by fostering the creation of relations and group activities between the actors that, in our opinion, are those with the most relevance in the Web content accessibility issue.               Keywords: ICT, Portugal, Web accessibility, accessibility issue, ethics, model, schools               Categories: J.4, K.3, K.4.1, L.2.0  
19|18||A Model-Based Graphical Editor to Design Accessible Media Players|  María González-García (Universidad Carlos III de Madrid, Spain)   Lourdes Moreno (Universidad Carlos III de Madrid, Spain)   Paloma Martínez (Universidad Carlos III de Madrid, Spain)   Raúl Miñon (Euskal Herriko Unibertsitatea, Spain)   Julio Abascal (Euskal Herriko Unibertsitatea, Spain)  Abstract: The spectacular rise of multimedia Web content,   especially video and audio content, makes addressing its   accessibility a matter of urgency. All the regulations recognize   that this type of content must be accessible to everyone, with or   without a disability. To address this issue, this article presents a   Model-Based Graphical Editor to design Accessible Media   Players. This tool has been created in order to provide support to   designers with little background in accessibility. To accomplish   this work, a review of Accessibility Standards Regulation has been   carried out, a set of accessibility requirements for accessible   media players is proposed and a modelling of these requirements has   been made.               Keywords: accessibility, graphical editor, media player, model-driven development, standard               Categories: H.1, H.5  
19|18||Development of Navigation Skills through Audio Haptic Videogaming in Learners who are Blind|  Jaime Sánchez (University of Chile, Chile)   Marcia de Borba Campos (Pontifical Catholic University of Rio Grande, Brazil)  Abstract: This study presents the development of a video   game with audio and haptic interfaces that allows for the   stimulation of orientation and mobility skills in people who are   blind through the use of virtual environments. We evaluate the   usability and the impact of the use of an audio and haptic-based   videogame on the development of orientation and mobility skills in   school-age learners who are blind. The results show that the   interfaces used in the videogame are usable and appropriately   designed, and that the haptic interface is as effective as the audio   interface for orientation and mobility purposes.               Keywords: haptic and audio interfaces, mobility, orientation, people who are blind               Categories: H.3.1, H.3.2, H.3.3, H.3.7, H.5.1  
19|18||A Virtual Reality Test for the Identification of Memory Strengths of Dyslexic Students in Higher Education|  Katerina Kalyvioti (The University of Ioannina, Greece)   Tassos A. Mikropoulos (The University of Ioannina, Greece)  Abstract: Research suggests that Virtual Reality has a key   role in the development of new diagnostic tools in neuropsychology   and shows great rehabilitative potentials for individuals with   specific neurological, intellectual and cognitive disabilities. In   the case of dyslexia, a neurodevelopmental reading disorder, the use   of Virtual Reality technologies has only been recently documented in   a handful of studies. The main focus of these studies has been the   identification of visuospatial strengths, the exploration of   nonverbal problem solving treatment and the increase of awareness in   educators and parents with children with dyslexia. Even fewer are   the studies of Virtual Reality and the lifelong memory difficulties   of adult individuals with dyslexia. With a more clinical, rather   than technological, perspective the goal of this paper was to design   specialized tasks in virtual environments to be part of a screening   process/assessment of characteristic memory difficulties for   undergraduate students diagnosed with dyslexia. Results showed that   there were no statistically significant differences in the   performance of students with dyslexia and students without dyslexia,   a finding which highlights the development and successful use of   compensatory memory strategies by the participants with   dyslexia. Taking into consideration the real life representations,   the multisensory approach, the increased sense of presence, the   well-designed tasks and the recorded positive attitude of all   participants, the study concludes that the use of Virtual Reality in   neurological and neurodevelopmental memory disorders will be   innovative and suggests that hands on Virtual Reality applications,   become an indispensable part of these deficits' cognitive assessment   and rehabilitation.               Keywords: assessment, compensatory strategies, dyslexia, memory, university students, virtual environments               Categories: H.4.m, J.5, L.0.0, L.1.1, L.2  
19|18||From Blended to Inclusive Learning: Accessibility, Profiles, Openness, and Higher Education|  Sofia B. Dias (University of Lisbon, Portugal)   José A. Diniz (University of Lisbon, Portugal)  Abstract: The use of technology can be seen as an   innovative challenge to restructure the teaching-learning process   and integrate Information and Communication Technologies (ICTs) in   independent, collaborative and interactive work. The main purposes   of this study are to understand users' needs and to identify their   profiles, in order to empower the quality of online   teaching-learning process. Identifying teachers' and students'   profiles and their needs as Course Management System users, in   particular, is necessary to guarantee the quality of a b-learning   process, with a more comprehensive face, towards inclusive   learning. Sixty-eight (68) face-to-face interviews were conducted   and validated, and a systematic content analysis was merged with a   multivariate analysis. The results reveal four profiles of teachers,   i.e., activities-oriented, interaction-oriented,   assessment-oriented, and collaboration-oriented, and three profiles   of students, i.e., interactive learning environment-oriented,   training-oriented, teachers' beliefs-oriented. In terms of   recognizing, understanding and responding to the academic community   specific needs, this study can support an inclusive,   multi-dimensional and holistic ICT knowledge for choosing adjustable   teaching-learning strategies that could be applied into the   enhancement of accessibility and info-inclusion into the learning   environment.               Keywords: Course Management System (CMS), accessibility, blended/inclusive learning, higher education, holistic Information and Communication Technologies (ICTs) knowledge, online teaching-learning process, users' profiles               Categories: L.2.2, L.3.0, L.3.4, L.3.5, L.3.6  
19|2|http://www.jucs.org/jucs_19_2|Software Components, Architectures   and ReuseModeling, Customization and Evaluation|
19|2||MDD Adoption in a Small   Company: Risk Management and Stakeholders' Acceptance|  Federico Tomassetti (Politecnico di Torino, Italy)   Marco Torchiano (Politecnico di Torino, Italy)   Lorenzo Bazzani (Trim srl, Italy)  Abstract: This article presents the knowledge and   experience acquired trough the process ofestablishing MDD practices   within a small Italian company. Special attention has been devoted   to project constraints, perceived risks, and relative mitigation   strategies. Moreover the articleevaluates how the introduction of   the MDD approach was received by different stakeholders. In   particular a structured questionnaire was the instrument used to   reveal and collect the perceptionsby different roles involved in the   MDD adoption process. The case study considered development of   applications conforming to a prescriptive architectural framework,   which addresses a complexmulti-tier architecture; the solution aims   at describing component composition while avoiding both repeating   tasks and writing awkward configurations.               Keywords: experience report, mode-driven development, risk management, small companies               Categories: H.5.5  
19|2||Modeling and Verification of Reconfigurable Actor Families|  Hamideh Sabouri (University of Tehran, Iran)   Ramtin Khosravi (University of Tehran, Iran)  Abstract: Software product line engineering enables   proactive reuse among a set of related products through explicit   modeling of commonalities and differences among them. Features are   usually used to distinguish different products as a product is   identified by its supported feature set that is represented by a   configuration. Dynamic product lines enhance flexibility of a   product by allowing run-time reconfiguration. In this paper, we   focus on modeling and verification of families of concurrent and   distributed systems that are reconfigurable. To this end, we   introduce the notion of variability in actor models to achieve   family of reconfigurable actors. Then, we present our methodology to   model this concept using the actor-based modeling language   Rebeca. The model checking backbone of Rebeca enables us to ensure   establishment of certain constraints on reconfigurations. We show   the applicability and effectiveness of our approach by applying it   on a set of case studies.               Keywords: actor models, dynamic software product lines, model checking, reconfiguration               Categories: D.2.13, D.2.4  
19|2||Domain-Oriented Customization of Service Platforms: Combining Product Line Engineering and Service-Oriented Computing|  Klaus Schmid (University of Hildesheim, Germany)   Holger Eichelberger (University of Hildesheim, Germany)   Christian Kröher (University of Hildesheim, Germany)  Abstract: Service-Oriented Computing (SoC) has been   established as an important paradigm over the last decade. A   particularly important part in a service-oriented solution is the   service-oriented platform. This provides an environment and   infrastructure for a number of service-oriented applications. An   important challenge in complex application areas is the need to   customize these platforms to the demands of a specific   context. Product line technologies can support this by providing the   concept of variability management to SoC. In this paper, we will   provide a reference model for (domain-specific) service platforms   and describe different approaches that provide customization   possibilities in a service platform context. The complexity of   handling the customization of large-scale service platforms in an   integrated manner will be addressed by introducing the concept of   production strategies for variability implementation   techniques.               Keywords: customization, domain-oriented, platform, service, software product line, variability               Categories: D.2.13, D.2.3  
19|2||Evaluation of a Systematic Approach to Requirements Reuse|  Fabiane Barreto Vavassori Benitti (Universidade do Vale do Itajaí, Brazil)   Rodrigo Cezario da Silva (Universidade do Vale do Itajaí, Brazil)  Abstract: The benefits of reusing artifacts in the   software development process are well-known in the software   engineering community, and the earlier in the system development   life-cycle reuse is attempted, the more benefit can be   expected. Thus, we highlight the reuse of requirement   specifications, leading to greater reuse of other artifacts such as   models, code and tests. This paper presents an approach to the   requirements reuse, supported by a tool that gives suggestions for   reuse from requirement patterns, a patterns catalog and traceability   between requirements. The efficiency and effectiveness of the   approach were evaluated using a quasi-experiment in a university. We   conducted a quantitative evaluation of the approach, and an   assessment of participants' perceptions regarding the use of the   approach and the computational tool. Finally, we performed a   qualitative assessment using the GQM method, from the point of view   of experts in the area of requirements engineering, in order to   obtain more indicators of the feasibility of applying the approach   in companies. The results of the quasi-experiment indicate that the   approach presented makes the activities of requirement elicitation   and specification about 40% more efficient and effective in terms of   the way they are conducted, without the support of the   approach. Regarding the perceptions on the use, the experimental   group positively evaluated the proposed approach and the developed   tool. Based on the evaluation by the GQM method, indicators were   obtained that the approach assists in activities of requirement   elicitation and specification, from the point of view of   experts.               Keywords: requirement patterns, requirements engineering, requirements reuse               Categories: D.2.1, D.2.13, M.8  
19|3|http://www.jucs.org/jucs_19_3|Managing Editor's Column|
19|3||Co-Allocation with Collective Requests in Grid Systems|  Matija Cankar (XLAB d.o.o., Slovenia)   Matej Artač (XLAB d.o.o., Slovenia)   Marjan Šterk (XLAB d.o.o., Slovenia)   Uroš Lotrič (University of Ljubljana, Slovenia)   Boštjan Slivnik (University of Ljubljana, Slovenia)  Abstract: We present a new algorithm for resource   allocation in large, heterogeneous grids. Its main advantage over   existing co-allocation algorithms is that it supports collective   requests with partial resource reservation, where the focus is on   better grid utilisation. Alongside the requests that must be   fulfilled by each resource, a collective request specifies the total   amount of a required resource property without a strict assumption   with regard to its distribution. As a consequence, the job becomes   much more flexible in terms of its resource assignment and the   co-allocation algorithm may therefore start the job earlier. This   flexibility increases grid utilisation as it allows an optimisation   of job placement that leads to a greater number of accepted   jobs. The proposed algorithm is implemented as a module in the   XtreemOS grid operating system. Its performance and complexity have   been assessed through experiments on the Grid'5000   infrastructure. The results reveal that in most cases the algorithm   returns optimal start times for jobs and acceptable, but sometimes   suboptimal resource sets.               Keywords: advance reservations, concurrency, grid computing, parallel applications, resource co-allocation               Categories: C.2.4, C.2.m, C.3  
19|3||Fast Self-Reconfigurable Embedded System on Spartan-3|  Enrique Cantó (University Rovira i Virgili, Spain)   Mariano Fons (University Rovira i Virgili, Spain)   Francesc Fons (University Rovira i Virgili, Spain)   Mariano López (Technical University of Catalonia, Spain)   Rafael Ramos (Technical University of Catalonia, Spain)  Abstract: Many image-processing algorithms require several   stages to be processed that cannot be resolved by embedded   microprocessors in a reasonable time, due to their   high-computational cost. A set of dedicated coprocessors can   accelerate the resolution of these algorithms, although the main   drawback is the area needed for their implementation. The main   advantage of a reconfigurable system is that several coprocessors   designed to perform different operations can be mapped on the same   area in a time-multiplexed way. This work presents the architecture   of an embedded system composed of a microprocessor and a run-time   reconfigurable coprocessor, mapped on Spartan-3, the low-cost family   of Xilinx FPGAs. Designing reconfigurable systems on Spartan-3   requires much design effort, since unlike higher cost families of   Xilinx FPGAs, this device does not officially support partial   reconfiguration. In order to overcome this drawback, the paper also   describes the main steps used in the design flow to obtain a   successful design. The main goal of the presented architecture is to   reduce the coprocessor reconfiguration time, as well as accelerate   image-processing algorithms. The experimental results demonstrate   significant improvement in both objectives. The reconfiguration rate   nearly achieves 320 Mb/s which is far superior to the previous   related works.               Keywords: FPGA, Spartan-3, embedded system, hardware accelerator, image-processing, partial reconfiguration, reconfigurable coprocessor               Categories: B.6.1, B.6.3, B.6.m, C.1.3, C.1.m  
19|3||Analysis of Mobile Service Usage Behaviour with Bayesian Belief Networks|"  Pekka Kekolahti (Aalto University, Finland)   Juuso Karikoski (Aalto University, Finland)  Abstract: The purpose of this paper is to identify   probabilistic relationships of mobile service usage behaviour, and   especially to understand the probabilistic relationship between   overall service usage diversity and average daily service usage   intensity. These are topical themes due to the high number of   services available in application stores which may or may not lead   to high usage diversity of mobile services. Four analytical methods   are used in the study, all are based on Bayesian Networks; 1) Visual   analysis of Bayesian Networks to find initially interesting   patterns, variables and their relationships, 2) user segmentation   analysis, 3) node force analysis and 4) a combination of   expert-based service clustering and machine learning for usage   diversity vs. intensity analysis. All the analyses were conducted   with handset-based data collected from university students and   staff. The analysis indicates that services exist, which mediate   usage of other services. In other words, usage of these services   increases the probability of using also other services. A service   called Installer is an example of this kind of a service. In   addition, probabilistic relationships can be found within certain   service cluster pairs in their usage diversity and intensity   values. Based on these relationships, similar mediation type of   behaviour can be found for service clusters as for individual   services. This is most visible in the relation between   System/Utilities and Business/Productivity service clusters. They do   not have a direct relationship but usage diversity is a mediator   between them. Furthermore, segmentation analysis shows that the user   segment called ""experimentalists"" uses more mediator services than   other user segments. Furthermore, ""experimentalists"" use a much   broader set of services daily, than the other segments. This study   demonstrates that a Bayesian Network is a straightforward way to   express model characteristics on high level. Moreover, Node Force,   Direct and Total effect are useful metrics to measure the mediation   effects. The clustering implemented as a hybrid of machine learning   and expert-based clustering process is also a useful way to   calculate relationships between clusters of more than a hundred   individual services.               Keywords: Bayesian Networks, clustering, handset-based data, machine learning, mobile services, segmentation               Categories: H.4.0, I.2.6, I.5.1  "
19|3||Specifying Patterns of Educational Settings by means of Ontologies|  Angels Rius (Universitat Oberta de Catalunya, Spain)   Jordi Conesa (Universitat Oberta de Catalunya, Spain)   Elena García-Barriocanal (University of Alcalá, Spain)   Miguel-Angel Sicília (University of Alcalá, Spain)  Abstract: Beyond the kind of processes dealt with the IMS   LD specification, there are other kinds of processes, which are   repeated periodically in learning environments that have not already   been described yet due to the lack of mechanisms to describe them   effectively. Inspired by the standard specification of language   processes in the business area and taking into account the patterns   philosophy used in the software engineering field, we propose an   open framework to formally describe generic processes that usually   occurs in the learning environments as patterns of educational   settings. The main contribution of this paper is an extensible   ontology-based framework to specify processes in learning   environments. This framework has been created with the aim of   improving the reusability of its formal specifications independently   of the educational institutions where the processes occur and the   learning platforms that support such processes. As a result of this   work we have created a graphical notation for specifying such kind   of processes easily and a CASE tool to facilitate its representation   and the population of the ontological framework. In a future this   framework could be extended to take more advantages: adapting the   specifications of patterns to different educational institutions,   using an implementation profile to achieve implementation   descriptions or other standards to provide other output   formats.               Keywords: analysis patterns, educational settings, model driven development, ontology, process modelling               Categories: D.2.1, D.2.1.3, D.3.1, I.5, L.3.4, M.8  
19|3||Text Representation for Efficient Document Annotation|  Christin Seifert (Passau University, Germany)   Eva Ulbrich (Know-Center Graz, Austria)   Roman Kern (Know-Center Graz, Austria)   Michael Granitzer (Passau University, Germany)  Abstract: In text classification the amount and quality of   training data is crucial for the performance of the classifier. The   generation of training data is done by human labellers - a tedious   and time-consuming work. To reduce the labelling time for single   documents we propose to use condensed representations of text   documents instead of the full-text document. These condensed   representations are key sentences and key phrases and can be   generated in a fully unsupervised way. We extended and evaluated the   TextRank algorithm to automatically extract key sentences and key   phrases. For representing key phrases we propose a layout similar to   a tag cloud. In a user study with 37 participants we evaluated   whether document labelling with these condensed representations can   be done faster and equally accurate by the human labellers. Our   evaluation shows that the users labelled tag clouds twice as fast   and as accurately as full-text documents. While further   investigations for different classification tasks are necessary,   this insight could potentially reduce costs for the labelling   process of text documents.               Keywords: TextRank, data mining, document labelling, supervised learning, tag clouds, text summarisation, word clouds               Categories: H.1.2, H.1.7  
19|3||A Decoupled Architecture for Scalability in Text Mining Applications|  Jorge Villalon    Rafael A. Calvo (University of Sydney, Australia)  Abstract: Sophisticated Text Mining features such as   visualization, summarization, and clustering are becoming   increasingly common in software applications. In Text Mining,   documents are processed using techniques from different areas which   can be very expensive in computation cost. This poses a scalability   challenge for real-life applications in which users behavior can not   be entirely predicted. This paper proposes a decoupled architecture   for document processing in Text Mining applications, that allows   applications to be scalable for large corpora and real-time   processing. It contributes a software architecture designed around   these requirements and presents TML, a Text Mining Library that   implements the architecture. An experimental evaluation on its   scalability using a standard corpus is also presented, and empirical   evidence on its performance as part of an automated feedback system   for writing tasks used by real students.               Keywords: automatic feedback, software architecture, text mining               Categories: D.2.11, I.7, L.3, M.1  
19|3||A Comparison of Five Programming Languages in a Graph Clustering Scenario|  Martin Stein (Karlsruhe Institute of Technology, Germany)   Andreas Geyer-Schulz (Karlsruhe Institute of Technology, Germany)  Abstract: The recent rise of social networks fuels the   demand for efficient social web services,whose performance strongly   benefits from the availability of fast graph clustering   algorithms. Choosing a programming language heavily affects multiple   aspects in this domain, such as run-time performance, code size,   maintainability and tool support. Thus, an impartial comparison can   provide valuable insights that are also useful for software   development in general. This article in-vestigates the languages   C++, Java, C#, F# and Python (as well as its close variant Cython)   in a controlled scenario: In each language, a graph clustering task   is implemented and executed. Thepaper introduces the problem to be   solved and gives an overview over the different characteristics of   the languages. After a detailed description of the testing   environment, we report runtime,memory and code size results and   discuss them with respect to the characteristics mentioned   before. The findings indicate C++ as the fastest language for the   challenge at hand, but they alsoshow that Java, C# and F# come close   under some circumstances. Furthermore, it becomes clear that the   amount of code can be significantly reduced with modern languages   like Python or F#.               Keywords: Benchmark, Graph Clustering, Language Performance, Modularity, Programming Languages               Categories: C.4, D.3, G.2.2  
19|4|http://www.jucs.org/jucs_19_4|Hybrid and Ensemble Methods in Machine Learning|
19|4||Concept Drift Detection and Model Selection with Simulated Recurrence and Ensembles of Statistical Detectors|  Piotr Sobolewski (Wrocław University of Technology, Poland)   Michal Woźniak (Wrocław University of Technology, Poland)  Abstract: The paper presents a concept drift detection   method for unsupervised learning which takes into consideration the   prior knowledge to select the most appropriate classification   model. The prior knowledge carries information about the data   distribution patterns that reflect different concepts, which may   occur in the data stream. The presented method serves as a temporary   solution for a classification system after a virtual concept drift   and also provides additional information about the concept data   distribution for adapting the classification model. Presented   detector uses a developed method called simulated recurrence and   detector ensembles based on statistical tests. Evaluation is   performed on benchmark datasets.               Keywords: concept drift detection, detector ensembles, simulated recurrence               Categories: H.2.8, I.2.6, I.5.2  
19|4||Improving Accuracy of Decision Trees Using Clustering Techniques|  Javier Torres-Niño (University Carlos III Madrid, Spain)   Alejandro Rodríguez-González (Centre for Plant Biotechnology and Genomics UPM-INIA, Spain)   Ricardo Colomo-Palacios (University Carlos III Madrid, Spain)   Enrique Jiménez-Domingo (University Carlos III Madrid, Spain)   Giner Alor-Hernandez (Instituto Tecnológico de Orizaba, Mexico)  Abstract: Data mining is an important part of information   management technology. Simply put, it is a method to extract and   analyze meaningful patterns and correlations in a large relational   database. In Data mining, Decision trees are one of the most   worldwide used tools for decision support.  In the emerging area of   Data mining applications, users of data mining tools are faced with   the problem of data sets that are comprised of large numbers of   features and instances. Such kinds of data sets are not easy to   handle for mining because decision trees generally depends on   several parameters like dataset used and configuration of the tree   itself among others in order to build an accurate model   classification.  In this work a novel hybrid classifier system is   presented for improving accuracy of decision trees using clustering   techniques. This system is formed by a clustering algorithm, a   decision tree and an optional module for identifying appropriate   parameters for the clustering algorithm. These three modules working   together are capable to increase the accuracy of the solutions. The   validation of the results of this work has been performed using   several well-known datasets and applying two decision trees   algorithms. The accuracy percentages are compared in order to show   our proposal improvement, obtaining good results. Finally two   clustering algorithms have been used to compare the accuracy between   different proposals.               Keywords: accuracy improvement, clustering, decision tree               Categories: H.3.3, I.5.2, I.6.1  
19|4||Boosting-based Multi-label Classification|  Tomasz Kajdanowicz (Wrocław University of Technology, Poland)   Przemyslaw Kazienko (Wrocław University of Technology, Poland)  Abstract: Multi-label classification is a machine learning   task that assumes that a data instance may be assigned with multiple   number of class labels at the same time. Modelling of this problem   has become an important research topic recently. This paper revokes   AdaBoostSeq multi-label classification algorithm and examines it in   order to check its robustness properties. It can be stated that   AdaBoostSeq is able to result with quite stable Hamming Loss   evaluation measure regardless of the size of input and output   space.               Keywords: AdaBoostSeq, boosting, machine learning, multi-label classification               Categories: I.2, I.2.6, I.2.8  
19|4||An Integrated MFFP-tree Algorithm for Mining Global Fuzzy Rules from Distributed Databases|  Chun-Wei Lin (Harbin Institute of Technology, P.R. China)   Tzung-Pei Hong    Yi-Fan Chen (National University of Kaohsiung, R.O.C.)   Tsung-Ching Lin (National University of Kaohsiung, R.O.C.)   Shing-Tai Pan (National University of Kaohsiung, R.O.C.)  Abstract: In the past, many algorithms have been proposed   for mining association rules from binary databases. Transactions   with quantitative values are, however, also commonly seen in   real-world applications. Each transaction in a quantitative database   consists of items with their purchased quantities. The multiple   fuzzy frequent pattern tree (MFFP-tree) algorithm was thus designed   to handle a quantitative database for efficiently mining complete   fuzzy frequent itemsets. It however, only processes a database for   mining the desired rules. In this paper, we propose an integrated   MFFP (called iMFFP)-tree algorithm for merging several individual   MFFP trees into an integrated one. The proposed iMFFP-tree algorithm   firstly handles the fuzzy regions for providing linguistic knowledge   for human beings. The integration mechanism of the proposed   algorithm thus efficiently and completely moves a branch from one   sub-tree to the integrated tree. The proposed approach can derive   both global and local fuzzy rules from distributed databases, thus   allowing managers to make more significant and flexible   decisions. Experimental results also showed the performance of the   proposed approach.               Keywords: distributed database, fuzzy data mining, iMFFP tree, integration, quantitative database               Categories: E.1, H.2.8, M.4, M.7  
19|4||Evolutionary Fuzzy System Ensemble Approach to Model Real Estate Market based on Data Stream Exploration|  Bogdan Trawiński (Wrocław University of Technology, Poland)  Abstract: An approach to predict from a data stream of   real estate sales transactions based on ensembles of genetic fuzzy   systems was presented. The proposed method relies on incremental   expanding an ensemble by models built over successive chunks of a   data stream. The output of aged component models produced for   current data is updated according to a trend function reflecting the   changes of premises prices since the moment of individual model   generation or the beginning of the data stream. The impact of   different trend functions on the accuracy of single and ensemble   fuzzy models was investigated in the paper. Intensive experiments   were conducted to evaluate the proposed method using real-world data   taken from a dynamically changing real estate market. The   statistical analysis of experimental output was made employing the   nonparametric methodology designed especially for multiple   comparisons including Friedman tests followed by Nemenyi's, Holm's,   Shaffer's, and Bergmann-Hommel's post-hoc procedures. The results   proved the usefulness of ensemble approach incorporating the   correction of individual component model output.               Keywords: Property valuation, data stream, ensembles, genetic fuzzy systems, predictive models, sliding windows, trend functions               Categories: H.2.8, I.2.6, I.5.2  
19|4||A Semi-Supervised Ensemble Learning Method for Finding Discriminative Motifs and its Application|  Thi Nhan Le (Japan Advanced Institute of Science and Technology, Japan)   Tu Bao Ho (Japan Advanced Institute of Science and Technology, Japan)   Saori Kawasaki (Japan Advanced Institute of Science and Technology, Japan)   Tatsuo Kanda (Chiba University, Japan)   Katsuhiko Takabayashi (Chiba University, Japan)   Shuang Wu (Chiba University, Japan)   Osamu Yokosuka (Chiba University, Japan)  Abstract: Finding discriminative motifs has recently   received much attention in biomedicine as such motifs allow us to   characterize in distinguishing two different classes of   sequences. It is common in biomedical applications that the quantity   of labeled sequences is very limited while a large number of   unlabeled sequences is usually available. The current methods of   discriminative motif finding are powerful and effective with large   labeled datasets, but they do not function well on small labeled   datasets. In this paper, we present a semi-supervised ensemble   method for finding discriminative motifs which is based on the SLUPC   algorithm, a separate-and-conquer searching method to discover   motifs of type `discriminative one occurrence per sequence'. The   proposed method, named E-SLUPC (Ensemble SLUPC), uses SLUPC to   search discriminative motifs from an extended labeled dataset that   contains labeled data and unlabeled data with predicted   labels. Strong discriminative and frequent motifs characterizing two   outcome classes of hepatitis C virus treatment (sustained viral   response and non-sustained viral response) were detected and   analyzed. Furthermore, the experimental evaluation shows that our   method can function considerably well in the common context of   medical research when the labeled data is usually difficult to   obtain.               Keywords: NS5A region, discriminative motif, ensemble learning, hepatitis C virus, self-training technique, separate-and-conquer search               Categories: I.5  
19|4||Integrating Multiple Experts for Correction Process in InteractiveRecommendation Systems|  Xuan Hau Pham (Quang Binh University, Vietnam)   Jason J. Jung (Yeungnam University, Korea)   Ngoc Thanh Nguyen (Vietnam National University, Vietnam)  Abstract: User rating is obviously considered to be an   important type of feedback informationfor Interactive Recommendation   System (RecSys). The quality and credibility of user ratings will   eventually influence the quality of recommendation. However, in the   real world, there areusually many inconsistent (e.g., mistakes and   missing values) or incorrect user ratings. Therefore, expert-based   recommendation framework has been studied to select the most   relevant expertsregarding a certain item's attribute (or   value). This kind of RecSys can i) discover user preferenceand ii)   determine a set of experts based on attributes and values of   items. In this paper, wepropose a consensual recommendation   framework, by integrating multiple experts' ratings, to conduct a   correction process which aims at modifying the ratings of other   users in order to makethe system more effective. Since our work   assumes that ratings from experts are assumed to be reliable and   correct, we first analyze user profile so as to determine   preferences and find out aset of experts. Next, we measure a minimal   inconsistency interval (MinIncInt) that might contain incorrect   ratings. Finally, we propose solutions to correct incorrect ratings   based on ratings frommultiple experts. The results show that our   solutions can improve both the ratings and the quality of RecSys on   the whole.               Keywords: RecSys, consensus, experts, incorrect rating, interactive recommendation systems, user preference               Categories: H.1.1, H.3.5, I.2.11  
19|5|http://www.jucs.org/jucs_19_5|Innovative Instructional Technologies|
19|5||Effectiveness of Cloud Systems and Social Networks in Improving Self-directed Learning Abilities and Developing Positive Seamless Learning Perceptions|"  Fezile Ozdamli (Near East University, Turkey)  Abstract: This study aims to analyze the conditions which affect students' perception on self-directed abilities and seamless learning using cloud systems and social network applications. A combination of qualitative and quantitative methods was used in the study. Forty teacher candidates from the Near East University who took the course ""Special Learning Methods"" participated in the study. The study was carried out in one academic semester (12 weeks) according to the blended learning approach. Each learner had an individually networked laptop or another mobile device which included a ""clip to EverNote"". The results indicated that Mobile Supported Seamless Learning spaces (MSSL) support flexibility in place and time of learning, improve learners' self-directed learning, and change their perceptions on seamless learning.               Keywords: cloud systems, mobile learning, seamless learning               Categories: L.3.0, L.3.5, L.3.6  "
19|5||Meta-Cognitive Tool Development for History Teaching: Investigating how Software Usability Affects Student Achievements|  Dilek Karahoca (University of Bahcesehir, Turkey)  Abstract: This paper presents a Meta-Cognitive Tool (MCT)   development for history teaching. It was developed to support   teaching history of civilization courses at the engineering faculty.   It covers hierarchically arranged concept maps which are presented   dynamically by using Extensible Markup Language (XML) files. MCTs   are integrated in e-learning portals to support self-learning. MCTs   were investigated in terms of the Human Computer Interaction (HCI)   discipline to evaluate their usability in online courses. For this   purpose, relationships between learners' cognitive abilities,   individual differences, and usability of e-learning portal were   considered in order to create a model between individual differences   and software usability. The usability of MCT was evaluated by 116   (70 male, 46 female) subjects who were registered for the HUM1005   History of Civilization I, a general elective course at the faculty   of engineering. They completed four different surveys: an IQ survey,   a personality survey, a motivation survey, and a software usability   measurement inventory (SUMI). This research compares intelligence,   personal factors, and motivation factors with the personal software   usability results in order to determine the correlations and   associations between the usability of the software and learners   individual differences. In the study, results show that the   usability of any education tool has effect on achievement of the   learner. Noteworthy, a correlation was found between Grade Point   Average (GPA) and usability scores.               Keywords: computer systems organization, information systems, software               Categories: C.0, D.1.7, H.2  
19|5||"Evaluation of Turkish ""E-Okul"" System in Terms of Usability"|"  Aslıhan Tüfekci (Gazi University, Turkey)  Abstract: Recently, many institutions have started to   offer online services via the internet. In this respect, it can be   said that one of the most frequently accessed websites in Turkey is   the ""e-Okul"" system offering services in the field of education. The   current study aims at evaluating the ""e-Okul"" system used by   parents, students and teachers, in terms of usability, identifying   the factors affecting its usability and, later, offering some   suggestions to increase its effectiveness and quality. In the study,   the ""e-Okul"" system was evaluated by ten high school teachers and 95   students and their parents. The Usability Test was administered to   the teachers. Components of this Usability Test included a   Demographic Survey, a Task List, a Satisfaction Questionnaire and an   Observation Form that were used as data collection tools. The   parents and students completed an Attitude Questionnaire. The data   obtained was analysed on the basis of effectiveness, efficiency and   satisfaction criteria, which form the basis for usability. According   to the results of the study, the users reported some design and   navigation problems, especially regarding the pages enabling access   to student information. Nevertheless, the parents and students were   found to be satisfied with the ""e-Okul"" system.               Keywords: ""e-Okul"" system, ICT, human-computer interaction, usability, usability tests               Categories: H.5.2, L.3.1  "
19|5||The Use of Social Networking Sites in Education: A Case Study of Facebook|"  Huseyin Bicen (Near East University, Turkey)   Huseyin Uzunboylu (Near East University, Turkey)  Abstract: The purpose of this research is to find out how   Facebook and Web 2.0 tools create a positive effect when used in   education and to investigate teachers' opinions about the Online   learning environment. This experimental study was carried out in   primary and secondary schools with teachers who use Facebook. The   study took six weeks and 30 hours. The teachers attended lessons and   accessed materials online and offline, in face-to-face learning   environment. Moreover, they were able to co-operate and share   information with their colleagues via Facebook. The study sample   consisted of 35 teachers from primary and secondary school who   constituted a blended learning group and 36 teachers from primary   and high school who formed an online learning group that enrolled in   the material development for Facebook course. These teachers were   chosen randomly. The participation was anonymous and the study was   carried out amongst volunteered teachers. Data was collected using a   5-point Likert scale questionnaire created by the authors and   entitled ""Teachers' Opinions about Facebook in Education"". The   questionnaire consisted of 39 positive statements about Facebook. It   was completed by teachers at the beginning (pre-experience test) and   the end of the study (post-experience test). Results show that, if   used for educational purposes, Facebook could bring about a positive   change in teachers' opinions. Results also indicate that Facebook   virtual environment helps teachers to do many activities with online   classes, which is not possible to do in schools. Teachers are   convinced that this environment helps students not only to improve   their team work, but also to improve their learning skills. Based on   the findings, recommendations are made about using Facebook in   education.               Keywords: Facebook, Web 2.0 tools, social networking, virtual learning environment               Categories: L.1.4, L.3.0, L.6.0, L.6.1  "
19|5||Tweeters on Campus: Twitter a Learning Tool in Classroom?|  Amandeep Dhir (Aalto University, Finland)   Khalid Buragga (King Faisal University, Saudi Arabia)   Abeer A. Boreqqah (King Faisal University, Saudi Arabia)  Abstract: Twitter is a well-known Web 2.0 microblogging   social networking site that is quite popular for organizing events   and sharing updates. It provides just in time communication, social   connectivity and immediate feedback through Web, smartphones, tablet   PCs, etc. The use of Twitter has also attracted educators and   researchers due to its growing popularity among students, teachers,   and academic communities as a whole. This study provides a critical   review of Twitter use in educational settings. By practicing a   systematic research methodology in the selection and review of   literature, different pedagogical and instructional benefits and   drawbacks of Twitter use in education were discussed. Based on these   discussions, it was discovered that Twitter has positive impact on   informal learning, class dynamics, motivation, as well as the   academic and psychological development of young students. However,   the potential long-term impact of Twitter on academic performance of   students and its long-term effect on learning is still worth   investigating.               Keywords: Twitter, classroom, educational technology, instruction, learning, learning management system, microblogging, pedagogy               Categories:  L.3.6, H.4.0, H.5, H.5.2, L.0.0, L.2.7, L.3.1, L.3.3, L.3.4  
19|5||Parent Opinions with Regard to Elementary School Student's Use of the Internet|  Murat Tezer (Near East University, North Cyprus)  Abstract: In the study, while parent opinions were asked   with regards to the use of the internet, a 5-point Likert type   questionnaire form was used to collect opinions, and the resulting   data was analysed to find the arithmetic mean, standard deviation   and t-test analysis using the SPSS 20.0 packet program. Following   the study, student parents stated positive opinions with regards to   internet usage. Also, in this study, necessary suggestions were made   so that families could educate their children with regards to the   internet and help them.               Keywords: Internet, Web, chidren, elementary school, family, father, mother, parent, student internet use               Categories: K.3.1, K.3.2, L.2.0, L.3.1, L.3.6  
19|5||The Role of the iPad in the Hands of the Learner|  Amandeep Dhir (Aalto University, Finland)   Nahla M. Gahwaji (King Abdulaziz University, Saudi Arabia)   Gote Nyman (University of Helsinki, Finland)  Abstract: The iPad is a well-known handheld interactive   multimedia tool that has been quite popular lately among teachers   and students. Previous research indicates that handheld digital   technology is, in general, capable of supporting learning and   educational literacy; however, iPad-focused studies are still   scarce. In this study, we access and review the instructional   benefits of using the iPad in educational spaces, such as classrooms   and laboratories, by reviewing a vast body of empirical and   theoretical findings reported by multidisciplinary literature on   digital technology and children, digital technology use in   classrooms, and the impact of interactive technology on learning,   instruction, and educational literature. We found that while some   studies suggest that the iPad motivates and brings positive impact   among students towards their studies, other studies suggest that the   long-term impact of the iPad on learning could be even   negative. Therefore, we highlight the common misconceptions and   conflicts about the use of this new technology and discuss its   advantages and challenges. We also sketch some of the future trends   relevant to incorporating the iPad into our learning   setups.               Keywords: collaborative work, educational games, iPad, instruction, interactive technology, learning, pedagogy               Categories: H.5.0, H.5.2, L.2.1, L.3.1, L.3.4, L.3.6, L.3.8  
19|6|http://www.jucs.org/jucs_19_6|Managing Editor's Column|
19|6||Investigations on a Pedagogical Calculus of Constructions|"  Loïc Colson (LITA, University of Lorraine, France)   Vincent Demange (LITA, University of Lorraine, France)  Abstract: In the last few years appeared   pedagogical propositional natural deduction   systems. In these systems one must satisfy the   pedagogical constraint: the user must give an   example of any introduced notion. In formal   terms, for instance in the propositional case, the main modification   is that we replace the usual rule (hyp) by the rule (p-hyp)       where   σ denotes a substitution which replaces variables of Γ   with an example. This substitution σ is called the motivation   of Γ.    First we expose the reasons of such   a constraint and properties of these ""pedagogical"" calculi: the   absence of negation at logical side, and the ""usefulness"" feature of   terms at computational side (through the Curry-Howard   correspondence). Then we construct a simple pedagogical restriction   of the calculus of constructions (CC) called   CCr. We establish logical limitations of this   system, and compare its computational expressiveness to Gödel   system T.  Finally, guided by the logical limitations of CCr, we give a formal and general definition of a pedagogical calculus of constructions.               Keywords: calculus of constructions, constructive mathematics, mathematical logic, negationless mathematics, pedagogical system, typed lambda-calculus               Categories: F.1.1, F.4.1  "
19|6||The Riesz Representation Operator on the Dual of C[0; 1] is Computable|  Tahereh Jafarikhah (University of Tarbiat Modares, Iran)   Klaus Weihrauch (University of Hagen, Germany)  Abstract: By the Riesz representation theorem,   for every linear functional F : C[0; 1] → ℝ there is a function g : [0; 1] →  ℝ of bounded variation such that      A computable version is proved in [Lu and Weihrauch(2007)]: a function g can be computed from F and its norm, and F can be computed from g and an upper bound of its total variation. In this article we present a much more transparent proof. We first give a new proof of the classical theorem from which we then can derive the computable version easily. As in [Lu and Weihrauch(2007)] we use the framework of TTE, the representation approach for computable analysis, which allows to define natural concepts of computability for the operators under consideration.               Keywords: Riesz representation theorem, computable analysis               Categories: F.0, F.1.1  
19|6||Compositionally Writing Proof Scores of Invariants in the OTS/CafeOBJ Method|  Kazuhiro Ogata (Japan Advanced Institute of Science and Technology (JAIST), Japan)   Kokichi Futatsugi (Japan Advanced Institute of Science and Technology (JAIST), Japan)  Abstract: Observational transition systems (OTSs) are   state machines that can be described as behavioral specifications in   CafeOBJ, an algebraic specification language and processor. The   OTS/CafeOBJ method uses OTSs and CafeOBJ for systems specification   and verification. Simultaneous induction is intensively used to   prove that an OTS enjoys invariants in the method. To prove that two   state predicates p and q are invariants with respect to an OTS S,   simultaneous induction generates the proof obligations: (1) p(υ0)   and p(υ) ∧ q(υ) ⇒ p(υ′), and (2) q(υ0) and p(υ) ∧ q(υ) ⇒   q(υ′) for each initial state υ0, each state υ and each successor   state υ′ of υ. Instead, we may also use the proof obligations: (1)   q(υ) ⇒ p(υ), and (2) q(υ0) and p(υ) ∧ q(υ) ⇒ q(υ′). The proof   technique generating proof obligations like this is called   semi-simultaneous induction. The proof obligation is equivalent to   (1) q(υ) ⇒ p(υ), and (2) q(υ0) and q(υ) ⇒ q(υ′). But, the   former may need less cases, making proofs shorter, than the   latter. More importantly, the former makes it possible to record the   process in which way lemmas have been conjectured. This article   demonstrates some benefits of (semi)simultaneous induction,   describes semi-simultaneous induction and justifies it.               Keywords: CafeOBJ, algebraic specification, invariant, observational transition system (OTS), simultaneous induction               Categories:  D.2.4, F.3.1  
19|6||LeadFlow4LD: A Method for the Computational Representation of the Learning Flow and Data Flow in Collaborative Learning|  Luis Palomino-Ramírez (ITESM, Campus Guadalajara, Mexico)   Miguel L. Bote-Lorenzo (University of Valladolid, Spain)   Juan I. Asensio-Pérez (University of Valladolid, Spain)   Laurence Vignollet (University of Savoie, France)   Yannis A. Dimitriadis (University of Valladolid, Spain)  Abstract: A computer representation of teaching-learning   processes in collaborative learning settings consists of modelling   not only the sequence of learning activities and educational   resources as existing learning design languages propose, but also   modelling both the sequence of invocations of tools needed to carry   out the learning activities and the flow of data among those   tools. Existing data flow approaches only model data with activities   but not data with tools. In this paper, we present LeadFlow4LD, a   learning design and workflow-based method to achieve such a   computational representation of collaborative learning processes in   an interoperable and standard way. The proposed method has been   assessed through the specification and enactment of a variety of   non-trivial collaborative learning situations. The experimental   results indicate that the level of expressiveness of the proposal is   adequate in order to represent the flow of tools invocations and   data which was missing in other existing research approaches.               Keywords: CSCL, IMS LD, data flow, learning design, learning flow, workflow               Categories: L.3.0, L.3.6  
19|6||Defining Distribution Constraints in Distributed User Interfaces|  Antonio Peñalver (Miguel Hernández University, Spain)   José Juán López (Miguel Hernández University, Spain)   Federico Botella (Miguel Hernández University, Spain)   José A. Gallud (Castilla la Mancha University, Spain)  Abstract: At present, the spread of hand held devices   with growing computing power and functionality allows that different   interaction elements can be distributed among a wide range of   devices from different platforms, supporting interaction with one or   many users. To take advantage of the benefits this kind of devices   provides, traditional user interfaces have been evolving towards   distributed user ones. The specification of the constraints on the   way in which these elements can be distributed is still an open   field and further research is needed. In this paper we propose a new   schema-based definition of Distributed User Interfaces (DUIs),   allowing the specification of the elements to be distributed,   defining constraints on the distribution process itself,   independently of the language selected to construct the   interface. Thus, the interface distribution process becomes the   creation of an XML instance from a grammar specified in Schema   language. We also introduce two new definitions to complete the   formalization of our previous definition of DUI. Our previously   defined Abstract User Interface (AUI) model jointly with this new   schema-based definition of DUIs will lead us to the full   specification of concrete DUIs. We provide some examples of the   distribution process using the proposed schema.               Keywords: distributed user interfaces, formal models, schemas               Categories: H.5.2, H.5.3  
19|7|http://www.jucs.org/jucs_19_7|Interaction Design in Educational Environments|
19|7||The Implementation, Deployment and Evaluation of a Mobile Personal Learning Environment|  Miguel Á Conde (University of Salamanca, Spain)   Francisco J. García-Peñalvo (University of Salamanca, Spain)   Marc Alier (Polytechnic University of Catalonia, Spain)   Jordi Piguillem (Polytechnic University of Catalonia, Spain)  Abstract: The application of ICT to learning, the Web 2.0   trends and the widespread use of technologies such as mobile devices   make it necessary to provide new solutions to satisfy the needs of   learners. Such solutions should treat the students as the centre of   the learning process. The students should be able to decide which   tools they will use to learn, and the learning institution must   consider the behaviour of students in such personal learning   activities independently of the location where learning activities   are carried out. In addition, learners can choose the type of   devices they will use with special attention to mobile   technologies. The work described in this paper proposes a   service-based approach to defining mobile personal learning   environments that facilitates communication with institutional   learning platforms. Such an approach is implemented as a   proof-of-concept and evaluated via a pilot study to demonstrate that   such types of mobile learning platforms are feasible and can   increase students' motivation to help them learn.               Keywords: Learning Management Systems, Personal Learning Environments, mLearning, mobile devices, students               Categories: L.2.0, L.2.1, L.2.2, L.2.3, L.3.0, L.3.6  
19|7||On the Development and Usability of a Diagram-based Collaborative   Brainstorming Component|  Diogo Azevedo (INESC TEC - INESC Technology & Science, Portugal)   Benjamim Fonseca (INESC TEC - INESC Technology & Science, Portugal)   Hugo Paredes (INESC TEC - INESC Technology & Science, Portugal)   Stephan Lukosch (Delft University of Technology, The Netherlands)   Jordan Janeiro (Delft University of Technology, The Netherlands)   Robert Owen Briggs (San Diego University, USA)  Abstract: The need for computer-supported collaboration   has grown over the last years and made collaboration an important   factor within organizations. This trend has resulted in the   development of a variety of tools and technologies to support the   various forms of collaboration. Many collaborative processes,   e.g. strategy building, scenario analysis, root cause analysis and   requirements engineering, require various collaboration support   tools. Data flow, fishbone and brainstorming diagrams, play an   important role within these synchronous collaborative applications   to create, evaluate, elaborate, discuss, and revise graphical   models. Currently, the necessary tools are not integrated and   flexible enough to support such processes. In this paper, a   synchronous collaborative brainstorming diagram editor integrated in   a flexible group support system is described. This approach goes   beyond the current state of the art as it can be seamlessly   integrated with other collaboration support tools such as text-based   brainstorming or voting. The usability of the taken approach is   evaluated within a case study on collaborative learning.               Keywords: ActionCenters, CSCW, Diagram Editor, brainstorm, collaboration, diagram-based               Categories: D.2.1, D.2.13, D.2.2, H.5.3, J.0  
19|7||Collaborative e-Learning through Drag & Share in Synchronous Shared Workspaces|  Felix Albertos Marco (University of Castilla-La Mancha, Spain)   Victor M.R. Penichet (University of Castilla-La Mancha, Spain)   José A. Gallud (University of Castilla-La Mancha, Spain)  Abstract: e-Learning platforms allow users to collaborate   with one other. Moodle, as one of the main e-Learning platforms,   provides tools to perform collaborative tasks. With these tasks,   students are able to share documents and information. The means   provided by Moodle are not enough to perform some collaborative   tasks, such as sharing documents in real-time. In this scenario   users must be aware of what is happening in the system   effectively. We propose the use of Drag & Share within Moodle, a   collaborative tool that allows users to synchronously share   resources in real-time. Through this tool, teachers are able to   easily provide a shared workspace for students and be able to create   groups. With such a tool, students can share all kind of resources   and be aware of what is going on in the system in which they are   participating and of what they are doing. All these features use   standard technologies, such as HTML5.               Keywords: HTML5, Moodle, awareness, collaboration, eLearning, real time, shared workspaces               Categories: K.3.1, K.4.3  
19|7||PETs at CSCL Service: Underutilised Potentials for Privacy Enhancing Distance Education|  Mohamed Bourimi (University of Siegen, Germany)   Dogan Kesdogan (University of Siegen, Germany)   Marcel Heupel (University of Siegen, Germany)   Dhiah el Diehn I. Abou-Tair (German Jordanian University, Jordan)   Niki Lambropoulos (University of Patras, Greece)  Abstract: Computer Supported Collaborative Learning (CSCL)   support is currently widely accepted to provide reliable and valid   formal and informal educational practices as proven to benefit   students in onsite as well as distant educational settings. However,   some results from case studies indicate that privacy problems could   negatively affect CSCL implementation in educational   settings. Privacy Enhancing Technologies research (PETs) and the   development of multilaterally secure systems are still limited   research topics within CSCL due to diverse reasons. Based on deep   related literature analysis and previous research results conducted   by the authors in building CSCL systems, three main categories were   identified for such reasons that have an impact in PETs and   multilateral security research: lack of awareness of such PETs   existence; lack of knowledge on ways to efficiently integrate them   in CSCL systems and settings; and reluctance to consider their   multilaterally secure implementation by CSCL participations due to   conflict of interests (e.g. explicit students monitoring   requirements, high integration costs, etc.). In this paper, these   categories are addressed and the PETs potential is discussed for   overcoming the associated emerging drawbacks focused on the distance   education CSCL settings in particular. The result of our research is   an integrated framework considering multilateral security   requirements.  Furthermore, proof of concept is provided; enhanced   privacy in such settings is applied by demonstrating the fulfilment   of selected improvements areas (i.e. mainly network, application   anonymity, and process support for resolving potential multilateral   security conflicts) in an existing collaborative distance education   system.                 Categories: H.4.1, K.3.1, K.6.m, K.8.m  
19|7||Assessment of Open-Ended Questions using a Multidimensional Approach for the Interaction and Collaboration of Learners in E-Learning Environments|  Loc Phuoc Hoang (Khon Kaen University, Thailand)   Ngamnij Arch-Int (Khon Kaen University, Thailand)  Abstract: Currently, the assessment of learners in   conventional e-learning systems is only one dimension in which   learners are required to produce answers, for example, by selecting   multiple-choice, true/false, or matching answers or by giving short   answers. This type of assessment still lacks interactions among the   learners, and thus, it might not fully support learning. Many   researchers have endeavored to propose an open-ended question method   for evaluation, but their methods still focus on content assessment   rather than learners' activities, which again lacks interactions   among the learners. This paper concentrates on creating a new   assessment method using open-ended questions with the aim of   enhancing collaborations, activities and interactions of learners at   the same time. The objectives are as follows: 1) to develop a   process model for multidimensional assessment (M-DA) to enable   effective learning; 2) to develop free-text answer assessments using   a vector space model and a semantic extraction model; and 3) to   develop an algorithm for evaluating learners based on a M-DA to   encourage learners' activities. In addition, we created an   environment for learners to be actively assessed and to interact   with others when studying online. Two groups of parallel learners   taking an e-course were tested on the two systems in a virtual   learning environment. The results of the experiment noted that the   system with multidimensional assessment showed a better outcome than   the system without M-DA.               Keywords: E-learning collaboration, collaborative virtual environment, free-text answers assessment, multidimensional assessment (M-DA), vector space model               Categories: I.2.7, L.0.0, L.0.1, L.2.0, L.3.5, L.3.6, L.6.2  
19|7||Interactive Design System for Schools using Cloud Computing|  Habib M. Fardoun (King Abdulaziz University, Saudi Arabia)   Bassam Zafar (King Abdulaziz University, Saudi Arabia)   Abdulrahman H. Altalhi (King Abdulaziz University, Saudi Arabia)   Antonio Paules (University of Castilla-La Mancha, Spain)  Abstract: The design of an educational system involves a   good understanding of the whole school environment in order to find   the correct approach to develop a comprehensive educational system   that will meet real educational needs in their operation. This   article describes a design model for an educational system based on   the teaching methods applied in the Spanish classrooms, which takes   into account new advances in technology, while preserving the   current teaching methods in the classroom to ensure a quality   teaching and learning process. This development has been achieved by   combining technological components such as Cloud Computing, Web   Services and Distributed User Interfaces. The proposed system is   based on a systematic approach where different phases are   implemented, containing workflows and stages.               Keywords: CSchool, ISO 9126-1, Web services, cloud computing, cloud computing architecture, distributed user interfaces, educational systems, interactive design, quality user interfaces, software engineering architecture               Categories:  D.2.2,  L.3.6, D.2.10, D.4.6, D.4.7, H.3.4, H.4.3, H.5.2, K.3.1, K.4.3, L.2.0, L.2.1, L.2.2, L.2.3, L.3.0  
19|7||A Proposal of an Architecture for Educational Environments|  Juan Enrique Garrido (University of Castilla-La Mancha, Spain)   Víctor M. R. Penichet (University of Castilla-La Mancha, Spain)   María D. Lozano (University of Castilla-La Mancha, Spain)  Abstract: Current technology allows educational environments to offer teachers and students the functionality and the information required at any time, whatever the place and circumstance. Concretely, these environments mix three remarkable features: ubiquity, context-awareness and collaboration. Accordingly, a system which is developed with these three features can avoid oversights when performing tasks. Additionally, many aspects of learning fundamentals can be improved, such as collaboration and cooperative learning or students' behaviour. In this paper, we present the definition of a system architecture, which is the first step in obtaining our proposed environment, as the adequate support is not found in any other related works. The architecture presents both a software architecture and a hardware architecture. The software architecture shows the layers in which the system distributes functionality and information. The hardware architecture shows the hardware components to be used, such as smartphones, server, communication elements, etc.               Keywords: collaboration, context-awareness, education, learning, ubiquity               Categories: I.2.6, K.3.1, K.3.2  
19|7||Collaboration and Learning Styles in Pure Online Courses: an Action Research|  Marija Blagojević (University of Kragujevac, Serbia)   Marjan Milosević (University of Kragujevac, Serbia)  Abstract: Collaboration provides numerous possibilities for realisation of active learning/teaching concepts in e-learning. For this reason it is recomendable to determine the optimal way in which to develop collaborative activities, with the possibility of adapting the appropriate modules' use in accordance with learners' characteristics. The paper presents a description of a behaviour pattern analysis, which deals with learners with different learning styles using collaborative modules. An action research was conducted using data from Master degree program that is conducted purely online. The research goals were to find out if there was a potential for improvement of collaborative modules usage, utilizing students preferences and produce recommendations for module future usage. The results showed that there was no difference among learners with different styles regarding either the frequency of access to collaborative modules or the frequency of different actions performed on these modules. Based on these results, a recommendation emerged to keep using these modules in similar way as before and put effort in finding additional data that could be used in further adaptation construct.               Keywords: Felder-Silverman learning style model, Kolb learning style model, collaboration modules, electronic courses, learning style               Categories: I.5, L.0, L.2, L.3  
19|7||Examining the Educational User Interface, Technology and Pedagogy for Arabic Speaking Children in Kuwait|  Amandeep Dhir (University of Helsinki, Finland)   Asmaa Alsumait (Kuwait University, Kuwait)  Abstract: The emergence of educational technology has   resulted in a widespread popularity of different forms of education   technologies among various multidisciplinary researchers. This is   evident based on the high number of empirical, theoretical, and   conceptual studies that are published on educational   technology-related research. However, many open research questions   and challenges remain unresolved. In this study, we are going to: 1)   present an educational technology research agenda underpinned by   extensive research and studies; 2) highlight the missing   interconnections between empirical findings of published studies and   the pedagogical theories; 3) discover if educational technology   research is overly dominated by studies conducted in developed   countries, while developing countries, for example, Arabic speaking   populations in the Middle-East in general and the Gulf states, in   particular, are overlooked by researchers. Based on our in-depth   review of the existing literature, we will discuss the challenges of   designing educational user interface, technology, and   pedagogy-related research, and finally propose guidelines and   recommendations for future research to overcome some of the existing   challenges.               Keywords: Arab child, Arabic, child-computer interaction, educational technology, educational user interface (EUI), learning, pedagogy               Categories:  H.5.0, H.5.2, L.2.1, L.3.1, L.3.4, L.3.6, L.3.8  
19|8|http://www.jucs.org/jucs_19_8|Advances in the Development of Highly Interactive Systems|
19|8||Using SWET-QUM to Compare the Quality in Use  of Semantic Web Exploration Tools|  Jose Luis González Sánchez (Universidad de Granada, Spain)   Roberto García (Universitat de Lleida, Spain)   Josep María Brunetti (Universitat de Lleida, Spain)   Rosa Gil (Universitat de Lleida, Spain)   Juan Manuel Gimeno (Universitat de Lleida, Spain)  Abstract: In order to make Semantic Web tools more   appealing to lay-users, a key factor is their Quality in Use, the   quality of the user experience when interacting with them. To assess   and motivate the improvement of the quality in use, it is necessary   to have a quality model that guides its evaluation and facilitates   comparability. The proposal is based on the international standard   ISO/IEC 25010:2011 and focuses on Semantic Web exploration tools,   those that make it possible for lay-users to browse and visualise   it. The model is applied to compare the three main Semantic Web   exploration tools that feature facets and the pivoting   operation. The analysis assesses that the work being carried out   with one of them, as part of a User-Centred Development process with   iterative user evaluations, outperforms the other two tools.               Keywords: Semantic Web, evaluation, quality, usability, user experience               Categories: H.5.2, H.5.4  
19|8||Applying Usability Engineering in InterMod Agile Development Methodology. A Case Study in a Mobile Application|  Begoia Losada (University of the Basque Country UPV/EHU, Spain)   Maite Urretavizcaya (University of the Basque Country UPV/EHU, Spain)   Juan-Miguel López-Gil (University of the Basque Country UPV/EHU, Spain)   Isabel Fernández-Castro (University of the Basque Country UPV/EHU, Spain)  Abstract: This paper explains when and how to integrate   aspects of usability engineering in the agile development process   proposed by the InterMod methodology. The aim of InterMod is to   facilitate the accurate development of high-quality interactive   software. This is accomplished by means of agile software   engineering activities and continuous assessment in which certain   usability evaluation techniques have been suitably integrated. Such   integration brings benefits to the early steps of the development   process. On the one hand, this integration promotes development   tailored to users' expectations. On the other hand, it helps to plan   the agile process of activities. In terms of developing a mobile   application, the use of prototypes in early stages of the   development process has been considered as being quite beneficial   for organizing the workflow. Using heuristic evaluations and user   tests has also been valuable when grouping evaluations in specific   iterations.               Keywords: agile development methodologies, software development, usability engineering               Categories: D.2.10  
19|8||A Method to Evaluate Emotions in Educational Video Games for Children|"  Natalia Padilla-Zea (Universidad de Granada, Spain)   José Rafael López-Arcos (Universidad de Granada, Spain)   José Luís González Sánchez (Universidad de Granada, Spain)   Francisco L. Gutiérrez Vela (Universidad de Granada, Spain)   Ana Abad-Arranz (Universidad de Granada, Spain)  Abstract: Although several evaluation analyses have recently been proposed to assess the user or player experience of playing a video game, we found the need for these to be adapted when we wanted to apply them to young children. However, young children are unable to spend a long time grading many attributes or indexes after playing. Thus, selecting the most important aspects to be analyzed is required in order to perform a non-time consuming and significant evaluation method to be used with children.  Hence, this work is focused on designing an evaluation method to assess emotions when young children (3-5 years old) play a video game. In particular, we are interested in educational video games because of the importance that emotion has in motivation, which in turn is highly important in education.  Although the method presented follows the pre-test, test and post-test classic structure, the activities carried out in each of these phases have been modified to, firstly, include no elements which require reading-writing skills, which are as yet undeveloped at this age and, secondly, to limit the emotional impact that children can suffer when they are aware that they are being evaluated.  We have applied the proposed method in a sample of 39 children playing the educational video game ""Ato's Adventure"", which was in its final development phases, obtaining very promising results both for the analysis method and for the video game.               Keywords: children's evaluation, educational videogames, evaluation of emotions               Categories: H.5.m  "
19|8||An Evaluation of Targeting Accuracy in Immersive First-Person Shooters Comparing Different Tracking Approaches and Mapping Models|  Arturo S. García (SymbiaIT, Spain)   Andrés Olivas (University of Castilla-La Mancha, Spain)   José P. Molina (University of Castilla-La Mancha, Spain)   Jonatan Martínez (University of Castilla-La Mancha, Spain)   Pascual González (University of Castilla-La Mancha, Spain)   Diego Martínez (University of Bristol, United Kingdom)  Abstract: Immersive Virtual Environments typically rely on   a tracking system that captures the position and orientation of the   head and hands of the cyber-user. Tracking devices, however, are   usually quite expensive and require a lot of free space around the   user, preventing them from being used for gaming at home. In   contrast with these expensive capture systems, the use of inertial   sensors (accelerometers and gyroscopes) to register orientation is   spreading everywhere, finding them in different control devices at   affordable prices, such as the Nintendo Wiimote. With a control like   this, the player can aim at and shoot the enemies like holding a   real weapon. However, the player cannot turn the head to observe the   world around because the PC monitor or TV remains in its   place. Head-mounted displays, such as the Oculus Rift, with a   head-tracker integrated in it, allows the player to look around the   virtual world. Even if the game does not support the head-tracker,   it can still be used if the sensor driver emulates the mouse, so it   can control the player's view. However, the point of view is   typically coupled with the weapon in first-person shooting (FPS)   games, and the user gets rapidly tired of using the neck muscles for   aiming. In this paper, these two components -view and weapon- are   decoupled to study the feasibility of an immersive FPS experience   that avoids position data, relying solely on inertial sensors and   the mapping models hereby introduced. Therefore, the aim of this   paper is to describe the mapping models proposed and present the   results of the experiment carried out that proves that this approach   leads to similar or even better targeting accuracy, while delivering   an engaging experience to the gamer.               Keywords: first-person shooters, human-computer interaction, video games, virtual reality               Categories: I.3.6  
19|8||Automatic Detection of Falls and Fainting|  Juan E. Garrido (University of Castilla-La Mancha, Spain)   Víctor M.R. Penichet (University of Castilla-La Mancha, Spain)   María D. Lozano (University of Castilla-La Mancha, Spain)   José A. F. Valls (University of Castilla-La Mancha, Spain)  Abstract: Healthcare environments have always been   considered an important scenario in which to apply new technologies   to improve residents and employees conditions, solve problems and   facilitate the performance of tasks. In this way, the use of sensors   based on user movement interaction allows solving complicated   situations that should be immediately addressed, such as controlling   falls and fainting spells in residential care homes. However,   ensuring that all the residents are always visually controlled by at   least one employee is quite complicated. In this paper, we present a   ubiquitous and context-aware system focused on geriatrics and   residential care homes, but it could be applied to any other   healthcare centre. This system has been designed to automatically   detect falls and fainting spells, alerting the most appropriate   employees to address the emergency. To that end, the system is based   on movement interaction through a set of Kinect devices that allows   the identification of the position of a person. These devices imply   some development problems that authors have had to deal with,   including camera location, the detection of head movements and   people in horizontal position. The proposed system allows   controlling each resident posture through a notification and warning   procedure. When an anomalous situation is detected, the system   analyses the resident posture and, if necessary, the most adequate   employee will be warned to react urgently. Ubiquity and   context-awareness are essential features since the proposed system   has to be able to know where any employee is and what they are doing   at any time. Finally, we present the outcomes of an evaluation based   on the ISO 9126-4 about the usability of the system.               Keywords: Interaction, Kinect, Movement, collaboration, context-awareness, healthcare, ubiquity               Categories: D.5.3  
19|8||Website Interactivity and Repeated Exposure, what Influences User Experience?|  Ons Al-Shamaileh (University of Manchester, United Kingdom)   Alistair Sutcliffe (University of Manchester, United Kingdom)  Abstract: This paper reports a study of the influence of   website design and repeated exposure to websites on user   judgment. Thirty respondents participated in this study; each   respondent viewed three websites on three occasions, with a two-week   gap between each visit. The three websites differed at their   interactivity level; a basic site with limited interactivity, an   interactive website with customization features, and a highly   interactive website with a virtual agent. Several criteria were   assessed through questionnaires. Interviews were conducted to   support questionnaire results. Finally, the relative importance of   the quality criteria and websites overall preferences were   investigated. Results showed that respondents were more positive   about the websites with higher interactivity, and the preference for   the more interactive site increased over time.               Keywords: repeated exposure, user experience, website interactivity               Categories: H.5.2  
19|8||Pick & Drag & Drop: Augmented Reality for Multiple File Sharing|"  Valeria Herskovic (Pontificia Universidad Católica de Chile, Chile)   Carolina Fuentes (Universidad de Chile, Chile)   Richard Ibarra (Universidad de Chile, Chile)   Javier Bustos-Jiménez (Universidad de Chile, Chile)  Abstract: Many users nowadays work with multiple   heterogeneous computing devices, such as desktop computers, tablets,   laptops and mobile phones. Transferring files between devices is   cumbersome and usually done through the internet (e.g. email or   cloud computing services) or physical devices such as flash   drives. Some solutions for this problem have been proposed, however,   they do not allow efficient and easy transferring of several files   over medium distances. To facilitate file transfer between different   devices, we implemented an augmented-reality based smartphone   application that uses ""pick-and-drop"" and ""drag-and-drop"" mechanisms   to transfer files between devices. This paper presents the   implementation and evaluation of the interaction technique, called   pick and drag and drop. This technique has two central   contributions: it allows transferring several files at once, and it   allows file transfer over greater distances than existing   alternatives. The technique was tested in two laboratory experiments   with promising results: time taken to transfer files was similar to   other options, and 78% of users declared preferring PDD to   alternative methods.               Keywords: augmented reality, data sharing, mobile, multiple devices, pick and drop               Categories:  H.5.1  "
19|8||Gesturing in the Air: Supporting Full Mobility in Remote Collaboration on Physical Tasks|  Weidong Huang (CSIRO ICT Centre, Australia)   Leila Alem (CSIRO ICT Centre, Australia)  Abstract: Many collaborative situations require that a   remote helper guides a local worker in performing manipulations of   physical objects in the real world (physical tasks). Existing   systems supporting such collaboration often confine collaborators in   fixed desktop settings. Therefore they have limited usefulness in   situations in which collaborators are mobile and/or desktop settings   are not feasible. In this paper, we present HandsInAir, a wearable   system for remote guidance. This system is designed to support   mobility of the collaborators and provide easy access to remote   expertise. HandsInAir draws on the richness of hand gestures for   remote guiding and implements a novel approach that supports   unmediated remote gestures and allows the helper to perform natural   gestures by hands without the need of a physical support. We review   related work, describe technical implementation, and present a   usability study demonstrating the usefulness and usability of   HandsInAir.               Keywords: mobile collaboration, remote collaboration, remote gestures, wearable computing               Categories: H.5.2  
19|8||A Case Study on User Experience (UX) Evaluation of Mobile Augmented Reality Prototypes|  Amandeep Dhir (Aalto University, Finland)   Mohammed Al-kahtani (Salman Bin Abdulaziz University, Saudi Arabia)  Abstract: Mobile Augmented Reality (MAR) blends the real   world with digital objects especially in ubiquitous devices such as   smartphones. The MAR applications provide an intelligent interface   for users. In this, valuable digital information is advertised in   physical spaces. However, the success of these applications is tied   directly to the degree of user acceptance. This makes understanding   the needs and expectations of the MAR's potential users of paramount   importance for designing and building the proper application. The   objective of the paper is to expose an important gap in the   development of novel applications in the virtual world. Previous   research has shown that it is essential to study and understand the   needs and expectations of the potential users of the upcoming   application or system. Studying user needs and expectations before   offering the developed application ensures a minimum level of   acceptance and, of course, success. This paper presents a detailed   study comprising of a user-experience (UX) evaluation of different   prototypes through the use of three different UX evaluation   methods. This kind of evaluation allows new developments to offer   systems, which do not fail. The main contributions of this study are   that it: 1) solicits expectations when consumers use MAR   applications, 2) assesses the UX over different prototypes using   three different metrics, 3) provides methodological insights on UX   evaluation experiments and, 4) is useful for anyone who wants to   develop handheld applications after understanding user expectations   and how his experience should progress. The results of the study   show that users value concreteness, realizability, personalization,   novelty, intuitiveness and the usefulness of presented   information. Paying attention to these factors can help develop more   acceptable MAR applications and lead to more novel future designs.               Keywords: end-user application, mobile mixed reality, mobile services, user expectations, user experience, user experience evaluations               Categories: H.5.0, H.5.1, H.5.2, L.2.1, L.3.1, L.3.4, L.3.6, L.3.8  
19|9|http://www.jucs.org/jucs_19_9|Ambient Assisted Living: Home Care|
19|9||Effects of Virtual Reality during Exercise in Children|  Jaime Guixeres (Polytechnic University of Valencia, Spain)   Laura Cantero (Universitat Jaume I. Ciber, Spain)   Empar Lurbe (Universitat Jaume I. Ciber, Spain)   Javier Saiz (Polytechnic University of Valencia, Spain)   Mariano Alcañiz (Polytechnic University of Valencia, Spain)   Ausias Cebolla (Universitat Jaume I. Ciber, Spain)   Patricia Escobar (Universitat Jaume I. Ciber, Spain)   Rosa Baños (Universitat Jaume I. Ciber, Spain)   Cristina Botella (Universitat Jaume I. Ciber, Spain)   Juan Francisco Lison (University of Valencia, Spain)   Julio Alvarez (Universitat Jaume I. Ciber, Spain)  Abstract: Virtual Reality (VR) could be an interesting   tool to combat obesity and sedentariness in children. During the   last years a multidisciplinary research team comprised of engineers,   psychologists, physiotherapists and paediatricians have been testing   these technologies. Throughout the tests, physiological   (cardiovascular and metabolic response with biomedical sensors   (smart fabrics TIAS) and psychological responses have been   collected. The results presented in this paper reflect two main   aspects: 1) the feasibility of the monitoring techniques employed   and 2) the validity of virtual reality and exergaming technologies   as promoters of physical activity and their potential as tools in   clinical intervention programs. In the first study (n=90) children,   a commercial platform was tested as support tool to aerobic exercise   in a treadmill. Results showed a more physiological effort by obese   group and limitations to measure effort perception with Borg scale   especially in obese group. In second study (n=126) a new VR platform   was developed (VREP) and tested as support of aerobic activities, a   difference of first study, all the boys completed both conditions   (same Aerobic exercise with/without support VR). 59.5% felt that   they had to exert more effort in the traditional   condition. Regarding to acceptability in both studies the vast   majority of the participants liked the idea of combining physical   activity with the VR platform as a form of treatment to increase   physical activity. The capacity of VR technology to create   controllable, multisensory, interactive 3D stimulus environments   within which children's performance can be motivated, recorded, and   measured, has been tested in these studies, offering clinical   assessment and intervention options which are not possible using   traditional methods.               Keywords: active gaming, children obesity, physical activity, physiological response, smart fabrics, virtual reality               Categories: J.3, J.4, J.6, J.7  
19|9||Evaluation of Bluetooth Low Energy Capabilities for Tele-mobile Monitoring in Home-care|  Antonio J. Jara (University of Murcia, Spain)   David Fernandez (University of Murcia, Spain)   Pablo Lopez (University of Murcia, Spain)   Miguel A. Zamora (University of Murcia, Spain)   Antonio F. Skarmeta (University of Murcia, Spain)   Leandro Marin (University of Murcia, Spain)  Abstract: Bluetooth Low Energy (BLE) is extending   Bluetooth technology to devices with lower communication   requirements and higher constraints in terms of memory capabilities   and power autonomy. Thereby, BLE makes feasible the wireless   transmission of information from smart objects such as wearable   clinical devices, ambient sensors and actuators. These smart objects   are starting to be internet-enabled devices, reaching the so   denominated Internet of Things (IoT). Our research work is focused   on analyze the capabilities of these technologies for continuous   data transmission and integration of clinical sensors in home-care   and Ambient Assisted Living environments. For this purpose, this   work analyses exhaustively the capabilities from BLE and compare   this with the capabilities from Bluetooth 2.1. In addition, it has   been considered the communications requirements from different   clinical devices such as an electrocardiogram (ECG) and a   capnograph. It is concluded that the performance from BLE is lower   than Bluetooth Classic (Bluetooth 2.1) for continuous   communications, since BLE is based on attributes (datapoints)   transfer instead of offering a communication session where can be   transmitted as much packets as required, without any size   constraint. Therefore, it is necessary to perform data   compression/aggregation when the amount of data to send is too large   to be stored in a BLE attribute. This work also presents how to   apply pre-processing techniques that greatly reduces the   transmission overload (performs signal compression) in order to   allow the continuous transmission of the ECG and capnograph signal   through BLE making so feasible the integration of continuous   clinical devices via BLE.               Keywords: Internet of Things, bluetooth low energy, clinical technology, continuous data transmission, electrocardiogram, mobile communications, mobile monitoring, performance, performance assessment, tele-monitoring               Categories: C.2, C.3, J.3, L.7, L.7.0  
19|9||A Modular System for Rapid Development of Telemedical Devices|  Jan Havlik (Czech Technical University in Prague, Czech Republic)   Lenka Lhotska (Czech Technical University in Prague, Czech Republic)   Jakub Parak (Czech Technical University in Prague, Czech Republic)   Jan Dvorak (Czech Technical University in Prague, Czech Republic)   Zdenek Horcik (Czech Technical University in Prague, Czech Republic)   Matous Pokorny (Czech Technical University in Prague, Czech Republic)  Abstract: Remote patient monitoring is gradually   attracting more attention as the population in developed countries   ages, and as chronic diseases appear more frequently in the   population. Miniaturization in electronics and mobile technologies   has led to rapid development of various wearable systems for remote   monitoring of vital signs, supervision systems in home care,   assistive technologies and similar systems. There is a significant   demand for developing the necessary devices very rapidly, especially   for shortening the way from an idea to a first function sample. This   paper presents a solution for rapidly developing devices for   telemedical applications, remote monitoring and assistive   technologies. The approach used here is to design and realize a   modular system consisting of input modules for signal acquisition, a   control unit for signal pre-processing, handshaking of data   communication, controlling the system and providing the user   interface and communication modules for data transmission to a   superordinate system. A description of specific applications   developed on the basis of the system is also presented in the   paper.               Keywords: assistive technologies, electrocardiography, heart rate, plethysmography, telemedicine, telemonitoring               Categories: B.4, I.5.4  
19|9||An Alert System for People Monitoring Based on Multi-Agents using Maps|  Pilar Castro Garrido (University of Córdoba, Spain)   Irene Luque Ruiz (University of Córdoba, Spain)   Miguel Ángel Gómez-Nieto (University of Córdoba, Spain)  Abstract: This paper describes an alert system for people   monitoring based on multi-agent using maps. This system monitors the   users' physical context using their mobile phone. The data   acquisition is made using the available sensors on mobile phone. A   set of agents on mobile phones are responsible for collecting,   processing and sending data to the server. Another set of agents on   server stores the data and checks the preconditions of the   restrictions associated with the user, in order to trigger the   appropriate alarms. These alarms are sent not only to the user that   violates a restriction, but also to the one responsible for   supervising the person monitored. The supervisor can control all the   supervised people through a map interface with functionality such as   sending a SMS or making a call directly from the map. The   applicability of the system will be illustrated with an example for   Alzheimer patient monitoring. These patients will carry on normal   activity in the home environment or home for the elderly, monitored   by their family or by nurses.               Keywords: JADE, maps, monitoring, multi-agents system, physical context, sensors               Categories: H.5, I.2.11, I.2.8, J.1, M.0  
19|9||A Tool for Telediagnosis of Cardiovascular Diseases in a Collaborative and Adaptive Approach|  Maria-Aydee Sanchez-Santana (Université de Franche-Comté, France)   Jean-Baptiste Aupet (Université de Franche-Comté, France)   Marie-Laure Betbeder (Université de Franche-Comté, France)   Jean-Christophe Lapayre (Université de Franche-Comté, France)   Antonio Camarena-Ibarrola (Universidad Michoacana de San Nicolás de Hidalgo, Mexico)  Abstract: In this paper, we present a new telediagnosis   environment for the detection of cardiovascular problems.This tool,   called VACODIS (VAscular COllaborative teleDIagnosiS), allows   practitioners to semi-automatically identify and quantify a   patient's potential cardiovascular complications. The system   generates first-time automatic detection of cardiovascular   abnormalities using Doppler ultrasound images.The system then   provides remote collaborative sharing of this information among   different doctors to allow distance telediagnostics. With this new   system, different actors in the field of medicine (nurses,   practitioners, etc.) will be able to contribute to a more reliable   diagnosis in the cardiovascular domain.               Keywords: adaptability, cardiovascular complications, collaborative work, telediagnosis               Categories: C.2.4, J.3  
19|9||Energy Efficient Smartphone-Based Activity Recognition using Fixed-Point Arithmetic|  Davide Anguita (Università degli Studi di Genova, Italy)   Alessandro Ghio (Università degli Studi di Genova, Italy)   Luca Oneto (Università degli Studi di Genova, Italy)   Xavier Parra (Universitat Politècnica de Catalunya, Spain)   Jorge L. Reyes-Ortiz (Universitat Politècnica de Catalunya, Spain)  Abstract: In this paper we propose a novel energy   efficient approach for the recog-nition of human activities using   smartphones as wearable sensing devices, targeting assisted living   applications such as remote patient activity monitoring for the   disabledand the elderly. The method exploits fixed-point arithmetic   to propose a modified multiclass Support Vector Machine (SVM)   learning algorithm, allowing to better pre-serve the smartphone   battery lifetime with respect to the conventional floating-point   based formulation while maintaining comparable system accuracy   levels. Experimentsshow comparative results between this approach   and the traditional SVM in terms of recognition performance and   battery consumption, highlighting the advantages of theproposed   method.               Keywords: SVM, activity recognition, assisted healthcare, energy efficiency, fixed-point arithmetic, remote monitoring, smartphones               Categories: D.2, H.1.2, I.2, I.2.6, I.2.9, J.3, J.7  
19|9||An Enhanced Process of Concept Alignment for Dealing with Overweight and Obesity|  María de Lourdes Martinez-Villaseñor (Universidad Panamericana Campus México, Mexico)   Miguel González-Mendoza (Tecnológico de Monterrey, Mexico)  Abstract: A major challenge for creating personalized diet   and activity applications is to capture static, semi-static and   dynamic information about a person in a user-friendly way. Sharing   and reusing information between heterogeneous sources like social   networking applications, personal health records, specialized   applications for diet and exercise monitoring, and personal devices   with attached sensors can achieve a better understanding of the   user. Gathering distributed user information from heterogeneous   sources and making sense of it to enable user model interoperability   entails handling the semantic heterogeneity of the user models. In   this paper, we enhance the process of concept alignment to   automatically determine semantic mapping relations to enable   interoperability between heterogeneous health and fitting   applications. We add an internal structure similarity measure to   increase the quality of generated mappings of our previous work. We   show that the addition of an internal structure analysis of source   data in the process of concept alignment improves the efficiency and   effectiveness of measuring results. Constrain and data type   verification done in the internal structure analysis proved to be   useful when dealing with common conflicts between concepts.               Keywords: diet and exercise monitoring, overweight and obesity, schema matching, user modeling interoperability               Categories: M.4, M.5, M.8  
19|9||Achieving Adaptive Augmented Reality through Ontological Context-Awareness applied to AAL Scenarios|  Ramón Hervás (Castilla-La Mancha University, Spain)   José Bravo (Castilla-La Mancha University, Spain)   Jesús Fontecha (Castilla-La Mancha University, Spain)   Vladimir Villarreal (Technological University of Panama, Republic of Panama)  Abstract: This paper presents a proposal for supporting   daily user needs by simple interactions with the environment through   an augmented-reality perspective that applies proactive adaptation   through knowledge representation using ontologies. The proposed   architecture (i-ARA) uses principles of the Semantic Web that endow   context-awareness and user personalization. In addition, these types   of services allow the supervision and management of what is   happening in the environment and, consequently, improve the   information offered to users. The architecture has been used to   implement applications using iPhone technology and has been applied   to illustrative scenarios, including Ambient Assisted Living.               Keywords: ambient assisted living, augmented reality, context-awareness, mobile computing, semantic web               Categories: H.5.2, I.2.4, M.4  
volume|issue|url|title|abstract
20|1|http://www.jucs.org/jucs_20_1|Interaction in Massive Courses|
20|1||Proposal for a Conceptual Framework for Educators to Describe and Design MOOCs|  Carlos Alario-Hoyos (Universidad Carlos III de Madrid, Spain)   Mar Pérez-Sanagustín (Universidad Carlos III de Madrid, Spain)   Dave Cormier (University of Prince Edward Island, Canada)   Carlos Delgado-Kloos (Universidad Carlos III de Madrid, Spain)  Abstract: Massive Open Online Courses (MOOCs) are a   disruptive trend in education. Several initiatives have emerged   during the last months to give support to MOOCs, and many educators   have started offering courses as MOOCs in different areas and   disciplines. However, designing a MOOC is not an easy   task. Educators need to face not only pedagogical issues, but also   other issues of logistical, technological and financial nature, as   well as how these issues relate and constrain each other. Currently,   little guidance is available for educators to address the design of   MOOCs from scratch keeping a balance between all these issues. This   paper proposes a conceptual framework for supporting educators in   the description and design of MOOCs called the MOOC Canvas. The MOOC   Canvas defines eleven interrelated issues that are addressed through   a set of questions, offering a visual and understandable guidance   for educators during the MOOC design process. As a practical usage   example, this paper shows how the MOOC Canvas captures the   description and design of a real 9-week MOOC. An analysis of the   different elements of the course shed some light on the usage of the   MOOC Canvas as a mechanism to address the description and design of   MOOCs.               Keywords: MOOC, canvas, design, framework               Categories: K.3.1, K.3.2  
20|1||Adapting an Awareness Tool for Massive Courses: the Case of ClassON|  Israel Gutiírrez-Rojas (Universidad Carlos III de Madrid, Spain)   Raquel M. Crespo-García (Universidad Carlos III de Madrid, Spain)   Carlos Delgado Kloos (Universidad Carlos III de Madrid, Spain)  Abstract: In this paper we analyse the challenges posed to   teachers and students in massive face-to-face classes and explore   how existing solutions can be applied to these contexts. In   particular, we focus on classON1, a tool that provides teachers and   students with the appropriate information to make the most out of   face-to-face sessions in the computer lab. classON has been well   tested in small-medium face-to-face lab sessions and we discuss some   of its characteristics (current ones and foreseen) to adapt it to   massive courses. As a result, we provide a set of recommendations   for adapting tools to support massive face-to-face learning   activities.               Keywords: active learning, face-to-face teaching, just-in-time teaching, massive learning environments, scalability, teacher awareness               Categories: H.5.2, K.3, K.3.1, L.3.0  
20|1||Developing a Web-Based Question-Driven Audience Response System Supporting BYOD|  Christian Haintz (Graz University of Technology, Austria)   Karin Pichler (Graz University of Technology, Austria)   Martin Ebner (Graz University of Technology, Austria)  Abstract: Question-driven Audience Response Systems (ARSs)   are in the focus of research since the 1960s. Since then, the   technology has changed and therefore systems have evolved too. This   work is about conception and implementation of the web-based ARS   RealFeedback which uses the principle of bring your own device   (BYOD). A state-of-the-art analysis compares the features of   existing web-based ARSs. The most important findings are used for   the conception and the implementation of the system. Thinking-aloud   tests, and the first usages during lectures confirm that the chosen   requirements are very significant and valuable for   lecturers.               Keywords: audience response system, bring your own device, question-driven, webbased               Categories: L.0.0, L.3.0, L.7.0  
20|1||Toward Project-based Learning and Team Formation in Open Learning Environments|"  Howard Spoelstra (Open University of the Netherlands, The Netherlands)   Peter van Rosmalen (Open University of the Netherlands, The Netherlands)   Peter Sloep (Open University of the Netherlands, The Netherlands)  Abstract: Open Learning Environments, MOOCs, as well as   Social Learning Networks, embody a new approach to   learning. Although both emphasise interactive participation,   somewhat surprisingly, they do not readily support bond creating and   motivating collaborative learning opportunities. Providing   project-based learning and team formation services in Open Learning   Environment can overcome these shortcomings. The differences between   Open Learning Environments and formal learning settings, in   particular with respect to scale and the amount and types of data   available on the learners, suggest the development of automated   services for the initiation of project-based learning and team   formation. Based on current theory on project-based learning and   team formation, a team formation process model is presented for the   initiation of projects and team formation. The data it uses is   classified into the categories ""knowledge"", ""personality"" and   ""preferences"". By varying the required levels of inter-member fit on   knowledge and personality, the team formation process can favour   different teamwork outcomes, such as facilitating learning, creative   problem solving or enhancing productivity. The approach receives   support from a field survey. The survey also revealed that in   every-day teaching practice in project-based learning settings team   formation theory is little used and that project team formation is   often left to learner self-selection. Furthermore, it shows that the   data classification we present is valued differently in literature   than in daily practice. The opportunity to favour different team   outcomes is highly appreciated, in particular with respect to   facilitating learning. The conclusions demonstrate that overall   support is gained for the suggested approach to project-based   learning and team formation and the development of a concomitant   automated service.               Keywords: MOOC, Open Learning Environment, Social Learning Network, project team formation, project-based learning, team formation service                "
20|10|http://www.jucs.org/jucs_20_10|Advances of Scientific Research on Technology Enhanced Learning in Social Networks and Mobile Contexts:  Towards High Effective Educational Platforms for Next Generation Education|
20|10||Incremental Prototyping Model for the Development of Educational Platforms: a Process of Design and Quality Standards|  Marcelo Careaga Butter (Universidad Católica de la Santisima Concepción, Chile)   María Graciela Badilla Quintana (Universidad Católica de la Santisima Concepción, Chile)   Eileen Sepulveda Valenzuela (Universidad Católica de la Santisima Concepción, Chile)  Abstract: Incremental Prototyping Method is an engineering   methodology which is presented as appropriate to collect progressive   contributions of users and experts of technological solutions that   are designed to meet educational challenges. This paper presents the   design process that is based on four circuits: theoretical,   pedagogical, and technological and management. These circuits   involved experts from different disciplines such as; computer   engineering, computer science education, graphic design and   communication and education. Results show educational platforms   which are the result of a recurring review process of the developed   technological products and the inclusion of quality standards. That   ensures the usability of the product; this means that the product   must be coherent and consistent with the educational purpose for   which it was initially required.               Keywords: Método Incremental Prototype Method, educational platforms, quality standards               Categories: L.3.6, L.6.0, L.6.1  
20|10||Several Semantic Web Approaches to Improving the Adaptation Quality of Virtual Learning Environments|  Eugenijus Kurilovas (Vilnius University Institute of Mathematics and Informatics, Lithuania)   Anita Juskeviciene (Vilnius University Institute of Mathematics and Informatics, Lithuania)   Svetlana Kubilinskiene (Vilnius University Institute of Mathematics and Informatics, Lithuania)   Silvija Serikoviene (Vilnius University Institute of Mathematics and Informatics, Lithuania)  Abstract: The aim of the paper is to investigate and   propose Semantic Web approaches to improving the adaptation quality   of Virtual Learning Environments (VLEs). These approaches are the   method for semantic search for Web 2.0 tools in VLEs, and the method   for curriculum mapping and semantic search for Learning Objects   (LOs) in VLEs. In the paper, a special attention is paid to   improving the adaptation capabilities of VLE, e.g. its suitability   for different learning styles such as VARK. Web 2.0 tools ontology   based on VARK model learning activities gives the possibility to   develop adaptive learning environment with better access to specific   learning content managing tools (i.e. Web 2.0 tools). The learner   will only need to enter the name of learning activity into the   search system field and the machine offers the appropriate tools to   perform this activity. The engine facilitates the search process by   optimizing workloads, thereby improving learner's satisfaction and   improving the efficiency and effectiveness of the learning   process. Presented curriculum mapping approach makes   interoperability and LOs semantic search possible by making use of   two smaller controlled vocabularies instead of a very large one on   competencies which would be more volatile. One could exchange   information on competencies in a multi-lingual and multi-cultural   environment by: (1) breaking down competencies, and (2) relating   these competency components to multilingual controlled   vocabularies. The research results have shown that, in order to   improve the adaptation quality of VLEs, it is very important to   improve semantic search for both LOs and Web 2.0 tools in   VLEs.               Keywords: Semantic Web, Virtual Learning Environments, adaptation quality, curriculum mapping, learning objects, learning styles               Categories: J.4, J.6, L.1.3, L.1.4, L.2.2, L.3.6, M.1, M.5  
20|10||A Compression Algorithm for Managing Digital Elevation Models in Mobile Devices|  Rolando Quintero (Instituto Politécnico Nacional, Mexico)   Giovanni Guzman (Instituto Politécnico Nacional, Mexico)   Miguel Torres (Instituto Politécnico Nacional, Mexico)   Rolando Menchaca-Mendez (Instituto Politécnico Nacional, Mexico)   Marco Moreno-Ibarra (Instituto Politécnico Nacional, Mexico)   Felix Mata (Instituto Politécnico Nacional, Mexico)  Abstract: Nowadays, there are many applications such as   disaster mitigation, survey-ing or geology-support, and others where   Digital Elevation Models (DEM) are useful in the field. DEM   typically requires a huge amount of data, making the tasks of   DEMtransmission over a wireless network or storing and displaying it   in a mobile device very complex. These tasks are important   challenges in computer science research. Up-to-date, the compression   techniques are used to compress DEMs with a high compression   coefficient, nevertheless, whether the user requires to access the   file or to obtain certaininformation about the raster data, it is   necessary to decompress the entire DEM file. In consequence, these   approaches are not well suited for applications focused on   deviceswith limited hardware resources. In this paper, a novel   compression/decompression technique is presented. This approach is   capable of obtaining the specific parameterssuch as altitudes and   contour lines of a sub-region of the DEM without using a full   decompression stage. A detailed analysis of the properties and   complexity of our approachis presented.               Keywords: Digital Elevation Model, compression algorithms, near-lossless compression               Categories: E.2, H.3.2, I.4.2  
20|10||Chat as a Tool for Social Knowledge Construction Using Asynchronous Discussion Groups in Economics Degree|  María Teresa García-Álvarez (University of A Coruña, Spain)   Laura Varela-Candamio (University of A Coruña, Spain)   Isabel Novo-Corti (University of A Coruña, Spain)  Abstract: The current higher education programs use   information and communication technologies to conduct interactive   teaching and learning activities. This paper creates an educational   method based on an Interaction Analysis Model through the use of   chats in higher education. Compared to the traditional functions of   the chats in education, our proposal introduces discussions of   current economic events and real cases. This contributes to develop   the problem-based learning and leads to students not only to improve   their knowledge but to develop skills such as teamwork or   leadership, which should be important characteristics of a graduate   in Business Degree. As a result, students transfer their knowledge   to solve current case studies improving their interest in the   subject greatly and, therefore, their motivation and the social   knowledge construction of the whole group.               Keywords: authoring tools and methods, computer-mediated communication, cooperative/collaborative learning, human-computer interface, interactive learning environments, knowledge management               Categories:  M.9, L.2.0, L.3.6, M.0  
20|10||Self-learning Mobile Robot Navigation in Unknown Environment Using Evolutionary Learning|  Mohammed Algabri (King Saud University, Saudi Arabia)   Hassan Mathkour (King Saud University, Saudi Arabia)   Hedjar Ramdane (King Saud University, Saudi Arabia)   Mansour Alsulaiman (King Saud University, Saudi Arabia)   Khalid Al-Mutib (King Saud University, Saudi Arabia)  Abstract: An autonomous mobile robot operating in an   unstructured environment must be able to learn with dynamic changes   to that environment. Learning navigation and control of mobile robot   in an unstructured environment is one of the most challenging   problems. Fuzzy logic control is a useful tool in the field of   navigation of mobile robot. In this research, we optimized a   performance of fuzzy logic controller by evolutionary learning   technique. Two proposed approaches have been designed and   implemented: Fuzzy Logic Controller (FLC) and Genetic-Fuzzy   Controller (GA-FLC). The Genetic Algorithm is used for automatically   learning to tune the membership function parameters for mobile robot   motion control.  Moreover, the performance of these approaches are   compared through simulation.               Keywords: Fuzzy Logic Controller, genetic algorithm, genetic-kuzzy algorithm, robotics, soft computing               Categories: I.2.3, I.2.9, L.2, L.5.0  
20|10||A Novel Vertical Fragmentation, Replication and Allocation Model in DDBSs|  Hassan I. Abdalla (King Saud University, Saudi Arabia)   Ali A. Amer (King Saud University, Saudi Arabia)   Hassan Mathkour (King Saud University, Saudi Arabia)  Abstract: Modern database systems are commonly   distributed, and data is kept at isolated locations (sites). The   various sites are connected through communications links, which may   be of low speed resulting in bottlenecks for data transfer between   sites. Data replication is considered as one of the effective   methods in dealing with such situations to achieve improved   performance in distributed database systems (DDBSs). In this work,   authors explore a new model for improving performance in distributed   database environment by using a vertical fragmentation method along   with a novel replication and allocation techniques. The solution   procedure consists of a new vertical fragmentation model to fragment   a relation and two phases of allocation of fragments to nodes. The   paper discusses the tradeoffs between the different scenarios for   finding an optimal way of deciding on attribute allocation to sites   by evaluating performance based on the collected requirements.  This   model will significantly reduce communication cost and query   response time in DDBSs.               Keywords: Vertical Fragmentation, allocation, clustering, distributed DBMS, frequency-matrix, heuristics, replication               Categories: H.2, H.2.8, H.3  
20|10||Exploiting the Performance-Energy Tradeoffs for Mobile Database Applications|  Puyuan Yang (University of Science and Technology of China, China)   Peiquan Jin (University of Science and Technology of China, China)   Lihua Yue (University of Science and Technology of China, China)  Abstract: In recent years, mobile operating systems,   represented by android and iOS, have become more and more popular in   smartphones. However, the energy issue in smartphones, which refers   to the poor battery capacity and management schemes, has been the   bottle-neck to further advance the development in this   area. Generally, mobile applications have to consider both   performance and energy consumption. But unfortunately, few works   have been focused on this issue. In this paper, we aim at conducting   an experimental study on the performance and energy tradeoffs for   mobile applications. In particular, we focus on mobile database   applications as they are one of the basic applications on mobile   operating systems. In detail, we use the android system as the basic   mobile platform, and the TPC-H benchmark as the workload, and build   a benchmark platform called TPCdroid to conduct performance and   energy measurement. In TPCdroid, we control the mobile database   performance by changing the processor frequency. The initial   experimental results show that lowering frequency is not always   helpful for reducing energy consumption. Moreover, we found that the   traditional energy reducing technologies based on X86 and magnetic   disks are not suitable for mobile database applications running on   ARM and flash memory. Finally, we analyse the relationship between   performance and energy consumption under different kinds of   workloads, which is done by adjusting the parameters reflecting   performance and energy consumption for mobile database   applications. The results show that the energy consumption has a   dynamic connection with the performance in mobile database   applications.               Keywords: Android, energy consumption, energy efficiency, mobile database, performance               Categories:  H.3.4, B.8.2  
20|10||ICTs, Mobile Learning and Social Media to Enhance Learning for Attention Difficulties|  Athanasios S. Drigas (NCSR DEMOKRITOS, Greece)   Rodi-Eleni Ioannidou (NCSR DEMOKRITOS, Greece)   Georgia Kokkalia (NCSR DEMOKRITOS, Greece)   Miltiadis Lytras (The American College of Greece, Greece)  Abstract: Recent development in the role of Information   and Communication Technologies (ICTs) at the field of special   education is thought significant. ICT nowadays is recognized as a   tool that can foster the knowledge and the experiences in the areas   of needs it serves as it is considered significant for teaching and   learning process. In the last decade, a number of studies have   demonstrated the benefits of various forms of ICTs tools for   children with attention difficulties and hyperactivity disorders   (ADHD). These tools can be employed to facilitate and train young   learners, as well as can help them to increase their quality of life   and functional independence.  In this paper we present a brief   review of the most representative research papers for computer-based   applications for diagnosis and intervention purposes included the   mobile learning and social media for technology enhanced learning   for people with Attention Deficit Hyperactivity Disorder.               Keywords: ADHD, ICT, diagnosis, education, intervention, mobile learning, social media               Categories: H.4, H.m, L.0, L.1, L.2, L.3, L.5, L.6  
20|10||When are Tweets Better Valued? An Empirical Study|"  Esam Alwagait (King Saud University, Saudi Arabia)   Basit Shahzad (King Saud University, Saudi Arabia)  Abstract: The increase in Twitter's popularity has been   phenomenal over time. Tweets are now not only a means of status   update and one-on-one communication, but they are also widely used   for trend setting and marketing. The probability that the user will   see a Tweet when he was offline at the time it was tweeted is very   low. In order to increase the Tweet impact, it is important to   determine the number of individuals online so that maximum number of   users see the Tweets. This research focuses on identifying the   individual users from Saudi Arabia based on the parameters already   set for the conduct of this study. The time-stamped data for 1000   selected individuals is retrieved from Twitter and is analyzed   accordingly. The number of online users is observed by recording the   ""last seen"" status. The retrieval of data is based on a number of   experiments that was run at same time on all days of the week to   reduce the inconsistent patterns. The data is then analyzed to see   the time slots where the online user percentage is higher as   compared to other time slots. The results of the study are focused   to identify and recommend the timings when the Tweets are better   valued and the impact is considerable.               Keywords: Saudi social connectivity, Saudi weekend twitter, Twitter Saudi Arabia, Twitter connectivity, best time to tweet               Categories: E.2, M.1, M.6  "
20|11|http://www.jucs.org/jucs_20_11|Methodologies, Technologies and Tools Enabling e-Government|
20|11||An Adaptive and Social-Aware Recommendation Algorithm for Administration Services|  Luis M. Álvarez Sabucedo (Universidade de Vigo, Spain)   Roberto Soto Barreiros (Universidade de Vigo, Spain)   Juan M. Santos Gago (Universidade de Vigo, Spain)   Manuel J. Fernández Iglesias (Universidade de Vigo, Spain)  Abstract: This paper addresses the recommendation of   online services provided by public administrations taking into   account both the specific characteristics of these services and the   perception of other citizens. The solution discussed is based on an   enhanced hybrid model that relies on content-based and collaborative   strategies aimed to exploit the information shared by other users to   validate the quality of the recommendations provided. As a relevant   feature, the proposed schema takes advantage of an automatic   compensation of the mentioned strategies. To make the most of theses   two approaches, the use of semantics is introduced to describe   knowledge and to make smart recommendation decisions. To facilitate   the task of other researchers and practitioners, details about the   actual development and validation of the proposed model are also   included in the paper, making it possible its replication in other   environmentsEurope is involved in a process of transition to digital   terrestrial television that is aimed to replace all analog   broadcasting infrastructures into digital ones by year 2012. Besides   the substitution of all broadcasting networks scattered around   Europe, this process includes the replacement of all household   elements related to the reception of terrestrial television   emissions, namely television appliances and antenna settings. As in   any major change in the every-day life of citizens, public   administrations must keep citizen informed and provide convenient   support, specially when dealing with the a communication medium   designated to be the carriers of services and information. This   paper tackles how this situation has been faced in Galicia, a   European region with special needs in this area, as shown in the   paper. Through a successful use case based on Geographical   Information Services and Web2.0 technologies, we illustrate some   features not present in related initiatives in other areas.               Keywords: Decision support systems, Webbased solutions, eGovernment, semantic technologies               Categories: H.4, I.2.1, M.4, M.8  
20|11||Middleware-Oriented Government Interoperability Frameworks: A Comparison|  Giansalvatore Mecca (Università della Basilicata, Italy)   Michele Santomauro (Università della Basilicata, Italy)   Donatello Santoro (Università della Basilicata, Italy)   Enzo Veltri (Università della Basilicata, Italy)  Abstract: We discuss deployment solutions for e-Government   Interoperability Frameworks (GIFs). We concentrate on   middleware-oriented GIFs, i.e., those in which middleware modules   act as intermediaries among information systems that need to   exchange data and services. A prominent example is the Italian   SPCoop interoperability framework. We review the SPCoop   architecture, and two popular open-source implementations of its   core modules, called OpenSPCoop and freESBee. We argue that the   comparison of these two solutions is relevant since they obey to   radically different philosophies, both in terms of the relationship   to the underlying J2EE container, and of their internal module   organization. Then, we discuss one of the main problems in   large-scale deployment of SPCoop-like GIFs, namely the need to   quickly deploy a large number of middleware instances over a   relatively small number of servers. We report a number of   experiments to discuss how the different design choices impact   performance. To the best of our knowledge, this is the first   large-scale test of the framework, from which a number of important   lessons can be learned.               Keywords: Government Interoperability Frameworks (GIF), Service Level Agreements (SLA), domain gateways, e-Government, interoperability, middleware               Categories: H.3.5, H.4.2, H.4.3  
20|11||A Model to Guide the Open Government Data Implementation in Public Agencies|  Mauricio Solar (Universidad Técnica Federico Santa Maria-UTFSM, Chile)   Fernando Daniels (Inter-American Organization for Higher Education, OUI-IOHE, Canada)   Roberto López (The Network of e-Government Leaders of Latin America and theCaribbean, RED GEALC, Uruguay)   Luis Meijueiro (Fundacion CTIC, Spain)  Abstract: This paper presents a model to diagnose maturity   and capabilities of Public Agencies (PAs) in pursuing the open data   principles and practices. The open data maturity model, called   OD-MM, was piloted in ten PAs from three Latin American countries,   validating in this way the web tool that operationalizes the   model. This web tool is a valuable diagnostic tool for PA's, since   it shows all weaknesses and provides the instrument (a roadmap) to   progress in the implementation of open data. We also propose a guide   to implement open data in PAs. This guide is the result of the OD-MM   application in Latin American PAs. The guide is simple and orients   decision makers so that PAs following the actions of the guide can   see their improved capacities when facing a diagnosis of their   institutional maturity in the implementation of open data.               Keywords: maturity model, open data, open government data, roadmap               Categories: D.2.8, D.2.9, J.7, K.4.1, K.4.3, K.5.2  
20|11||A Secure Multi-Layer e-Document Method for Improving e-Government Processes|  Gia Nghia Vo (La Trobe University, Australia)   Richard Lai (La Trobe University, Australia)  Abstract: In recent years, there has been a tremendous   growth in e-Government services due to advances in Information   Communication Technology and the number of citizens engaging in   e-Government transactions. In government administration, it is very   time consuming to process different types of documents and there are   many data input problems. There is also a need to satisfy   citizens requests to retrieve government information and to link   these requests to build an online document without asking the   citizen to input the data more than once. To provide an e-Government   service which is easy to access, fast and secure, the e-Document   plays an important role in the management and interoperability of   e-Government Systems. To meet these challenges, this paper presents   a Secure Multilayer e-Application (SMeA) method for improving   e-Government processes. This method involves five steps: namely (i)   identifying an e-Template; (ii) building a SMeA; (iii) mapping the   data; (iv) processing the e-Application; and (v) approving the   e-Application.  The first step involves requirements analysis and   the last four involve data analysis for building a SMeA. To   demonstrate its usefulness, we applied SMeA to a case study of an   application for a licence to set up a new business in   Vietnam.               Keywords: XML/XSD, business process, citizen-centric, e-document, e-government, re-engineering, security criterion expression, service orientation               Categories: E.m, H.3.3, H.3.5, H.4.3, J.1  
20|12|http://www.jucs.org/jucs_20_12|Immersive Education: What does the Future Hold?|
20|12||Exploring Interrelationships among High School Students' Engagement Factors in Introductory Programming Courses via a 3D Multi-user Serious Game Created in Open Sim|  Nikolaos Pellas (University of the Aegean, Greece)  Abstract: The technological affordances of   three-dimensional (3D) multi-user virtual worlds and their   effectiveness in task-based learning approaches are to a large   extent well-established in the international field of computer   literacy research. However, less attention was given to their   positive or negative impact on student engagement. The current study   seeks to investigate the interrelationships of students' engagement   among multidimensional constructs consisting of cognitive, emotional   and behavioral factors in order to understand better the educational   community the learning effectiveness emerged through a 3D   computer-supported and multi-user serious game created for   introductory programming courses. An instructional design framework   based on Papert's theory of Constructionism to be amplified the   students' activities and management of their interactions in a 3D   multi-user serious game created via an Open Sim standalone server   integrated with Scratch4OS is also proposed. Fifty-five   (n=55) voluntary students from three different   high schools participated and experienced in a 3D mind-trap puzzle   game named Co.Co.I.A. (Collaborative Construction   of Interactive Artifacts) to learn basic programming structures. The   empirical study findings indicated that student behavioral   engagement (attention, retention and energy expenditure for activity   completion) had not only a linear correlation with cognitive   engagement (learning strategies for the construction of the   knowledge domain), but it had also a positive association with   emotional engagement (students' positive emotions and achievement   orientation) in collaborative learning tasks, causing the   reinforcement of the other two factors as well.               Keywords: Open Sim, Scratch4OS, programming courses, serious games, student engagement               Categories: L.3.0, L.3.4, L.3.6, L.3.8, L.5.1, L.6.1, L.6.2  
20|12||PhyMEL-WS: Physically Experiencing the Virtual World. Insights into Mixed Reality and Flow State on Board a Wheelchair Simulator|  Carmen Fernández Panadero (Universidad Carlos III de Madrid, Spain)   Valentín de la Cruz Barquero (Universidad Carlos III de Madrid, Spain)   Carlos Delgado Kloos (Universidad Carlos III de Madrid, Spain)   David Morán Núñez (Simumak, Spain)  Abstract: Psychology has widely probed the relationship   between body, mind and emotions, these findings have been   traditionally applied to physical learning but its penetration into   the academic environment was still slower than expected. Virtual   worlds, augmented reality and gamification applied to learning   experiences, have once again highlighted the correlation between the   emotional state of the student and his learning outcomes. There have   been many studies around the concept of flow   proposed by Csíkszentmihályi in 1988, what factors influence their   extent and how to promote it. Although the proposed model is widely   accepted by the scientific community there are some studies showing   discrepancies between theoretical models and experimental   results. The scientific community demands more studies on how to   measure flow and how to analyse the factors behind these   discrepancies. This paper presents a study with 20 students between   21 and 36 years using a wheelchair simulator to reach awareness   about the difficulties that people with disabilities face   daily. Experience confirms the discrepancies between emotions   calculated from the model and expressed directly by students. Two of   the main findings of this study are: (1) the influence of gender on   emotions and (2) some of the factors that moderate the theoretical   measures to fit empirical values are related to the four defining   traits of a game proposed by McGonigal (challenging goals, clear   rules, real time feedback and voluntary participation).               Keywords: 3DOF, Unity3D, Virtual Worlds, accessibility, disability, flow state, learning, simulation, social awareness, wheelchair               Categories: J.3, L.3.0, L.3.1, L.3.6, L.5  
20|12||A Decentralized Infrastructure for Ubiquitous Learning Environments|  Jorge Luis Victória Barbosa (University of Vale do Rio dos Sinos (UNISINOS), Brazil)   Débora Nice Ferrari Barbosa (Feevale University, Brazil)   Jezer Machado de Oliveira (University of Vale do Rio dos Sinos (UNISINOS), Brazil)   Solon Andrade Rabello Jr. (University of Vale do Rio dos Sinos (UNISINOS), Brazil)  Abstract: This article proposes a decentralized   infrastructure for ubiquitous learning environments called   Global. The two main contributions of Global are its decentralized   strategy and its extensible architecture based on software   agents. Global can be specialized to create ubiquitous learning   environments through the extension of its agents or through the   addition of new agents. The article presents the infrastructure   architecture, describing the agents and auxiliary   components. Moreover, the article approaches the implementation and   evaluation of Global through two applications dedicated to   education. The evaluation showed that the infrastructure could be   used for the development of decentralized learning systems,   supporting specifically the characteristics considered as strategic   for ubiquitous learning.               Keywords: decentralization, ubiquitous computing, ubiquitous learning               Categories: L.3.0, L.3.6, L.7.0  
20|12||City Ads: Embedding Virtual Worlds and Augmented Reality in Everyday Educational Practice|  Juan A. Muñoz-Cristóbal (Universidad de Valladolid, Spain)   Alejandra Martínez-Monés (Universidad de Valladolid, Spain)   Juan I. Asensio-Pérez (Universidad de Valladolid, Spain)   Sara L. Villagrá-Sobrino (Universidad de Valladolid, Spain)   Javier E. Hoyos-Torio (Universidad de Valladolid, Spain)   Yannis Dimitriadis (Universidad de Valladolid, Spain)  Abstract: The use of immersive environments such as 3D   virtual worlds (3DVWs) and augmented reality (AR) in education has   been profusely explored during the last decades, showing significant   evidence of its benefits for learning. However, the attempts to   integrate immersive environments in everyday educational practice   are hampered by the difficulties that these environments pose to   teachers willing to set them up within the already demanding ecology   of technological resources present in the classroom. GLUEPS-AR is a   system aimed to help teachers deploy and enact learning designs that   make use of web technologies (Virtual Learning Environments and Web   2.0 tools), as well as immersive environments such as virtual globes   (e.g. Google Earth) used as 3DVW, and general-purpose mobile AR   apps. This paper presents the evaluation of the support provided by   GLUEPS-AR for teachers that want to appropriate immersive   environments in their everyday practice with an affordable   orchestration effort. The evaluation followed an interpretive   research perspective, and it was carried out in the context of an   authentic learning situation about advertising, conducted at a   university undergraduate course for pre-service teachers. The   results of the evaluation showed that GLUEPS-AR effectively   supported the teacher in seamlessly embedding 3DVWs and AR in her   practice.               Keywords: augmented reality, immersion, seamless learning, ubiquitous learning, virtual world               Categories: K.3.1, K.3.2, L.3.0, L.3.6, L.7  
20|12||User Support for Managed Immersive Education: An Evaluation of in-World Training for OpenSim|  Indika Perera (University of Moratuwa, Sri Lanka)   Dulani Meedeniya (University of Moratuwa, Sri Lanka)   Colin Allison (University of St Andrews, United Kingdom)   Alan Miller (University of St Andrews, United Kingdom)  Abstract: Supporting users for a competent interaction   with 3 dimensional virtual worlds can increase their user experience   within the immersive education environment. User manuals and other   guide documents are popular supporting instruments for training new   users of a software system. Quite often these documents have many   screenshots of the application user interface which are used to   steer a new user through sequential orders of actions. However, for   complex scenarios of user interactions, such as those found in   virtual worlds, these types of documents can become unhelpfully   lengthy and unintuitive. The first part of this research was a   comparative analysis of traditional document-based user support with   an in-world approach; a prototype training island was developed in   OpenSim and evaluated for its training support against the OpenSim   user guide documents. The results suggested in-world training can be   a better option of training for OpenSim than training   documents. Second part of this research was to evaluate a completed   training environment, which consist of two OpenSim islands, one for   basic user training and one for training advanced OpenSim   management. The results suggested that training for advanced OpenSim   management, which is not covered in user guide documents, make users   competent for managing their immersive environment. The final part   of the research, a case study, examined the effective use of this   complete training environment for module teaching and learner   support. The results suggest that for learning the skills essential   for productive use of OpenSim-based educational environments, an   in-world approach covering advanced management functions of OpenSim   is likely to be a better option than traditional user manuals for   the future needs for immersive education as a mainstream   practice.               Keywords: OpenSim, immersive education, in-world training, user training, virtual worlds               Categories: L.3.0, L.3.6, L.3.7, L.5.0, L.5.1  
20|13|http://www.jucs.org/jucs_20_13|Collaborative Computing and Applications|
20|13||Developing Distributed Collaborative Applications with HTML5 under the Coupled Objects Paradigm|  Nelson Baloian (University of Chile, Chile)   Diego Aguirre (University of Chile, Chile)   Gustavo Zurita (University of Chile, Chile)  Abstract: One of the main tasks in developing distributed   collaborative systems is to support synchronization processes. The   Coupled Objects paradigm has emerged as a way to easily support   these processes by dynamically coupling arbitrary user interface   objects between heterogeneous applications. In this article we   present an architecture for developing distributed collaborative   applications using HTML5 and show its usage through the design and   implementation of a series of collaborative systems in different   scenarios. The experience of developing and using this architecture   has shown that it is easy to use, robust and has good   performance.                 Categories: H.3.1, H.3.2, H.3.3, H.3.7, H.5.1  
20|13||Understanding Collaboration in Volunteer Computing Systems|  Davide Vega (Universitat Politècnica de Catalunya, Spain)   Roc Meseguer (Universitat Politècnica de Catalunya, Spain)   Felix Freitag (Universitat Politècnica de Catalunya, Spain)   Sergio F. Ochoa (Universidad de Chile, Chuile)  Abstract: Volunteer computing is a paradigm in which   devices participating in a distributed environment share part of   their resources to help others perform their activities. The   effectiveness of this computing paradigm depends on the   collaboration attitude adopted by the participating   devices. Unfortunately for software designers it is not clear how to   contribute with local resources to the shared environment without   compromising resources that could then be required by the   contributors. Therefore, many designers adopt a conservative   position when defining the collaboration strategy to be embedded in   volunteer computing applications. This position produces an   underutilization of the devices local resources and reduces the   effectiveness of these solutions. This article presents a study that   helps designers understand the impact of adopting a particular   collaboration attitude to contribute with local resources to the   distributed shared environment. The study considers five   collaboration strategies, which are analyzed in computing   environments with both, abundance and scarcity of resources. The   obtained results indicate that collaboration strategies based on   effort-based incentives work better than those using   contribution-based incentives. These results also show that the use   of effort-based incentives does not jeopardize the availability of   local resources for the local needs.               Keywords: collaboration strategy, effort-based incentives, resource sharing, software design, volunteer computing               Categories: C.2.1, C.2.3, C.2.4, C.2.m  
20|13||Semantic Based Support for Planning Information Delivery in Human-agent Collaborative Teams|  Natasha Lino (The University of Edinburgh, United Kingdom)   Clauirton Siebra (Federal University of Paraíba, Brazil)   Austin Tate (The University of Edinburgh, United Kingdom)  Abstract: Collaborative teams are organizations where   joint members work together to solve mutual goals. Mixed-initiative   planning systems are useful tools in such situations, because they   can support several common activities performed in these   organizations. However, as collaborative members are involved in   different decision making planning levels, they consequently require   different information types and forms of receiving planning   information. Unfortunately, collaborative planning delivery is a   subject that has not been given much attention by researchers, so   that users cannot make the most of such systems since they do not   have appropriate support for interaction with them. This work   presents a general framework for planning information delivery,   which is divided into two main parts: a knowledge representation   aspect based on an ontological set and a reasoning mechanism for   multimodality visualization. This framework is built on a   mixed-initiative planning basis, which considers the additional   requirements that the human presence brings to the development of   collaborative support systems.               Keywords: intelligent planning, multiagent systems, ontology design               Categories: H.5.2, M.4  
20|13||An Adaptive Intent Resolving Scheme for Service Discovery and Integration|  Cheng Zheng (Western University, Canada)   Weiming Shen (Western University, Canada)   Hamada Ghenniwa (Western University, Canada)  Abstract: Service discovery and integration is an   important research area with efforts invested to explore the   potential advantages of collaborative computing in general and   service-oriented computing in particular. However, current   technologies still limit their application within the reach of   enterprise systems or privately available services. Intents is an   emerging and innovative technique aimed to discover and integrate   publically available services. In Intents, intent message resolving   is a critical step which is deemed to decide the quality of the   whole system. However, existing schemes applied in intent resolving   adopt the exact-matching strategy which may rule out services   desired by the user. This paper brings in information retrieval   techniques and applies them to intent resolving. We take an   empirical approach through extensive experiments and analyses on a   real dataset to obtain guiding principles. Based on the resulting   principles, an adaptive intent resolving scheme is   designed. Afterwards, we integrate the scheme into the Intents user   agent developed in a previous project.               Keywords: intent resolving, intents, service discovery and integration, web services               Categories: H.1.0, H.3.4, H.4.0, H.5.2  
20|13||EmotionsOnto: an Ontology for Developing Affective Applications|  Juan-Miguel López-Gil (Universidad del País Vasco (UPV/EHU), Spain)   Rosa Gil (Universitat de Lleida, Spain)   Roberto García (Universitat de Lleida, Spain)   Cesar A. Collazos (Universidad del Cauca, Colombia)  Abstract: EmotionsOnto is a generic ontology for   describing emotions and their detection and expression systems   taking contextual and multimodal elements into account. The ontology   is proposed as a way to develop an easily computerizable and   flexible formal model. Moreover, it is based on the Web Ontology   Language (OWL) standard, which also makes ontologies easily   shareable and extensible. Once formalized as an ontology, the   knowledge about emotions can be used in order to make computers more   personalised and adapted to users' needs. The ontology has been   validated and evaluated by means of an applications based on a   emotions-aware Tangible User Interface (TUI). The TUI is guided by   emotion knowledge previously gathered using the same TUI and   modelled using EmotionsOnto.               Keywords: context, design of affective interaction systems, emotions, multimodality, ontologies               Categories: H.5.2, I.2.4  
20|13||A Utility-Oriented Routing Scheme for Interest-Driven Community-Based Opportunistic Networks|"  Xiuwen Fu (Wuhan University of Technology, China)   Wenfeng Li (Wuhan University of Technology, China)   Giancarlo Fortino (University of Calabria, Italy)   Pasquale Pace (University of Calabria, Italy)   Gianluca Aloi (University of Calabria, Italy)   Wilma Russo (University of Calabria, Italy)  Abstract: Opportunistic networks, as representative   networks evolved from social networks and Ad-hoc networks, have been   on cutting edges in recent years. Many research efforts have focused   on realistic mobility models and cost-effective routing schemes. The   concept of ""community"", as one of the most   inherent attributes of opportunistic networks, has been proved to be   very helpful in simulating mobility traces of human society and   selecting suitable message forwarders. This paper proposes an   interest-driven community-based mobility model by considering   location preference and time variance in human behavior   patterns. Based on this enhanced mobility model, a novel two-layer   routing algorithm, named InterCom, is presented   by jointly considering utilities generated by users' activity degree   and social relationships. The results, obtained throughout an   intensive simulation analysis, show that the proposed routing scheme   is able to improve delivery ratio while keeping the routing overhead   and transmission delay within a reasonable range with respect to   well-known routing schemes for opportunistic networks.               Keywords: community, mobility model, opportunistic Nntworks, performance evaluation, routing algorithm, simulation analysis               Categories: H.3.1, H.3.2, H.3.3, H.3.7, H.5.1  "
20|13||Maximum Capacity Overlapping Channel Assignment Based on Max-Cut in 802.11 Wireless Mesh Networks|  Ming Yang (Southeast University, P.R. China)   Bo Liu (Southeast University, P.R. China)   Wei Wang (Southeast University, P.R. China)   Junzhou Luo (Southeast University, P.R. China)   Xiaojun Shen (University of Missouri, USA)  Abstract: By exploiting multi-radio multi-channel   technology, wireless mesh networks can effectively provide wireless   broadband access to the Internet for mobile users. Due to the   limited number of orthogonal channels, overlapping channel   assignment is one of the main factors that greatly affect the   network capacity. However, current results in this area are not so   satisfying. In this paper, we first propose a model for measuring   achieved network capacity in MR-WMNs. Then we prove that finding an   optimal overlapping channel assignment in a given MR-WMN with odd   number of channels, is equivalent to finding an optimal assignment   by only using its orthogonal channels. This theory allows us to use   fewer channels to solve complicated channel assignment   problems. Third, we prove that in 802.11b/g MR-WMN the simplified   optimization problem is a Max-3-Cut problem. Although this problem   is NP-hard, it has an efficient approximation algorithm that   achieves approximation ratio of 1.19616 probabilistically by using   the algorithm for Max-Cut whose approximation ratio is 1.1383   probabilistically. Based on the algorithm for Max-Cut, this paper   proposes Max-Cut based channel assignment (MCCA) which uses a   heuristic method to adjust the result produced by the Max-Cut   algorithm to achieve an even better result. Finally, we perform   extensive simulations to compare the MCCA with a state-of-the-art   Tabu-Search based algorithm. The results show that the Max-Cut based   overlapping channel assignment algorithm effectively and efficiently   improves on the network capacity compared with existing   algorithms.               Keywords: Max-Cut, capacity optimization, graph coloring, multi-radio multi-channel wireless mesh network, overlapping channel assignment               Categories: C.2.1, C.2.5, C.2.6, G.1.6, G.2.3  
20|14|http://www.jucs.org/jucs_20_14|Managing Editor's Column|
20|14||Epidemia: Variable Consistency for Transactional Cloud Databases|  Itziar Arrieta-Salinas (Universidad Pública de Navarra, Spain)   José Enrrique Armendáriz-Iñigo (Universidad Pública de Navarra, Spain)   Joan Navarro (La Salle - Ramon Llull University, Spain)  Abstract: Classic replication protocols running on   traditional cluster-based databases are currently unable to meet the   ever-growing scalability demands of many modern software   applications. Recent cloud-based storage repositories overcome such   limitations by fostering availability and scalability over data   consistency and transactional support. However, many applications   that cannot resign from their transactional nature are unable to   benefit from the cloud paradigm. This paper presents Epidemia, a   distributed storage architecture featuring a hybrid approach that   combines classic database replication with a cloud-inspired   infrastructure to provide transactional support and high   availability. This architecture is able to offer different   consistency levels according to the client demands, thanks to a   replication strategy based on epidemic updates in which the replicas   of each data partition are organized hierarchically. Additionally,   the behavior of a prototype implementation under different workload   scenarios is evaluated. Conducted experiments verify that (1)   configuration parameters such as the partitioning scheme or the   replication protocol play a crucial role on system's throughput, and   (2) the existence of replica hierarchies that are asynchronously   updated is able to alleviate the scalability limitations of   traditional replicated databases by directing transactions that   tolerate a certain staleness in the versions of retrieved data items   to these replicas.               Keywords: cloud computing, data consistency, distributed databases, elasticity, transaction processing, transactions               Categories: H.2.4  
20|14||Formal Modeling and Verification of Motor Drive Software for Networked Motion Control Systems|  Youngdong Kim (University of Seoul, Korea)   Ikhwan Kim (University of Seoul, Korea)   Inhye Kang (University of Seoul, Korea)   Taehyoun Kim (University of Seoul, Korea)   Minyoung Sung (University of Seoul, Korea)  Abstract: This paper presents a model-based approach to   the design and verification of motordrive software for networked   motion control systems. We develop a formal model for an   Ethernetbased motion system, where, using timed automata, we   describe the concurrent and synchronizedbehaviors of the components,   i.e., motion controller, motor drives, and communication links. The   drive, in particular, is modeled in enough detail to accurately   reflect the software implementa-tion used in a real drive. We use   the design of multitasked drive software with fixed-priority   preemptive scheduling. With UPPAAL model checking, we verify the   precision and accuracyof the rendered motion in terms of the   requirements on the actuation delay at each drive and the actuation   deviation between different drives, respectively. The analysis   results demonstratethe benefits of our model-based approach in the   safety verification and design space exploration of motor drive   software. We show that it is possible to verify deadlock freeness   and real-timeschedulability in an early design phase. And, for   varying number of drives and size of messages, we can successfully   determine the combination of task periods that leads to the best   precision andaccuracy.               Keywords: Actua-tion delay and deviation, formal methods, motor drive software, timed automata               Categories: D.2.4, J.7  
20|14||An Effective Genetic Algorithm for Multi-objective Integrated Process Planning and Scheduling with Various Flexibilities in Process Planning|  Xinyu Li (Huazhong University of Science and Technology, China)   Xiaoyu Wen (hengzhou University of Light Industry, China)   Liang Gao (University of Science and Technology, China)  Abstract: Process planning and scheduling are two of the   most important functions in modern manufacturing system. Considering   their complementarity, integrating them more tightly can improve the   performance and productivity of the whole manufacturing   system. Meanwhile, the multi-objective optimization problem is   widespread existing in manufacturing system. In this paper, an   effective genetic algorithm is proposed to optimize the   multi-objective integrated process planning and scheduling (IPPS)   problem with various flexibilities in process planning. Three types   of flexibilities related to process, sequence and machine are   considered. And three objectives including makespan, total machine   workload and maximal machine workload are taken into account   simultaneously. According to the model and characteristics of   multi-objective IPPS, the framework of the proposed algorithm is   designed to optimize three objectives simultaneously. Effective   genetic operations are employed in the proposed algorithm. Pareto   set is set to store and maintain the solutions obtained during the   searching procedure, the proposed algorithm could get several Pareto   optimal solutions during one searching process. Two experiments are   employed to test the performance of the proposed algorithm. The   experiment results show that the proposed algorithm can solve   multi-objective IPPS problem with various flexibilities in process   planning effectively and obtain good solutions.               Keywords: Integrated process planning and scheduling, genetic algorithm, multi-objective optimization               Categories: J.6  
20|14||A Self-stabilizing Algorithm for Locating the Center of Maximal Outerplanar Graphs|  Michal Pańczyk (Maria Curie-Sklodowska University, Poland)   Halina Bielak (Maria Curie-Sklodowska University, Poland)  Abstract: Self-stabilizing algorithms model distributed   systems, which automatically recover from transient failures in the   state of the system.  The center of a graph   comprises a set of vertices with minimum eccentricity. Farley and   Proskurowski showed the linear time algorithm for locating the   center of an outerplanar graph in the classical computing   paradigm. The present paper investigates the selfstabilizing   algorithm for finding the center of maximal outerplanar graphs,   using a new approach with dual trees.               Keywords: center of a graph, outerplanar graph, self-stabilization               Categories: C.2.4, G.2.2  
20|14||Context Classification Framework for Handset-based End User Studies|  Tapio Soikkeli (Aalto University, Finland)   Juuso Karikoski (Aalto University, Finland)   Heikki Hämmäinen (Aalto University, Finland)  Abstract: Utilizing rich end user context information is   viewed as one of the necessary approaches in developing more   personalized mobile services and user experiences. The practical   impact of end user context research and new opportunities in the   field provided by emerging data collection methods such as   handset-based measurements (i.e., collecting usage data directly   from the end users' devices) have inspired new highly interesting   large scale empirical context studies, but also brought quite   diverse usage of the term context itself. Proper discussion and   usage of context requires an unambiguous statement of how the term   is understood in the particular case. On one hand the term should be   positioned with the existing and commonly understood general   definitions, but on the other hand it should also be acknowledged   that especially an empirical research paper, or a context-aware   service, can grasp only some specific aspects or elements of   context. This paper proposes a context classification framework that   aims to clarify the use of the term context in handset-based related   end user studies. The framework is partly based on the experimental   experience accumulated in our own handset panel studies. While   helping researchers to plan context data acquisition and communicate   and position the end user context elements used, the framework helps   other stakeholders, such as application developers and service   providers, to identify and utilize research and data most relevant   for their particular needs. The paper also demonstrates the   expressivity of the framework by examples.               Keywords: context, end user, framework, handset-based measurements, privacy               Categories: H.1.0, H.4.0, K.8.0  
20|15|http://www.jucs.org/jucs_20_15|The Social Media in Academia and EducationResearch R-evolutions and a Paradox: Advanced Next Generation Social Learning Innovation|
20|15||Web 2.0 and Social Networking Services in Municipal Emergency Management: A Study of U.S. Cities|  Chien-Wen Shen (National Central University, Taiwan)   Shih-Hsuan Chu (National Central University, Taiwan)  Abstract: Given the increasingly important role social   networking services play as sources of information during disasters,   this study aims to investigate how the municipal governments and   their emergency agencies employed RSS or Atom, webcast, Facebook,   Twitter, YouTube, and photo-sharing platforms in the major   U.S. cities. Our findings show that the emergency agencies of San   Diego, Los Angeles, and San Jose are the top 3 performers on the Web   2.0 services. Regarding the social networking services provided by   municipal emergency agencies, New York, Los Angeles, and   Philadelphia rank among the top 3 cities. While San Diego city   government and its emergency agencies provide the most number of Web   2.0 channels, New York City and its emergency agencies have the   highest number of services in Facebook, Twitter, YouTube, and   photo-sharing platforms (Flickr, Pinterest, and Instagram). Because   big cities can support better collaboration and communication during   crisis if they provide more services on social networking services,   under-performing cities can enhance their services by learning from   the top-performing cities such as San Diego or New York City.               Keywords: Web 2.0, Websyndication, e-Government, emergence management, social media               Categories: A.1, K.4.1, K.4.2  
20|15||Mapping the Impact of Social Media and Mobile Internet on Chinese Academia's Performance: A Case on Telemedicine Research 2005-2013|"  Jinghuai She (Capital University of Economics and Business, P.R. China)   Xi Zhang (Tianjin University, P.R. China)   Weiguang Wang (Chinese Academy of Sciences, P.R. China)   Patricia Ordóñez de Pablos (University of Oviedo, Spain)  Abstract: Social media and mobile internet are both   hottest topics in internet technologies which bring great challenges   and wonderful opportunities for a large number of researchers in   recent years. In some research fields, i.e., telemedicine or   e-healthcare, Chinese researchers quickly took advantage of the   spread of social media and mobile internet. In this study, we   conducted a citation analysis with CiteSpace II by comparing the   performance between researchers from China and advanced countries   (e.g., USA) in Telemedicine field from 2005-2013. Although there   remain huge gaps between China and developed countries, we found   that social networks and mobile internet helped Chinese researchers   to narrow the gap quickly in recent years. We also found that in the   sub fields such as ""SNS-facilitated telemedicine"" or ""m-healthcare"",   Chinese researchers even achieved similar performance as compared   with world class researchers. These findings implicate that SNS or   mobile internet may help researchers in developing countries to   bridge the digital divide and enhance ""late-mover   advantage"".               Keywords: Chinese academia, citation analysis, e-healthcare, mobile internet, social network               Categories: J.4, K.1, K.3, L.7  "
20|15||Media Content Adaptation Framework for Technology Enhanced Mobile e-Learning|  Atif Alamri (King Saud University, Saudi Arabia)   Ghulam Muhammad (King Saud University, Saudi Arabia)   Abdulhameed A. Al Elaiwi (King Saud University, Saudi Arabia)   Khalid N. Al-Mutib (King Saud University, Saudi Arabia)   M. Shamim Hossain (King Saud University, Saudi Arabia)  Abstract: The increasing demand for ubiquitous access to   technology enhanced learning environment has faced a challenge of   heterogeneity in terms of networks, mobile device, platforms and   finally, the learning content in various formats. In order to   alleviate the challenge of the said diversity, content adaptation is   essential. However, because of the diversity of the mobile users,   networks and the rich media learning content, it is a major   challenge for the access of learning content by the desired devices   in the mobile learning environment. In order to alleviate the   challenge of learning content mismatch, content adaptation is   essential. This paper describes a content adaptation framework for   mobile e-learning.               Keywords: E-learning, learning object, media content adaptation, mobile learning               Categories: H.3.5, H.5.1, H.5.2, H.5.3  
20|15||Technological Readiness for Teaching Practices in Immersive Learning Environments Open Sim|  María Graciela Badilla Quintana (Universidad Católica de la Santísima Concepción, Chile)   Miquel Àngel Prats Fernández (Universitat Ramon Llull, City)   Marcelo Careaga Butter (Universidad Católica de la Santísima Concepción, Chile)   Juan Carlos Gacitúa (Universidad de Concepción, Chile)   Cecilia Vásquez Carillo (University of Bridgeport, USA)  Abstract: This article presents some results obtained   partially during the first year of the TYMMI project. TYMMI's aim is   to strengthen the professional performance of pre-service teachers   in the real classroom. Through the design of a free immersive   virtual world Open Sim we have developed a technology readiness for   27 pre-service high school English teachers who are preparing their   career at Universidad Católica de la Santísima Concepcion, in   Chile. Initial results show some evidence of working in a three   dimensional environment and in a virtual learning platform (called   EV@ supported by Moodle) through Sloodle. One of the first findings   we have gathered are: motivation for using these environments,   strengthening ICT skills, and also technological difficulties for   the development of the academic activities of interaction during   teaching practices.               Keywords: Open Sim, Sloodle, Virtual Worlds, teaching practices               Categories: L.2.3, L.5.0, L.6.1  
20|15||Adapting Learning Contents to Mobile Devices and Context to Improve Students' Learning Performance: A Case Study|  Antonio Garcia Cabot (University of Alcala, Spain)   Eva Garcia-Lopez (University of Alcala, Spain)   Luis de-Marcos (University of Alcala, Spain)   Javier Abraham-Curto (University of Alcala, Spain)  Abstract: E-learning has been a revolution in recent   years in training field. This, combined with the increased use of   mobile devices has caused the emergence of m-learning. Hence new   problems have appeared in the training field, such as displaying   correctly learning contents in a mobile device that has restricted   features or taking into account the learner's context in the   learning process, who could be anywhere. For this reason the   adaptation concept is used, in order to personalize or adapt the   learning contents to each student. This paper presents a case study   in a real course using a multi-agent system for adapting the   learning contents to the learner's context and to his/her mobile   device. The results of the experiment show that the students who   used the adaptive system (experimental group) obtained better grades   than the students who did not (control group).               Keywords: case study, context-aware, experimental design, learning performance, mobile device adaptation               Categories: G.3, I.2.6, K.3.2  
20|15||Leveraging Non-explicit Social Communities for Learning Analytics in Mobile Remote Laboratories|  Pablo Orduña (University of Deusto, Spain)   Aitor Almeida (University of Deusto, Spain)   Salvador Ros (Spanish University for Distance Education (UNED), Spain)   Diego López-de-Ipiña (University of Deusto, Spain)   Javier Garcia-Zubia (University of Deusto, Spain)  Abstract: When performing analytics on educational   datasets, the best scenario is where the dataset was designed to be   analyzed. However, this is often not the case and the data   extraction becomes more complicated. This contribution is focused on   extracting social networks from a dataset which was not adapted for   this type of extraction and where there was no relation among   students: a set of remote laboratories where students individually   test their experiments by submitting their data to a real remote   device. By checking which files are shared among students and   submitted individually by them, it is possible to know who is   sharing how many files with who, automatically extracting what   students are bigger sources. While it is impossible to extract the   full real social network of these students, all the edges found are   clearly part of it. These relations can indeed be used as a new   input for performing the analytics on the dataset.               Keywords: data mining, learning analytics, remote laboratories, social network analysis               Categories: H.2.8, K.3.1, K.3.2  
20|15||"A ""Mobile Virtual Lab"" for Supporting Engineering Curricula"|  Francesco Colace (DIEM - Università degli Studi di Salerno, Italy)   Massimo De Santo (DIEM - Università degli Studi di Salerno, Italy)   Luca Greco (DIIN - Università degli Studi di Salerno, Italy)  Abstract: E-Learning is offering new approaches and   opportunities in the field of education above all in the sector of   the virtual laboratories. The opportunity to interact with the real   instruments that are in a lab represents an effective way for the   implementation of a teaching approach oriented to a problem solving   strategy. The wide diffusion of mobile devices (smartphones and   tablets) makes this approach more effective and appealing for the   students. In this paper we introduce Jini Technologies to design and   implement a distributed architecture for a mobile virtual lab for   supporting the activities of an Electronic Measurement Course. The   aim of this environment is offering to the students the opportunity   to experiment a real interaction with the laboratory's   instruments everywhere and every time by the use of mobile   devices. A prototype of the architecture and its services will be   discussed and an evaluation campaign will be showed.               Keywords: distributed systems, m-learning, trial and error approach, virtual lab               Categories: H.1, H.5, L.5  
20|15||Does a Change in Weekend Days Have an Impact on Social Networking Activity?|  Basit Shahzad (King Saud University, Saudi Arabia)   Esam Alwagait (King Saud University, Saudi Arabia)  Abstract: Twitter has gained phenomenal popularity over   time, especially in Saudi Arabia, where it enjoys unmatched usage   and is considered highly attractive. Tweets are now an important   source of trend-setting and marketing along with their conventional   use for information exchange. Recently, Saudi Arabia changed its   working days so that weekends are Friday and Saturday instead of   Thursday and Friday. To identify the impact of such a change on the   usage of social networks, five detailed experiments are   conducted. Time-stamped data for selected individuals are retrieved   from Twitter and analyzed accordingly to observe usage   behavior. Moreover, the results of these experiments are compared   with results obtained last year, before the weekend was   changed.               Keywords: Saudi Facebook connectivity, Saudi Social activity trends, Saudi weekend Twitter, best time to tweet, weekend change connectivity               Categories: E.2, M.1, M.6  
20|15||Enhancing Learning Experience of the Disabled: An Accessible Tourism Platform|"  Yen-Chun Jim Wu (National Taiwan Normal University, Taiwan)   Chan-Lan Chang (Shu-Te University, Taiwan)   Ying-Jiun Hsieh (National Chung Hsing University, Taiwan)  Abstract: The purpose of the study is to propose a   completely barrier-less, or ""accessible"" tourism platform and makes   suggestions to facilitate current travel information for disabled   persons. Drawing on in-depth interviews with tourism industry   representatives and academics, and applying Long Tail theory's three   ""forces"" and nine ""rules"", the study makes assessments as to the   viability of the disabled tourism niche, creating an accessible   tourism communication network to connect upstream and downstream   travel agencies in a Web 2.0 environment. Web 2.0 is an appropriate   platform that can be seen as a launching pad or accelerator to share   knowledge between business and customer, as well as customer and   customer.  This platform can provide adoptive learning experiences   and behavioural enhancements.  This study sets up an accessible   tourism communications network based on Web 2.0 concepts,   contributing a real platform that travel agents can refer to as they   take their first steps to provide travel packages that accommodate   the needs of the disabled, a previously marginally represented group   in the sustainable tourism literature.               Keywords: Web 2.0, long tail theory, the disabled, tourism               Categories: M.0, M.5  "
20|2|http://www.jucs.org/jucs_20_2|Managing Editor's Column|
20|2||Showing the Benefits of Applying a Model Driven Architecture for Developing Secure OLAP Applications|  Carlos Blanco (University of Cantabria, Spain)   Ignacio García-Rodríguez de Guzmán (University of Castilla-La Mancha, Spain)   Eduardo Fernández-Medina (University of Castilla-La Mancha, Spain)   Juan Trujillo (University of Alicante, Spain)  Abstract: Data Warehouses (DW) manage enterprise   information that is queried for decision making purposes by using   On-Line Analytical Processing (OLAP) tools. The establishment of   security constraints in all development stages and operations of the   DW is highly important since otherwise, unauthorized users may   discover vital business information.  The final users of OLAP tools access and analyze the information from the corporate DW by using specific views or cubes based on the multidimensional modelling containing the facts and dimensions (with the corresponding classification hierarchies) that a decision maker or group of decision makers are interested in. Thus, it is important that security constraints will be also established over this metadata layer that connects the DW's repository with the decision makers, that is, directly over the multidimensional structures that final users manage. In doing so, we will not have to define specific security constraints for every particular user, thereby reducing the developing time and costs for secure OLAP applications.  In order to achieve this goal, a model driven architecture to automatically develop secure OLAP applications from models has been defined. This paper shows the benefits of this architecture by applying it to a case study in which an OLAP application for an airport DW is automatically developed from models. The architecture is composed of: (1) the secure conceptual modelling by using a UML profile; (2) the secure logical modelling for OLAP applications by using an extension of CWM; (3) the secure implementation into a specific OLAP tool, SQL Server Analysis Services (SSAS); and (4) the transformations needed to automatically generate logical models from conceptual models and the final secure implementation.               Keywords: MDA, OLAP, SSAS, Security, case study, confidentiality, data warehouses, model driven, transformations               Categories: H.2, H.2.1, H.2.2, K.6.5, L.4.0  
20|2||Identifying Fuzzy Controllers Parameter by Fuzzy Clustering Technique|  Tarek Chenaina (Manouba University, Tunisia)   Abdulaziz Alraddadi (Taibah University, Saudi Arabia)  Abstract: In fuzzy control, there is a large amount of   parameters involved in the system design. Due to their   interdependency, these parameters are sometimes conflicting causing   an unavoidable trade-off among performance indices. It is difficult   to discern the best combination of fuzzy parameters with respect to   a given range of some performance indices. In this case, a   clustering technique represents a powerful tool to deal with the   problem. Main clusters of fuzzy controllers having similar behavior   with respect to some performance indices are discovered. In order to   precisely characterize rule bases and transform them to a   quantifiable entity, transition between topological and numerical   form of fuzzy rule bases is studied. Formulating a vector space   structure and a base of relationships between fuzzy sets represents   one of the main foci of the research. Adding logic parameters and   defuzzification procedures to the formulated vectors is required to   apply the clustering technique. In fact, this latter requires the   existence of quantifiable fuzzy controllers. The obtained vectors   are then treated by a fuzzy-neural clustering algorithm. Membership   nuance to a cluster allows better legibility to evaluate relevance   and relative interest of fuzzy controller parameters according to   performance indices.               Keywords: classes of fuzzy controllers, clustering and learning, fuzzy logic, fuzzy logic controllers, vector space               Categories: I.2, I.5  
20|2||DIE: A Domain Specific Aspect Language for IDE Events|  Johan Fabry (University of Chile, Chile)   Romain Robbes (University of Chile, Chile)   Marcus Denker (INRIA Lille Nord Europe, France)  Abstract: Integrated development environments (IDEs) have   become the primary way to develop software. Besides just using the   built-in features, it becomes more and more important to be able to   extend the IDE with new features and extensions. Plugin   architectures exist, but they show weaknesses related to   unanticipated extensions and event handling. In this paper, we argue   that a more general solution for extending IDEs is needed. We   present and discuss a solution, motivated by a set of concrete   examples: a domain specific aspect language for IDE events. In it,   join points are events of interest that may trigger the advice in   which the behavior of the IDE extension is called. We show how this   allows for the development of IDE plugins and demonstrate the   advantages over traditional publish/subscribe systems.               Keywords: IDE, aspects, development environment, domain specific aspect languages, plugins               Categories: D.2.3, D.2.6,, D.3.2  
20|2||Unsupervised Structured Data Extraction from Template-generated Web Pages|  Tomas Grigalis (Vilnius Gediminas Technical University, Lithuania)   Antanas Čenys (Vilnius Gediminas Technical University, Lithuania)  Abstract: This paper studies structured data extraction   from template-generated Web pages. Such pages contain most of   structured data on the Web. Extracted structured data can be later   integrated and reused in very big range of applications, such as   price comparison portals, business intelligence tools, various   mashups and etc. It encourages industry and academics to seek   automatic solutions. To tackle the problem of automatic structured   Web data extraction we present a new approach - structured data   extraction based on clustering visually similar Web page   elements. Our method called ClustVX combines visual and pure HTML   features of Web page to cluster visually similar Web page elements   and then extract structured Web data. ClustVX can extract structured   data from Web pages where more than one data record is present. With   extensive experimental evaluation on three benchmark datasets we   demonstrate that ClustVX achieves better results than other   state-of-the-art automatic structured Web data extraction methods.               Keywords: Deep Web, data extraction, structured web data, wrapper induction               Categories: H.0, H.2.8, H.3.3, H.3.5  
20|2||Towards Formal Linear Cryptanalysis using HOL4|  Osman Hasan (University of Sciences and Technology (NUST), Pakistan)   Syed Ali Khayam (University of Sciences and Technology (NUST), Pakistan)  Abstract: Linear cryptanalysis (LC), first introduced by   Matsui, is one of the most widely used techniques for judging the   security of symmetric-key cryptosystems. Traditionally, LC is   performed using computer programs that are based on some fundamental   probabilistic algorithms and lemmas, which have been validated using   paper-and-pencil proof methods. In order to raise the confidence   level of LC results, we propose to formally verify its foundational   probabilistic algorithms and lemmas in the higher-orderlogic theorem   prover HOL4. This kind of infrastructure would also facilitate   reasoning about LC properties within the HOL4 theorem prover. As a   first step towards the proposed direction, this paper presents the   formalization of two foundations of LC, which were initially   proposed in Matsui's seminal paper. Firstly, we formally verify the   Piling-up Lemma, which allows us to compute the probability of a   block cipher's linear approximation, given the probabilities of   linear approximations of its individual modules. Secondly, we   provide a formal probabilistic analysis of Matsui's algorithm for   deciphering information about the unknown bits of a cipher key. In   order to illustrate the practical effectiveness and utilization of   our formalization, we formally reason about a couple of LC   properties.               Keywords: cryptography, formal verification, higher-order logic, probability theory, theorem proving                
20|2||Combining Psycho-linguistic, Content-based and Chat-based Features to Detect Predation in Chatrooms|  Javier Parapar (University of A Coruña, Spain)   David E. Losada (Universidade de Santiago de Compostela, Spain)   Alvaro Barreiro (University of A Coruña, Spain)  Abstract: The Digital Age has brought great benefits for   the human race but also some draw-backs. Nowadays, people from   opposite corners of the World can communicate online via instant   messaging services. Unfortunately, this has introduced new kinds of   crime. Sexual predators haveadapted their predatory strategies to   these platforms and, usually, the target victims are kids. The   authorities cannot manually track all threats because massive   amounts of online conversationstake place in a daily   basis. Automatic methods for alerting about these crimes need to be   designed. This is the main motivation of this paper, where we   present a Machine Learning approachto identify suspicious subjects   in chat-rooms. We propose novel types of features for representing   the chatters and we evaluate different classifiers against the   largest benchmark available.This empirical validation shows that our   approach is promising for the identification of predatory   behaviour. Furthermore, we carefully analyse the characteristics of   the learnt classifiers. Thispreliminary analysis is a first step   towards profiling the behaviour of the sexual predators when   chatting on the Internet.               Keywords: cybercrime, machine learning, psycho-linguistic analysis, sexual predation, support vector machines, text mining               Categories: H.3.0, H.4  
20|2||A Virtual Campus for E-learning Inclusion: The Case of SVC-G9|  Daniel Perez-Gonzalez (University of Cantabria, Spain)   Pedro Soto-Acosta (University of Murcia, Spain)   Simona Popa (University of Murcia, Spain)  Abstract: Academics and professionals agree that, to adapt   higher education institutions to the XXI century, it is imperative   to extend the use of ICT as well as the virtualization of many   human-interaction activities. There is therefore a need to move from   the use of ICT as support tools to e-learning instruments based on   virtual environments. These environments can be used for   e-inclusion. That is, systems can be used to remove communication   and interaction barriers that people with disabilities may face in   the real world. This paper presents a project which implies the   implementation of a virtual interuniversity campus where nine   Spanish higher education institutions took part. To enhance Web   accessibility as the usability of the system by users with   disabilities is one of the main project's objectives. In addition,   the paper analyses the teen-year experience of an e-business course   for engineers offered simultaneously by the nine universities   through this platform. The main conclusions of this work can be   valuable to higher education institutions which have implemented or   intend to implement a virtual interuniversity campus.               Keywords: accessibility, e-inclusion, e-learning, higher education, teaching innovation, usability               Categories: L.2.3, L.2.5, L.2.7, L.3.0, L.3.1  
20|3|http://www.jucs.org/jucs_20_3|Conceptual Modelling with Specific Focus on Service-Oriented Systems|
20|3||Towards an Extended Model of Conceptual Representations in Formal Ontologies: A Typicality-Based Proposal|  Marcello Frixione (University of Genoa, Italy)   Antonio Lieto ((University of Turin, Italy)  Abstract: In this paper we propose a possible solution for   the problem of the computational representation of non-classical   concepts (i.e. concepts that cannot be characterized in terms of   necessary and sufficient conditions) in the field of formal   ontologies. In particular, taking into account empirical evidences   coming from cognitive psychology, according to which concept   representation is not a unitary phenomenon, we suggest that a   similar approach to the representation of conceptual knowledge could   be useful also in the field of ontology based technologies. Finally   we propose, in a linked open data perspective, conceptual spaces as   a suitable framework for developing some aspects of the presented   proposal.               Keywords: concept representation, concepts theories, conceptual spaces, formal ontologies, hybrid conceptual representation, prototypes               Categories: I.2.0, I.2.4  
20|3||Translation of Structural Constraints from Conceptual Model for XML to Schematron|  Jakub Klímek (Czech Technical University in Prague, Czech Republic)   Soběslav Benda (Charles University in Prague, Czech Republic)   Martin Nečaský (Charles University in Prague, Czech Republic)  Abstract: Today, XML (eXtensible Markup Language) is a   standard for exchange inside and among IT infrastructures. For the   exchange to work an XML format must be negotiated between the   communicating parties. The format is often expressed as an XML   schema. In our previous work, we introduced a conceptual model for   XML, which utilizes modeling, evolution and maintenance of a set of   XML schemas and allows schema designers to export modeled formats   into grammar-based XML schema languages like DTD and XML   Schema. However, there is another type of XML schema languages   called rule-based languages with Schematron as their main   representative. In our preceding conference paper [Benda et   al.(2013)] we briefly introduced the process of translation from our   conceptual model to Schematron. Expressing XML schemas in Schematron   has advantages over grammar-based languages and in this paper, we   describe the previously introduced translation in more detail with   focus on structural constraints and how they are represented in   Schematron. Also, we discuss the possibilities and limitations of   translation from our grammar-based conceptual model to the   rule-based Schematron.               Keywords: Schematron, XML schema, conceptual modeling, translation               Categories: D.2.2, H.2.3  
20|3||Service Composition Management: A Risk-Driven Approach|  Shang-Pin Ma (National Taiwan Ocean University, Taiwan)   Ching-Lung Yeh (National Taiwan Ocean University, Taiwan)   Ping-Chang Chen (National Taiwan Ocean University, Taiwan)  Abstract: How to effectively and efficiently monitor,   manage, and adapt web services in a composite service or a   service-oriented application is becoming a significant issue. In   this paper, we argue that it is insufficient to only solve emerging   service faults at the deployment time or runtime; instead, we   propose that the prediction of service faults is equally   important. We devised a risk-driven service composition management   (RDSCM) approach including four main phases: (1) preparation, (2)   planning, (3) monitoring and reaction, and (4) analysis. By applying   the proposed approach, risky component services can be removed   earlier, and the fault source can be tracked and identified more   easily when a fault occurs. We developed a prototype to realize the   proposed approach, and conducted experiments to verify the   approach. The implementation and experiments demonstrate that the   proposed risk-driven approach can effectively and efficiently ensure   the robustness of a service-oriented system.               Keywords: risk management, service composition, service management               Categories: D.2, D.2.11  
20|3||Evaluation of OCL Expressions over XML Data Model|  Jakub Malý (Charles University, Czech Republic)   Martin Nečaský (Charles University, Czech Republic)  Abstract: Complex applications can benefit greatly from   using conceptual models and Model Driven Architecture during   development, deployment and runtime. XML applications are not   different. In this paper, we examine the possibility of using Object   Constraint Language (OCL) for expressing constraints over a   conceptual model for XML data. We go through the different classes   of OCL expression and show how each class can be translated into   XPath constructs. Subsequently we show how the constraints can be   checked using Schematron. We introduce a function library OclX,   which provides constructs necessary to translate those OCL   constructs that have no counterpart in XPath. With our tool, it is   possible to check validity of OCL constraints in XML   data.               Keywords: MDA, OCL, Schematron, XML, integrity constraints               Categories: D.2.1, D.2.2, H.2.3  
20|3||Generating an Excerpt of a Service Level Agreement from a Formal Definition of Non-Functional Aspects Using OWL|  Mariam Rady (Johannes Kepler University Linz, Austria)  Abstract: If we take a look at current cloud computing   services, the only quality guarantee they provide are vague Service   Level Agreements(SLA). In this paper we modelled some non-functional   aspects in an ontology and used this ontology as a knowledge base to   generate an excerpt from a service contract. We concentrate in this   excerpt on availability as it is one of the most discussed   attributes in current Service Level Agreements.               Keywords: OWL, QoS, SLA, contracting, non-functional aspects, ontology               Categories: C.4, H.3.5, K.5.m, K.6.4  
20|3||Automatic Authentication to Cloud-Based Services|  Mircea Boris Vleju (Christian Doppler Laboratory for Client-Centric Cloud Computing (CDCC), Austria)  Abstract: We describe the concept of automatic   authentication for cloud-based services via the use of a   client-centric solution for small and medium enterprises (SMEs). In   previous work we have introduced the Identity Management Machine   (IdMM) whichis designed to handle the interaction between a client's   identity directory and various cloud identity management systems. We   now further refine this machine by describingits interaction with   various cloud authentication systems. The IdMM is designed to aid   SMEs in their adoption or migration to cloud-based services. The   system allowsSMEs to store its confidential data on-premise,   enhancing the client's control over the data. We further enhance the   privacy related aspects of a client-to-cloud interaction viathe   introduction of obfuscated and partially obfuscated identities which   allow SMEs to also choose the type of data being sent to a cloud   service. Since the IdMM is a singlesign-on system capable of   automatic authentication the risk of phishing or other social   engineering attacks is reduced as an individual user may not be   aware of his or hercredentials for a given cloud service.               Keywords: astract state machine, automatic authentication, client centric, cloud computing, identity management, small and medium enterprises               Categories:  D.2.10, F.1, H.4, H.5.3, K.6.5  
20|3||A Framework for Cost-Aware Process Management: Cost Reporting and Cost Prediction|  Moe Thandar Wynn (Queensland University of Technology, Australia)   Wei Zhe Low (Queensland University of Technology, Australia)   Arthur H. M. ter Hofstede (Queensland University of Technology, Australia)   Wiebe Nauta (Eindhoven University of Technology, The Netherlands)  Abstract: Organisations are constantly seeking efficiency   gains for their business processes in terms of time and   cost. Management accounting enables detailed cost reporting of   business operations for decision making purposes, although   significant effort is required to gather accurate operational   data. Process mining, on the other hand, may provide valuable   insight into processes through analysis of events recorded in logs   by IT systems, but its primary focus is not on cost implications. In   this paper, a framework is proposed which aims to exploit the   strengths of both fields in order to better support management   decisions on cost control. This is achieved by automatically merging   cost data with historical data from event logs for the purposes of   monitoring, predicting, and reporting process-related costs. The   on-demand generation of accurate, relevant and timely cost reports,   in a style akin to reports in the area of management accounting,   will also be illustrated. This is achieved through extending the   open-source process mining framework ProM.               Keywords: business process management, cost prediction, cost reporting, management accounting, process mining               Categories: H.4  
20|3||Multilevel and Coordinated Self-management in Autonomic Systems based on Service Bus|  Mohamed Zouari (Université de Toulouse, France)   Codé Diop (Université de Toulouse, France)   Ernesto Exposito (Université de Toulouse, France)  Abstract: Modern dynamic distributed systems require to   dynamically take into account at runtime the changes in users' needs   and the execution environment variations in order to improve the   quality of service. The evolution of distributed systems, through   the smart management of their properties and the extension of the   existing integration infrastructures, becomes a necessity. Autonomic   computing allows the self-management of system properties at   runtime, according to fluctuations in the environment and changes in   users' requirements. However, the mechanisms for parallel and   distributed execution of multiple self-management processes have not   been addressed substantially. It is critical to coordinate the   execution of several processes performed by different autonomic   managers, while still guaranteeing specific and global goals   achievement. We address this issue by proposing a software   architecture that allows the coordination of multiple autonomic   managers which handle several componentbased and service-oriented   collaborative software entities. This architecture offers a   distributed cross-layer self-management solution through   orchestration and choreography. Using both techniques, autonomic   managers running on multiple locations and different layers will be   able to achieve their goals in a consistent and cost-effective   way. In this paper, we present a set of mechanisms intended to   coordinate the distributed execution of a set of self-management   processes in one or more layers. We have chosen an use case   involving the self-management of autonomic data replication systems   integrated via an autonomic service bus in order to illustrate our   approach.               Keywords: autonomic computing, distributed and coordinated management, enterprise service bus, quality of service               Categories: D.2.11, D.2.12, D.2.9  
20|4|http://www.jucs.org/jucs_20_4|Managing Editor's Column|
20|4||Classification of VANET MAC, Routing and Approaches A Detailed Survey|  Sana Ajmal (Center for Advanced Studies in Engineering, Pakistan)   Asim Rasheed (Muhammad Ali Jinnah University, Pakistan)   Amir Qayyum (Muhammad Ali Jinnah University, Pakistan)   Aamir Hasan (Center for Advanced Studies in Engineering, Pakistan)  Abstract: Human safety considerations linked with rapidly   growing auto mobile market has given special attention to the   Intelligent Transportation System (ITS). ITS provides a set of   standards for inter vehicular communication with emphasis on safety,   traffic efficiency and infotainment related applications. In ITS,   the vehicles acting as mobile nodes, form a specialized ad hoc   network, known as Vehicular Ad-hoc Network (VANET). Although, VANET   and ITS are under intense research since last decade, technology   still lacks large scale deployment. Vehicle to Vehicle (V2V) and   Vehicle to Infrastructure (V2I) communications are the main research   goals of ITS. High relative node velocity and high active node   density has presented peculiar challenges to connectivity within   VANET. VANET connectivity and routing requirements range from   the time critical safety applications, to the time and space   hovering, delay tolerant and infotainment applications. This paper   reviews connectivity issues in VANET with emphasis on routing,   and offers comprehensive literature review on state of the art in   VANET routing, with its detailed classifications. It also compares   some standard architectures of VANET from MAC, routing and management   perspective, i.e., WAVE by IEEE, CALM by ISO, C2CNet by C2C   consortium / GeoNet.               Keywords: ITS, routing metrics, routing protocols, vehicular ad hoc networks               Categories: C.2.2  
20|4||An Approach to Skew Detection of Printed Documents|  Darko Brodić (University of Belgrade, Serbia)   Carlos A. B. Mello (Universidade Federal de Pernambuco, Brazil)   Čedomir A. Maluckov (University of Belgrade, Serbia)   Zoran N. Milivojevic (College of Applied Technical Science Niš, Serbia)  Abstract: In this paper, we propose an approach to   estimate the text skew for printed documents. This is an important   step to prevent errors in further stages of an automatic document   processing system (as text segmentation). Our approach is based on   the statistical analysis of the height of the connected   components. In a nutshell, our algorithm is comprised of four steps:   (i) removal of redundant data; (ii) establishment of the connected   components, which represent filled convex hulls around each text   element; (iii) enlargement of these components using morphological   erosion; (iv) removal of the largest connected component to identify   the first estimation of text skew. According to it, the connected   components are enlarged by oriented morphological erosion and the   longest of them is extracted. Statistical moments are applied to   this longest component to evaluate its orientation and the global   text skew of the document is identified. At the end of this process,   the original document is rotated back based on the calculated   angle. The performance of the proposed algorithm is examined by   testing on a custom dataset. The results support the robustness of   our approach.               Keywords: connected component analysis, document image analysis, moment based method, skew estimation, statistical analysis               Categories: I.4, I.4.10, I.4.5, I.4.7, I.5, I.5.3, I.7, I.7.2  
20|4||A Hybrid Approach for Group Profiling in Recommender Systems|  Ingrid Christensen (ISISTAN (CONICET-UNCPBA), Argentina)   Silvia Schiaffino (ISISTAN (CONICET-UNCPBA), Argentina)  Abstract: Recommendation is a significant paradigm for   information exploring, which focuses on the recovery of items of   potential interest to users. Some activities tend to be social   rather than individual, which puts forward the need to offer   recommendations to groups of users. Group recommender systems   present a whole set of new challenges within the field of   recommender systems. In this paper, we present a hybrid approach   based on group profiling for homogeneous and non-homogenous groups   containing a few distant individual profiles among their   members. This approach combines three familiar individual   recommendation approaches: collaborative filtering, content-based   filtering and demographic information. This hybrid approach allows   the detection of those implicit similarities in the user rating   profile, so as to include members with divergent profiles. We also   describe the promising results obtained when evaluating the approach   proposed in the movie and music domain.               Keywords: aggregate ratings, group heterogeneity, group profiling, group recommender systems, hybrid recommender systems               Categories: I.2.1, I.2.6, L.2.2, L.2.7, L.6.2  
20|4||An Approach for Mapping Domain-Specific AOM Applications to a General Model|  Patricia Matsumoto (Instituto Tecnológico de Aeronáutica, Brazil)   Eduardo Guerra (Instituto Tecnológico de Aeronáutica, Brazil)  Abstract: An Adaptive Object Model (AOM) is a common   architectural style for systems in which classes, attributes,   relationships and behaviors of applications are represented as   metadata consumed at runtime. This allows them to be very flexible   and changeable at runtime, enabling their modification by end users   without source code modification. Nevertheless, this flexibility   comes with a cost of a greater complexity when developing the   system, and therefore one usually uses a bottom-up approach, adding   flexibility only when it is needed. As a consequence, many AOM   components are tied to the specific domain of a single application   and this fact makes it difficult to develop and use generic and   reusable AOM frameworks that properly handle specific requirements   of the AOM architecture. This work presents an architectural model   that aims to adapt domain-specific AOM core structures to a common   core structure by identifying AOM roles played by each element   through custom metadata configuration. By doing this, this model   allows the integration of domain-specific AOM applications and AOM   frameworks, making it feasible to develop reusable components for   the AOM architecture. This model is evaluated by creating an AOM   framework and a case study based on it, in which is performed a   modularity and a performance analysis.               Keywords: Adaptive Object Model, adaptive system, architecture, decoupling, framework, metadata, modularity               Categories: D.1.5, D.2.10, D.2.11, D.2.13, D.2.2  
20|4||Developing Scenario-based Serious Games for Complex Cognitive Skills Acquisition: Design, Development and Evaluation of the EMERGO Platform|  Aad Slootmaker (Open University of the Netherlands, The Netherlands)   Hub Kurvers (Open University of the Netherlands, The Netherlands)   Hans Hummel (Open University of the Netherlands, The Netherlands)   Rob Koper (Open University of the Netherlands, The Netherlands)  Abstract: Serious games are considered to provide powerful   and attractive ways to acquire complex cognitive skills for   education and training. But existing platforms for development of   game-based e-learning often appear either not to be very   user-friendly or too rigid or costly. This article addresses the   design, development and evaluation of a generic platform for fast   and flexible development and delivery of a wide variety of   scenario-based games that enables complex cognitive skills   acquisition. We present the requirements for the EMERGO platform and   which common components it offers to cater for most of the needed   functionalities within scenario-based games. We explain how users in   various roles can use the platform to manage, develop, deliver and   play a broad variety of scenario-based games. Evaluation data are   presented to back up the claim that the platform indeed allows for   faster, more user-friendly and less costly development and delivery   of scenario-based games. Seven years after the platform has been   launched, it until now has proven successful and still continues to   evolve. We close off with some conclusions and needs for further   development.               Keywords: adaptive eLearning, eLearning Platforms, game based learning, technology enhanced learning               Categories: L.2.0, L.3.0, L.3.6, L.5.1  
20|5|http://www.jucs.org/jucs_20_5|Software Components, Architectures and Reuse: Software Product Line Engineering and Source Code Enhancements|
20|5||A Toolset for Checking SPL Refinements|  Felype Ferreira (Federal University of Pernambuco, Brazil)   Rohit Gheyi (Federal University of Campina Grande, Brazil)   Paulo Borba (Federal University of Pernambuco, Brazil)   Gustavo Soares (Federal University of Campina Grande, Brazil)  Abstract: Developers evolve software product lines (SPLs)   manually or using typical program refactoring tools. However, when   evolving an SPL to introduce new features or to improve its design,   it is important to make sure that the behavior of existing products   is not affected. Typical program refactorings cannot guarantee that   because the SPL context goes beyond code and other kinds of core   assets, and involves additional artifacts such as feature models and   configuration knowledge. Besides that, we typically have to deal   with a set of alternative assets that do not constitute a   well-formed program in an SPL. As a result, manual changes and   existing program refactoring tools may introduce behavioral changes   or invalidate existing product configurations. To reduce such risks,   we propose approaches and implement four tools for making product   line evolution safer. These tools check if SPL transformations   preserve the behavior of the original SPL products. They implement   different and practical approximations of refinement notions from a   theory for safely evolving SPLs. Besides specifying the algorithms   of each approach, we compare them with respect to soundness,   performance and code coverage in 35 evolution scenarios of an SPL   with 32 KLOC.               Keywords: checking tools, refactoring, safe evolution, software product lines               Categories: D.2.13, D.2.4, D.2.5, D.2.7  
20|5||Controlled Experiments Comparing Black-box Testing Strategies for Software Product Lines|  Paola Accioly (Federal University of Pernambuco, Brazil)   Paulo Borba (Federal University of Pernambuco, Brazil)   Rodrigo Bonifacio (University of Brasília, Brazil)  Abstract: SPL testing has been considered a challenging   task, mainly due to the diversity of products that might be   generated from an SPL. To deal with this problem, techniques for   specifying and deriving product specific functional test cases have   been proposed. However, there is little empirical evidence of the   benefits and drawbacks of these techniques. To provide this kind of   evidence, in a previous work we conducted an empirical study that   compared two design techniques for black-box manual testing, a   generic technique that we have observed in an industrial test   execution environment, and a product specific technique whose   functional test cases could be derived using any SPL approach that   considers variations in functional tests. Besides revisiting the   first study, here we present a second study that reinforce our   findings and brings new insights to our investigation. Both studies   indicate that specific test cases improve test execution   productivity and quality.               Keywords: black-box testing, empirical software engineering, software product lines               Categories: D.2.5, D.2.7, G.3  
20|5||Consistency Checking in Early Software Product Line Specifications - The VCC Approach|  Mauricio Alférez (Universidade Nova de Lisboa, Portugal)   Roberto E. Lopez-Herrejón (Johannes Kepler University, Austria)   Ana Moreira (Universidade Nova de Lisboa, Portugal)   Vasco Amaral (Universidade Nova de Lisboa, Portugal)   Alexander Egyed (Johannes Kepler University, Austria)  Abstract: Software Product Line Engineering (SPLE) is a successful paradigm to produce a family of products for a specific domain. A challenge in SPLE is to check that different models used in early SPL specification do not contain inconsistent information that may be propagated and generate inconsistent  products that do not conform to its requirements. This challenge is difficult to address due to the high number of possible combinations of product features and model fragments specifying those features. Variability Consistency Checking (VCC) offers automatic means to address that challenge. VCC relates information inferred from the relationships between features and from base models related to those features. Validating if all the products in an SPL satisfy user-defined consistency constraints is based on searching for a satisfying assignment of each formula generated by VCC. We validated VCC and its supporting tool on two case studies from different application domains, the results were encouraging as we did not observed significant performance penalties.               Keywords: architecture design, feature modeling analysis, highly configurable systems, model-based software product lines, model-driven development, requirements engineering, variability modeling, variability-intensive systems, verification               Categories: D.2.1, D.2.10, D.2.11, D.2.13, D.2.2, D.2.4, F.3.1, F.4.1, I.6.4, I.6.5  
20|5||Defining and Validating a Feature-Driven Requirements Engineering Approach|  Raphael Pereira de Oliveira (Federal University of Bahia (UFBA), Brazil)   David Blanes (Universitat Politecnica de Valencia (UPV), Spain)   Javier Gonzalez-Huerta (Universitat Politecnica de Valencia (UPV), Spain)   Emilio Insfran (Universitat Politecnica de Valencia (UPV), Spain)   Silvia Abrahão (Universitat Politecnica de Valencia (UPV), Spain)   Sholom Cohen (Carnegie Mellon University, USA)   Eduardo Santana de Almeida (Federal University of Bahia (UFBA), Brazil)  Abstract: The specification of requirements is a key   activity for achieving the goals of any software project and it has   long been established and recognized by researchers and   practitioners. Within Software Product Lines (SPL), this activity is   even more critical owing to the need to deal with common, variable,   and product-specific requirements, not only for a single product but   for the whole set of products. In this paper, we present a   Feature-Driven Requirements Engineering approach (FeDRE) that   provides support to the requirements specification of SPL. The   approach realizes features into functional requirements by   considering the variability captured in a feature model. It also   provides detailed guidelines on how to associate chunks of features   from a feature model and to consider them as the context for the Use   Case specification. The evaluation of the approach is illustrated in   a case study for developing an SPL of mobile applications for   emergency notifications. This case study was applied within 14   subjects, 8 subjects from Universitat Politècnica de   València and 6 subjects from Federal University of   Bahia. Evaluations concerning the perceived ease of use, perceived   usefulness, effectiveness and efficiency as regards requirements   analysts using the approach are also presented. The results show   that FeDRE was perceived as easy to learn and useful by the   participants.               Keywords: requirements specification, reuse, software product lines               Categories: D.2.1, D.2.13  
20|5||Flexible Feature Binding with AspectJ-based Idioms|  Rodrigo Andrade (Federal University of Pernambuco, Brazil)   Henrique Rebelo (Federal University of Pernambuco, Brazil)   Marcio Ribeiro (Federal University of Alagoas, Brazil)   Paulo Borba (Federal University of Pernambuco, Brazil)  Abstract: In Software Product Lines (SPL), we can bind   reusable features to compose a product at different times, which in   general are static or dynamic. The former allows customizability   without any overhead at runtime. On the other hand, the latter   allows feature activation or deactivation while running the   application with the cost of performance and memory consumption. To   implement features, we might use aspect-oriented programming (AOP),   in which aspects enable a clear separation between invariable code   and variable code. In this context, recent work provides   AspectJ-based idioms to implement flexible feature binding. However,   we identified some design deficiencies. Thus, to solve the issues of   these idioms, we incrementally create three AspectJ-based idioms. We   apply these idioms to provide flexible binding for 16 features from   five different product lines. Moreover, to evaluate our idioms, we   quantitatively analyze them with respect to code cloning,   scattering, tangling, and size by means of software metrics. Besides   that, we qualitatively discuss our idioms in terms of code   reusability, changeability, instrumentation overhead, behavior, and   feature interaction. In conclusion, we show evidences that our   idioms address the issues of those existing ones.               Keywords: aspect-oriented programming, flexible feature binding, idioms, software product lines               Categories: D.1.m, D.2.13, D.2.8  
20|5||Verification of Software Product Line Artefacts: A Checklist to Support Feature Model Inspections|  Rafael Maiani de Mello (COPPE-Federal University of Rio de Janeiro, Brazil)   Eldanae Nogueira Teixeira (COPPE-Federal University of Rio de Janeiro, Brazil)   Marcelo Schots (COPPE-Federal University of Rio de Janeiro, Brazil)   Cláudia Maria Lima Werner (COPPE-Federal University of Rio de Janeiro, Brazil)   Guilherme Horta Travassos (COPPE-Federal University of Rio de Janeiro, Brazil)  Abstract: Software Product Line Engineering (SPL) should   ensure the correctness, completeness and consistenc y of its   artefacts and related domain to prevent the propagation of defects   in derived products. Software inspection techniques are effective in   detecting defects in software artefacts and avoiding their   propagation throughout the software development process.  However,   the results of a quasi-systematic review of the technical literature   reported in this paper pointed to a lack of such techniques to   support the inspection of SPL artefacts, including techniques to   support the inspection of feature models (FMs) that are largely used   in domain modelling. Therefore, a checklist-based inspection   technique (FMCheck) has been developed to support the detection of   defects on FMs. FMCheck is configurable and can be applied to the   original feature model notation (the F ODA approach) and its   extensions, including the Odyssey-FEX notation. The inspection   technique was empirically evaluated, having indicated its   feasibility and effectiveness. It is possible to see that inspectors   applying FMCheck to inspect F-s can be more effective than those   applying ad-hoc techniques, regarding four distinct   domains.               Keywords: domain engineering, experimental software engineering, feature model, software inspection, software product line, software reuse               Categories: D.2.1, D.2.13, D.2.2, D.2.4  
20|5||A Catalogue of Refactorings to Remove Incomplete Annotations|  Flavio Medeiros (Federal University of Campina Grande, Brazil)   Maarcio Ribeiro (Federal University of Alagoas, Brazil)   Rohit Gheyi (Campina Grande, Brazil)   Baldoino Fonseca (Federal University of Alagoas, Brazil)  Abstract: Developers use the C Preprocessor (CPP) to   handle portability and variability in program families of different   sizes and domains. However, despite the widely use of the CPP in   practice, it is often criticised due to its negative impact on code   quality and maintainability, tool development, and its error-prone   characteristics. In particular, developers aggravate these problems   when using incomplete annotations, i.e., directives encompassing   only parts of syntactical units. In a previous work, we performed an   empirical study on 41 C program family releases and found that   almost 90% of syntax errors occur in incomplete annotations. There   are some refactorings to remove incomplete annotations proposed in   the literature. However, they clone code and increase Lines of Code   (LOC). To avoid incomplete annotations and their intrinsic problems,   in this article we propose a catalogue of refactorings that converts   incomplete annotations into complete ones without cloning code. We   implement an Eclipse plug-in to help developers applying our   refactorings automatically. To evaluate our catalogue, we performed   a study to analyse questions related to code cloning, LOC, and   number of directives. To answer our research questions, we analyse   releases of 12 C program families of different domains ranging from   4.9 thousand to 1.5 million LOC. The results show that our catalogue   can remove all incomplete annotations without cloning code, and   increasing only in 0.04% the LOC and in 2.10% the number of   directives.               Keywords: C language, preprocessors, program families, refactoring               Categories: D.2.3, D.2.7, D.3.4  
20|5||Thesaurus-Based Tag Clouds for Test-Driven Code Search|  Otavio A. L. Lemos (Federal University of São Paulo, Brazil)   Adriano C. de Paula (Federal University of São Paulo, Brazil)   Gustavo Konishi (Federal University of São Paulo, Brazil)   Sushil Bajracharya (Black Duck Software, Inc., USA)   Joel Ossher (University of California, USA)   Cristina Lopes (University of California, USA)  Abstract: Test-driven code search (TDCS) is an approach to   code search and reuse that uses test cases as inputs to form the   search query. Together with the test cases that provide more   semantics to the search task, keywords taken from class and method   names are still required. Therefore, the effectiveness of the   approach also relies on how good these keywords are, i.e., how   frequently they are chosen by developers to name the desired   functions. To help users choose adequate words in their query test   cases, visual aids can be used. In this paper we propose   thesaurus-based tag clouds to show developers   terms that are more frequently used in the code repository to   improve their search. Terms are generated by looking up words   similar to the initial keywords on a thesaurus. Tag clouds are then   formed based on the frequency in which these terms appear in the   code base. Our approach was implemented with an English thesaurus as   an extension to CodeGenie, a Java- and Eclipse-based TDCS tool. Our   evaluation shows evidence that the approach can help improve the   number of returned results, recall (by ∼28%, on average), and   precision (by ∼14%, on average). We also noticed the visual   aid can be especially useful for non-native speakers of the language   in which the code repository is written. These users are frequently   unaware of the most common terms used to name specific functionality   in the code, in the given language.               Keywords: code search, software reuse, tag clouds, test-driven code search               Categories: D.2.13  
20|5||What Should I Code Now?|  Luiz Laerte Nunes da Silva Junior (Universidade Federal Fluminense, Brazil)   Alexandre Plastino (Universidade Federal Fluminense, Brazil)   Leonardo Gresta Paulino Murta (Universidade Federal Fluminense)  Abstract: In the software development field, the amount of   data related to documentation and to the source code itself is   huge. Relevant knowledge can be extracted from these data, provided   that the adequate tools are in place. In this context, data mining   can be seen as an important tool. This paper presents a new approach   for code completion based on sequential patterns mined from previous   developed source code. According to what is being coded, suggestions   of new code sequences are made based on the mined patterns. As a   result, a plug-in for the Eclipse IDE, named Vertical Code   Completion, was developed and applied over widely known Open Source   systems, identifying that our approach could provide suggestions   that would anticipate what a developer intends to code.               Keywords: code completion, sequential pattern mining, software maintenance               Categories:  D.2.13, D.2.3, H.2.8  
20|6|http://www.jucs.org/jucs_20_6|Enterprise Information Systems|
20|6||The Role of Absorptive Capacity in the Usage of a Complex Information System:  The Case of the Enterprise Information System|  Maral Mayeh (Deakin University, Australia)   Thurasamy Ramayah (Universiti Sains Malaysia, Malaysia)   Simona Popa (University of Murcia, Spain)  Abstract: The purpose of this study is to model the   relationship between absorptive capacity and intention to use in the   Enterprise Resource Planning (ERP) environment in Iran. This   research is a correlation study where a field survey was employed   for data collection. The unit of analysis is Iranian individuals who   are ERP user in organizations using ERP systems. The questionnaires   were sent to the selected organizations. Using a structural equation   modeling analysis we tested the hypothesized relationship using AMOS   version 16.0. The results indicate that all three absorptive   capacity measures to be good predictors of intention to   use. Absorptive capacity for applying was the strongest predictor   followed by absorptive capacity for understanding and absorptive   capacity for assimilating. When implementing complex information   systems, managers must also look at the absorptive capacity of the   users in order to successful implementation of the system and to   ensure continued usage. Previous researchers have not looked at the   role of absorptive capacity in system usage at the same rate as   those related to technology acceptance research which only focuses   on the ease of use and usefulness. Thus this research adds on to the   existing literature where future researchers may want to expand on   the factors that may influence absorptive capacity for further   policy implications.               Keywords: ERP, Iran, SEM, absorptive capacity for applying,, absorptive capacity for assimilating, absorptive capacity for understanding               Categories: H.1.1, H.1.2, H.2.4, H.3.4, H.4.2  
20|6||Using and Extending Formal Concept Analysis to Visualise Variability during Requirements Engineering|  Tom Huysegoms (KU Leuven, Belgium)   Monique Snoeck (KU Leuven, Belgium)   Guido Dedene (KU Leuven, Belgium)   Antoon Goderis (KBC Global Services, Belgium)   Frank Stumpe (KBC Global Services, Belgium)  Abstract: Research on variability in software artefacts is   something which is already studied extensively in research. The   visualisation of variability is one aspect of this research, and   results like e.g. feature diagrams are well-known and   well-spread. When it concerns the origin of the variability within   the phase of requirements engineering, research is much scarcer. A   visualisation technique for both representing the origin and the   amount of variability in requirements is not readily available in   research. This paper provides a way to represent the origin of   variability in requirements with the aid of a technique called   formal concept analysis (FCA). Additionally the support that FCA can   provide for variability related decisions during (early)   requirements engineering is also depicted in this paper. Proof of   the usability of FCA for the visualization, and documentation, of   variability is shown with the aid of a real-life case study. FCA is   also applied in the real-life case study to check the compatibility   of FCA as a visualization method to support variability decision   making during requirements engineering.               Keywords: Variabilization, formal concept analysis, harmonization, requirements management, variability management               Categories: I.3.8  
20|6||A Taxonomy for Virtual Enterprises|  Goran D. Putnik (Polytechnic Institute of Cávado and Ave, Portugal)   Maria Manuela Cruz-Cunha (Polytechnic Institute of Cávado and Ave, Portugal)  Abstract: The purpose of this paper is to present a   taxonomy able to contribute to building a framework within the   domain of Virtual Enterprises (VE), to facilitate the sharing of   knowledge and contributions to knowledge, as well as for trust   building among VE stakeholders. A VE taxonomy currently does not   exist, and this lack is felt in the ambiguous way that some concepts   are addressed, leading to a fragment understanding that hinders the   development of the science of VE integration and management. The   structure of the taxonomy developed is based on the view of the   system as a 5-tuple consisting of Input, Control, Output, Mechanism,   and Process, which is the underlying system-view in the well-know   IDEF0 diagramming technique. In particular, this taxonomy addresses   the VE extended lifecycle that implies the use of a   meta-organization called Market of Resources, as an original   contribution to the VE theory and practice. The taxonomy presented   does not repeat what the literature already includes, or the   commonplaces, and it is constructed in a way to be easily   complemented with other VE partial taxonomies that may be found in   literature. Some suggestions for extensions to other interrelated   domains (as evolution leaves taxonomies in an open or incompleteness   state) are given in the text.               Keywords: Market of Resources, taxonomy, virtual enterprise               Categories: L.1.3, M.4  
20|6||Gamification as a Disruptive Factor in Software Process Improvement Initiatives|  Eduardo Herranz (Universidad Carlos III de Madrid, Spain)   Ricardo Colomo-Palacios (Ostfold University College, Norway)   Antonio de Amescua Seco (Universidad Carlos III de Madrid, Spain)   Murat Yilmaz (Çankaya University, Turkey)  Abstract: For any Software Process Improvement (SPI)   initiative to succeed human factors, in particular, motivation and   commitment of the people involved should be kept in mind. In fact,   Organizational Change Management (OCM) has been identified as an   essential knowledge area for any SPI initiative. However, enough   attention is still not given to the human factors and therefore, the   high degree of failures in the SPI initiatives is directly linked to   a lack of commitment and motivation. Gamification discipline allows   us to define mechanisms that drive people's motivation and   commitment towards the development of tasks in order to encourage   and accelerate the acceptance of an SPI initiative. In this paper, a   gamification framework oriented to both organization needs and   software practitioners groups involved in an SPI initiative is   defined. This framework tries to take advantage of the transverse   nature of gamification in order to apply its Critical Success   Factors (CSF) to the organizational change management of an   SPI. Gamification framework guidelines have been validated by some   qualitative methods. Results show some limitations that threaten the   reliability of this validation. These require further empirical   validation of a software organization.               Keywords: gamification, organizational change management, software process improvement               Categories: D.2.7, D.2.9  
20|6||Decision Support System to Diagnosis and Classification of Epilepsy in Children|  Rui Rijo (INESCC - Institute for Systems and Computers Engineering at Coimbra, Portugal)   Catarina Silva (University of Coimbra, Portugal)   Luis Pereira (Polytechnic Institute of Leiria, Portugal)   Dulce Gonçalves (Polytechnic Institute of Leiria, Portugal)   Margarida Agostinho (Hospital Santo André, Portugal)  Abstract: Clinical decision support systems play an   important role in organizations. They have a tight relation with the   information systems. Our goal is to develop a system to support the   diagnosis and the classification of epilepsy in children. Around 50   million people in the world have epilepsy. Epilepsy diagnosis can be   an extremely complex process, demanding considerable time and effort   from physicians and healthcare infrastructures. Exams such as   electroencephalograms and magnetic resonances are often used to   create a more accurate diagnosis in a short amount of time. After   the diagnosis process, physicians classify epilepsy according to the   International Classification of Diseases, ninth revision   (ICD-9). Physicians need to classify each specific type of epilepsy   based on different data, e.g., types of seizures, events and   exams' results. The classification process is time consuming and,   in some cases, demands for complementary exams. This work presents a   text mining approach to support medical decisions relating to   epilepsy diagnosis and ICD-9-based classification in children. We   put forward a text mining approach using electronically processed   medical records, and apply the K-Nearest Neighbor technique as a   white-box multiclass classifier approach to classify each instance,   mapping it to the corresponding ICD-9-based standard code. Results   on real medical records suggest that the proposed framework shows   good performance and clear interpretations, albeit the reduced   volume of available training data. To overcome this hurdle, in this   work we also propose and explore ways of expanding the   dataset.               Keywords: ICD codes, clinical decision support systems, data mining, diagnosis, electronic medical records, epilepsy, machine learning, medical information systems, text mining               Categories: H.3.1, H.4.2  
20|6||Understanding the Growth by KILT Model and TYPUS Metrics|  Rinaldo C. Michelini (University of Genova, Italy)   Roberto P. Razzoli (University of Genova, Italy)  Abstract: The goal of the study is investigating the odd   claim of the human civilisation, which modifies the wild   natural surrounds by synthetic   alterations, defined improvements, bestowing «value   added». Indeed, the history seems sanctioning that the   «life-quality» on the earth has been expanding, with   enhanced chances and increased resources, compared to the native   prospects of the wilderness. Only at the millennium turnover, the   ecology globalisation shows the impeding threats of   over-depletion/pollution, exceeding the extant recovery and   reclamation capabilities of the environment. The new imperative   turns to be the «sustainable growth», with caginess in   defining if the trends can be positive, being conditioned by the   empowered recycling, retrieval and renovation measures. In fact,   sustainability requires   lifecycle supply-chain visibility, resource   bookkeeping and revamp planning. The lifecycle starts when the idea   of a product is born and lasts until complete disposal after   realisation and operation. In the musts' specification/analysis, the   crucial policy (global plans, detailed design, assembly plots, etc.)   are followed by manufacturing, testing, delivery, diagnostics and   operation, advertising, service, maintenance, etc.; then,   disassembly and firing are scheduled, requiring reclamation and   recovery, via re-cycling (material reprocessing) or re-using (part   refurbishing). The present study summarises pilot cues for   understanding the product-process agendas, using the   TYPUS metrics and the   KILT model, prospected by the   authors, in previous works.               Keywords: eco-project, ecology globalisation, economy globalisation, lifecycle management, sustainable growth               Categories: J.6  
20|7|http://www.jucs.org/jucs_20_7|Trending Breakthroughs in Human-Computer Interaction|
20|7||A User-Aware Approach to Provide Adaptive Web Services|  Chiraz El Hog (Sfax University, Tunisia)   Raoudha Ben Djemaa (Sfax University, Tunisia)   Ikram Amous (Sfax University, Tunisia)  Abstract: Web services are rapidly gaining acceptance as a   fundamental technology in the web fields. They are becoming the   cutting edge of communication between the different applications all   over the web. Because of today's wide diversity of devices together   with the variety of the user's preferences, context-aware web   services are becoming a fundamental challenge that must be   targeted. This issue is a part of the Human Computer Interaction   (HCI) discipline and it aims at adapting the web service behavior   according to the user's context such as his specific work   environment, language, type of Internet connection, devices and   preferences. Many solutions have been proposed in this   area. Nevertheless, the adaptation was carried out only at the   runtime and it partially covered the user's general context. In this   paper, we introduce a new context-aware approach that provides   adaptive web services. Our approach allows to express requirements   by taking into account potential user's profile in addition to the   functional one. While the latter ensures the description of the web   service-functionalities, adaptation expresses the ability of a   service to be self-adapted to runtime context changes. Our approach   deals with adaptation from the very beginning of the modeling step   of a web service. Furthermore, it upgrades description and   publication usual methods in order to support profile   specification.               Keywords: HCI, adaptation, uddi, uml, web service, wsdl               Categories: D.2.2, H.2.3, H.3.5, I.5.2  
20|7||User-Centered Requirement Engineering for Accessible Chats in m-Learning|  Rocío Calvo (Universidad Carlos III de Madrid, Spain)   Ana Iglesias (Universidad Carlos III de Madrid, Spain)   Lourdes Moreno (Universidad Carlos III de Madrid, Spain)  Abstract: Chat applications are useful synchronous tools   in mobile learning (m-learning) environments. However, these tools   have accessibility problems which cannot be avoided by students and   teachers with disabilities. This paper focuses on detecting these   accessibility problems. Specifically, this paper presents the   Requirement Engineering (RE) process carried out to obtain the   requirements needed to improve the interaction for people who   experience problems with the Flow and Rhythm of the conversation in   chats. A methodological approach has been followed and Software   Engineering (SE) and Human Computer Interaction (HCI) disciplines   were combined in order to improve the interaction during the   chat.               Keywords: accessibility, human computer interaction, mobile, chat, requirements engineering, software engineering               Categories: D.2.1, H.5.2, H.5.3  
20|7||Keyboard-Card Menus: A New Presentation of Non-Standard Shortcuts|"  Benjamin Berman (The University of Iowa, USA)   Juan Pablo Hourcade (The University of Iowa, USA)  Abstract: ""Keyboard-card menus"" are a new type of menu   system in which potentially hundreds of menu items are arranged in   sets of keyboard patterns that are designed to be navigated using   only a computer keyboard's character keys, for fast access. In   selecting items from these menus, novice users physically rehearse   the same actions that an expert would use. We describe these menus   and their potential applications in further detail, along with a   study comparing keyboard-card menus' presentation of what are   effectively shortcuts with a presentation of these same shortcuts   that uses dropdown menus. The data from our study shows that   keyboard-card menus have significant advantages over dropdown menus   in making the transition to expert use faster.               Keywords: accuracy, computer chording, efficiency, keyboard shortcuts, learnability, visualization               Categories: H.5.m  "
20|7||Let me Listen to Poetry, Let me See Emotions|  Diana Arellano (Filmakademie Baden-Wuerttemberg, Germany)   Cristina Manresa-Yee (University of Balearic Islands, Spain)   Volker Helzle (Filmakademie Baden-Wuerttemberg, Germany)  Abstract: This paper presents the design, implementation   and evaluation of the interactive installation The Muses of Poetry   (MoP). In MoP the user interacts with a virtual character, who in   turn recites poetry while manifesting the emotional content of the   poem using visual cues (as facial expressions) and an affective   voice. The novelty of MoP is that it combines real-time character   animation, semantic analysis, natural voice interaction and poetry   to create a unique and surprising experience for the   user.               Keywords: User experience, affective computing, human-computer interaction               Categories: H.5, J.5  
20|7||First-Person Locomotion in 3D Virtual Environments: a Usability Analysis|  Sergio Moya (Polytechnical University of Catalonia, Spain)   Sergi Grau (Polytechnical University of Catalonia, Spain)   Dani Tost (Polytechnical University of Catalonia, Spain)  Abstract: 3D Virtual Environments (VE) are becoming   popular as a tool for cognitive, functional and psychological   assessment. Navigation in these environments is recognized as one of   the most difficult activities in 3D Virtual Environments (VE). Users   unfamiliar to 3D games, specially elder persons, get puzzled when   they try to virtually move an avatar through these   environments. Their inability to navigate prevents them from   concentrating in the task and even to finish it. In this paper, we   analyze the influence of different factors in locomotion control. We   investigate the impact of having the cursor fixed at the camera   center or leaving it free inside the current view. We also analyze   the influence of the pitch angle on the camera control. In addition,   we have designed an automatic locomotion system that we compare to   user-controlled locomotion. We describe a virtual scenario and a   test task that we have implemented to evaluate these different   methods with users of diverse profiles.               Keywords: camera control, locomotion, navigation, usability, virtual worlds               Categories: D.2.8, H.2  
20|8|http://www.jucs.org/jucs_20_8|Adaptive Services for the Future Internet|
20|8||Dynamic Verification of Mashups of Service-Oriented Things through a Mediation Platform|  Antonio Brogi (University of Pisa, Italy)   Javier Cubo (Universidad de Málaga, Spain)   Laura González (Universidad de la República, Uruguay)   Ernesto Pimentel (Universidad de Málaga, Spain)   Raúl Ruggia (Universidad de la República, Uruguay)  Abstract: The new Internet is evolving into the vision of   the Internet of Things, where physical world entities are integrated   into virtual world things. Things are expected to become active   participants in business, information and social processes. Then,   the Internet of Things could benefit from the Web Service   architecture like today's Web does; so Future service-oriented   Internet things will offer their functionality via service-enabled   interfaces. As demonstrated in previous work, there is a need of   considering the behaviour of things to develop applications in a   more rigorous way. We proposed a lightweight model for representing   such behaviour based on the service-oriented paradigm and extending   the standard DPWS profile to specify the (partial) order with which   things can receive messages. To check whether a mashup of things   respects the behaviour, specified at design-time, of composed   things, we proposed a static verification. However, at run-time a   thing may change its behaviour or receive requests from instances of   different mashups. Then, it is required to check and detect   dynamically possible invalid invocations provoked by the behaviour's   changes. In this work, we extend our static verification with an   approach based on mediation techniques and complex event processing   to detect and inhibit invalid invocations, checking that things only   receive requests compatible with their behaviour. The solution   automatically generates the required elements to perform run-time   validation of invocations, and it may be extended to validate other   issues. Here, we have also dealt with quality of service and   temporal restrictions.               Keywords: behaviour, complex event processing, composition, internet of things, mashup, mediation patterns, run-time verification, service-oriented things, web of things               Categories: D.2.10, D.2.11, D.2.12  
20|8||An Event-Driven Integration Platform for Context-Aware Web Services|  Laura González (Universidad de la República, Uruguay)   Guadalupe Ortiz (University of Cádiz, Spain)  Abstract: Web services are nowadays one of the preferred   technologies to implement service-oriented architectures and to   communicate distributed applications. On the other hand,   context-awareness is highly demanded for distributed   applications. However, even though there are excellent tools and   frameworks for service development, getting services to be   context-aware is still under investigation. In turn, an Enterprise   Service Bus (ESB) is a standards-based integration platform, which   provides mediation capabilities (e.g. routing, transformation). ESBs   are being increasingly used in conjunction with Complex Event   Processing (CEP) engines to support event-driven architectures   scenarios. In this regard, this paper proposes an ESB-based   integration platform which, leveraging its mediation capabilities   and a CEP engine, allows the construction of context-aware web   services. Concretely, CEP techniques are used to detect the complex   situations that may affect services and mediation mechanisms are   used to adapt service requests and responses to make them   context-aware.               Keywords: complex event processing, context-awareness, enterprise service bus, web services               Categories: D.2.11, D.2.12, D.2.13  
20|8||Efficient Multi-Objective Optimisation of Service Compositions in Mobile Ad hoc Networks Using Lightweight Surrogate Models|  Dionysios Efstathiou (King's College London, United Kingdom)   Peter McBurney (King's College London, United Kingdom)   Steffen Zschaler (King's College London, United Kingdom)   Johann Bourcier (University of Rennes 1, France)  Abstract: Infrastructure-less Mobile Ad hoc NETworks   (MANETs) and ServiceOriented Architecture (SOA) enable the   development of pervasive applications. Based on SOA, we can abstract   devices' resources as software services which can be combined into   value-added composite services providing complex functionalities   while exhibiting specified QoS properties. Configuring compositions   with optimal QoS is challenging due to dynamic network topologies   and availability of resources. Existing approaches seek to optimise   the selection of which services to participate in a centralised   orchestration without considering the overhead for estimating their   combined QoS. QoS metrics can be used as fitness functions to guide   the search for optimal compositions. When composing services offered   by diverse devices, there is no trivial relationship between the   composition's QoS and its component services. Measuring the fitness   values of a candidate composition could be done either by monitoring   its actual invocation or simulating it. However, both approaches are   too expensive to be used within an optimisation process. In this   paper, we propose a surrogate-based multi-objective optimisation   approach for exploring trade-off compositions. The evaluation   results show that by replacing the expensive fitness functions with   lightweight surrogate models, we can vastly accelerate the   optimisation algorithm while producing trade-off solutions of high   quality.               Keywords: optimisation, service composition, surrogate models               Categories: D.2.11, D.2.2  
20|8||Internet of Things Aware WS-BPEL Business Processes Context Variables and Expected Exceptions|"  Dulce Domingos (University of Lisbon, Portugal)   Francisco Martins (University of Lisbon, Portugal)   Carlos Cândido (University of Lisbon, Portugal)   Ricardo Martinho (Polytechnic Institute of Leiria, Portugal)  Abstract: Business processes can use Internet of Things   (IoT) information to monitor context data in real-time and to   respond to changes in their values in a timely fashion. For this   matter, business process definition and execution languages should   foresee an easy way for process modelers to define which values to   monitor, and which automatic behaviors to adopt when these values   change. In this paper, we propose the use of context variables to   monitor sensor values, as well as a when-then language construct to   detect and handle changes in these values within business   processes. We define a Web Services Business Process Execution   Language (WS-BPEL) extension to convey these constructs, and   implement then using a ""BPEL language transformation"" approach. With   these contributions, process modelers can define IoT-aware business   processes avoiding the increase of process complexity and keeping   their focus on modeling the processes' main logic. In addition, the   language transformation approach assures the portability of   processes using our constructs amongst WS-BPEL execution   engines.               Keywords: IoT, WS-BPEL extension, business process, context variable, language constructs               Categories: C.3, H.4.1  "
20|8||Extending Policy Languages for Expressing the Self-Adaptation of Web Services|  Haithem Mezni (University of Jendouba, Tunisia)   Walid Chainbi (National School of Engineers, SOIE, Tunisia)   Khaled Ghedira (National School of Engineers, SOIE, Tunisia)  Abstract: With the growing demand on Web Services,   self-adaptation in the highly-dynamic environment is becoming a key   capability of service-based systems. As a solution for Web services   to provide added value and high QoS, combining self-* and policies   allows reducing management complexity and effectively drives   adaptation. Also, providers must participate in the self-adaptation   process as they are aware of the capabilities of their offered   services and exceptions that may occur. Despite the important role   of service providers, existing approaches did not address this major   issue. Thus, the description of self-adaptive Web services must not   be limited to functional and QoS data. To address these issues, we   extend the WS-Policy framework to represent capabilities and   requirements of self-* Web services. We also extend UDDI in order to   store and manage service policies, as the current UDDI model does   not offer these capabilities. Finally, we propose an ECA-based   planning mechanism to specify decision making in the self-adaptation   process.               Keywords: ECA rules, UDDI, WS-policy, autonomic computing, quality of service, self-adaptation, web services               Categories: C.2.4, H.3, H.3.5  
20|9|http://www.jucs.org/jucs_20_9|Managing Editor's Column|
20|9||Capturing and Relating Multilingual Clinical Cases|  Renato de Freitas Bulcão-Neto (Innolution Sistemas de Informatica, Brazil)   José Antonio Camacho Guerrero (Innolution Sistemas de Informatica, Brazil)   Paulo Schor (Universidade Federal de São Paulo, Brazil)   Alessandra Stanquini Lopes (Universidade Federal de São Paulo, Brazil)   Marcio Branquinho Dutra (Universidade de São Paulo, Brazil)   Alessandra Alaniz Macedo (Universidade de São Paulo, Brazil)  Abstract: Recent studies reveal that the Internet use has   grown tremendously in the past few years, most rapidly in   non-English-speaking regions. However, this scenario creates a   demand for innovative information retrieval services to better   support a world wide community. This paper presents the MedLink   linking service, which automatically identifies semantic   relationships among multilingual clinical cases and makes them   available to users as hyperlinks. As a proof of concept, we also   present an experiment relating multilingual clinical cases in   Ophthalmology, where the relationships created by MedLink were   qualitatively analyzed by a Faculty with strong Ophthalmology   background. Analysis results are described in terms of the   completeness and the fidelity of the relationships created, which   can be most useful in a globalized world for several purposes   including research, teaching, and presurgical decision   making.               Keywords: cross-language information retrieval, medical informatics, multilingual Web, semantic relationships               Categories: H.3, H.4  
20|9||Decisions: Algebra, Implementation, and First Experiments|  Antonina Danylenko (Linnaeus University, Sweden)   Jonas Lundberg (Linnaeus University, Sweden)   Welf Löwe (Linnaeus University, Sweden)  Abstract: Classification is a constitutive part in many   different fields of Computer Science. There exist several approaches   that capture and manipulate classification information in order to   construct a specific classification model. These approaches are   oftentightly coupled to certain learning strategies, special data   structures for capturing the models, and to how common problems,   e.g. fragmentation, replication and model over-fitting, are   addressed.  In order to unify these different   classification approaches, we define a Decision Algebrawhich defines   models for classification as higher order decision functions   abstracting from their implementations using decision trees (or   similar), decision rules, decisiontables, etc. Decision Algebra   defines operations for learning, applying, storing, merging,   approximating, and manipulating models for classification, along   with some generalalgebraic laws regardless of the implementation   used.  The Decision Algebra abstraction has   several advantages. First, several useful DecisionAlgebra operations   (e.g., learning and deciding) can be derived based on the   implementation of a few core operations (including merging and   approximating). Second,applications using classification can be   defined regardless of the different approaches.Third, certain   properties of Decision Algebra operations can be proved regardless   of the actual implementation. For instance, we show that the merger   of a series of probablyaccurate decision functions is even more   accurate, which can be exploited for efficientand general online   learning.  As a proof of the Decision Algebra   concept, we compare decision trees with decisiongraphs, an efficient   implementation of the Decision Algebra core operations, which   cap-ture classification models in a non-redundant way. Compared to   classical decision tree implementations, decision graphs are 20%   faster in learning and classification withoutaccuracy loss and   reduce memory consumption by 44%. This is the result of experiments   on a number of standard benchmark data sets comparing accuracy,   access time, and sizeof decision graphs and trees as constructed by   the standard C4.5 algorithm.  Finally, in order to test our hypothesis about increased accuracy when merging decisionfunctions, we merged a series of decision graphs constructed over the data sets. The result shows that on each step the accuracy of the merged decision graph increases withthe final accuracy growth of up to 16%.               Keywords: classification, decision algebra, decision function, decision graph, decision tree               Categories: D.3.1, I.2.4, I.2.6, I.2.m  
20|9||A Personalized Approach for Re-ranking Search Results Using User Preferences|  Naglaa Fathy (Ain Shams University, Egypt)   Tarek F. Gharib (King Abdulaziz University, Saudi Arabia)   Nagwa Badr (Ain Shams University, Egypt)   Abdulfattah S. Mashat (King Abdulaziz University, Saudi Arabia)   Ajith Abraham (Machine Intelligence Research Labs, USA)  Abstract: Web search engines provide users with a huge   number of results for a submitted query. However, not all returned   results are relevant to the user's needs. Personalized search aims   at solving this problem by modeling search interests of the user in   a profile and exploiting it to improve the search process. One of   the challenges in search personalization is how to properly model   user's search interests. Another challenge is how to effectively   exploit these models to enhance the search quality. In this paper,   an effective hybrid personalized re-ranking search approach is   proposed by modeling user's search interests in a conceptual user   profile, and then exploiting this profile in the re-ranking   process. The user profile consists of concepts obtained by   hierarchically classifying user's clicked search results into   categories. These categories are extracted from the taxonomy of   concepts called The Open Directory Project (ODP) where each concept   represents a category. Additionally, each concept in the user   profile consists of two types of documents; taxonomy document and   viewed document. Taxonomy document is used to represent the user   general interests as it contains information from web pages   originally associated with such ODP category. Viewed document is   used to represent the user specific interests as it contains   information from web pages clicked by the user. Finally, the   re-ranking process of search results is performed by semantically   integrating user's general and specific interests from the user   profile together with rankings of the traditional search   engine. Experimental results show that semantic identification of   user's search interests improves re-ranking quality by providing   users with the most relevant results at the top of the search   results list.               Keywords: open directory project, personalization, re-rank, search engine, taxonomy, user profile               Categories: H.3.3  
20|9||On Alternative Approaches for Approximating the Transposition Distance|  Gustavo Rodrigues Galvão (University of Campinas, Brazil)   Zanoni Dias (University of Campinas, Brazil)  Abstract: We study the problem of sorting by   transpositions, which consists in computing the minimum number of   transpositions required to sort a permutation. This problem is   NP-hard and the best approximation algorithms for solving it are   based on a standard tool for attacking problems of this kind, the   cycle graph. In an attempt to bypass it, some researches posed   alternative approaches. In this paper, we address three algorithms   yielded by such approaches: a 2.25-approximation algorithm based on   breakpoint diagrams, a 3-approximation algorithm based on   permutation codes, and a heuristic based on longest increasing   subsequences. Regarding the 2.25-approximation algorithm, we show   that previous experimental data on its approximation ratio are   incorrect. Regarding the 3-approximation algorithm, we close a   missing gap on the proof of its approximation ratio and we show a   way to run it in O(n log n) time. Regarding the heuristic, we   propose a minor adaptation that allow us to prove an approximation   bound of 3. We present experimental data obtained by running these   algorithms for all permutations with up to 13 elements and by   running these algorithms and the best known algorithms based on the   cycle graph for large permutations. The data indicate that the   2.25-approximation algorithm is the best of the algorithms based on   alternative approaches and that it is the only one comparable to the   algorithms based on the cycle graph.               Keywords: approximation algorithms, genome rearrangement, sorting by transpositions               Categories: F.2.0, G.2.3  
20|9||Some Aspects of the Reliability of Information on the Web|"  Narayanan Kulathuramaiyer (University of Malaysia Sarawak, Malaysia)   Hermann Maurer (Graz University of Technology, Austria)   Rizwan Mehmood (Graz University of Technology, Austria)  Abstract: When we look up information in the WWW we hope   to find information that is correct, fitting in quantity for our   purposes and written at a level that we can   understand. Unfortunately, very often one of the above criteria will   not be met. A young person looking for information on some aspect of   physics may well be frustrated when finding a complex formula whose   understanding requires higher mathematics.  In other cases,   information may be much too voluminous or too short. This seems to   indicate that what we need is presentation of material at various   levels of detail and complexity. But most important of all, and this   is what we are going to discuss in this paper is: how do we know   that what we read is actually true? We will analyse this problem in   the introductory section. We will show that it is impossible to   expect ""too much"". We will argue that some improvements can be made,   particularly if the domain is restricted. We will then examine   certain types of geographical information. Detailed research shows   that some quantitative measurements like the area of a country or   the highest mountains of a country, even if different sources   disagree, can be verified by explaining why the discrepancies occur   and by trusting numbers if they are identical in very different   databases.               Keywords: checking facts, heuristic approaches, reliability of information, statistical techniques, verification of information               Categories: H.1, H.3, H.4, L.1, L.4, L.6  "
20|9||FLOP: A User-Friendly System for Automated Program Assessment|  Luis Llana (Universidad Complutense de Madrid, Spain)   Enrique Martin-Martin (Universidad Complutense de Madrid, Spain)   Cristóbal Pareja-Flores (Universidad Complutense de Madrid, Spain)   J. Ángel Velázquez-Iturbide (Universidad Rey Juan Carlos, Spain)  Abstract: Currently, automated systems for program   submission and assessment play a central role in the teaching of   programming. A number of such systems have been developed in the   last two decades. However, their adoption in regular programming   teaching presents an obstacle: the overhead work required for the   design of each problem, for compilation of problem collections, and   for mundane management tasks. An open challenge is to make these   systems easier to use and to reduce to a minimum the number of   management tasks. In this article we present the FLOP system, which   was developed to satisfy this goal. The contribution of the article   is twofold. On the one hand, we present the FLOP system itself and   its user-friendly features. On the other hand, we present in detail   the user-centered design process used to design and enhance the ease   of use of FLOP. Several actions were undertaken to inquire users   concerns and needs, with a usability evaluation of FLOP conducted   with students being the most fruitful action.               Keywords: FLOP, automated assessment systems, learning of programming, user-centered design               Categories: D.2.5, K.3.1, K.3.2, L.0.0, L.3.6  
20|9||A Middleware Architecture for Dynamic Adaptation in Ubiquitous Computing|  João Lopes (Federal University of Rio Grande do Sul, Brazil)   Rodrigo Souza (Federal University of Rio Grande do Sul, Brazil)   Cláudio Geyer (Federal University of Rio Grande do Sul, Brazil)   Cristiano Costa (University of the Vale do Rio dos Sinos, Brazil)   Jorge Barbosa (University of the Vale do Rio dos Sinos, Brazil)   Ana Pernas (Federal University of Pelotas, Brazil)   Adenauer Yamin (Federal University of Pelotas, Brazil)  Abstract: The development of applications that adapt to   the environment and remain running even when the user is moving or   switching device, remains an open research challenge. In this   article we present a view of the EXEHDA middleware and a new service   created for dynamic adaptation. EXEHDA is service-oriented, adaptive   and was conceived to support the execution of ubiquitous   applications. The main concept in the proposed design for the   middleware and for the application is context awareness expressed in   an adaptive behavior. The middleware manages and implements the   follow-me semantics for ubiquitous applications. This is also a key   to provide functionality adapted to the constraints and   unpredictability of the large-scale environment.  To achieve this   objective, EXEHDA employs various strategies in its services to   allow the adaptation to the current context, such as on-demand   adaptive service loading, and dynamic discovery and   configuration. In that sense, EXEHDA provides services for   distributed adaptive execution, context recognition, ubiquitous   storage and access, and anonymous and asynchronous   communications. To evaluate the new service proposed for dynamic   adaptation we developed a case study, implementing an application in   medical area. Analyzing the results we can see that the users found   the application easy to use and usefulness for health workers at a   hospital. This work is sponsored by RNP, FINEP and CNPq - Brazilian   Foundations.               Keywords: adaptive middleware, context-aware adaptation, dynamic adaptation, service-oriented middleware, ubiquitous computing               Categories: C.2.4, J.3, L.7  
20|9||Extending an Application-Level Checkpointing Tool to Provide Fault Tolerance Support to OpenMP Applications|  Nuria Losada (University of A Coruña, Spain)   María J. Martín (University of A Coruña, Spain)   Gabriel Rodríguez (University of A Coruña, Spain)   Patricia González (University of A Coruña, Spain)  Abstract: Despite the increasing popularity of   shared-memory systems, there is a lack of tools for providing fault   tolerance support to shared-memory applications. CPPC (ComPiler for   Portable Checkpointing) is an application-level checkpointing tool   focused on the insertion of fault tolerance into long-running MPI   applications. This paper presents an extension to CPPC to allow the   checkpointing of OpenMP applications.  The proposed solution   maintains the main characteristics of CPPC: portability and reduced   checkpoint file size. The performance of the proposal is evaluated   using the OpenMP NAS Parallel Benchmarks showing that most of the   applications present small checkpoint overheads.               Keywords: OpenMP, checkpointing, fault tolerance, parallel programming               Categories: D.1.3, D.4.5  
20|9||Formal Study of Routing Protocols for Wireless Sensor Networks|  José Antonio Mateo (Universidad de Castilla La-Mancha, Spain)   María del Carmen Ruiz (Universidad de Castilla La-Mancha, Spain)   Hermenegilda Maciá (Universidad de Castilla La-Mancha, Spain)   Juan José Pardo (Universidad de Castilla La-Mancha, Spain)  Abstract: NORA (Network rOle-based Routing Algorithm) and   NORIA (Network rOle-based Routing Intelligent Algorithm) are novel   routing algorithms for Wireless Sensor Networks (WSNs), which   combine various effective techniques in order to reduce energy   consumption and improve data routes. NORA is an algorithm, which   uses local and neighbourhood information to assign a role to each   node on the net, whereas NORIA adds a fuzzy logic engine to NORA in   order to improve this assignment. These algorithms are far from   being trivial, and, therefore, there is a clear need for the use of   formal methods to check their correctness and performance, prior to   their deployment in a real environment. To this end, this paper   presents a neat and rigorous study of both algorithms, and, for the   sake of completeness, we study and compare also both with a   well-known routing protocol: Tree Routing. Finally, Coloured Petri   Nets (CPNs) have been chosen as an appropriate modelling language,   using the well-known tool, CPNTools, to conduct our   experiments.               Keywords: coloured Petri nets, performance evaluation, routing algorithms, wireless sensor networks               Categories: D.2.10, D.2.4, F.1.1, F.4.3  
volume|issue|url|title|abstract
21|1|http://www.jucs.org/jucs_21_1|Learning Analytics|
21|1||The Procrastination Related Indicators in e-Learning Platforms|  Maria del Puerto Paule-Ruiz (University of Oviedo, Spain)   Moises Riestra-Gonzalez (Accenture Analytics, Spain)   Miguel Sánchez-Santillan (University of Oviedo, Spain)   Juan Ramon Pérez-Pérez (University of Oviedo, Spain)  Abstract: In general, research confirms that learning is   more effective when students obtain feedback regarding their   learning progress. Currently, new versions of e-learning platforms   include indicators that provide some static feedback mechanisms and   help both learners and educators in planning their learning   strategies. This paper explains the usage of indicators in current   e-learning systems, generates a taxonomy for their classification,   and studies their influence on student performance. Also, it   provides a study which is based on the combination of a user-based   evaluation process that facilitates data collection and data mining   algorithms to infer association rules between learning variables and   performance. The results highlight how procrastination influences   negative learning performance and how time-related indicators are   tightly coupled with students' performance in e-learning   platforms.               Keywords: educational data mining, feedback, learning analytics, procrastination               Categories: H.2.8, H.5.2, K.3.1  
21|1||Dropout Prediction and Reduction in Distance Education Courses with the Learning Analytics Multitrail Approach|  Wagner Cambruzzi (Universidade do Vale do Rio dos Sinos - UNISINOS, Brazil)   Sandro José Rigo (Universidade do Vale do Rio dos Sinos - UNISINOS, Brazil)   Jorge L. V. Barbosa (Universidade do Vale do Rio dos Sinos - UNISINOS, Brazil)  Abstract: Distance Education courses are present in large   number of educational institutions. Virtual Learning Environments   development contributes to this wide adoption of Distance Education   modality and allows new pedagogical methodologies. However, dropout   rates observed in these courses are very expressive, both in public   and private educational institutions.  This paper presents a   Learning Analytics system developed to deal with dropout problem in   Distance Education courses on university-level education. Several   complementary tools, allowing data visualization, dropout   predictions, support to pedagogical actions and textual analysis,   among others, are available in the system. The implementation of   these tools is feasible due to the adoption of an approach called   Multitrail to represent and manipulate data from several sources and   formats.  The obtained results from experiments carried out with   courses in a Brazilian university show the dropout prediction with   an average of 87% precision. A set of pedagogical actions concerning   students among the higher probabilities of dropout was implemented   and we observed average reduction of 11% in dropout rates.               Keywords: distance education, learning analytics               Categories: L.3, L.3.5, L.3.6  
21|1||Learning Analytics for the Academic:  An Action Perspective|  Alan Dix (Talis, United Kingdom)   Justin Leavesley (Talis, United Kingdom)  Abstract: If learning analytics are to directly benefit   students' learning rather than simply inform broad policy decisions,   they must be used by academics in the midst of busy and fragmented   lives.  This paper takes an ecological or action-oriented   perspective of the use of learning analytics in higher education,   drawing on research sources in psychology, human-computer   interaction and visual analytics.  We unpack the circumstances   during the learning interactions of academics with course materials   and students where analytics could trigger or influence action.   This leads to a framework based around different academic   timescales, and the strategies for synchronising the recognition of   need with the potential for execution of teaching and learning   interventions.               Keywords: action, embodiment, human-computer interaction, learning analytics, learning support, teaching analytics               Categories: H.1.2, H.5.2, K.3, K.3.1  
21|1||"Learning Analytics at ""Small"" Scale:  Exploring a Complexity-Grounded Model for Assessment Automation"|  Sean Goggins (University of Missouri, USA)   Wanli Xing (University of Missouri, USA)   Xin Chen (Purdue University, USA)   Bodong Chen (University of Minnesota, USA)   Bob Wadholm (University of Missouri, USA)  Abstract: This study proposes a process-oriented,   automatic, formative assessment model for small group learning based   on complex systems theory using a small dataset from a   technology-mediated, synchronous mathematics learning   environment. We first conceptualize small group learning as a   complex system and explain how group dynamics and interaction can be   modeled via theoretically grounded, simple rules. These rules are   then operationalized to build temporally-embodied measures, where   varying weights are assigned to the same measures according to their   significance during different time stages based on the golden ratio   concept. This theory-based measure construction method in   combination with a correlation-based feature subset selection   algorithm reduces data dimensionality, making a complex system more   understandable for people. Further, because the discipline of   education often generates small datasets, a Tree-Augmented Naïve   Bayes classifier was coded to develop an assessment model, which   achieves the highest accuracy (95.8%) as compared to baseline   models. Finally, we describe a web-based tool that visualizes   time-series activities, assesses small group learning automatically,   and also offers actionable intelligence for teachers to provide   real-time support and intervention to students. The fundamental   contribution of this paper is that it makes complex, small group   behavior visible to teachers in a learning context   quickly. Theoretical and methodological implications for technology   mediated small group learning and learning analytics as a whole are   then discussed.               Keywords: assessment, complex systems, learning analytics, small group learning               Categories: E.0, L.0.0, L.1.1, L.3.6, L.6.2  
21|1||Towards a Learning-Aware Application Guided by Hierarchical Classification of Learner Profiles|  Behnam Taraghi (Graz University of Technology, Austria)   Anna Saranti (Graz University of Technology, Austria)   Martin Ebner (Graz University of Technology, Austria)   Vinzent Müller (UnlockYourBrain GmbH, Germany)   Arndt Großmann (UnlockYourBrain GmbH, Germany)  Abstract: Learner profiling is a methodology that draws a   parallel from user profiling. Implicit feedback is often used in   recommender systems to create and adapt user profiles. In this work   the implicit feedback is based on the learner's answering behaviour   in the Android application UnlockYourBrain, which poses different   basic mathematical questions to the learners. We introduce an   analytical approach to model the learners' profile according to the   learner's answering behaviour. Furthermore, similar learner's   profiles are grouped together to construct a learning behaviour   cluster.  The choice of hierarchical clustering as a means of   classification of learners' profiles derives from the observations   of learners behaviour. This in turn reflects the similarities and   subtle differences of learner behaviour, which are further analysed   in more detail. Building awareness about the learner's behaviour is   the first and necessary step for future learning-aware   applications.               Keywords: Markov chain, dimension reduction, hierarchical clustering, learner profiling, learning analytics               Categories: L.2.2, M.0, M.4, M.5  
21|1||Development of the Learning Analytics Dashboard to Support Students' Learning Performance|  Yeonjeong Park (Ewha Womans University, South Korea)   Il-Hyun Jo (Ewha Womans University, South Korea)  Abstract: The Learning Analytics Dashboard (LAD) is an   application to show students' online behavior patterns in a virtual   learning environment. This supporting tool works by tracking   students_ log-files, mining massive amounts of data to find meaning,   and visualizing the results so they can be comprehended at a   glance. This paper reviews previously developed applications to   analyze their features. Based on the implications from the review of   previous studies as well as a preliminary investigation on the need   for such tools, an early version of the LAD was designed and   developed. Also, in order to improve the LAD, a usability test   incorporating a stimulus recall interview was conducted with 38   college students in two blended learning classes. Evaluation of this   tool was performed in an experimental research setting with a   control group and additional surveys were conducted asking   students about perceived usefulness, conformity, level of   understanding of graphs, and their behavioral changes. The results   indicated that this newly developed learning analytics tool did not   significantly impact on their learning achievement. However, lessons   learned from the usability and pilot tests support that visualized   information impacts on students understanding level; and the   overall satisfaction with dashboard plays as a covariant that   impacts on both the degree of understanding and students' perceived   change of behavior. Taking in the results of the tests and students'   open-ended responses, a scaffolding strategy to help them understand   the meaning of the information displayed was included in each sub   section of the dashboard. Finally, this paper discusses future   directions in regard to improving LAD so that it better supports   students_ learning performance, which might be helpful for those who   develop learning analytics applications for students.               Keywords: dashboard, learning analytics, learning management system, perceived usefulness, pilot test, usability test, visualization               Categories: L.2.1, L.3.5, L.3.6  
21|1||A Visual Analytics Method for Score Estimation in Learning Courses|  Luis de-la-Fuente-Valentín (Universidad Internacional de La Rioja, Spain)   Abelardo Pardo (The University of Sydney, Australia)   Fernando López Hernández (Universidad Internacional de La Rioja, Spain)   Daniel Burgos (Universidad Internacional de La Rioja, Spain)  Abstract: The provision of awareness is a well-known   method for fostering students' self-reflection, a metacognitive   skill often related to academic success and considered one of the   key skills of the 21st century. Although the information discovered   using learning analytics techniques can be useful in fostering   self-reflection, its delivery to students should be done without   distracting them from their learning goals. This paper presents a   visualization technique based on similarity measures and their   relationship with final course results, in order to foster students'   awareness. The approach is based on the idea that 'students that   behave similarly are graded similarly'. This idea is validated with   an empirical evaluation to determine the visualization technique's   accuracy when used to find a relationship between similarity and   grade. The study used a previously collected dataset and several   volunteers were asked to estimate the students' scores with graphics   provided as the only source of information. The obtained results   validate the proposal as a means to foster effective   self-reflection.               Keywords: awareness, human-computer interface, intelligent tutoring systems, score estimation, self-reflection               Categories: L.2.1, L.2.4, L.3  
21|1||Learning Analytics for English Language Teaching|  Hannah Volk (University of Graz, Austria)   Karl Kellner (Private University of Teacher Education KPH Graz, Austria)   David Wohlhart (Private University of Teacher Education KPH Graz, Austria)  Abstract: In recent times, online learning platforms get   more and more attention and the number of collected data is   growing. Learning analytics is a valuable opportunity to gain   specific information for a better understanding of student's   learning behaviour and to improve their learning success. In this   work, the collected data of the online learning platform   www.more-online.at is analysed and first research results are   presented. The main objective is to analyse the usage behaviour over   a school year and to show the diffusion of the online platform among   provinces in Austria, different school types and other   characteristics. Furthermore, the content of the online platform is   put under closer examination to enable decisions about the   efficiency and effectiveness of different types of   exercises.               Keywords: big data analysis, e-learning, educational data mining, learning analytics               Categories: L.3.0, L.3.5  
21|2|http://www.jucs.org/jucs_21_2|Managing Editor's Column|
21|2||Safe Motor Controller in a Mixed-Critical Environment with Runtime Updating Capabilities|  Jose Luis Gutiérrez-Rivas (University of Granada, Spain)   Simon Holmbacka (Åbo Akademi University, Finland)   Miguel Míndez-Macías (Seven Solutions Inc., Spain)   Wictor Lund (Åbo Akademi University, Finland)   Sebastien Lafond (Åbo Akademi University, Finland)   Johan Lilius (Åbo Akademi University, Finland)   Javier Díaz-Alonso (University of Granada, Spain)  Abstract: Safety-critical systems and certification   standards are the bare essential elements for the development   process of avionics, automotive and industrial embedded systems. The   necessity of including non-safety capabilities to reduce the price   of these systems has resulted in a new type of critical systems, the   mixed-criticality ones. These systems should be able to execute   safety-critical applications but, at the same time, to run   non-safety-critical functionalities without affecting the integrity   of the safety-critical tasks. This paper presents a new system   architecture which includes safety-critical and non-safety-critical   parts in order to form a mixed-criticality system. The system   consists of a reliable platform with a dual-core processor   (implemented using a FPGA) architecture designed as open-hardware,   running two isolated real-time operating systems which are connected   through a safe core-to-core communication channel that executes the   safety-critical applications. Moreover, the safety-critical system   is connected to an external processor, an ARM9, which is used as an   external sensing system. The ARM9 runs the non-safety-critical   applications and allows the system to insert modifications updating   without affecting the safety capabilities of the safety-critical   part. This platform is described providing evidences of the   isolation between safety-critical (SC) and non-safety-critical (NSC)   applications, as well as describing an updating methodology for   non-safety-critical applications. This system is validated using a   complete and reliable application for safe emergency stop   applications for industrial machinery.               Keywords: FPGA, Mixed Critical, Safety Critical, isolation, real-time operating system, runtime updating mechanism               Categories: B.1.3, C.3, D.2.11  
21|2||Flexible Provisioning Adult Learners|  Henry Hermans (Open University of the Netherlands, The Netherlands)   José Janssen (Open University of the Netherlands, The Netherlands)   Hubert Vogten (Open University of the Netherlands, The Netherlands)   Rob Koper (Open University of the Netherlands, The Netherlands)  Abstract: In adult education there is a continuous,   growing demand for learning opportunities that fit the specific   characteristics and preferences of particular learner groups or   individual learners. This requires educational institutions to   rethink their business and educational models, and develop more   flexible online course solutions using ICT. An important downside of   this trend is an increasingly complex logistic process that is very   difficult to manage, in particular with respect to the provisioning   process: which teaching and learning services and facilities should   be made available, to whom, when, and how. Rather than implementing   provisioning rules directly in the software applications that make   up the online delivery environment, we propose a model for an   educational provisioning system (EPS) that allows for highly   flexible provisioning and reduces the workload drastically. This   system is responsible for both expressing and processing   provisioning rules that meet the demands of new (online) course   models. It supports the use of so-called course access levels that   enable to address and provision various learning target groups   separately by means of a single course. For reasons of efficiency we   suggest an architecture in which the EPS is loosely coupled to the   applications in the teaching and learning environment. A first EPS   implementation at the Open University of the Netherlands is   presented and discussed.               Keywords: adult learners, e-Learning, educational provisioning, flexible delivery, online courses, technology enhanced learning               Categories: L.2.0, L.2.2, L.3.0, L.3.5  
21|2||Leveraging Hybrid Recommenders with Multifaceted Implicit Feedback|  Marcelo G. Manzato (Sao Paulo University (ICMC-USP), Brazil)   Edson B. Santos Junior (Sao Paulo University (ICMC-USP), Brazil)   Rudinei Goularte (Sao Paulo University (ICMC-USP), Brazil)  Abstract: Research into recommender systems has focused on   the importance of considering a variety of users' inputs for an   efficient capture of their main interests. However, most   collaborative filtering efforts are related to latent factors and   implicit feed- back, which do not consider the metadata associated   with both items and users. This article proposes a hybrid   recommender model which exploits implicit feedback from users by   considering not only the latent space of factors that describes the   user and item, but also the available metadata associated with   content and individuals. Such descriptions are an important source   for the construction of a user's profile that contains relevant and   meaningful information about his/her preferences. The proposed model   is generic enough to be used with many descriptions and types and   characterizes users and items with distinguished features that are   part of the whole recommendation process.  The model was evaluated   with the well-known MovieLens dataset and its composing modules were   compared against other approaches reported in the literature. The   results show its effectiveness in terms of prediction   accuracy.               Keywords: implicit feedback, latent factors, metadata awareness, recommender systems, user demographic               Categories: H.3.1, H.3.3, H.3.4  
21|2||Public Services Provided with ICT in the Smart City Environment: The Case of Spanish Cities|  Daniel Pérez-González (Universidad de Cantabria, Spain)   Raimundo Díaz-Díaz (Universidad de Cantabria, Spain)  Abstract: Social, technological and economic changes,   citizen demand of services modernization, new ICT developments   related to the Internet of Things and an economic situation that   urges more efficient public administrations, have allowed the   adoption of ICT by municipalities in order to provide public   services. All the foregoing constitutes a boost of the smart city   concept, which is considered in the scientific literature mainly   from a technical point of view, overlooking deeper analysis on the   specific services being provided by means of smart technologies. The   current research identifies services provided using smart   technologies at 26 Spanish smart cities and the degree of smart   development of those cities based on which services provide. The   results highlight that the services most widely implemented are   those that allow direct reductions in local administration   expenditure. On the other hand, the remaining services enjoy greater   perspectives of future development. Additionally, three groups of   smart city development have been identified, which allows   benchmarking analysis and enhances the exchange of information   between the cities.               Keywords: ICT, benchmarking of cities, public services, smart city, technology for smart cities               Categories: C.2.m, H.3.5, H.4.3  
21|2||An Anonymization Algorithm for (α, β, γ, δ)-Social Network Privacy Considering Data Utility|  Mehri Rajaei (Iran University of Science and Technology, Iran)   Mostafa S. Haghjoo (PayameNoor University, Iran)   Eynollah Khanjari Miyaneh (Iran University of Science and Technology, Iran)  Abstract: A well-known privacy-preserving network data   publication problem focuses on how to publish social network data   while protecting privacy and permitting useful analysis. Designing   algorithms that safely transform network data is an active area of   research. The process of applying these transformations is called   anonymization operation. The authors recently proposed the   (?,?,?,?)-SNP (Social Network Privacy) model and its an   anonymization technique. The present paper introduces a novel   anonymization algorithm for the (?,?,?,?)-SNP model. The   desirability metric between two individuals of social network is   defined to show the desirability of locating them in one group   keeping in mind privacy and data utility considerations. Next,   individuals are grouped using a greedy algorithm based on the values   of this metric. This algorithm tries to generate small-sized groups   by maximizing the sum of desirability values between members of each   group. The proposed algorithm was tested using two real datasets and   one synthetic dataset. Experimental results show satisfactory data   utility for topological, spectrum and aggregate queries on   anonymized data. The results of the proposed algorithm were compared   in the topological properties with results of two recently proposed   anonymization schemes: Subgraph-wise Perturbation (SP) and   Neighborhood Randomization (NR). The results show that the proposed   method is better than or similar to SP and NR for preservation of   all structural and spectrum properties, except for the clustering   coefficient.               Keywords: anonymization, background knowledge, data utility, information loss, network data sharing, privacy               Categories: H.0,, H.2, K.6.5, L.4  
21|2||A Recommender System for Non-traditional Educational Resources: A Semantic Approach|  Agustín Cañas Rodriguez (Universidade de Vigo, Spain)   Juan M. Santos Gago (Universidade de Vigo, Spain)   Luis E. Anido Rifón (Universidade de Vigo, Spain)   Roberto Pérez Rodríguez (Universidade de Vigo, Spain)  Abstract: This paper describes a software system that   allows for discovering nontraditional educational resources, that is   to say, those that go beyond educational content and incorporate   elements such as: software applications that may support the   teaching-learning process; events that take place outside school   boundaries, such as new expositions in museums and theatre   performances; and people who may participate as experts in some   Learning Activity. The huge quantity of information available   potentially all that can be extracted from the Internet- enforces us   to adopt a strategy that enables filtering resources in accordance   with their appropriateness and relevance, that is, an strategy based   on recommendations. Besides, due to their particular nature   (e.g. the most relevant events are those that will take place in the   same city where the school is located) the apropriateness of those   resources is highly dependent on the context where teaching and   learning is produced. Therefore, the recommender system takes into   account contextual factors when calculating the relevance of every   resource. This system was evaluated with several focus groups in the   scope of the iTEC project, which belongs to the European Commision's   Framework Programme 7.               Keywords: context-Aware recommender, multicriteria recommendation, recommender system, semantic technologies, technology enhanced learning               Categories: L.1, L.2, L.3  
21|2||A Review of Linked Data Proposals in the Learning Domain|  Guillermo Vega-Gorgojo (Universidad de Valladolid, Spain)   Juan I. Asensio-Pérez (Universidad de Valladolid, Spain)   Eduardo Gómez-Sánchez (Universidad de Valladolid, Spain)   Miguel L. Bote-Lorenzo (Universidad de Valladolid, Spain)   Juan A. Munoz-Cristobal (Universidad de Valladolid, Spain)   Adolfo Ruiz-Calleja (Tallinn University, Estonia)  Abstract: This study critically reviews the recently   published scientific literature on Linked Data proposals in the   educational field. After systematically searching online   bibliographic databases, 33 original works satisfied the scope and   quality criteria, and thus were included in this review. Studies   were classified with respect to TEL research areas;   interoperability, personalization and contextualized learning were   the main areas addressed. Many studies have a foundation on learning   object and repository research, where Linked Data practices are   applied to simplify the integration of educational datasets. As   learning institutions are gradually exposing their key datasets as   Linked Data, an emergent educational data web is being   constituted. A number of the reviewed works consume these data for   different purposes, reporting reusability and enrichment   benefits. Nevertheless, upcoming proposals should be aware of   existing challenges, derived from the Linked Data model, such as the   lack of control of data sources or varying degrees of data   quality.We also give some recommendations for delivering Linked   Databased proposals in education, including a classification of   vocabularies, datasets and technological products. Future research   directions include the release of new datasets as Linked Data,   federation and interlinking practices to improve the cohesion of the   emergent educational Web of Data, generation of learning artifacts,   curation and enrichment of educational data, novel educational   applications consuming Linked Data, and performance   improvements.               Keywords: computer uses in education, intelligent web services and semantic web, libraries/information reposit               Categories: I.2.12, J.8.12, K.3.1  
21|3|http://www.jucs.org/jucs_21_3|Recent Advances in Security and Privacy in Big Data|
21|3||Polymorphic Malicious JavaScript Code Detection for APT Attack Defence|  Junho Choi (Chosun University, South Korea)   Chang Choi (Chosun University, South Korea)   Ilsun You (Korean Bible University, South Korea)   Pankoo Kim (Chosun University, South Korea)  Abstract: The majority of existing malware detection   techniques detects malicious codes by identifying malicious behavior   patterns. However, they have difficulty identifying new or modified   malicious behaviors; consequently, new techniques that can   effectively and accurately detect new malicious behaviors are   crucial. This paper proposes a method that defines the malicious   behaviors of malware using conceptual graphs that are able to   describe their concepts and the relationships among them and,   consequently, infer their malicious behavior patterns. The inferred   patterns are then learned by a Support Vector Machine (SVM)   classifier that compares and classifies the behaviors as either   normal or malicious. The results of experiments conducted verify   that the proposed method detects malicious codes more efficiently   than conventional methods. In the experimental results, it exhibits   a better detection rate than that of malicious code detection   methods that rely solely on the signature based approach. This   suggests that the proposed method is not only suitable for detection   of malicious codes, but is also more efficient than other detection   methods as it combines the advantages of more than two malicious   code detection methods.               Keywords: APT attack defence, conceptual graph, malicious code detection               Categories: D.4.6, I.2.6, K.6.5  
21|3||A Resolving Set based Algorithm for Fault Identification in Wireless Mesh Networks|  Xiaoding Wang (Fujian Normal University, China)   Li Xu (Fujian Normal University, China)   Shuming Zhou (Fujian Normal University, China)   Joseph K. Liu (Institute for Infocomm Research, Singapore)  Abstract: Abstract: Wireless Mesh Networks   (WMNs) have emerged as a key technology for   next-generation wireless networking. By adding some Long-ranged   Links, a wireless mesh network turns into a complex network with the   characteristic of small worlds. As a communication backbone, the   high fault tolerance is a significant property in communication of   WMNs. In this paper, we design a novel   malfunctioned router detection algorithm, denoted by   A-SRS, on searching resolving set based on   private neighbor of dominating set. The A-SRS not   only offers a highly efficient solution to position malfunctioned   routers against intermitted communication that guarantees the   availability of network services, but also   pursues the minimum number of detecting routers due to limited   resource of wireless mesh routers. We also explore the cardinality   of resolving set and complexity of A-SRS based on   the parameters: the minimum degree, the size of underlying graph   G and the number of iterations. The algorithm   enjoys better simulation results that it employs less detecting   routers than the other strategies in the size of resolving   set.               Keywords: dominating set, fault tolerance, resolving set, wireless mesh network               Categories: C.2.0  
21|3||On the Security of a User Equipment Registration Procedure in Femtocell-Enabled Networks|  Chien-Ming Chen (Harbin Institute of Technology Shenzhen Graduate School, China)   Tsu-Yang Wu (Harbin Institute of Technology Shenzhen Graduate School, China)   Raylin Tso (National Chengchi University, Taiwan, R.O.C.)   Masahiro Mambo (Japan, Kanazawa University)   Mu-En Wu (Soochow University, Taiwan, R.O.C.)  Abstract: Mobile data traffic has been growing at an   increasing rate with the popularity of smartphones, tablets, and   other wireless devices. To reduce the load on the network, mobile   network operators deploy femtocells to increase their coverage and   performance and to eliminate wireless notspots. Femtocells are   low-cost devices that connect a new femtocell network architecture   to the core telecommunication network through a licensed spectrum   and standardized interface protocols.  In this   paper, we first note that the user equipment registration procedure,   which is defined in the 3GPP (Third Generation Partnership Project)   standard, in a femtocellenabled network is vulnerable to   denial-of-service attacks. We then propose a mechanism to defend   against these attacks. For compatibility, the proposed mechanism   makes use of the well-defined control message in the 3GPP standard   and modifies the user equipment registration procedure as little as   possible.               Keywords: 3GPP standard, Femtocell, denial-of-service attack, security               Categories: H.2, H.3.7, H.5.4  
21|3||Restricted Identification Secure in the Extended Canetti-Krawczyk Model|  Lucjan Hanzlik (Wrocław University of Technology, Poland)   Mirosław Kutyłowski (Wrocław University of Technology, Poland)  Abstract: In this paper we consider restricted identification (RI) protocols which enable strongauthentication and privacy protection for access control in an unlimited number of domains. A single secret key per user is used to authenticate and derive his identity within any domain,while the number of domains is unlimited and the scheme guarantees unlinkability between identities of the same user in different domains. RI can be understood as an universal solution thatmay replace unreliable login and password mechanisms. It has to secure against adversaries that gather personal data by working on a global scale, e.g. by breaking into one service for gettingpasswords that a user frequently re-uses at different places.  We consider security of an extended version of the Chip Authentication Restricted Identification(ChARI) protocol presented at the 11th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom 2012). We preserve the features of ChARI (avoidingthe critical security problems of group keys in the RI solution deployed in the German personal identity cards), but provide security proof in the well-studied Canetti-Krawczyk model (sucha proof has not been provided for ChARI). Our extension has similar computational complexity as the original ChARI protocol in terms of the number of modular exponentiations.               Keywords: ChARI, Diffie-Hellman key agreement, chip authentication, eCK model, personal identity card, restricted identification, sector identity, unlinkability               Categories: D.4.6, E.3, K.6.5  
21|3||Searchable Public-Key Encryption with Data Sharing in Dynamic Groups for Mobile Cloud Storage|  Qi Xia (University of Electronic Science and Technology of China, China)   Jianbing Ni (University of Electronic Science and Technology of China, China)   Ansuura John Bosco Aristotle Kanpogninge (University for Development Studies, Ghana)   James C. Gee (University of Pennsylvania, USA)  Abstract: Mobile cloud computing is referred as the   combination of cloud computing and mobile networks to bring benefits   for both mobile users and cloud computing providers. While once the   data of mobile users is outsourced to the cloud, it is a formidable   and challenging task for the data owners to realize both the data   confidentiality and the utilization because it seems unachievable to   search and retrieve the special contents on the data encrypted by   traditional encryption schemes. To address this issue, we propose a   searchable public-key encryption scheme for a group of users in   mobile cloud storage. In our proposal, a dynamic asymmetric group   key agreement protocol is utilized for data sharing among a body of   mobile users and the technique of proxy re-signature is employed to   update the searchable ciphertexts when the mobile users in the group   varies. Through the security proof and performance evaluation, we   demonstrate the new scheme is both secure and efficient, and hence   it reaches the requirements of the users, network operators, as well   as cloud computing providers in application.               Keywords: cloud storage, data sharing, mobile cloud computing, mobile network, searchable encryption                
21|3||An Improved Cloud Data Sharing Scheme with Hierarchical Attribute Structure|  Zhusong Liu (Guangdong University of Technology, China)   Hongyang Yan (Guangzhou University, China)   Zhiqiang Lin (Chinese Academy of Sciences, China)   Lingling Xu (South China University of Technology, China)  Abstract: Cloud computing is an emerging computing paradigm that can provide storage resources and computing capacities services over the Internet. However, some new security issues arise when users' sensitive data are outsourced and shared in untrusted cloud. The traditional techniques to protect the confidentiality of sensitive data stored in cloud are encryption and related cryptographic tools. And the corresponding private keys to access and decrypt the files are disclosed to only authorized users. However, these traditional solutions are not scalable because the computational cost of encryption and other access control is heavy for devices with limited computation ability.  In this paper, we present a new way to implement scalable and fine-grained access control systems, which can be applied for big data in untrusted cloud computing environment. The solution is based on symmetric, efficient broadcast encryption and fine-grained attribute-based encryption (ABE). In this access control system, users are able to join and revoked with broadcast encryption. An outsourced Hierarchical ABE scheme is first proposed in this paper to construct the access control system. The security analysis is also               Keywords: attribute-based encryption, fine-grained access control, multi-authority               Categories: H.2, H.3.7, H.5.4  
21|3||Insecurity of an Efficient Privacy-preserving Public Auditing Scheme for Cloud Data Storage|  Hongyu Liu (University of Electronic Science and Technology of China, China)   Leiting Chen (University of Electronic Science and Technology of China, China)   Zahra Davar (University of Wollongong, Australia)   Mohammad Ramezanian Pour (University of Wollongong, Australia)  Abstract: Cloud storage has a long string of merits but at   the same time, poses many challenges on data integrity and   privacy. A cloud data auditing protocol, which enables a cloud   server to prove the integrity of stored files to a verifier, is a   powerful tool for secure cloud storage. Wang et al. proposed a   privacy-preserving public auditing protocol, however, Worku et   al. found the protocol is seriously insecure and proposed an   improvement to remedy the weakness. In this paper, unfortunately, we   demonstrate that the new protocol due to Worku et al. fails to   achieve soundness and obtains merely limited privacy. Specifically,   we show even deleting all the files of a data owner, a malicious   cloud server is able to generate a response to a challenge without   being caught by TPA in their enhanced but unrealistic security   model. Worse still, the protocol is insecure even in a correct   security model. For privacy, a dishonest verifier can tell which   file is stored on the cloud. Solutions to efficient public auditing   mechanisms with perfect privacy protection are still worth   exploring.               Keywords: cloud storage, data integrity, privacy-preserving,, security analysis               Categories: H.2, H.3.7, H.5.4  
21|3||Multi-Authority Attribute-Based Encryption Scheme from Lattices|  Guoyan Zhang (Shandong University, China)   Jing Qin (Shandong University, China)   Shams Qazi (University of Wollongong, Australia)  Abstract: Access control can selectively restrict access   to sensitive information stored by third-party sites on the   Internet. Attribute-based encryption (ABE) schemes can strengthen   the effective combination of flexibility and operability of access   control. They allow one sender to encrypt a message for more than   one recipient, and to specify who should be able to decrypt, using   attributes alone. Since 2005, many powerful ABE schemes have been   presented, but there are two types of problem that haven't be   efficiently resolved so far. On the one hand, as practical extension   of identity-based encryption (IBE) schemes, ABE schemes are also   confronted with key escrow problem. On the other hand, attribute set   belonging to one user is usually monitored by different authorities   in this era of collaboration. Multi-authority ABE (MA-ABE) schemes   can simultaneously resolve these problems, but now they have not   been thoroughly investigated yet. More precisely, MA-ABE schemes   against quantum attack are the main barrier of the development of   ABE schemes in a `post-quantum' world.  In this paper, we firstly present a MA-ABE scheme from lattices, in which identities of users are authenticated by a central authority, which improves the efficiency of authentication. Furthermore, different attribute private keys are still distributed by different authorities, and the central authority cannot obtain any secret information of other attribute authorities, which resolves key escrow problem to some extent. In MAABE, attribute private keys belonging to one user are generated by different authorities, and how to ensure correct decryption is one of the crux of schemes. Our scheme gives a simple solution, and each user's attribute private keys are combined using sharing of common public information to automatically realize correct decryption. To our best knowledge, this is the first MA-ABE scheme from lattices, and it is more efficient than the MA-ABE presented by Melissa Chase. Finally, we present a multi-authority large universe ABE scheme, in which the sizes of the public key and the ciphertext are only relative to the number of the attribute authorities, and a user will be able to decrypt a ciphertext if and only if he has at least tK attributes from each authority K.               Keywords: LWE, MA-ABE, lattices, preimage sampling functions               Categories: E.3  
21|4|http://www.jucs.org/jucs_21_4|Managing Editor's Column|
21|4||Heuristic Algorithms for Manufacturing and Replacement Strategies of the Production System|  Robert Bucki (Institute of Management and Information Technology in Bielsko-Biał, Poland)   Bronislav Chramcov (Tomas Bata University in Zlín, Czech Republic)   Petr Suchánek (Silesian University in Opava, Czech Republic)  Abstract: The paper highlights the problem of minimizing   economic costs of making orders in the automated manufacturing   system which consists of work centres arranged in a series. Each of   them is equipped with tools which carry out defined manufacturing   operations. Tools are replaced with new ones only when no   manufacturing operation can be performed any more in order to   minimize the residual pass. The equations of state of the production   line are presented and heuristic control strategies are discussed in   detail. The criterion is to minimize the number of replacement   procedures which results in maximizing the use of tools in work   centres. To prove the correctness of the presented approach the   paper is supported with an extended simulation study based on   implementing available combinations of either manufacturing or   replacement strategies taking into account various configurations   which come into being in the real manufacturing environment. The   simulation results form the basis for the detailed analysis to meet   the requirements of the applicable decision-making   procedures.               Keywords: computer simulation, heuristic algorithms, manufacturing strategy, manufacturing system, optimization               Categories: F.1.1, F.2.1, G.1.6, I.1.2  
21|4||RITA: a useR Interface evaluaTion frAmework|  Selem Charfi (LAMIH-UMR CNRS 8201, UVHC, France)   Houcine Ezzedine (LAMIH-UMR CNRS 8201, UVHC, France)   Christophe Kolski (LAMIH-UMR CNRS 8201, UVHC, France)  Abstract: Interactive systems are constantly   evolving. This evolution leads to new challenges. One of these   challenges pertains to the quality of dialogue between interactive   systems and humans. This dialogue essentially takes place through   user interfaces. User interface evaluation is essential to improve   communication between a system and its users. The research on   interface evaluation is plentiful. Nevertheless, user interface   evaluators still encounter difficulties. Therefore, in this article   we suggest expanding the functionalities of existing evaluation   tools by proposing a user interface evaluation framework. This   framework is composed by software applications structured following   a modular architecture. It is based on three different evaluation   techniques and has a modular architecture that can be configured to   evaluate different user interfaces. After being presented, this   framework is tested on a network supervision system for a project in   the transportation domain. The main advantages of the presented   Framework are the following: (1) the guidelines are not hard coded   into the evaluation engine; (2) it is based on three different   evaluation techniques to avail further data for the evaluation; (3)   it is structured following a modular architecture to enable flexible   and configurable use; (4) interaction data are automatically   captured and analyzed; and (5) the framework is intended for the   evaluation of different kind of user interfaces.               Keywords: electronic informer, ergonomic guidelines, ergonomic quality inspection, questionnaire, usability, user interface evaluation, utility               Categories: H.5.2  
21|4||Sentiment and Behaviour Annotation in a Corpus of Dialogue Summaries|  Norton Trevisan Roman (University of São Paulo, Brazil)   Paul Piwek (The Open University, United Kingdom)   Ariadne Maria Brito Rizzoni Carvalho (University of Campinas, Brazil)   Alexandre Rossi Alvares (University of São Paulo, Brazil)  Abstract: This paper proposes a scheme for sentiment   annotation. We show how the task can be made tractable by focusing   on one of the many aspects of sentiment: sentiment as it is recorded   in behaviour reports of people and their interactions. Together with   a number of measures for supporting the reliable application of the   scheme, this allows us to obtain sufficient to good agreement scores   (in terms of Krippendorf's alpha) on three key dimensions: polarity,   evaluated party and type of clause. Evaluation of the scheme is   carried out through the annotation of an existing corpus of dialogue   summaries (in English and Portuguese) by nine annotators. Our   contribution to the field is twofold: (i) a reliable   multi-dimensional annotation scheme for sentiment in behaviour   reports; and (ii) an annotated corpus that was used for testing the   reliability of the scheme and which is made available to the   research community.               Keywords: automatic dialogue summarisation, computational linguistics, corpus annotation, natural language processing, sentiment analysis               Categories: I.2.7, L.1.3  
21|4||Point Density Evaluation of Airborne LiDAR Datasets|  Bojan Rupnik (University of Maribor, Slovenia)   Domen Mongus (University of Maribor, Slovenia)   Borut Žalik (University of Maribor, Slovenia)  Abstract: Light Detection And Ranging (LiDAR) technology   provides the means for fast and accurate acquisition of geospatial   data. Quality control of the derived data is an important process   for verifying whether the requirements of the scanning mission have   been met. Point density presents one of the most important factors   for evaluating LiDAR data. This paper presents a new method for   evaluating the point density of LiDAR data through by applying   methods of computational geometry. This method treats the LiDAR scan   with regard to terrain characteristics and divides it into those   areas that can be scanned and those that prevent quality scanning   and produce weak returns. Point density evaluation is performed   using the Voronoi diagram, which allows efficient extraction of   actual LiDAR point density.               Keywords: LiDAR, Voronoi diagram, computational geometry, point density, quality control, remote sensing               Categories: I.3.5, I.3.8, J.7  
21|4||From Terminology Extraction to Terminology Validation:An Approach Adapted to Log Files|  Hassan Saneifar (LIRMM - University Montpellier 2 - CNRS, France)   Stéphane Bonniol (Satin Technologies, France)   Pascal Poncelet (LIRMM - University Montpellier 2 - CNRS, France)   Mathieu Roche (TETIS - Cirad - Irstea - AgroParisTech, France)  Abstract: Log files generated by computational systems   contain relevant and essential information. In some application   areas like the design of integrated circuits, log files generated by   design tools contain information which can be used in management   information systems to evaluate the final products. However, the   complexity of such textual data raises some challenges concerning   the extraction of information from log files. Log files are usually   multi-source, multi-format, and have a heterogeneous and evolving   structure. Moreover, they usually do not respect natural language   grammar and structures even though they are written in   English. Classical methods of information extraction such as   terminology extraction methods are particularly irrelevant to this   context. In this paper, we introduce our approach EXTERLOG to   extract terminology from log files. We detail how it deals with the   specific features of such textual data. The performance is   emphasized by favoring the most relevant terms of the domain based   on a scoring function which uses a Web and   context based measure. The experiments show that   EXTERLOG is a well-adapted approach for terminology extraction from   log files.               Keywords: information extraction, log files, natural language processing, terminology extraction, terminology ranking, text mining               Categories: H, I.2.7, I.7  
21|5|http://www.jucs.org/jucs_21_5|Massive Open Online Courses: Combining Methodologies and Architecture for a Success Learning|
21|5||Detection and Evaluation of Emotions in Massive Open Online Courses|  Derick Leony (Universidad Carlos III de Madrid, Spain)   Pedro J. Muñoz-Merino (Universidad Carlos III de Madrid, Spain)   José A. Ruipérez-Valiente (Universidad Carlos III de Madrid, Spain)   Abelardo Pardo (University of Sydney, Australia)   Carlos Delgado Kloos (Universidad Carlos III de Madrid, Spain)  Abstract: Massive Open Online Courses (MOOCs) have grown   up to the point of becoming a new learning scenario for the support   of large amounts of students. Among current research efforts related   to MOOCs, some are studying the application of well-known   characteristics and technologies. An example of these   characteristics is adaptation, in order to personalize the MOOC   experience to the learners skills, objectives and   profile. Several educational adaptive systems have emphasized the   advantages of including affective information in the learner   profile. Our hypothesis, based on theoretical models for the   appraisal of emotions, is that we can infer the learners   emotions by analysing their actions with tools in the MOOC   platform. We propose four models, each to detect an emotion known to   correlate with learning gains and they have been implemented in the   Khan Academy Platform. This article presents the four models   proposed, the pedagogical theories supporting them, their   implementation and the result of a first user study.               Keywords: MOOC, affective computing, emotion detection, learning analytics, user modelling               Categories: J.4, L.2.2, L.3.6  
21|5||Cloud Interoperability Service Architecture for Education Environments|  Rocael Hernández Rizzardini (Galileo University, Guatemala)  Abstract: MOOC adoption is growing, and several challenges   are presented with it. One of them is the use of innovative tools   for learning, with a special emphasis in having learners to   represent their acquired knowledge in creative forms; therefore,   some experiences in that regard will be introduced. Thus,   orchestrating the learning experience with cloud-based external   tools (realized as Web 2.0 tools) brings interoperability issues   such as automated management of tools and interoperability   scalability. This paper presents a new version of an architecture   that is capable of interoperability with external tools by defining   a semantic description of the tools' Web API using linked data. This   creates the next generation of tool interoperability for educational   environments. Furthermore, it makes machine discovery of the Web API   possible; therefore, it does not require custom system interfaces to   interoperate. It simplifies the plugging in of new external tools   and maintenance of integrated services. Additionally, the   architecture makes it possible to automate simple and complex tasks   to be performed with the external tools, such as creating thousands   of tool instances to be used by MOOC learners. The results are very   promising and demonstrate that this approach is innovative, scalable   and highly accurate. Currently, no standard, specification or   framework has the same type of flexibility, integration simplicity   and robust management for external tools.               Keywords: Hydra, JSON-LD, MOOC, cloud education environments, cloud-based tools, interoperability, scalability, semantic web, vocabularies               Categories: L.1.3, L.1.4, L.3.0, L.3.6  
21|5||Seeking Open Educational Resources to Compose Massive Open Online Courses in Engineering Education  An Approach based on Linked Open Data|"  Nelson Piedra (Universidad Técnica Particular de Loja, Ecuador)   Janneth Chicaiza (Universidad Técnica Particular de Loja, Ecuador)   Jorge López (Universidad Técnica Particular de Loja, Ecuador)   Edmundo Tovar (Universidad Politécnica de Madrid, Spain)  Abstract: The OER movement has tended to define ""openness""   in terms of access to use and reuse educational materials, and to   address the geographical and financial barriers among students,   teachers and self-learners with open access to high quality digital   educational resources. MOOCs are the continuation of this trend of   openness, innovation, and use of technology to provide learning   opportunities for large numbers of learners. In the last years, the   amount of Open Educational Resources on the Web has increased   dramatically, especially thanks to initiatives like OpenCourseWare   and other Open Educational Resources movements. The potential of   this vast amount of resources is enormous. In this paper an   architecture based on Semantic Web technologies and the Linked Data   guidelines to support the inclusion of open materials in massive   online courses is presented. Linked Data is considered as one of the   most effective alternatives for creating global shared information   spaces, it has become an interesting approach for discovering and   enriching open educational resources data, as well as achieving   semantic interoperability and re-use between multiple Open   Educational Resources repositories. The notion of Linked Data refers   to a set of best practices for publishing, sharing and   interconnecting data in RDF format. Educational repositories   managers are, in fact, realizing the potential of using Linked Data   for describing, discovering, linking and publishing educational data   on the Web. This work shows a data architecture based on semantic   web technologies that support the discovery and inclusion of open   educational materials in massive online courses in engineering   education. The authors focus on a type of openness: open of contents   as regards re-use and re-mix, i.e. freedom to reuse the material, to   combine it with other materials, to adapt and to share it further   under an open license.               Keywords: Linked Data, Linked OER Data, MOOC, OCW, OER, integration, openness, reuse               Categories: L.1.1, L.1.3, L.1.4, L.3.0, L.3.2  "
21|5||Methodological Approach and Technological Framework to Break the Current Limitations of MOOC Model|  Ángel Fidalgo-Blanco (Technical University of Madrid, Spain)   María Luisa Sein-Echaluce (University of Zaragoza, Spain)   Francisco J. García-Peñalvo (GRIAL Research Group University of Salamanca, Spain)  Abstract: A methodological approach and technological   framework are proposed to improve learning outcomes in Massive Open   Online Courses (MOOCs), taking into account the distinguishing   features of this kind of massive courses over traditional online   courses. The proposed methodology integrates the learning strategies   of xMOOCs and cMOOCs with adaptivity and knowledge management   capabilities. In order to test the learning results of the   methodology and the need of supporting technological framework for   it, a MOOC was made based on the methodological proposal and using a   MOOC platform called MiríadaX. The quantitative results have   improved considerably the MOOC completion rate (compared to the   average of the rest of MOOC MiríadaX) and the qualitative results   show a great satisfaction with the learning outcomes of the   learners. However, the technological environment did not allow us   develop all the methodological capabilities and it was one of the   main concerns of the MOOC attendances. Therefore, from the analysis   of collected data and considering the limitations of current MOOC   technology platforms, a technological framework has been   designed. It may incorporate the proposed methodology in an   efficient and effective way. Based on this proposed technological   framework, a MOOC platform has been developed and delivered, used by   three Spanish Universities to offer MOOCs. This new platform and the   supported technological framework have been tested with a first   pilot with promising results.               Keywords: adaptive learning, connectivism, instructivism, learning management system, massive open online course, technological framework               Categories: K.3.1, K.3.2  
21|5||MyLearningMentor: A Mobile App to Support Learners Participating in MOOCs|  Carlos Alario-Hoyos (Universidad Carlos III de Madrid, Spain)   Iria Estévez-Ayres (Universidad Carlos III de Madrid, Spain)   Mar Pérez Sanagustín (Pontificia Universidad Católica, Chile)   Derick Leony (Universidad Carlos III de Madrid, Spain)   Carlos Delgado Kloos (Universidad Carlos III de Madrid, Spain)  Abstract: MOOCs have brought a revolution to   education. However, their impact is mainly benefiting people with   Higher Education degrees. The lack of support and personalized   advice in MOOCs is causing that many of the learners that have not   developed work habits and self-learning skills give them up at the   first obstacle, and do not see MOOCs as an alternative for their   education and training. MyLearningMentor (MLM) is a mobile   application that addresses the lack of support and personalized   advice for learners in MOOCs. This paper presents the architecture   of MLM and practical examples of use. The architecture of MLM is   designed to provide MOOC participants with a personalized planning   that facilitates them following up the MOOCs they enroll. This   planning is adapted to learners' profiles, preferences, priorities   and previous performance (measured in time devoted to each   task). The architecture of MLM is also designed to provide tips and   hints aimed at helping learners develop work habits and study   skills, and eventually become self-learners.               Keywords: MOOCs, mentoring, planning, study skills, work habits               Categories: K.3.1, K.3.2  
