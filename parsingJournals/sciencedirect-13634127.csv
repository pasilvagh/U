volume|issue|url|title|abstract
5|1|http://www.sciencedirect.com/science/journal/13634127/5/1|Introduction|Chez Ciechanowicz, Baltimore Teaching Fellow Course Director, Information Security Group Royal Holloway, University of London
5|1||Report Highlights|
5|1||Platform Security and Common Criteria|
5|1||Platform Security: What is Lacking?|
5|1||High Security Modules â Still Needed Despite Advances in Platforms|
5|1||How Strong do Platforms Need to be From a Legal Perspective?|
5|1||Computing Platform Security in Cyberspace|
5|1||Windows 2000 Security: A Balanced View1|
5|2|http://www.sciencedirect.com/science/journal/13634127/5/2|Introduction|
5|2||Report Highlights|Highlights from each of the articles in the report have been extracted to give the reader a quick overview of the contents and to summarize the key messages.
5|2||Computer Evidence â Recent Issues|
5|2||Whoâs Bugging You? How Are You Protecting Your Information?|
5|2||PABX Security|
5|2||The Role of Technology in Computer Forensic Investigations|
5|2||The Computer Misuse Act 1990: Understanding and Applying the Law|
5|2||IT as an Enabler of Computer Fraud|
5|3|http://www.sciencedirect.com/science/journal/13634127/5/3|Introduction|
5|3||Report Highlights|
5|3||Introduction to WAPâs Wireless Transport Layer Security|
5|3||The WAP Forumâs Wireless Public Key Infrastructure|
5|3||Bluetooth Security â An Overview|
5|3||TETRA Security|
5|3||Security for the Third Generation (3G) Mobile System|
5|3||Design of Security Algorithms for Third Generation Mobile Telephony|
5|3||Security Concerns in IP-Based Telephony: Covering TIPHON as a Case Study|
5|4|http://www.sciencedirect.com/science/journal/13634127/5/4|Introduction|
5|4||Report Highlights|Highlights from each of the articles in the report have been extracted to give the reader a quick overview of the contents and to summarize the key messages.
5|4||PKI standards|
5|4||Implementing a PKI|
5|4||The Intersection of Public Key Infrastructures and the Law|
5|4||PKI â Panacea1 or Silver Bullet?|Prologue
5|4||Authorization Models â PKI Versus the Real World|The widely marketed Public Key Infrastructure as a means of securing business by electronic means requires communication between individuals. Most business models communicate with groups and relate roles to individual actors. Can these models be resolved efficiently and securely? Are new mechanisms needed or can you re-work existing technologies?
5|4||Certificate Classes|
5|4||Achieving Certainty in an Age of Uncertainty|In an era where the private domain is being rapidly replaced by the use of public networks, most notably the Internet, how can you be sure that your counterparty is really who he/she claims to be and how can you achieve contractual enforceability? In this article, we outline the Identrus model and its applicability for those responsible for the treasury function in companies worldwide.
5|4||Identrus â the âTechnical Platformâ|In his outline of Identrus, John Bullard described the business rationale for its existence, and its fundamental principles of trust, global interoperability and simplicity. He has explained how the delivery of identity assurance services, within a supporting framework of operating rules, and governed through the application of private contract law, allows Identrus to deliver trusted digital signature services on a global basis. In this article we discuss how these services are realized by Identrus and its participants, in practice, and outline some of the technology underpinning the system.
volume|issue|url|title|abstract
6|1|http://www.sciencedirect.com/science/journal/13634127/6/1|Introduction|
6|1||Report Highlights|Highlights from each of the articles in the report have been extracted to give the reader a quick overview of the contents and to summarize the messages.
6|1||What is a VPN?|
6|1||Implementing Virtual Private Networks in Today's Organization|
6|1||VPN Security Policy|
6|1||IPsec Networking Standards â An Overview|
6|1||VPNs and Lightweight Clients11|
6|1||Enabling the User: The VPN in Context|Despite the growth of IP-VPN capabilities too little attention has been paid to date to other key enterprise trends such as the increasing use of other virtual services and the growing use of enterprise directories. As the nature and number of relationships between the enterprise and the service provider becomes more complex, and the content of IP-VPN services becomes more feature-rich, new approaches are required. Organizations face a choice of either maintaining application/service-specific mechanisms or adopting a centralized approach exploiting technology such as directories more widely. These trends are discussed and a potential way forward outlined which puts the end-user at the heart of the issue.
6|1||Placement of Intelligence Within Networks to Provide Corporate VPN Services|
6|2|http://www.sciencedirect.com/science/journal/13634127/6/2|Introduction|
6|2||Report Highlights|Highlights from each of the articles in the report have been extracted to give the reader a quick overview of the contents and to summarize the messages.
6|2||Database Security in a Web Environment|
6|2||Role Based Access Control Models|
6|2||Database Security: Retrospective and Way Forward|
6|2||XML security|
6|2||Security for Workflow Systems|
6|2||Security in Federated Database Systems|
6|2||Security for eBusiness|
6|2||Security for Distributed Databases|
6|3|http://www.sciencedirect.com/science/journal/13634127/6/3|Introduction|
6|3||Report Highlights|
6|3||Information Security Risk Management â When Should It be Managed?|
6|3||Risk Assessment|
6|3||Information Security Risks and Managed Security Service|
6|3||Handling Distributed Denial-of-Service Attacks|
6|3||Information Incident Management|
6|3||Organizational Leaderâs Use Of Risk Management for Information Technology|
6|3||Information Security Governance|“Directors have a responsibility to protect shareholder value. This responsibility applies just as stringently to valued information assets as it does to any other asset. Boards must recognise that securing that information is not just an investment; it is essential for survival in all cases and for many it can even create competitive advantage.”
6|4|http://www.sciencedirect.com/science/journal/13634127/6/4|Introduction|
6|4||Report Highlights|Highlights from each of the articles in the report have been extracted to give the reader a quick overview of the contents and to summarize the key messages. <Iz10.5>
6|4||Red Alert|
6|4||Pickânâmix comparative tests.|
6|4||Backdoors and Trojan Horses: By the Internet Security Systemsâ X-Force|The article, written by Internet Security Systems’ X-Force explains what Trojan Horses are and how they can be detected. Also included are descriptions of Trojans that may infect Windows and Unix based systems and details of their payloads.
6|4||Travelling with Linux malware: Is Linux security for real?|
6|4||Wormâs Fashion Salon|
6|4||The Virus Writer and The Reporter|
volume|issue|url|title|abstract
7|1|http://www.sciencedirect.com/science/journal/13634127/7/1|Introduction|
7|1||Report Highlights|Highlights from each of the articles in this issue have been extracted to give the reader a quick overview of the contents and to summarize the main points.
7|1||Unix Filesystem Security|
7|1||Vulnerability Management in Unix Environments|“In theory, theory and practice are the same. In practice, they’re not.” Bruce Schneier
7|1||Design of Secure Unix|
7|1||Securing the Shell â Implementing a Host Level Default Deny Policy|
7|1||A Framework for Choosing Your Next Generation Authentication/Authorization System|
7|2|http://www.sciencedirect.com/science/journal/13634127/7/2|Introduction|
7|2||Report Highlights|Highlights from each of the articles in the report have been extracted to give the reader a quick overview of the contents and to summarize the key messages.
7|2||Is there a Need for Survivable Computation in Critical Infrastructures?|
7|2||Protecting the Critical National Infrastructure â Developing a Method for the Measurement of Threat Agents in an Information Environment|
7|2||Benchmarking for Critical Infrastructure Protection|
7|2||Information Sharing in the Cyber Age: a Key to Critical Infrastructure Protection|
7|2||Securing the Critical IP Infrastructure|
7|2||The UK Financial Sector's Place in the Critical National Infrastructure|
7|3|http://www.sciencedirect.com/science/journal/13634127/7/3|Introduction|
7|3||Report Highlights|
7|3||Identity and Authentication in the E-economy|
7|3||Smart Cards and the Associated Infrastructure Problem|
7|3||Secure Authentication Using Biometric Methods|
7|3||Cryptography from Pairings: A Snapshot of Current Research|
7|3||The Development of Open, Federated Specifications for Network Identity|
7|3||Addressing Online Identity: Understanding the Microsoft Passport Service|
7|3||Secure Access Management: Trends, Drivers and Solutions|
7|4|http://www.sciencedirect.com/science/journal/13634127/7/4|Introduction|
7|4||Report Highlights|Highlights from each of the articles in the report have been extracted to give the reader a quick overview of the contents and to summarize the key messages.
7|4||Who holds the key to IT security?|
7|4||New Advances in Automatic Gait Recognition|
7|4||Biometric Standards â An Overview|
7|4||Implementation of Biometric Systems â Security and Privacy Considerations|As biometric systems are deployed within security systems, or as part of identification programs, implementation issues relating to security and privacy need to be considered. The role of a biometric system is to recognize (or not) an individual through specific physiological or behavioral traits. The use of the word ‘recognize’ is significant — defined in the Oxford Dictionary as “identify as already known”. In other words, a biometric system does not establish the identity of an individual in any way, it merely recognizes that they are who they say they are (in a verification or a ‘positive identification’ system), or that they were not previously known to the system (in a ‘negative identification’ system, for example, to avoid double enrollment in a welfare system). This tie between the actual identity of an individual and the use of biometrics is subtle and provokes much debate, particularly relating to privacy and other societal issues. This paper seeks to clarify come of these issues by providing a framework, and by distinguishing between technology and societal issues.
7|4||Spoofing and Anti-Spoofing Measures|
volume|issue|url|title|abstract
8|1|http://www.sciencedirect.com/science/journal/13634127/8/1|Introduction|
8|1||Are we smart about security?|The introduction of new technologies and changes in behaviours has resulted in an erosion of personal contact and greater reliance on security systems and safeguards. The proliferation of independent security measures has generated an increasing amount of security information that must be stored and recalled by the consumer. Overall security can then be weakened as the consumer is inexpert at managing such data and really needs an integrated high security solution that is also easy to use. The multi-application smart card offers a promising solution, however, we may need to challenge some existing practices if we are to empower the citizen in the online world.
8|1||An overview of the GlobalPlatform smart card specification|Over the last five years smart card technology has changed considerably, both at the hardware and software level. More powerful microprocessors along with secure multi-application smart card operating systems provided the necessary functionality required by a large number of smart card applications. GlobalPlatform is considered among the leading multi-application smart card propositions that make an attempt to meet the requirements, for post issuance, issuer control, and interoperability. This article provides an overview of the GlobalPlatform card specification with an emphasis on its security functionality.
8|1||Defending against cache-based side-channel attacks|Cache-based side-channel analysis is a new technique that uses the application-specific behaviour of cache memory to leak secret information about a running algorithm to the attacker. Two complementary methods have been proposed that describe how such attacks could be mounted, but there has been little work on how one might defend devices against the resulting security breaches. This paper surveys a number of hardware- and software-based approaches to defending against such methods of attack and evaluates each using simulated results.
8|1||Secure SIM lifecycle management|
8|1||Software attacks on smart cards|
8|1||Overview about attacks on smart cards1|When compared with data carriers such as cards with magnetic stripes or diskettes, the potential for protecting and securing data is one of the main advantages of cards with electronic chips (smart cards). Consequently, the chip hardware must be designed in an optimum fashion to meet this purpose; this includes the corresponding cryptographic procedures for securing the secret data. However, security is not only dependent on the specialised hardware of the microcontroller or on the cryptographic algorithms implemented in the operating system software. The security of applications for smart cards and the design principles applied by the developers to meet these security needs are of fundamental importance. The essential property of a smart card is its ability to offer a secure environment for data and programs. This article examines the range of possible attacks against smart cards, and the measures that can be used to protect against these attacks.
8|2|http://www.sciencedirect.com/science/journal/13634127/8/2|Introduction|
8|2||Forensic analysis on a Lotus Notes server|Many of the requests to perform forensics on email systems that I have been involved with have focused on the examination of a particular userÄ±Ìs mailbox looking for content that would prove any of the points of the case. This type of targeting allows the use of traditional forensics tools to search for the existence of specific content. Recently, however, in support of a civil case that attempted to gather evidence of inappropriate sharing and misuse of privileged information, the importance of the analysis was less on the content of any particular message. Key to the case was the timing and distribution of key messages. The data collected was from images of the corporate Lotus Notes server. I was responsible for identifying technologies capable of gathering and presenting the data to legal counsel. This article describes the methods used to assist in the analysis of the 12 Gigabytes of email files found on the server
8|2||Addressing the data problem|
8|2||Computer forensics: past, present and future|
8|2||Some stepping stones in computer forensics|“Well what are we going to do with this lot?” The “lot” that my team at the Computer Crime Unit (CCU) at New Scotland Yard were looking at comprised of bits of computer parts just shipped from Nairobi by the Kenyan Police. Bundles of metal covered in bubble-wrap; this was the evidence of a serious attack on computer systems around the world, and to be honest we were not sure what to do next. It was the box and component parts from a PC that could have been used by a suspect. We put all the component parts back together, turned on the power supply, and, surprise, surprise — nothing happened. This will look good in Court, we could more or less write the brief for any future defence counsel ourselves. “Officer, are you trying to tell the Court that you obtained this evidence from a computer that was operating normally?” Worse, this was not the only evidence due to arrive from other countries. Even worse, reports of system failure were arriving by the hour from medical establishments in the UK and other sites around the world; the press and media were bombarding us for information; the senior bods at the Yard wanted answers and we still did not have a clue who the perpetrator was or how to analyse his program.
8|2||A comprehensive approach to digital incident investigation|The investigation of digital incidents and computer-related crimes has, over the past 18 months, become increasingly complex. Although the majority of digital incidents investigated by law enforcement still comprise child pornography, online frauds and other common crimes, two disturbing trends have emerged. First, digital incidents are becoming more complex and, second, they are becoming more expensive to investigate.
8|2||Management strategies for implementing forensic security measures|We live in the age of electronic information and rapidly evolving technology. Almost every aspect of our lives is touched or somehow controlled by technology-driven processes, procedures and devices. It is therefore important to understand that because of the pervasive electronic influence, the opportunist or criminal element has turned its attention to exploiting weaknesses inherent in many traditional and electronic information systems. With that undisputable fact in mind, we must face the inevitable: a successful criminal or unacceptable incident occurring within the organization’s perimeter of the information and/or computer and network infrastructure.
8|3|http://www.sciencedirect.com/science/journal/13634127/8/3|Introduction|Much has happened since the previous issue of the Technical Report (vol 5 no 4) that focused on Public Key Infrastructures (PKI). It has certainly not all been positive and even the most fervent supporter of the technology has given up on the cries of ”This is the year of the PKI”. In this edition we take stock of some of the current issues facing the ‘PKI industry’ and look at some possible ways forward.
8|3||PKI needs good standards?|
8|3||Certificate policies and certification practice statements â a practical approach|The IETF [1], RFC2527 [2] describes and defines the contents of documentation that is at the heart of the process-driven elements of a PKI. These are captured in the certificate policy (CP), which defines what is delivered, and the certification practice statement (CPS), which defines how it is delivered. The RFC has formed the basis for the contents of both documents. However, with the move of PKI from employment via service providers to deployment directly by organisations, and the extension in the use of PKI to a much wider and less knowledgeable potential market, the difficulties of creating an appropriate set of documentation have become apparent. While I do not suggest that RFC2527 is wrong, I argue that it appears to pose as many questions as it answers when it comes to implementation. In this article I attempt to consider the factors that influence the implementation of a documented infrastructure and suggest a pragmatic approach, based on RFC2527, to delivering a document structure that will support the delivery of PKI services and the understanding of trust that can be placed in those services.
8|3||tScheme â voluntary approval for certificate authority services|
8|3||Could there ever be a unitary digital certificate?|
8|3||Delegated Certificate Validation:: A new approach to simplifying PKI and achieving trust interoperability|The trust provided by a PKI system rests on the fact that the digital certificates being used within the infrastructure are authentic and can be relied upon. As such, the process of validating certificates is central to the management of risks within a PKI and for resolving any disputes which may arise later.
8|3||ID-PKC: a fresh approach to public key cryptography|
8|3||A comparison between traditional public key infrastructures and identity-based cryptography|With the recent acceleration in research into identity-based public key cryptography (ID-PKC), we consider this to be an opportune moment to compare and contrast ID-PKC with more traditional public key infrastructures (PKI). Because of the similarity in the nature of both approaches, we aim to identify the distinguishing features of each approach. In doing so, we highlight the important questions to be asked when weighing up the benefits and drawbacks of the two technologies.
8|3||The NHS as a proving ground for cryptosystems|This paper examines the challenges that the National Health Service poses as an environment for public key cryptography systems.
8|4|http://www.sciencedirect.com/science/journal/13634127/8/4|Introduction|
8|4||The art of intrusion testing|
8|4||An XML-based architecture to perform data integration and data unification in vulnerability assessments|One of the problems facing penetration testers is that a test can generate vast quantities of information that need to be stored, analysed and cross-referenced for later use. Consequently, this paper will present an architecture based on the encoding of information within an XML document. We will also demonstrate how, through application of the architecture, large quantities of security-related information can be captured within a single database schema. This database can then be used to ensure that systems are conforming to an organisation's network security policy.
8|4||Eliminating noise from intrusion detection systems|Effective noise reduction for intrusion detection systems (IDS) is a continuous area of research. One of the techniques for eliminating unqualified IDS alerts is to correlate them with environmental intelligence about the network and systems. This article provides an overview of correlation requirements with a proposed architecture and solution for the correlation and classification of IDS alerts in real time. The implementation of the QuIDScor correlation engine was validated on a real-world network and demonstrated a significant reduction of false alerts.
8|4||An historical perspective of software vulnerability management|The intent of this article is to provide the reader with an historical perspective of software vulnerability assessment. This historical overview will examine the lessons learned from the periods of formal approaches as applied to system certification and validation; to the periods where ‘simplistic’ tools are introduced to perform the tasks of vulnerability assessment; then to an overview of a macroscopic approach for studying the fundamental output of the complex nonlinear system known as software development; and finally to the present, where state-of-the-art tools and methodologies are beginning to apply principles of formal methods to the evaluation of software. The events and lessons learned from each of these periods will become evident to the reader, concluding with a requirement set and an outline for moving vulnerability analysis into the future.
8|4||Measuring vulnerabilities and their exploitation cycle|In a world ruled by chaotic causality, Heisenberg's uncertainty principle is only a natural limitation. Analysts only have their personal logic, experience and intuition to depend on in order to make judgments regarding the safety of a system. However, today's analysts are getting bombarded with large amounts of data coming from all kinds of security-related products, such as vulnerability scanners, anti-viruses, firewalls etc, causing information overload and data congestion. Thus, the question remains: How can analysts make a correct judgment regarding the vulnerabilities from which a system is suffering, especially when all the ammunition he/she possesses can not deal with such a complex, ever-changing environment? To this end, we believe that structuring knowledge/information regarding a specific domain in an object-oriented hierarchy tree, and providing a formal model to reason and construct possible scenarios of attacks, will provide an analyst with the necessary ammunition.
8|4||Penetration testing and social engineering: Hacking the weakest link|
8|4||How to ensure an effective penetration test|
8|4||Useful vulnerability assessment|It is a commonly held view that the goal of vulnerability testing is to uncover as many vulnerabilities as possible, and ideally to uncover all vulnerabilities in the tested systems. In my opinion this is incorrect; the main point of vulnerability testing should be to enable an organization to fix the vulnerabilities that their risk assessment requires them to fix, and to provide input to their risk assessment process on subjects their current assessment underestimates. This article focuses on a pragmatic approach to vulnerability assessment that helps organizations become more secure.
volume|issue|url|title|abstract
9|1|http://www.sciencedirect.com/science/journal/13634127/9/1|Introduction|
9|1||Business and technical motivation for identity management|
9|1||The use of hardware tokens for identity management|Contrasts smart cards with time- and event-based tokens for identity management. Considers security requirements of the systems. Draws attention to an issue with the key generation process for the most popular token on the market.
9|1||Microsoft .NET Passport and identity management|As part of its .NET initiative, Microsoft developed and is currently deploying a Web-based single sign-in (SSI) service called .NET Passport. In this article, we overview, discuss, and put into perspective Microsoft .NET Passport's SSI service. More specifically, we address the question whether Microsoft .NET Passport provides an appropriate solution for the user authentication and authorization or identity management problem on the World Wide Web (WWW).
9|1||Privacy-enhancing identity management|Privacy-Enhancing Technologies (PET) are the technical answer to social and legal privacy requirements. PET become constituents for tools to manage users' personal data. Users can thereby control their individual digital identity, i.e. their individual partial identities in an online world. Existing commercially available identity management systems (IMS) do not yet provide privacy-enhancing functionality.
9|1||Privacy in enterprise identity federation â policies for Liberty 2 single sign on|Cross-domain identity management is gaining significant interest in industry. A well-known example is the Liberty Alliance's specifications for single sign on of web users across different enterprises. The Liberty Alliance stresses that account linking is voluntary for the users and that privacy is an important consideration. We evaluate the privacy of these specifications in detail. We point out some ambiguities and propose a concrete privacy policy together with a few changes to the Liberty processing rules. Our analysis demonstrates that identity-management policies need detailed advance planning even in a limited context.
9|1||Virtual organisations in computer grids and identity management|
9|1||Identity management in mobile cellular networks and related applications|While identity management systems for the Internet are debated intensively identity management in mobile application has grown silently over the last 12 years. More then 980 million GSM subscriptions and the SIM infrastructure are the basis for many application oriented initiatives to manage identities. This paper discusses the technological foundations as well as the application scenarios and the privacy challenges and opportunities.
9|1||User provisioning with SPML|
9|2|http://www.sciencedirect.com/science/journal/13634127/9/2|Introduction|
9|2||Malicious software â past, present and future|
9|2||The future of virus detection|
9|2||Deconstructing malware: what it is and how to stop it|
9|2||This business of malware|For the past few years there has been a shift away from proof-of-concept, “bragging-rights” or destructive virus and Trojans, to that of malware designed for the purpose of making money for the author. This paper describes many of the methods by which this underground economy turns a profit, detailing specific well-known malware and the motives behind it.
9|2||Sound of silence|Every one of us has heard about a number of virus outbreaks lately. There has been a battle between authors of Netsky and Bagle, the release of the Sasser network worm and a great deal of others. But one thing is common – that there have been no virus outbreaks for other platforms but Windows.
9|2||Understanding today's malware|
9|2||Business issues relating to malware|General security structure and framework requirements can be summarized as the requirements needed to operate and build an appropriate security infrastructure. This appropriateness should be measured in a manner that shows how security architectures deliver value to any business in any circumstance.
9|3|http://www.sciencedirect.com/science/journal/13634127/9/3|Introduction|
9|3||Introduction to XML Encryption and XML Signature|
9|3||Access control for XML documents and data|Protecting data over the web is today a crucial need for many companies and organizations. This requires not only the use of cryptographic and digital signature techniques for protecting data during transmission, but also the development of suitable access control models and mechanisms able to support the specification and enforcement of a variety of access control policies. In this paper, we first discuss which are the main access control requirements for web data, and compare some of the most important research proposals with respect to these requirements. We then present Author-X [ 6] as an example of comprehensive system for controlling access to web data.
9|3||XML-based access control languages|One of the most challenging problems in managing large, distributed, and heterogeneous networked systems is specifying and enforcing security policies regulating interactions between parties and access to services and resources. Recent proposals for specifying and exchanging access control policies adopt XML-based languages. XML appears in fact a natural choice as the basis for the common security-policy language, due to the ease with which its syntax and semantics can be extended and the widespread support that it enjoys from all the main platform and tool vendors.
9|3||The Open Digital Rights Language: XML for Digital Rights Management|Digital Rights Management (DRM) covers a broad area of intellectual property management and enforcement. DRM aims to provide secure and trusted services to control the use and distribution of content. DRM technologies have evolved from the primarily enforcement-centric view to a more recent comprehensive value-chain view that manages secure content at all stages of the lifecycle. A fundamental feature of DRM systems and standards that are now appearing is the “Rights Expression Language” (REL). The REL is an XML-based language that captures the information required for DRM transactions, from the rights holder down to the allowable usages for end users. DRM systems need to produce and understand RELs to enable the trusted experience. One of the more successful RELs is the Open Digital Rights Language (ODRL). ODRL was created in 2000 to meet the needs of a wide range of requirements from different sectors. It has recently been adopted by the Open Mobile Alliance (OMA) as the REL used in its DRM specifications for mobile content. This paper will provide a brief overview of DRM followed by a detailed look at the ODRL language and its use of XML. Finally, the OMA profile of ODRL will be reviewed to show how XML-based RELs are being used and extended by the community.
9|3||Federated identity and web services|
9|3||Dissecting application security XML schemas: AVDL, WAS, OVAL â state of the XML security standards report|Recent activities in applications security research and industry have inspired companies and researchers to create a standard way of defining and describing vulnerabilities, expressing different application needs with respect to various aspects of vulnerabilities, making vulnerability descriptions accessible to disparate computer systems.
9|4|http://www.sciencedirect.com/science/journal/13634127/9/4|Introduction|
9|4||Secure mobile business applications â framework, architecture and implementation1|Emerging mobile technologies such as PDAs, laptops and smart phones together with wireless networking technologies such as WLAN and UMTS promise to empower mobile employees to become better integrated into their companies' business processes. However, the actual uptake of these technologies is still to come; one hindrance is security of mobile devices and applications.
9|4||Digital Rights Management: The Open Mobile Alliance DRM specifications|Ubiquitous access to the Internet, especially from mobile phones, offers the possibility of easy access for the user to desirable contents such as songs, videos, ringtones and books. However, this easy access also exposes the owners of this content to potential fraud and piracy. Digital Rights Management technologies are used to ensure that digital content can only be consumed on authorised devices that enforce copyright protection and allow the management of content throughout its entire life cycle. This article provides an overview of Digital Rights Management with particular focus on the Open Mobile Alliances DRM standards.
9|4||Trends in mobile security standards|
9|4||RFID security|Radio Frequency Identification (RFID) systems have become popular for automated identification and supply chain applications. This article describes the technical fundamentals of RFID systems and the associated standards. Specifically, we address the security and privacy aspects of this relatively new and heterogeneous radio technology. We discuss the related security requirements, the threats and the implemented mechanisms. Then the current security and privacy proposals and their enhancements are presented. Finally we discuss the role of this technology in Ubiquitous Computing.
9|4||User requirements for security in wireless mobile systems|Security of wireless mobile systems continues to be a hot topic; now generating its own conferences and platforms, such as the recent 2nd IEE Secure Mobile Communications held by the IEE on 23 September 2004. The general discussion on security in wireless systems takes place in technical fora, and while this is a totally valid discussion, it sometimes seems to be taking place in isolation. From the user perspective the wireless system usually forms part of a larger, interconnected system. This paper raises the question, “What about the user?” and offers some views on the user requirements on this most important part of system design where people are one end of the chain which involves wireless and other systems.
9|4||Mobile terminal security and tracking|As mobile terminals become increasingly sophisticated, the need for robust security also increases. Terminals are moving from simple, voice centric, devices to devices which are capable of multiple functions with multi media capability. Increased capability and the convergence of systems (for example wireless with the internet) bring increased risks. In this article the increase in capability of current and future devices is examined and security issues are observed, considering the large range of terminals - from simple hand-held terminals to more complex, nomadic, laptops or even wireless PCs. In addition the environments within which these devices may operate is considered (and in this document particular attention is paid to the Personal Area Network environment). With wireless devices one of the most important features for secure data transmission is the use of encryption - the basic concept is therefore outlined herein before looking at mobile tracking (a service that might be seen in a similar light to location based services) and finally the article indicates an approach to security for future systems.
volume|issue|url|title|abstract
10|1|http://www.sciencedirect.com/science/journal/13634127/10/1|Introduction to February 2005 issue of ISTR|
10|1||Introduction to Web services and their security|Web services enable access to data that has previously been locked within corporate networks and accessible only by using custom-built software. Along with the benefits of Web services comes a serious risk of security breaches. This article gives a brief overview of the key technologies in the arena of Web services and the relevant security technologies. It briefly describes Web services building blocks—SOAP, UDDI, and WSDL—providing more details on SOAP. The focus of attention, however, is on the technologies for protecting SOAP messages and communicating security-relevant information with Web services, XML security, WS-Security, and SAML.
10|1||Web services and web service security standards|This paper provides a short introduction to basic web services concepts and describes in greater detail the various specifications related to reliability, transactions and in particular security which are referred to as the Microsoft/IBM WS-* family of specifications. The authors were not involved in the development and specification of the family of WS-* specs described in this paper.
10|1||Notes from the field: Implementing a security solution for Web Services|There are many articles explaining why it is necessary to limit access to sensitive resources that are exposed to traffic originating from untrusted users and networks. Generally, such articles will also describe generic security solutions that address these issues. In this article we go one step further and describe the installation of security technology designed to protect extranet web pages and Web Services of a telecommunications company. We give a brief overview of the PEP–PDP architecture described in RFC 2753 which provides a reference model for the products used in the deployment.
10|1||Authorisation in Grid computing|This paper briefly surveys how authorisation in Grid computing has evolved during the last few years, and presents the latest developments in which Grid applications can utilise a policy controlled authorisation infrastructure to make decisions about which users are allowed to perform which actions on which Grid resources. The paper describes the Global Grid Forum SAML interface for connecting policy based authorisation infrastructures to Grid applications, and then describes the PERMIS authorisation infrastructure which has implemented this interface. The paper concludes with suggestions about how this work will evolve in the future.
10|1||Message level security for web services|Security and web services are consistently reported among the top technologies of interest to businesses. Concerns about security are a major deterrent to companies considering use of the technology. This paper provides a summary of the emerging consensus on security for collaborative business using web services in an open environment. The most common security measure using transport layer security may be sufficient for simple applications. However, for more complex environments, e.g. more than two parties, or multiple web services, complete messages or individual parts of messages may be encrypted and signed to protect the confidentiality and integrity of web service messages. Tokens may also be added to messages to assert claims, e.g. about checks that have been carried out by a trusted authority to confirm identities.
10|1||Security in the Semantic Web using OWL|Information assurance, security, and privacy have moved from narrow topics of interest to information system designers to become critical issues of fundamental importance to society. This opens up new requirements and opportunities for novel approaches. Meeting this challenge requires to advance the theory and practice of security, privacy, and trust of Web-based applications and to provide declarative policy representation languages and ontologies together with algorithms to reason about policies. This paper summarizes an ontological approach to enhancing the Semantic Web with security.
10|2|http://www.sciencedirect.com/science/journal/13634127/10/2|Trusted computing group history|
10|2||AEGIS: A single-chip secure processor|This article presents the AEGIS secure processor architecture, which enables new applications by ensuring private and authentic program execution even in the face of physical attack. Our architecture uses two new primitives to achieve physical security. First, we describe Physical Random Functions which reliably protect and share secrets in a manner that is cheaper and more secure than existing solutions based on non-volatile memory. Second, off-chip memory protection mechanisms ensure the integrity and the privacy of off-chip memory. Our processor, with its new protection mechanisms, has been implemented on an FPGA, and is fully functional. We briefly assess the cost of the security mechanisms in our processor and show that it is reasonable.
10|2||Trusted computing and open source|Trusted computing can help defend Linux and other open source operating systems and applications from attack. It can help protect desktop and mobile Linux clients from on-line and off-line integrity and confidentiality attacks. It can measure and remotely attest to the integrity of a system. It can provide authentication mechanisms which are resistant to phishing and pharming attacks. This paper describes the features of Trusted Computing's Trusted Platform Module (TPM), shows how the TPM can provide these protections, and summarizes work in the open source community to implement them.
10|2||Towards multilaterally secure computing platformsâwith open source and trusted computing|
10|2||An Advanced Trusted Platform for mobile phone devices|
10|2||Compatibility, competition, and control in trusted computing environments|Trusted computing (TC) technologies deployed in the PC platform could shift the balance of power in some on-line interactions away from computer end-users and consumers of information goods and services. This effect occurs when remote attestation features make previously indistinguishable software configurations distinguishable; service and information goods providers can then discriminate against disfavored client software. Network externalities mean that even those who don't opt-in to TC use may still be harmed by widespread TC deployment. These effects might be “defanged” by some technical changes to TC designs.
10|2||Trusted computing using AMD âPacificaâ and âPresidioâ secure virtual machine technology|
10|3|http://www.sciencedirect.com/science/journal/13634127/10/3|Introduction â Intrusion detection and prevention|
10|3||Intrusion Detection Systems and Intrusion Prevention Systems|
10|3||An overview of network evasion methods|In recent years much attention has been paid in the network security space to a variety of issues including performance and detection capability. Resistance to evasion however has not been pursued with the same level of interest. During this time many of the technologies have evolved. New applications, protocols and services abound and even the security devices themselves have also become more complex. This lack of focus combined with significant change presents new risks. This paper provides an overview of evasion techniques both new and old, and considers them relative to current technologies.
10|3||Informing the decision process in an automated intrusion response system|
10|3||Next-generation intrusion prevention: Accounting for the attack timeline|
10|3||Data mining and machine learningâTowards reducing false positives in intrusion detection|Intrusion Detection Systems (IDSs) are used to monitor computer systems for signs of security violations. Having detected such signs, IDSs trigger alerts to report them. These alerts are presented to a human analyst, who evaluates them and initiates an adequate response. In practice, IDSs have been observed to trigger thousands of alerts per day, most of which are mistakenly triggered by benign events (i.e., false positives). This makes it extremely difficult for the analyst to correctly identify alerts related to attacks (i.e., true positives).
10|4|http://www.sciencedirect.com/science/journal/13634127/10/4|Editorial: âThe security perimeterâ|
10|4||Inventing the future â The vision of the Jericho Forum|The world of the future will be very different from today. We can expect to encounter radical changes as the Information Age transforms business, society and security. Information Security professionals must look ahead, embrace the challenges and develop new forward-looking security solutions. This paper explains why and how this can be done, and explains the vision and work of the Jericho Forum, a new group that is setting out to do just that.
10|4||De-Perimeterisation: Benefits and limitations|De-Perimeterisation is a new term to describe phenomena becoming common in modern ICT environments. It refers to the erosion of the hard-shell model used to describe the structure of traditional information security implementations while capturing the growing requirement for perimeters to be breached in order to facilitate commerce and collaboration. The Jericho Forum, formed by a group of leading information security managers, has started an exploration of De-Perimeterisation concentrating on identifying its scope and creating working groups to study and specify requirements. This paper, after a review, discusses the benefits and the limitations of this approach.
10|4||Firewalls â Are they enough protection for current networks?|Firewalls are widely deployed in most organizations connected to the Internet to implement their information security policy and to protect information from unauthorized access. Yet intruders still manage to attack systems and gain unauthorized access to information that is supposedly protected by these firewalls. This article examines some of the history and background of firewalls and what has led up to the current situation. Additionally this article will examine how any organization, even your home network, can be made a far safer place using readily available existing firewall technologies.
10|4||The Laws of Vulnerabilities: Which security vulnerabilities really matter?|New security vulnerabilities are discovered on a daily basis. With each new announcement, the same questions arise. How significant is this vulnerability? How prevalent? How easy is it to exploit? Due to a lack of global vulnerability data, answers are hard to find and risk rating is even more difficult. The Laws of Vulnerabilities are the conclusions of analyzing statistical vulnerability information over a three-year period. Those vulnerabilities have been identified in the real world across hundreds of thousands of systems and networks. These data are not identifiable to individual users or systems. However, it provides significant statistical data for research and analysis, which enabled us to define and publish the Laws of Vulnerabilities (http://www.qualys.com/research/rnd/vulnlaws/).
10|4||The extended security perimeter|In recent years, the Perimeter of Operational Security has extended to meet the expectations of both the internal business, and that of clients, and outsourced expectations. A further emergence has been seen in areas like mobile computing, which empower workers and executives alike to not only work from outside the perimeter of control, but to also communicate through it, and these circumstances, and strivers in operational connectivity, and working practices have imposed some significant challenges for the business in order to deploy and support a security policies end-to-end.
10|4||Web services: Developers dream or hackers heaven?|This article provides a high level of web services security, the evolving standards and discusses security issues that these standards do not address. Specifically it discusses:
10|4||Why âPhishâ when you can Trawl?|A particular ‘hot’ issue is outlined and the general state of wireless security is scrutinised. It appears that we still have some way to go before this topic is exhausted. Starting with a history of some of the more defining wireless surveys in the UK, Europe and the U.S. we then explore the major twists and turns of the wireless evolution bringing us right up to date with a peak at the current trends and future dangers of wireless technology.
volume|issue|url|title|abstract
11|1|http://www.sciencedirect.com/science/journal/13634127/11/1|Editorial|
11|1||Information security and the law|Law and regulation increasingly affect how information security is implemented in organisations. This article explores how information security can also make a positive contribution by helping a business comply with laws, regulations and guidance on governance and on e-commerce by adding value. It also discusses some steps which an information security manager can take to achieve this.
11|1||Communication service providers: Forensic source and investigatory tool|This article examines recent developments in the criminal law in the UK and Europe that address the role of CSPs as a forensic source and investigatory tool. Substantial new powers have been granted to law enforcement agencies to enable them to effectively utilise CSPs in the fight against criminality that, as well as generating controversy in terms of those that use communication services, also impose a substantial burden on CSPs.
11|1||Digital signature legislation: The first 10 years|
11|1||ISMS, security standards and security regulations|This article briefly describes the introduction and evolution of Information Security Management Systems (ISMS), their application and the introduction of national and regulatory requirements to protect information and how these regulations may be mapped into an ISMS.
11|1||Preparing Information Security for legal and regulatory compliance (SarbanesâOxley and Basel II)|The problem for many IT and Information Security departments is how to keep abreast of new and never-ending regulation and legislation and translate it into IT terms. This article reviews two of the more recent examples (Sarbanes–Oxley and Basel II), how compliance can be addressed in a more cost-effective fashion and how this is changing the role of Information Security.
11|1||The Computer Misuse Act|The Computer Misuse Act 1990 (CMA) created a number of offences to address the growing incidence of unauthorised access to computer systems. This paper describes the provisions of the Act and examines the experience of the 15 years that it has been in force. The Act was based on a report from the law commission which provides good insight into the intentions behind the various provisions, and against which the success of the Act can be measured. Unfortunately there are few authoritative statistics available and much of the evidence is anecdotal. However, it is possible to draw some conclusions. The picture that emerges is that prosecutions are rare, convictions can be difficult to obtain and sentences tend to be light. At the same time the incidence of hacking has increased substantially and is still increasing. The damage caused by computer misuse is significant and also increasing and the vulnerabilities that can be exploited by the criminally minded are also growing in number and severity. Some specific cases have shown up gaps in the law, for example in prosecuting certain Denial of Service attacks. There has been an attempt to amend the law to plug that particular gap, but as yet the Government has not allocated sufficient priority to it. The report concludes that while the CMA was a great step forward when it was introduced, its success has been limited. There is a need to review the Act, going somewhat further than existing proposals to address, not only specific shortcomings of the Act but also to address recent changes in technology and software practices that affect some of the notions of what actions are authorised and under what circumstances. Furthermore there is a need to review sentencing policy to reflect the seriousness of the damage that hacking attacks can inflict.
11|1||The future of UK data protection regulation|The UK Data Protection Act, 1998 has been in force for nearly 5 years, and is based on a European Directive that was initially proposed 15 years ago. In that time, both the technological environment and commercial business models have changed out of all recognition, notably in the areas of electronic commerce and mobile communications, leading to questions about the Act's continuing viability as the basis for an appropriate regulatory model for data protection in the Information Society. This paper examines why data protection regulation in the UK may have a rough ride ahead, and considers possible options for the future.
11|1||Using IT governance and COBIT to deliver value with IT and respond to legal, regulatory and compliance challenges|With Sarbanes–Oxley and other legislation, securing IT within a company has become law. This article takes a look at how compliance legislation can be used to get more support from the Board when it comes to security issues, and how information assets still need to be protected further.
11|1||A new institute for a new millennium|
11|2|http://www.sciencedirect.com/science/journal/13634127/11/2|Introduction â Cryptography|
11|2||Cryptography and trust|The fundamental concern of Information Assurance today is the issue of trust. Cryptography is one of the main technical defence mechanisms in our armoury, and yet the relationship between the two has rarely been explored. This paper will look at some of the interplay between trust issues and cryptography.
11|2||A cryptographic tour of the IPsec standards|In this article, we provide an overview of cryptography and cryptographic key management as they are specified in IPsec, a popular suite of standards for providing communications security and network access control for Internet communications. We focus on the latest generation of the IPsec standards, recently published as Request for Comments 4301–4309 by the Internet Engineering Task Force, and how they have evolved from earlier versions of the standards.
11|2||An overview of RFID tags and new cryptographic developments|The advantages and pitfalls of RFID deployment have gained much attention in academia and industry. While cryptography might offer a solution to many of the most pressing problems, the unique implementation demands of an RFID tag severely restrict the range of available options. In this article we review some of the issues involved.
11|2||EMV card payments â An update|A report on the status of EMV card payment technology and a look at where this payment technology is heading.
11|2||Integrity of intention (a theory of types for security APIs)|The task of a security API is to allow users to process data and key material according to the designer's intentions, and to prevent any malicious sequence of commands from violating these intentions. Security APIs do this by attaching metadata to keys and data – type information – to record acceptable usage policy, which is checked by individual API commands in order to approve or deny a particular manipulation. But what actually is type information? This paper proposes a conceptual framework for understanding cryptographic type, and how it maintains the integrity of the designer's intentions in an API. We describe four core conceptual components of type: form, use, role and domain. We compare our model to real-life security APIs, and argue that designing new systems within the bounds of the model improves safety, eliminating many common security issues.
11|2||Recent developments in cryptographic hash functions: Security implications and future directions|One of the most important classes of cryptographic algorithms in current use is the class of cryptographic hash functions. Hash functions are ubiquitous in today's IT systems and have a wide range of applications in security protocols and schemes, such as providing software integrity, digital signatures, message authentication and password protection. Among their many security requirements, cryptographic hash function algorithms need to feature a property known as collision resistance, that is, it must be infeasible to construct two distinct inputs with the same hash output. This article provides an overview of cryptographic hash functions and some of the recent developments affecting their security, namely the discovery of efficient methods for constructing collisions for algorithms such as MD5 and SHA-1. We also discuss the many implications of these recent attacks, and the possible directions for the development of the theory of hash functions.
11|3|http://www.sciencedirect.com/science/journal/13634127/11/3|Security: An end user perspective|
11|3||Biometrics: security: An end user perspective|
11|3||What user-controlled identity management should learn from communities|To enable trustworthy privacy, identity management has to be user-controlled, i.e. each user administrates his/her partial identities being supported by an identity management system running on his/her machines under his/her control. Past work on user-controlled identity management focused on isolated users administrating their partial identities mainly used towards organizations, e.g., shops, public administrations and the like. But users intensively interact with other users as well. Additionally, these interactions are not only direct, but indirect, too, as, e.g., within communities. A universally usable identity management meta-system (IMMS) will have to be able to handle and combine all interactions possible.
11|3||Security standards: An end-user perspective|
11|3||Security considerations for broadcast systems|
11|3||On the potential of high density smart cards|
11|3||The complexity of DPA type side channel attacks and their dependency on the algorithm design|This theoretical paper analysis the dependency of side channel attacks like DPA on the attacked algorithm. By general examination of the complexity of DPA type side channel attacks the influence of algorithmic parameter is shown. It is shown that the careful selection or design of algorithms can increase the security of implementations of algorithms in addition to and independent from conventional DPA attack countermeasures.
11|4|http://www.sciencedirect.com/science/journal/13634127/11/4|Editorial for v.11 n.4 of the Information Security Technical Report: âWindows Security Revisitedâ|
11|4||Windows device interface security|
11|4||NetHost-sensor: Monitoring a target host's application via system calls|Intrusion detection has emerged as an important approach to network, host and application security. Network security includes analysing network packet payload and other inert network packet profiles for intrusive trends; whereas, host security may employ system logs for intrusion detection. In this paper, we contribute to the research community by tackling application security and attempt to detect intrusion via differentiating normal and abnormal application behaviour. A method for anomaly intrusion detection for applications is proposed based on deterministic system call traces derived from a monitored target application's dynamic link libraries (DLLs). We isolate associated DLLs of a monitored target application; log system call traces of the application in real time and use heuristic method to detect intrusion before the application is fully compromised. Our investigative research experiment methodology and set-up are reported, alongside our experimental procedure and results that show our research effort is effective and efficient, and can be used in practice to monitor a target application in real time.
11|4||Windows Vista security: First impressions|This article looks at Microsoft's latest operating system, based upon a pre-release RC1, to provide an overview to Windows Vista, its new security features and provide early indications on how Vista lives up to its design aims from a security perspective. In-depth discussions of potential vulnerabilities within Vista have been omitted from this article for brevities sake, but links to further reading are provided at the end to a number of documents on this area.
11|4||New Vistas in elliptic curve cryptography|The past 10 years have been witness to a sea change in the availability and distribution of high security cryptography for broad civilian applications. In this paper, we give a brief history of cryptography support in Windows and describe the upcoming architectural changes, including support for ECC, forthcoming in Windows Vista.
11|4||Virtual machines for enterprise desktop security|A virtual machine monitor (VMM) allows a single computer to run two or more operating systems at the same time. VMMs are relatively simple and are typically built to high assurance standards, which means that the quality of isolation provided by a virtual machine monitor is usually greater than that which can be achieved with a general-purpose operating system. This paper discusses how the flexibility afforded by multiple OS environments and the robust isolation provided by a virtual machine monitor can be used to improve client PC security. A prototype system is also described.
volume|issue|url|title|abstract
12|1|http://www.sciencedirect.com/science/journal/13634127/12/1|ISTR special issue on critical infrastructure protection|
12|1||Simulation and test: Instruments for Critical Infrastructure Protection (CIP)|
12|1||Internet as a multiple graph structure: The role of the transport layer|
12|1||The role of Wireless Sensor Networks in the area of Critical Information InfrastructureÂ Protection|Critical Infrastructures, such as energy, banking, and transport, are an essential pillar to the well-being of the national and international economy, security and quality of life. These infrastructures are dependent on a spectrum of highly interconnected information infrastructures for their smooth, reliable and continuous operation. The field of protecting such Critical Information Infrastructures, or CIIP, faces numerous challenges, such as managing the secure interaction between peers, assuring the resilience and robustness of the overall system, and deploying warning and alert systems, amongst others. In this tapestry of CIIP, Wireless Sensor Networks can be used as an invaluable tool due to their intelligent distributed control capabilities, alongside with their capability to work under severe conditions. In this paper, we justify why Wireless Sensor Networks technology is suitable for providing security for these scenarios, describing both their advantages and research issues and their role in the overall scheme of protecting the Critical Information Infrastructures.
12|1||Security in Mobile IPv6: A survey|Secure mobile communication is essential for the pervasive accessibility of critical information infrastructure. Connecting control systems with the business enterprise, wireless telemetry and mobile user interaction with critical infrastructure systems are examples of services that motivate the need for secure mobile communication. Mobile IPv6 is being touted to provide communication support for such services. The security of Mobile IPv6 poses key challenges impeding its wide-scale adoption. Several security mechanisms have been proposed in the literature. This paper surveys security vulnerabilities of Mobile IPv6, provides a taxonomy for the main existing and proposed solutions, and then extends to outline some open issues.
12|1||Connectivity models of interdependency in mixed-type critical infrastructure networks|Determining interdependencies and cascading failure modes in critical infrastructures is a complex problem that is exacerbated further by the diverging characteristics of the interconnected infrastructure types. Services in some types of infrastructure such as telecommunications or the electric grid are provided and consumed instantly. Others, notably oil and gas but also other infrastructures built on physical resources, however, exhibit buffering characteristics. In this paper we describe a model for the abstract representation of both types of infrastructure networks and their interdependencies. The model is then validated and demonstrated using characteristic topologies and interconnections.
12|1||Adaptive real-time anomaly detection with incremental clustering|Anomaly detection in information (IP) networks, detection of deviations from what is considered normal, is an important complement to misuse detection based on known attack descriptions. Performing anomaly detection in real-time places hard requirements on the algorithms used. First, to deal with the massive data volumes one needs to have efficient data structures and indexing mechanisms. Secondly, the dynamic nature of today's information networks makes the characterisation of normal requests and services difficult. What is considered as normal during some time interval may be classified as abnormal in a new context, and vice versa. These factors make many proposed data mining techniques less suitable for real-time intrusion detection. In this paper we present ADWICE, Anomaly Detection With fast Incremental Clustering, and propose a new grid index that is shown to improve detection performance while preserving efficiency in search. Moreover, we propose two mechanisms for adaptive evolution of the normality model: incremental extension with new elements of normal behaviour, and a new feature that enables forgetting of outdated elements of normal behaviour. These address the needs of a dynamic network environment such as a telecom management network. We evaluate the technique for network-based intrusion detection, using the KDD data set as well as on data from a telecom IP test network. The experiments show good detection quality and act as proof of concept for adaptation of normality.
12|2|http://www.sciencedirect.com/science/journal/13634127/12/2|Convergence|This paper will look at the range of areas in which convergence is taking place and looks at some of the effects that it is having. It looks at some of the effects that new technologies are having and the interaction that is taking place between the different technology areas. It then goes on to discuss the implications that these developments will have for the security of the new and converged environment and services.
12|2||Can CLI be trusted?|Calling Line Identification (CLI) tells the recipient of a telephone call the number at the other end of the line. However, various insecurities mean that even on traditional telephone systems, CLI cannot be entirely relied upon to be accurate. Once Voice-over-IP (VoIP) enters the picture, CLI validity effectively depends upon the integrity of Internet traceability, and must therefore be treated with considerable suspicion.
12|2||Risks due to convergence of physical security systems and information technology environments|The areas of physical security and information technology (IT) are often if not usually worlds apart. The same is true for physical security and IT security; in most organizations separate functions for physical security and IT security exist. Because these functions are in place and because they at least in part achieve their goals, management tends to perceive that major risks they try to mitigate are being addressed. Convergent security risks in physical security systems and information technology (IT) are, however, almost without exception overlooked. Physical security systems and devices, process control systems, and IT infrastructures are being integrated without sufficient consideration of the security risks that the increasing intermingling of these systems and infrastructures introduces. Serious security-related incidents due to unmitigated physical convergence risks are starting to occur. Adequately dealing with the convergence problem requires organizations to implement multiple solutions.
12|2||Secure Mobile Architecture (SMA) â A way to fix the broken Internet|The Internet is broken. There have been many attempts to fix it, but they are all complex and very difficult to implement and none of them answer the fundamental questions of what is wrong with it. The first basic flaw is the very nature of the Internet Protocol address. It is treated as both a name and an address to deliver the information to its end-to-end destination. In addition, the security of the protocol is dependent on that address. The second major flaw is the inability of the Internet protocols to address mobility with fast and secure handoff. The Secure Mobile Architecture (SMA) fundamentally addresses these flaws in the very nature of the Internet Protocols. It does this by treating the IP layer as an insecure transport layer. It requires four elements to effect this transformation of the Internet. It can be integrated into existing Intranets. It can function easily in the namespace of an Internet service provider (ISP), an enterprise, or governments. The rest of this chapter will take you through the architecture and its elements.
12|2||In the new converged world are we secure enough?|
12|2||When networks collide|Convergence, the term used to describe two or more disparate technologies coming together to provide additional functionality or improve efficiency. However, one particular technology convergence often exposes an organisation to potential risks, even if a conscious decision has been made not to integrate it into the business. That is the convergence of wireless and wired IP networks. The aim of this paper is to identify the risks associated with implementing wireless networks, and the risks associated with not implementing sufficient controls in detecting unauthorised wireless networks.
12|3|http://www.sciencedirect.com/science/journal/13634127/12/3|Editorial|
12|3||Grid security: Next steps|One of the more mature instances of a service-oriented architecture is the model known as Grid computing. Computational Grids and Data Grids are becoming commonplace in certain sectors, yet the style of security they implement is suitable only for a fairly small subset of possible user communities. Using some case studies and experience, we describe the existing Grid security models, explain why they represent shortcomings for some applications, and describe some emerging architectures, Trusted Computing and virtualisation, which help address the problems.
12|3||Daonity â Grid security from two levels of virtualization|The service oriented architecture of grid computing has been thoughtfully engineered to achieve a service level virtualization: not only should a grid be a virtual machine (also known as a virtual organization, VO) of unbounded computational power and storage capacity, but also should the virtual machine be serviceable in all circumstances independent from serviceability of any of its component. At present, a grid VO as a result of service level virtualization only is more or less confined to participants from scientific computing communities, i.e., can have a limited scale. It is widely agreed that for a grid to pool resources of truly unbounded scale, commercial enterprises and in particular server-abundant financial institutions, should also “go for the grid,” i.e., open up their servers for being used by grid VO constructions. We believed that it is today's inadequate strength of the grid security practice that is the major hurdle to prevent commercial organizations from serving and participating the grid.
12|3||On the deployment of a real scalable delegation service|This paper explains the evolution of the concept of delegation since its first references in the context of distributed authorization to the actual use as a fundamental part of a privilege management architecture. The work reviews some of the earliest contributions that pointed out the relevance of delegation when dealing with distributed authorization, in particular we comment on PolicyMaker and KeyNote, and also on SDSI/SPKI. Then, we elaborate on Federation as a particular case of delegation, and remark the importance given to Federation by the industry. Finally, the paper discusses about Privilege Management Infrastructures, introducing a new mechanism to extend their functionality using advanced delegation services.
12|3||Coordinated decision making in distributed applications|
12|3||Embedded security in a pervasive world|Embedded systems have become an integral part of our everyday life. Devices like vehicles, household appliances, and cell phones are already equipped with embedded microcontrollers. The networking of the myriads of embedded devices gives rise to the brave new world of pervasive computing. Pervasive computing offers enormous advantages and opportunities for users and businesses through new applications, increased comfort, and cost reduction. One often overlooked aspect of pervasive computing, however, are new security threats.
12|3||The security challenges for mobile ubiquitous services|It is envisaged that in future mobile ubiquitous environments, users will be able to seamlessly, search, access and consume a rich offering of services and content from an array of Service/Content Providers, whilst they are on the move, anytime, anywhere. Unfortunately, this new computing paradigm also brings along new and unique security challenges. Novel security solutions are therefore required. But, in order for appropriate security solutions to be devised, all possible security threats must first be thoroughly analysed, and the corresponding security requirements be identified. In this paper, we examine the security issues germane to a mobile ubiquitous environment. We then suggest some possible solutions which may be employed to address these security issues. Open research issues are also highlighted.
12|3||Ubiquitous security for ubiquitous computing|
12|3||An effective multi-layered defense framework against spam|
12|4|http://www.sciencedirect.com/science/journal/13634127/12/4|Introduction to this issue (12/4)|
12|4||Computational immunology and anomaly detection|
12|4||Biology, immunology and information security|Biology has succeeded in solving many computational and communication problems in the natural world, and computer users are ever inspired by its apparently ingenious creativity. Today scientists are building artificial immune systems and discussing autonomic computing, with self-healing, self-anything systems. We discuss the relevance and efficacy of these approaches. Are they better than classical software engineering design?
12|4||Survival in cyberspace|The immune system response of the vertebrates demonstrates an extremely adaptive and resilient defensive capability against a broad spectrum of pathogenic attacks. The field of artificial immune systems (AISs) aims to replicate this capability in the digital environment. In particular, we would like to understand adaptive survivability and defence in large-scale computing networks. In this paper we discuss some of the background concepts to AIS and focus on one specific aspect required to achieve a digital immune system, i.e. the social dynamics of competitive and co-operative defence. In particular, the ability of an information network to maintain itself in the face of continuous perturbation raises more complex issues related to system metabolism and network topology.
12|4||Biologically-inspired Complex Adaptive Systems approaches to Network Intrusion Detection|The pervasiveness of the computing power has made it an inevitable commodity of the modern time. The inexorable technological advances clearly predict the continually increasing reliance of human life on the computing systems in the future. Intelligent portable devices are commonplace these days and information accessibility is ubiquitous. There is a network underlying any computer infrastructure. Complex Adaptive Systems (CAS) are a relatively new field with techniques inspired by Biology, Sociology and other fields. The field of CAS studies systems as a network of interdependent components. There has been a major breakthrough in the field of Network Intrusion Detection Systems (NIDS) in computer security through the adoption of a CAS perspective. This paper surveys some key work in this area with the primary focus being placed on biologically-inspired CAS approaches to NIDS.
12|4||Sensing danger: Innate immunology for intrusion detection|The immune system provides an ideal metaphor for anomaly detection in general and computer securities in particular. Based on this idea, artificial immune systems have been used for a number of years for intrusion detection, unfortunately so far with little success. However, these previous systems were largely based on immunological theory from the 1970s and 1980s and over the last decade our understanding of immunological processes has vastly improved. In this paper we present two new immune-inspired algorithms based on the latest immunological discoveries, such as the behaviour of Dendritic Cells. The resultant algorithms are applied to real-world intrusion problems and show encouraging results. Overall, we believe that there is a bright future for these next-generation artificial immune algorithms.
12|4||Immunology, diversity, and homeostasis: The past and future of biologically inspired computer defenses|While biological metaphors have a long history of use in computer security, they have been more successful in describing malicious software than in helping to create better defenses. Immune system mechanisms, diversity, and homeostasis have helped inspire the development of promising computer security technologies. To fulfill the promise of biologically inspired security, however, more work is needed in understanding how living systems defend themselves and how those ideas can be brought to computers. This paper presents past successes, limitations, and opportunities for future work in this promising area. It then also addresses why there are significant barriers to such advances.
12|4||Immuno-inspired autonomic system for cyber defense|The biological immune system is an autonomic system for self-protection, which has evolved over millions of years probably through extensive redesigning, testing, tuning and optimization process. The powerful information processing capabilities of the immune system, such as feature extraction, pattern recognition, learning, memory, and its distributive nature provide rich metaphors for its artificial counterpart. Our study focuses on building an autonomic defense system, using some immunological metaphors for information gathering, analyzing, decision making and launching threat and attack responses. This on-going research effort is not to mimic the nature but to explore and learn valuable lessons useful for self-adaptive cyber defense systems.
12|4||Dealing with software viruses: A biological paradigm|We introduce a probability model for populations of cells and viruses that interact in the presence of an anti-viral agent. Cells can be infected by viruses, and their longevity and ability to avoid infection are modified if they survive successive attacks by viruses. Viruses that survive the effect of the anti-viral agent may find that their ability to survive a future encounter with molecules of the anti-viral agent is modified, as is their ability to infect a healthy cell. Additionally, we assume that the anti-viral agents can be a cocktail with different proportions of agents that target different strains of the virus. In this paper, we give the state equations for the model and derive its analytical solution in steady state. The solution then provides insight into the appropriate mix or “cocktail” of anti-viral agents that can be designed to deal with the virus' ability to mutate. In particular, the analysis shows that the concentration of anti-viral agent by itself does not suffice to ultimately control the infection, and that it is important to dose a mix of anti-viral agents so as to target each strain of virus in a specific manner, taking into account the ability of each virus strain to survive in the presence of the anti-viral agents. Models of this kind may eventually lead to the computer aided design of therapeutic protocols or drug design.
volume|issue|url|title|abstract
13|1|http://www.sciencedirect.com/science/journal/13634127/13/1|Securing Web applications|Web application vulnerabilities have become a major concern in software security. We will present major attack patterns, i.e. SQL injection, cross-site scripting, cross-site request forgery, JavaScript hijacking, and DNS rebinding, together with a survey and assessment of the countermeasures available to web application developers.
13|1||White and grey-box verification and validation approaches for safety- and security-critical software systems|In this article, the problem of assessing software trustworthiness is considered from a holistic perspective addressing both safety- and security-critical application domains. In particular, the importance of achieving high structural coverage during component and integration testing phases is stressed. In view of the immense effort required by manual testing activities, the present article suggests novel automatic test case generation techniques, capable of maximizing test coverage and minimizing test amount. The tools developed on the basis of these approaches were successfully applied to achieve high control flow, data flow and interface coverage by means of a low number of test cases.
13|1||Re-engineering Xen internals for higher-assurance security|The Xenon project is investigating the construction of a higher-assurance open source separation kernel based on the Xen open source hypervisor. Just as the Xen open source hypervisor was initially developed from the open source Linux operating system, by simplifying Linux and modifying its design, the Xenon separation kernel is being developed from Xen. The primary goal of the Xenon project is to investigate issues in creating an open source software product with higher security assurance than conventional open source software. The Xenon project is also focused on (1) problems relating to separation kernels that support unmodified uninterpreted commercial off the shelf (COTS) guests and (2) distinctions between these kinds of separation kernels and hypervisors. This paper explains the Xenon project's approach to re-engineering Xen's internal structure into a higher-assurance form. If conventional open source software cannot be brought into this form with moderate amounts of re-engineering then higher-assurance open source software is probably not practical. Our results indicate that moderate amounts of re-engineering will be sufficient for all but a small part of the code. The remaining code is small enough to be addressed in a reasonable time, even though more effort is required.
13|1||Security-by-contract on the .NET platform|Over the last few years, the success of GPS-enabled PDAs has finally instigated a breakthrough of mobile devices. Many people now already have a device that can connect to the Internet and run untrusted code, typically a cell-phone or PDA. Having such a large interconnected and powerful computing base presents some new security issues. In order to counter new threats, the traditional security architectures need to be overhauled to support a new and more flexible way of securely executing mobile code.
13|1||Dynamic taint propagation: Finding vulnerabilities without attacking|We apply dynamic taint propagation to find input validation bugs using less effort than typical security testing. We monitor a target program as it executes in order to track untrusted user input. Our system works in conjunction with normal functional testing, so effort devoted to functional testing can be directly leveraged to uncover vulnerabilities. The result is that we achieve higher test coverage (and therefore find more bugs) than typical security testing techniques and make it practical for quality assurance organizations with no security experience to test the security of the software they examine.
13|1||Secure software development: Why the development world awoke to the challenge|
13|2|http://www.sciencedirect.com/science/journal/13634127/13/2|Introduction to this issue|
13|2||National e-ID card schemes: A European overview|Across Europe electronic identity (e-ID) card schemes are emerging. The motivation for their deployment varies from country to country, and hence also their ability to interoperate. National schemes are defined by government agencies and application usage by non-government entities has been limited. Changes are occurring, however, both in terms of secondary use by the private sector as well as various activities to enable more interoperability across national e-ID card schemes.
13|2||Insights on identity documents based on the Belgian case study|Efficient eGovernment and eCommerce require the ability to authenticate citizens and transactions online, whereas the increasing mobility of citizens demands reliable identification. Identity documents tend to become the most popular form of identity tokens used for these purposes. An important problem, however, is that they can easily be passed on or used by a fraudster. We discuss the use of identity documents and the problem of linking these documents with their genuine holder. We discuss ePassports and eID cards in general using the Belgian identity documents as a reference.
13|2||Some thoughts on the underlying logic and process underpinning Electronic Identity (e-ID)|This article I have outlined the fundamental issues that underpin any Identity or e-ID Scheme and any attempt to turn them into an automated e-ID delivery. The significance of Identity has almost gone un-noticed as our highly complex and interdependent technological society has evolved. It is only with the debate surrounding ID card systems and the rise of internet and electronic fraud that there is any awakening and understanding of the real issues that underpin identity and its impact upon society. The article examines why Identity matters by comparing what goes into the underlying logic and process underpinning electronic identity. The European Commission national ID Card scheme and other international perspectives are compared with what the USA is doing in this area and with what the UK is proposing with its national ID Card scheme. A discusses the basics components of identity, identity crime and some unintended consequences of electronic identity schemes.
13|2||Identity management of e-ID, privacy and security in Europe. A human rights view|With privacy enhancing identity management, end users are given better ways for managing their identities for specific contexts. One could easily argue that the need to implement identity management systems that are privacy enhancing follows from the EU data protection regulation. One of the challenges while developing privacy enhancing identity management is getting governments to become genuinely interested, both in their capacity of data processing organisation and legislator or policy maker. Another challenge, this time for the private sector, is to find the right balance between data protection perfection and simplicity or users' convenience, while developing privacy enhancing identity management systems. After a brief discussion of these challenges we discuss the growing human rights recognition of the value of digital identity and its management. In particular, the German constitutional court seems to pave the way for a basic right to have digital identity protected and secured.
13|2||Legal and organizational challenges and solutions for achieving a pan-European electronic ID solution: or I am 621216-1318, but I am also 161262-43774.1 Do you know who I am?|In this article I discuss the creation of a pan-European eID and the legal and organizational challenges connected to that in cross-border transactions within the EU/EEA. I mainly focus on issuance procedures and (the lack of) a European “standard” on a unique identifier of physical persons that can be used in the eID. My main solution here is to use, as far as possible, existing national and international requirements on the content of passport and how they are issued. In addition I present two issues that I think the European Commission should focus on that would have a significant positive effect on the work on achieving cross-border interoperability. These issues are (i) setting up requirements for Validation Authorities and self-declaratory schemes and (ii) setting up a quality classification system, where different national security levels can be mapped up against neutral requirements adopted by the European Commission.
13|2||Identity management throughout one's whole life|Identity management has to comprise all areas of life throughout one's whole lifetime to gain full advantages, e.g., ease-of-use for all kinds of digital services, authenticity and authorisation, reputation and user-controlled privacy.
13|2||The benefits and drawbacks of using electronic identities|In this article we carry out a critical analysis of the benefits and drawbacks which are likely when we include electronic data to hold, validate and process the information used to generate and manage an identity. In addition, we consider the potential knock-on impact of this for the transactions which rely on this electronic identity information.
13|2||âBuilding secure business applications at Microsoftâ by J. Steer and A. Popli|
13|2||Building secure business applications at Microsoft|
13|3|http://www.sciencedirect.com/science/journal/13634127/13/3|Developments in mobile communications security|
13|3||Future consumer mobile phone security: A case study using the data-centric security model|Consumer mobile phone security requires more attention, now that their data storage capacity is increasing. At the same time, much effort is spent on data-centric security for large enterprises. In this article we try to apply data-centric security to consumer mobile phones. We show a maturity model that can be used as a roadmap for improving their security. Additionally, several shortcomings of the data-centric approach are discussed.
13|3||A mobile device management framework for secure service delivery|In a mobile ubiquitous environment, service interactions between a user device and a service provider should be secure, regardless of the type of device used to access or consume a service. We present a Secure Device Management Framework (SDMF), designed to securely deliver services to user devices, whilst also hiding (some of) the complexity of security management from users. Key to this framework is the Device Management Entity (DME), that manages a user device's security credentials, and interacts with service providers on its behalf. This framework also provides users with assurance that a compromised device cannot consume the delivered service, and, at the same time, prevents users from illegally sharing their credentials with other users. We achieve these objectives using Trusted Computing functionality and certain other security mechanisms.
13|3||Authentication & key agreement for off-portal mobile applications|This paper identifies serious user privacy concerns with the 3GPP Generic Bootstrapping Architecture protocol when used as the basis for security for certain Off-portal applications such those encountered in e-health environments. A possible alternative approach avoiding these concerns is also outlined.
13|3||Spontaneous mobile device authentication based on sensor data|Small, mobile devices or infrastructure devices without user interfaces, such as Bluetooth headsets, wireless LAN access points, or printers, often need to communicate securely over wireless networks. Active attacks can only be prevented by authenticating wireless communication, which is problematic when devices do not have any a priori information about each other. In this article, we describe three different authentication methods for device-to-device authentication based on sensor data from various physical out-of-band channels: shaking devices together, authentication based on spatial reference, and transmission via visible laser.
13|3||New mutual agreement protocol to secure mobile RFID-enabled devices|The design of a secure communication scheme for Radio Frequency IDentification (RFID) systems has been extensively studied in recent years in view of the awareness of individual privacy and the requirement of robust system security. Most of previous works assume the communication channel between an RFID reader and its backend server is secure and concentrate on the security enhancement between an RFID tag and an RFID reader. However, once RFID reader modules are extensively deployed in consumers' handheld devices, the privacy violation problems at reader side will be deeply concerned by individuals and organizations. In this paper, we assume the future communication environment for RFID systems will be all wireless and insecure. Under such infrastructure, handheld device, such as mobile phone, embedded with RFID reader modules will be situated everywhere and operated with many RFID tags in various RFID application systems. In the meantime, it is more difficult to secure the privacy of a mobile RFID-enabled device than before without novel communication protocol. Hence, we propose a new mutual agreement protocol to secure the authenticity and privacy of engaged mobile RFID readers while constructing a secure session key between a server and a reader. Based on our security analyses, we show that our scheme can enhance data security and provide privacy protection at reader side even in the presence of an active adversary under insecure mobile RFID environment.
13|3||Secure authenticated group key agreement protocol in the MANET environment|
13|3||On handling insider attacks in wireless sensor networks|Wireless sensor networks can be used in various security-critical applications. The most challenging security problems are insider attacks. In this article we present security strategies to cope with insider attacks and a classification of mechanisms which apply the strategies. We show that strategies and mechanisms for wireless sensor networks have different characteristics and realizations than in classic computer systems because of the special requirements and conditions.
13|3||Mobile communication security controllers an evaluation paper|Cellular communication via a traditional mobile handset is a ubiquitous part of modern life and as device technology and network performance continues to advance, it becomes possible for laptop computers, Personal Digital Assistants [PDAs; Note abbreviations will be shown in square brackets to avoid confusion with references.] and even electrical meters to better exploit mobile networks for wireless communication. As the diverse demands for network access and value added services increase, so does the importance of maintaining secure and consistent access controls. A critical and well-proven component of the GSM and UMTS security solution is the smart card in the form of the SIM or USIM respectively. This has also extended into some regions using variants of CDMA standards where the RUIM is specified. However with the enlarged range of communications devices, some manufacturers claim that the hardware selection, chip design, operating system implementation and security concept are different from traditional mobile phones. This has led to a suggestion that types of “Software SIM” should be used as an alternative to the smart card based solution. This paper investigates the suggestion.
13|4|http://www.sciencedirect.com/science/journal/13634127/13/4|Introduction|
13|4||Information Security management: A human challenge?|This paper considers to what extent the management of Information Security is a human challenge. It suggests that the human challenge lies in accepting that individuals in the organisation have not only an identity conferred by their role but also a personal and social identity that they bring with them to work. The challenge that faces organisations is to manage this while trying to achieve the optimum configuration of resources in order to meet business objectives. The paper considers the challenges for Information Security from an organisational perspective and develops an argument that builds on research from the fields of management and organisational behaviour. It concludes that the human challenge of Information Security management has largely been neglected and suggests that to address the issue we need to look at the skills needed to change organisational culture, the identity of the Information Security Manager and effective communication between Information Security Managers, end users and Senior Managers.
13|4||Assessing the âinsiderâoutsider threatâ duality in the context of the development of publicâprivate partnerships delivering âchoiceâ in healthcare services: A sociomaterial critique|Containing the ‘outsider’ threat to the information systems of organisations as well as recognising the disruptive potential of ‘insiders’ are fundamentals of security management. However, the recent development of public–private partnerships in the UK requires a reassessment of the continuing utility of such dualities. This paper draws upon a sociological understanding of the complexities of organisational practices as well as a grounded case study of the implementation of the NHS ‘Choose and book’ service across both public and private healthcare organisations in order to challenge these essentialist forms of sociotechnical analysis. The paper proposes a sociomaterial understanding of information systems and organisational dynamics that does not seek to separate out distinct ‘human’ and ‘technical’ information security risks. Rather, it asserts that the organisational outcomes of the introduction of new information systems are necessarily emergent and contingent, and it is with these indeterminate realities that security analysts have to engage.
13|4||In a âtrustingâ environment, everyone is responsible for information security|Information security is important in any organisation and particularly where personal and medical information is routinely recorded. Further, where the organisational culture revolves around trust, as in the medical environment, insider threats, both malicious and non-malicious, are difficult to manage. International research has shown that changing security culture and increasing awareness is necessary as technical resolutions are not sufficient to control insider threats. This area of information security is both important and topical in view of the recently publicised breaches of patient health information. Ensuring that all staff assumes responsibility for information security, particularly as part of an information security governance framework, is one practical solution to the problem of insider threats.
13|4||ISMS insider intrusion prevention and detection|A wide variety of different techniques and technologies are potentially applicable for ISMS insider intrusion prevention and detection. In this report we examine three approaches that have not been reviewed in any great detail recently, namely: simulation and modelling, scenario gaming and game theory, and artificial learning technologies. We show how each of these diverse approaches might be applicable to particular corporate scenarios that may eventuate as a result of potential insider intrusions into an ISMS.
13|4||Catching the malicious insider|This paper looks at the issue of the malicious insider and at a range of the environmental and technical issues that have led to the current situation. The paper also examines why the threat from the malicious insider is changing and looks at a range of measures that can be taken in order to minimise the likelihood of an attack and to enhance the probability of detection in the case of an attack.
13|4||Practical management of malicious insider threat â An enterprise CSIRT perspective|Communication and Information Systems (CIS) now form the primary information store, exchange and data analysis for all modern military and are crucial to command and control. The ubiquitousness of CIS within the military not only means that there is a complete reliance on CIS, but also presents new avenues of attack by malicious insiders. Military sources say that the insider threat is their number one security concern. This paper presents a case study of the technical counter measures and processes used to deter, detect and mitigate malicious insider threats that the author has researched, using non-classified anonymous interview and the analysis of anonymised qualitative field data, within a specific military organisation. It is not the intention of the author that this paper be viewed as an analysis of the “current state of play” of threats and countermeasures that generically exist across all military and defence organisations – rather it presents the technological and organisational processes utilised and challenges encountered at one organisation. A short discussion of the Computer Security Incident Response Team (CSIRT) structure adopted to successfully manage insider and other CIS security threats is presented, followed by a more detailed overview of existing and emerging technical efforts to deter, detect and mitigate such malicious insider threats within the military environment under study. Emphasis will be on the emerging technologies such as anomaly detection using real-time e-discovery, enterprise forensics and profiling users “cyber” behaviour and how these integrate into CSIRT technologies and processes. The technical advantages and challenges that such technologies present within a military alliance will be discussed. The success of such technologies in combating current malicious insider threat environment will be briefly compared with those put forward as challenges in the “Research on mitigating the insider threat to information systems #2” workgroup which took place in 2000 (Anderson et al., 2000.). In closing the author introduce the concept of Stateful Object Use Consequence Analysis as a way of managing the insider threat.
13|4||An extensible analysable system model|Analysing real-world systems for vulnerabilities with respect to security and safety threats is a difficult undertaking, not least due to a lack of availability of formalisations for those systems. While both formalisations and analyses can be found for artificial systems such as software, this does not hold for real physical systems. Approaches such as threat modelling try to target the formalisation of the real-world domain, but still are far from the rigid techniques available in security research. Many currently available approaches to assurance of critical infrastructure security are based on (quite successful) ad-hoc techniques. We believe they can be significantly improved beyond the state-of-the-art by pairing them with static analyses techniques.
13|4||Information security management standards: Compliance, governance and risk management|Managing information security as opposed to the IT security is an area that is now eventually coming of age. For many years the focus has been mainly on IT security and with the implementation of such security left to the IT department and technical experts. Early in the 90s things started to change with the first draft of an information security management standard BS 7799 focusing in on security related to people, processes, information as well as IT. Since then there has been many developments taking us to where we are today with these early security management standards being transformed in international standards published by ISO/IEC. These standards are being used by hundreds of thousands of organisations using these standards worldwide. Based on the authors previously copyrighted writings, this article explores what these standards have got to offer organisations, what benefits are to be gained and how such standards have helped with compliance. In particular it focuses in on the insider threat as an example of one of the growing problems that organisations need to deal with and how these international standards are useful in helping to solve the insider threat problem.
volume|issue|url|title|abstract
14|1|http://www.sciencedirect.com/science/journal/13634127/14/1|Cloud security technologies|You may have heard a new term that started making rounds very recently – “cloud-based security”. In this paper we describe past and contemporary security technologies based on the knowledge provided from the servers in the Internet “cloud”. We discuss how cloud-based malware scanners can simbiotically coexist with traditional scanning technologies, what are the advantages and limitations of the new approach. We also touch on the privacy aspects and challenges related to testing (especially comparative testing) of the cloud security solutions.
14|1||Making sense of anti-malware comparative testing|If there is a single problem illustrating the gulf between the anti-malware industry and the rest of the online world, it revolves around the difficulties and misunderstandings that plague product testing and evaluation. This article considers these issues and the initiatives taken by the anti-malware and testing sectors to resolve some of them.
14|1||Detection of malicious code by applying machine learning classifiers on static features: A state-of-the-art survey|This research synthesizes a taxonomy for classifying detection methods of new malicious code by Machine Learning (ML) methods based on static features extracted from executables. The taxonomy is then operationalized to classify research on this topic and pinpoint critical open research issues in light of emerging threats. The article addresses various facets of the detection challenge, including: file representation and feature selection methods, classification algorithms, weighting ensembles, as well as the imbalance problem, active learning, and chronological evaluation. From the survey we conclude that a framework for detecting new malicious code in executable files can be designed to achieve very high accuracy while maintaining low false positives (i.e. misclassifying benign files as malicious). The framework should include training of multiple classifiers on various types of features (mainly OpCode and byte n-grams and Portable Executable Features), applying weighting algorithm on the classification results of the individual classifiers, as well as an active learning mechanism to maintain high detection accuracy. The training of classifiers should also consider the imbalance problem by generating classifiers that will perform accurately in a real-life situation where the percentage of malicious files among all files is estimated to be approximately 10%.
14|1||A look at Portable Document Format vulnerabilities|
14|2|http://www.sciencedirect.com/science/journal/13634127/14/2|Introduction to this issue|
14|2||Smart card applications and security|This article gives brief introduction to the security mechanisms used in smart card technology. Firstly we introduce the properties of contact and contactless smart cards; then we give the anatomy of smart card hardware and the popular security features implemented. These security features are arranged in the attack and countermeasure pairs, so it is easier for the readers to understand the security issues in the smart card technology.
14|2||Attacking smart card systems: Theory and practice|Smart card technology has evolved over the last few years following notable improvements in the underlying hardware and software platforms. Advanced smart card microprocessors, along with robust smart card operating systems and platforms, contribute towards a broader acceptance of the technology. These improvements have eliminated some of the traditional smart card security concerns. However, researchers and hackers are constantly looking for new issues and vulnerabilities. In this article we provide a brief overview of the main smart card attack categories and their corresponding countermeasures. We also provide examples of well-documented attacks on systems that use smart card technology (e.g. satellite TV, EMV, proximity identification) in an attempt to highlight the importance of the security of the overall system rather than just the smart card.
14|2||Smart card security evaluation: Community solutions to intractable problems|Evaluation of smart card security faced seemingly intractable problems of consistency and repeatability in its early days. The deeply specialised technologies, large parameter spaces for attacks, and the evolving attack types and countermeasures mean that the scope for variation in evaluation practice, and hence in evaluation conclusions, is potentially huge. The situation is further complicated by the fact that countermeasures against some types of attacks depend on both hardware and software, but there is also a need to evaluate hardware without specific software present at the time of evaluation. Stakeholders in the smart card world have formed a Community that has successfully created and applied interpretation of Common Criteria (ISO 15408) to deal with this problem and to achieve international mutual recognition of evaluation results. This paper discusses examples of the smart card security problem in order to illustrate some of the difficulties, and describes some of the interpretation that has been defined for rating the difficulty of an attack via calculation of an attack potential. It also considers the nature of the Community that has enabled the interpretation to be both defined and put into practice successfully.
14|2||Multiapplication smart card: Towards an open smart card?|Smart cards were invented four decades ago so as to keep data secrets and to process them secretly. Even though their main goal are still the same today, the smart cards have been subject to many evolutions at both their hardware and software levels. Indeed they have been the target of numerous attacks and new demands from the market. These demands have expanded their domains of application. When they were born and during some thirty years smart cards have been monolithic platforms with a fixed piece of software dedicated to one single application. But in the mid 90's, some technologies appeared that have broken this situation by enabling to easily host several applications on the same card. These new technologies have changed the business models and pushed the smart cards towards new domains and to a world where they will integrate lots of new functionalities.
14|2||How to defend against smartcard attacks â Or the amazing number of different ways to check a PIN securely|
14|2||Transport ticketing security and fraud controls|For many years, public transportation systems have been an essential part of day-to-day life and so the principle of needing a “ticket” has been familiar to generations of travellers. However as technology has advanced it has become possible to make use of electronic tickets that have significant advantages both for travellers and for the transport system operators. There has been a lot of recent publicity regarding weaknesses in some electronic ticket solutions; which whilst based on some solid facts tend to suggest that transport ticket security and fraud control is primarily a smart card/RFID technology issue. However this cannot be the case as systems exist that do not use such technology; or use it along side legacy systems. This paper will consider technology problems, but will first establish the bigger picture of transport ticketing and will finally make suggestions for future evolution of such systems.
14|2||Electronic passports â from secure specifications to secure implementations|For some years more and more countries have been introducing electronic passports. A reason for that is the need of higher security of travel documents in an age where people fear terrorism and crime. There are the US requirements for VISA Waiver countries to issue biometric enabled Passports and the European Commission's decision for a chip based storage of facial image and fingerprints in passports issued by EU member states. In this article standards for ePassports in terms of security and the implementations of security mechanisms are analysed.
14|2||Smart cards and remote computing: Interaction or convergence?|Computing power is largely becoming a basic supply which you can envisage to buy from a provider like you buy power or water. This is the result of a now long running trend that consists in connecting computing resources together so as to set up what can globally be referred to as a remote computing platform, the most up-to-date incarnation of which is the notion of a grid (Foster and Kesselman, 2003). These resources can then be shared among users, what means circulating codes and the results of their execution over a network, what is highly insecure. At the other end of the spectrum of computing devices, smart cards (2 and 3) offer extremely secure but extremely limited computing capabilities. The question is thus to bridge the gap between computational power and high security. The aim of this paper is to show how large and high capacity remote computing architectures can interact with smart cards, which certainly are the most widely deployed, still the smallest computing systems of the information technology era, so as to improve the overall security of a global infrastructure.
14|3|http://www.sciencedirect.com/science/journal/13634127/14/3|The changing shape of privacy and consent|
14|3||Privacy and consent in the digital era|In today's digital era no one has knowledge, access or control of all their available personal information. This makes the very concepts of privacy and consent increasingly illusory and raises questions that are likely to shape not only the future form of cyberspace, but also the political, social and economic interactions within it. The institutions tasked with regulation of the physical world are ill equipped to respond and undertake a similar role in the virtual world; the timescales, dimensions and scope are all materially different. This article sets out five dilemmas that will need to be addressed in the search for solutions.
14|3||Reflections on privacy, identity and consent in on-line services|The paper gives an overview of the evolution of the laws protecting personal data privacy in the UK over the last 30 years. Against this background, the author considers: the compromises to personal data privacy brought about by the electronic age; individual motivations for using e-services and the balance of risks and benefits; the place of identity management in e-transactions; and, the ways that data guardianship can be improved by an understanding of the roles and responsibilities of those responsible for personal data in organisations, data handlers and individual citizens. The conclusions reached are that once personal data has been recorded electronically it persists and the divide between public and private space is blurred. Citizens should retain rights to personal data including the right to be asked for their consent before it is shared or linked for commercial or administrative purposes. This puts a particular duty on government to behave (and be perceived to behave) responsibly and transparently with regard to the collection, use and disposal of personal data so as to create trust and support democracy.
14|3||Improving the secure management of personal data: Privacy on-line IS important, but it's not easy|This article introduces the growing importance of privacy and the need for an improved understanding of the issues involved. A key requirement is for organisations to better understand the relationship between security and privacy and, therefore, to ensure the design of their systems includes the ability to safeguard privacy and staff consistently apply controls that include the protection of individuals' personal data. A new approach to information security is proposed, as well as some outline results of the application of new methods and mechanisms for ensuring privacy in multi-agency data sharing. It is hoped that this article will prompt dialogue about the need to reconsider existing methods and tools for securely managing data.
14|3||âPrivacy and public policy delivery â Dichotomy or designâ|
14|3||Privacy and consent in pervasive networks|Pervasive networks and location based systems have the potential to provide many new services. However the user of these services often has to provide personal information to allow the service to operate effectively. This article considers the problem of protecting personal information in this environment, and reports on the legislative and technical efforts being made to protect user privacy.
14|3||Victorian values: Politicians and the public incorrectly see security and privacy as opposites|
14|3||What's happened to PETs?|Given that many candidate technical elements have been available for some time, it seems strange that Privacy Enhancing Technologies (PETs) have achieved neither widespread implementation in mainstream products, nor visible adoption by individual data subjects.
14|3||Informational privacy, consent and the âcontrolâ of personal data|This paper reviews how the notion of control has been conceptualised in relation to informational privacy and, from a perspective of consent and the revocation of consent, suggests that there are more sophisticated notions of control over personal data that can be proposed. The paper outlines some of the challenges underlying these enhanced notions of control in the context of privacy and consent.
14|3||Young people, disclosure of personal information and online privacy: Control, choice and consequences|This paper examines the privacy implications of the different online practices in which young people disclose personal information, and how associated configurations of choice and control create possibilities for violations of online privacy. The implications of the commercial and non-commercial use of young peoples' personal information are examined, with a specific focus on how this can potentially facilitate cyberbullying. The paper suggests that educational strategies should more clearly focus on encouraging young people to protect their online privacy, encourage control over disclosure practices, and consider the potential commercial and non-commercial uses of their information. There is a need for development of these strategies to be informed by empirical research exploring the everyday contexts and social norms which influence young peoples' online behaviour. Such an evidence-base can inform a critical review of educational, legal and regulatory actions which aim to protect their online privacy and safety.
14|3||The need for enhanced privacy and consent dialogues|The aim of this article is to present the case for a closer examination of the privacy and consent dialogues that take place during the use of on-line services. This article explores the concepts of privacy and consent in on-line services, discusses the facets of both concepts and presents a case study from Sunderland City Council to illustrate the complexity of deploying privacy and consent dialogue within on-line services. The article concludes with an outline of how enhanced understanding of privacy and consent concepts can result in improved tools to support dialogue and result in a negotiated understanding of the privacy that can be expected and the consent that it is required. This rationale is the underpinning of the VOME project – Visualisation and Other Methods of Expression – funded by TSB, EPSRC and ESRC.
14|3||The first practical guide to data security law and breach action!|
14|4|http://www.sciencedirect.com/science/journal/13634127/14/4|Changing staff behaviour|
14|4||The irreversible march of technology|The ongoing advancement of technology delivers numerous benefits, with enhanced functionality, more capable devices, and new online services all being made available to users on continual basis. At the same time, however, each new advance has the potential to introduce additional risk, with the consequence that users can quickly find themselves exposed if they do not maintain adequate safeguards and awareness. This paper considers some of the security challenges facing end-users, and the extent to which these have evolved alongside changes in the underlying technologies. The discussion reveals that while some aspects of security provision have clearly changed, this does not necessarily result in a situation that actually benefits the user. Indeed, they may find themselves facing a greater burden in terms of security tasks or complexity, or alternatively being underserved by protection options that no longer match the activities they are undertaking.
14|4||Information security management: An entangled research challenge|In May 2009 the Information Security Group, Royal Holloway, became host to a medical sociologist from St. George’s Hospital, University of London, under EPSRC’s discipline hopping scheme. As part of this knowledge transfer activity, a sociotechnical study group was formed comprising computer scientists, mathematicians, organisational researchers and a sociologist. The focus of this group is to consider different avenues of sociotechnical research in information security. This article briefly outlines some of the areas of research where sociotechnical studies might contribute to information security management.
14|4||Human factors in information security: The insider threat â Who can you trust these days?|This paper examines some of the key issues relating to insider threats to information security and the nature of loyalty and betrayal in the context of organisational, cultural factors and changing economic and social factors. It is recognised that insiders pose security risks due to their legitimate access to facilities and information, knowledge of the organisation and the location of valuable assets. Insiders will know how to achieve the greatest impact whilst leaving little evidence. However, organisations may not have employed effective risk management regimes to deal with the speed and scale of change, for example the rise of outsourcing. Outsourcing can lead to the fragmentation of protection barriers and controls and increase the number of people treated as full time employees. Regional and cultural differences will manifest themselves in differing security threat and risk profiles. At the same time, the recession is causing significant individual (and organisational) uncertainty and may prompt an increase in abnormal behaviour in long-term employees and managers – those traditionally most trusted – including members of the security community. In this environment, how can organisations know who to trust and how to maintain this trust?
14|4||A safety approach to information security communications|Safety risk communications is a discipline which is significantly more mature than information security risk communications. This article reviews relevant topics in safety communications and discusses their potential application to information security.
14|4||Protecting clients from insider attacks on trust accounts|Law firms are no exception to the trend towards computerized information infrastructures, particularly because the very nature of their business is collecting and storing highly confidential client data. One area of activity which has come under intense security is the integrity of trust accounts. There have been many incidents of trust account fraud reported internationally, including a case in Australia, where a employee of a law firm stole $4,500,000 from the trust funds of forty-two clients. Trust account fraud is also widely associated with money laundering, a growing major crime involving financial transactions that enable unlawful activity to be disguised.
14|4||How do you make information security user friendly?|
14|4||Contribution of corporate social responsibility to information security management|Contemporary societies develop scepticism about the social responsibility of businesses. There are expectations that firms/corporations/industries/companies make more than just economic contributions. In the area of information technology, more and more companies recognize their responsibility to promote information security management, above and beyond the level required by law, in order to achieve/build a secure information society for daily business operations. While concepts of Corporate Social Responsibility (CSR) have been applied to a plethora of sectors/industries, information security from the aspect of CSR is still behind in both theory and practice. The purpose of this paper is to apply the concept of CSR to the practice of information security management. The paper reviews and analyzes the theoretical background (definitions) of CSR from both practice and the literature and tries to explain what socially responsible management of information security actually is.
14|4||The positive outcomes of information security awareness training in companies â A case study|One of the key factors in successful information security management is the effective compliance of security policies and proper integration of “people”, “process” and “technology”. When it comes to the issue of “people”, this effectiveness can be achieved through several mechanisms, one of which is the security awareness training of employees. However, the outcomes should also be measured to see how successful and effective this training has been for the employees.
volume|issue|url|title|abstract
15|1|http://www.sciencedirect.com/science/journal/13634127/15/1|Protocols and cryptography|
15|1||Cryptography in the real world|This article discusses how and why controls on cryptography have changed over the last 20 years or so, now focusing more on lawful access to the plain text of protected data than on control of movement of cryptographic products. The effect of this change on users of cryptography, and the way organisation can minimise their business risks in this new environment are discussed.
15|1||The MIFARE Classic story|The MIFARE Classic product from NXP Semiconductors has been much maligned over recent years and whilst some of the criticism is well justified by virtue of the inherent security problems, it is by no means the weakest card/RFID in use today. In this article we give a brief overview of the MIFARE Classic card, its use, design and security. We start by looking at the range of card and RFID products and placing the MIFARE Classic in its intended position. The process of risk assessment is then discussed as a means of choosing “appropriate” products and solutions. We then discuss the history of the MIFARE Classic, its design, security features and associated attacks. The long-lasting effects of the attacks and publicity are considered with respect to not only the MIFARE Classic, but for similar product risk reviews.
15|1||The status of National PKIs â A European overview|A series of European Union initiatives and frameworks have been issued during the last years, for the provision of electronic services to individuals, businesses and government organizations. Most of these efforts imply the use of digital certificates for a wide variety of national and transnational transactions. This paper presents the concept of National PKI through a systemic view, compares and contrasts the main inhibitors and enablers, discusses popular use cases, and also examines the European landscape together with open issues.
15|1||Choosing key sizes for cryptography|After making the decision to use public-key cryptography, an organisation still has to make many important decisions before a practical system can be implemented. One of the more difficult challenges is to decide the length of the keys which are to be used within the system: longer keys provide more security but mean that the cryptographic operation will take more time to complete. The most common solution is to take advice from information security standards. This article will investigate the methodology that is used produce these standards and their meaning for an organisation who wishes to implement public-key cryptography.
15|1||Caveat venditor|Tamper-resistant Hardware Security Modules (HSMs) are a core technology used to build assurance in the security of large IT systems protecting and manipulating sensitive data. This paper draws on the authors years of experience working to deploy HSM-based solutions in the financial industry. We argue that as soon as you scratch the surface of the simple “buy and forget” model where an HSM is bought to satisfy a compliance requirement, the buyer encounters initial and ongoing challenges when trying to cover all the bases for security. There is now (compared with 10 years ago) a good public literature on HSM vulnerabilities, but even checking resistance against known threats and attack classes becomes very difficult in practice, let alone considering theoretic and new attacks which have not been widely implemented across HSM platforms. Part of the problem is the lack of security details in vendor information, part is lack of awareness of the issues for the buyers. Some older attacks such as the decimalisation table attack have been largely addressed; others such as PIN block translation (and other oracles) have not. This paper argues that the balance of responsibility between buyer and vendor to maintain security awareness has much room for improvement, and that existing certification processes such as FIPS-140 leave huge gaps that need to be covered when building assurance. In the retail sector strong buyer protections exist because the layperson cannot be expected to understand and manage all the relevant risks, but in the financial industry the assumption has been that buyers have the skills to evaluate the products – “Caveat Emptor”. But maybe it is time to redress this balance with a little “Caveat Venditor”?
15|1||Identity based encryption: Progress and challenges|Identity based cryptography is currently among the most active areas of research in cryptography. In this article we discuss identity based encryption (IBE) which has the potential for widespread real world adoption and has in fact already been deployed commercially. We will discuss the many advantages and disadvantages of IBE and briefly introduce various schemes that have been proposed in the literature. We discuss the real world impact of IBE and highlight some issues which we think will become more pertinent as IBE and related technologies become more well known and widely deployed.
15|2|http://www.sciencedirect.com/science/journal/13634127/15/2|Identity Theft and Reconstruction|
15|2||Online identity: Giving it all away?|With a wealth of personal data now residing across various locations online, individuals can find themselves at increasing risk of too much information being exposed. This in turn may increase the potential for threats such as cyber-snooping, social engineering, and identity theft based upon the gathered details. In many cases the exposure occurs as a result of what individuals directly post about themselves on social networks and blog sites, whereas in some cases it happens thanks to other people posting things beyond their control. This paper examines the potential risks and some of the routes by which information might be harvested. It then proceeds to consider some of the potential consequences, presenting examples of how people can be duped using freely available information and how willingly they appear to expose it to others. Recognising the ease of online search, and the difficulty of reigning back information once it is exposed, the requirement is clearly to improve user awareness and control over their data in the first instance.
15|2||The art of alchemy|Normally the focus of any organisation is on the protection of ‘hard’ information, e.g. intellectual property, within the implementation of their information security program. This article discusses how the potential risks associated with the leakage of ‘soft’ information (that in itself may hold no value) into the public domain is higher today than it has ever been before. The article also offers some measures that can be taken to mitigate these risks.
15|2||Social networking and the risk to companies and institutions|Social networks open up new business opportunities for customer acquisition and retention, facilitate knowledge transfer within the company, and can positively influence work climate. However, they can also quickly destroy a company image that took years to build, while the use of social networks at work not only risks a loss in productivity but may also undermine legal obligations. Eager networkers might also divulge company internals to competitors or the public at large. And last but not least, “friendships” open up completely new attack vectors for professional hackers, thus significantly increasing company exposure to online break-ins. This article briefly summarizes the opportunities and dangers that this development poses for business. This contribution is based on an earlier article by the same authors (in German) (Langheinrich and Karjoth, 2010).
15|2||Privacy threats in a mobile enterprise social network|The ‘Instant Knowledge’ system is an enterprise based social network that aims to introduce employees of the enterprise to contacts within the organization who may have skills relevant to particular tasks. The skills database is maintained through context-aware devices, and mobile devices in particular. The aim is to populate the database automatically based on user context data and to provide automatic introductions, again based on context data. This paper examines the security and privacy implications of this system and shows that while threat modelling on its own provides a solid base from which to secure the system, this is not enough to ensure that all privacy issues are considered. This is demonstrated by applying a mis-use case analysis that shows how personal identifying information can be inadvertantly leaked to malicious parties.
15|2||Digital forensics and the issues of identity|The issue of what we consider to be the identity of a person has become increasingly complex as we have made ever greater use of the facilities and services that have been made available by developing technologies and the Internet. In the past people normally had one identity, while in the current environment it is acceptable to maintain separate ‘identities’ for different aspects of our on-line interactions.
15|2||Foolâs gold|
15|3|http://www.sciencedirect.com/science/journal/13634127/15/3|Computer crime â A 2011 update|
15|3||Botnets: To what extent are they a threat to information security?|
15|3||High tech criminal threats to the national information infrastructure|National information infrastructure (NII), vital to the nation's security and economic stability, comprises both physical and electronic infrastructures. Information and communications technologies (ICT) form the backbone of many aspects of the NII and reliance on ICT has created many new risks. Cyberthreats are becoming more sophisticated with the blending of once distinct types of attack into more damaging forms. This paper examines the technology-related risks associated with the NII and provides examples of existing incidents and areas in which new threats might emerge. To be able to mitigate these risks, it remains crucial to understand infrastructure interdependencies and to establish public-private partnerships to ensure that weaknesses in systems are not able to be exploited.
15|3||Assessing insider threats to information security using technical, behavioural and organisational measures|The UK government took a bruising in the headlines (Sep 2008) after a Home Office contractor lost a USB stick containing unencrypted data on all 84,000 prisoners in England and Wales. As a result, the Home Office terminated the £1.5 million contract with the management consultancy firm.
15|3||Mobile telephony security compromises|
15|4|http://www.sciencedirect.com/science/journal/13634127/15/4|Matchmaking between PCI-DSS and Security|
15|4||PCI DSS audit and compliance|PCI DSS compliance involves responding to a series of requirements imposed by the credit card industry. To succeed, organisation must implement strict information security management processes and should master the risks related to the protection of credit card sensitive data. There are many actions that could be accomplished before hand to ease the audit process, to reduce the effort and time consumed by the audit engagement and to ensure audit conclusions reflect the exact risk posture of the organisation.
15|4||Incident response and compliance: A case study of the recent attacks|
15|4||From auditor-centric to architecture-centric: SDLC for PCI DSS|This paper examines ways to improve security architecture by harnessing the executive attention that compliance activities like PCI DSS bring to security and focus that attention toward improving security architecture over the long term. Threat modeling fills a gap between the system's functional requirements and the auditor's checklist, and is used to catalyze this change of focus.
15|4||Compliance complacency: How âcheck-boxâ compliancy remains a pitfall for many organizations worldwide|
15|4||How tokenization and encryption can enable PCI DSS compliance|PCI DSS tends to affect companies in ways they never imagined. It seems like the successful marketing of a few banks has put numerous cards in all of our customers’ wallets, and many prefer to use them instead of checks or cash. In this chapter, guest author Branden Williams will discuss several methods by which you can tackle this issue, ultimately leading us down a discussion of the various uses for encryption and tokenization, and how we can use those to reduce the impact that PCI DSS has on our organization.
volume|issue|url|title|abstract
16|1|http://www.sciencedirect.com/science/journal/13634127/16/1|Next generation networks|
16|1||Challenges for the security analysis of Next Generation Networks|The increasing complexity of information and telecommunications systems and networks is reaching a level beyond human ability, mainly from the security assessment viewpoint. Methodologies currently proposed for managing and assuring security requirements fall short of industrial and societal expectations. The statistics about vulnerabilities and attacks show that the security, reliability and availability objectives are not reached and that the general threat situation is getting worse. With the deployment of Next Generation Networks – NGNs, the complexity of networks, considering their architecture, speed and amount of connections, will increase exponentially. There are several proposals for the network and security architectures of NGNs, but current vulnerability, threat and risk analysis methods do not appear adequate to evaluate them. Appropriate analysis methods should have some additional new characteristics, mainly regarding their adaptation to the continuous evolution of the NGNs. In addition, the application of security countermeasures will require technological improvements, which will demand further security analyses. This paper evaluates the current vulnerability, threat and risk analysis methods from the point of view of the new security requirements of NGNs. Then, the paper proposes to use autonomic and self-adaptive systems/applications for assuring the security of NGNs.
16|1||A survey on fraud and service misuse in voice over IP (VoIP) networks|The migration from circuit-switched networks to packet-switched networks necessitates the investigation of related issues such as service delivery, QoS, security, and service fraud and misuse. The latter can be seen as a combination of accounting and security aspects. In traditional telecommunication networks, fraud accounts for annual losses at an average of 3%–5% of the operators’ revenue and still increasing at a rate of more than 10% yearly. It is also expected that in VoIP networks, the situation will be worse due to the lack of strong built-in security mechanisms, and the use of open standards. This paper discusses the fraud problem in VoIP networks and evaluates the related available solutions.
16|1||Clustering NGN user behavior for anomaly detection|In the vision of both researchers and standardization committees, networks and services will evolve in the direction of increasing pervasiveness, convergence, and quality of service management capability. Consequently, users will gain an increasing dependency on the presence and availability of network connectivity and the huge plethora of provided services. Yet fostering the development of our society, such dependency on a relatively young technology poses serious threats, especially from the trustworthiness, security and privacy point of view. In this paper, we will describe and critically evaluate user behavior clustering aimed at monitoring and assuring the security of NGN-based applications. Different models of user behavior, developed within both ISP and academic research projects will be described, and several techniques for manipulating and exploiting such model for the anomaly detection purpose will be described and evaluated.
16|1||Side effects of identity management in SIP VoIP environment|
16|2|http://www.sciencedirect.com/science/journal/13634127/16/2|Social networking threats|
16|2||The threats of social networking: Old wine in new bottles?|Despite the many potential benefits to its users, social networking appears to provide a rich setting for criminal activities and other misdeeds. In this paper we consider whether the risks of social networking are unique and novel to this context. Having considered the nature and range of applications to which social networks may be applied, we conclude that there are no exploits or fundamental threats inherent to the social networking setting. Rather, the risks and associated threats treat this communicative and social context as an enabler for existing, long established and well-recognised exploits and activities.
16|2||Social networking as a nexus for engagement and exploitation of young people|This paper addresses commonalities between two different forms of exploitation of young people – child abuse images and online solicitation and radicalisation. A number of areas of similarity are identified, and the implications of these commonalities are discussed. The role of social networking as a critical factor is particularly explored.
16|2||Real-time detection of childrenâs skin on social networking sites using Markov random field modelling|Social networking sites are increasingly being used as the source for paedophiles to search for, download and exchange child exploitation images. Law Enforcement Agencies (LEAs) around the world face a difficult challenge to combat technologically-savvy paedophiles. In this paper, we propose a framework for detecting images containing children’s pictures in different poses, with the ultimate view of identifying and classifying images as corresponding to the COPINE scale. To achieve the goal of automatic detection, we present a novel stochastic vision model based on a Markov Random Fields (MRF) prior, which will employ a skin model and human affine-invariant geometric descriptor to detect and identify skin regions containing pornographic contexts.
16|2||Bucket attack on numeric set watermarking model and safeguards|Numeric set watermarking is a way to provide ownership proof for numerical data. Numerical data can be considered to be primitives for multimedia types such as images and videos since they are organized forms of numeric information. Thereby, the capability to watermark numerical data directly implies the capability to watermark multimedia objects and discourage information theft on social networking sites and the Internet in general. Unfortunately, there has been very limited research done in the field of numeric set watermarking due to underlying limitations in terms of number of items in the set and LSBs in each item available for watermarking. In 2009, Gupta et al. proposed a numeric set watermarking model that embeds watermark bits in the items of the set based on a hash value of the items’ most significant bits (MSBs). If an item is chosen for watermarking, a watermark bit is embedded in the least significant bits, and the replaced bit is inserted in the fractional value to provide reversibility. The authors show their scheme to be resilient against the traditional subset addition, deletion, and modification attacks as well as secondary watermarking attacks.
16|2||Socio-technological phishing prevention|Phishing is deceptive collection of personal information leading to embezzlement, identity theft, and so on. Preventive and combative measures have been taken by banking institutions, software vendors, and network authorities to fight phishing. At the forefront of this resilience are consortiums such as APWG (Anti-Phishing Working Group) and PhishTank, the latter being a collaborative platform where everyone can submit potentially phishing web-pages and classify web-pages as either phish or genuine. PhishTank also has an API that the browsers use to notify users when she tries to load a phishing page. There are some organizations and individuals who are very active and highly accurate in classifying web-pages on PhishTank. In this paper, we propose a defense model that uses these experts to fight phishing.
16|2||Social networking searching and privacy issues|The explosion of social networking sites has not only changed the way people communicate, but also added a new dimension to the way for searching or investigating people. As users share a wide variety of information on social networking sites, concerns are growing about organisations’ access to personally identifiable data and users are increasingly worried about privacy on social network sites. The main threat with data gathering is not only from where gathering it, but also where it goes afterwards. Neither social network sites providers nor the governments have any way to effectively protect users against privacy violations. However, a variety of efforts need to be explored to change the situation. Social network sites should continue work to strengthen privacy settings. Laws and policies should be improved to regulate the social networking searching in its legality, necessity and proportionality.
16|2||How much material on BitTorrent is infringing content? A case study|BitTorrent is a widely used protocol for peer-to-peer (P2P) file sharing, including material which is often suspected to be infringing content. However, little systematic research has been undertaken to establish to measure the true extent of illegal file sharing. In this paper, we propose a new methodology for measuring the extent of infringing content. Our initial results indicate that at least 89.9% of files shared contain infringing content, with a replication study on another sample finding 97%. We discuss the limitations of the approach in this case study, including sampling biases, and outline proposals to further verify the results. The implications of the work vis-à-vis the management of piracy at the network level are discussed.
volume|issue|url|title|abstract
17|1-2|http://www.sciencedirect.com/science/journal/13634127/17/1-2|Practical application of information security models|Information risk security management is an area that is constantly moving to respond to new threats, standards and technologies. Security is now a part of information risk management, which in turn has a place in the overall business risk management strategy.
17|1-2||Economics and the cyber challenge|Economics can be used as a tool to explain, describe, and to a certain extent predict many forms of human behaviour. However, there is only a limited body of work on its application to information security, much of which is acknowledged as partial or incomplete. As a consequence, there is a paucity of robust explanatory or predictive models that are tuned for the peculiarities of the “cyber” challenge, either to organisations, or, at a higher level, the nation state.
17|1-2||Technology is not enough: Taking a holistic view for information assurance|Information security has become a boardroom topic, lost laptops and hacked systems make front page news across the globe, but while technology is a key piece of any corporate security strategy, it is not enough. In this paper, Dr. Bunker examines the change in emphasis for information security from being hidden in the backroom of IT to a responsibility of every employee.
17|1-2||Feature extraction from vein images using spatial information and chain codes|The pattern formed by subcutaneous blood vessels is unique attribute of each individual and can therefore be used as a biometric characteristic. Exploiting the specific near infrared light absorption properties of blood, the capture procedure for this biometric characteristic is convenient and allows contact-less sensors. However, image skeletons extracted from vein images are often unstable, because the raw vein images suffer from low contrast. We propose a new chain code based feature en- coding method, using spatial and orientation properties of vein patterns, which is capable of dealing with noisy and unstable image skeletons. Chain code comparison and a selection of preprocessing methods have been evaluated in a series of different experiments in single and multi-reference scenarios on two different vein image databases. The experiments showed that chain code comparison outperforms minutiae-based approaches and similarity based mix matching.
17|1-2||Continuous keystroke dynamics: A different perspective towards biometric evaluation|In this paper we will describe a way to evaluate a biometric continuous keystroke dynamics system. Such a system will continuously monitor the typing behaviour of a user and will determine if the current user is still the genuine one or not, so that the system can be locked if a different user is detected. The main focus of this paper will be the way to evaluate the performance of such a biometric authentication system. The purpose of a performance evaluation for a static and for a continuous biometric authentication system differ greatly. For a static biometric system it is important to know how often a wrong decision is made. On the other hand, the purpose of a performance evaluation for a continuous biometric authentication system is not to see if an impostor is detected, but how fast he is detected. The performance of a continuous keystroke dynamic system will be tested based on this new evaluation method.
17|1-2||Corrigendum to âSocial networking as a nexus for engagement and exploitation of young peopleâ [Inform Secur Tech Rep 16 (2) (2011) 44â50]|
17|3|http://www.sciencedirect.com/science/journal/13634127/17/3|Security and privacy for digital ecosystems|
17|3||Server-aided signatures verification secure against collusion attack|Wireless handheld devices are increasingly popular. The authenticity of the information or a program to be downloaded is important, especially for business uses. In server-aided verification (SAV), a substantial part of the verification computation can be offloaded to an untrusted server. This allows resource-constrained devices to enjoy the security guarantees provided by cryptographic schemes, such as pairing-based signatures, which may be too heavyweight to verify otherwise.
17|3||A lightweight framework for secure life-logging in smart environments|As the world becomes an interconnected network where objects and humans interact with each other, new challenges and threats appear in the ecosystem. In this interconnected world, smart objects have an important role in giving users the chance for life-logging in smart environments. However, smart devices have several limitations with regards to memory, resources and computation power, hindering the opportunity to apply well-established security algorithms and techniques for secure life-logging on the Internet of Things (IoT) domain. The need for secure and trustworthy life-logging in smart environments is vital, thus, a lightweight approach has to be considered to overcome the constraints of Smart Objects. The purpose of this paper is to present in details the current topics of life-logging in smart environments, while describing interconnection issues, security threats and suggesting a lightweight framework for ensuring security, privacy and trustworthy life-logging. In order to investigate the efficiency of the lightweight framework and the impact of the security attacks on energy consumption, an experimental test-bed was developed including two interconnected users and one smart attacker, who attempts to intercept transmitted messages or interfere with the communication link. Several mitigation factors, such as power control, channel assignment and AES-128 encryption were applied for secure life-logging. Finally, research into the degradation of the consumed energy regarding the described intrusions is presented.
17|3||Kynoid: Real-time enforcement of fine-grained, user-defined, and data-centric security policies forÂ Android|We introduce Kynoid, a real-time monitoring and enforcement framework for Android. Kynoid is based on user-defined security policies which are defined for data-items. This allows users to define temporal, spatial, and destination constraints which have to hold for single items. We introduce an innovative approach to allow for the real-time tracking and enforcement of such policies. In this way, Kynoid is the first extension for Android which enables the enforcement of security policies of data-items stored in shared resources. We outline Kynoid's architecture, present its operation and discuss it in terms of applicability, and performance. By providing a proof-of-concept implementation we further show the feasibility of our framework.
17|3||HiPoLDS: A Hierarchical Security Policy Language for Distributed Systems|Expressing security policies to govern distributed systems is a complex and error-prone task. Policies are hard to understand, often expressed with unfriendly syntax, making it difficult for security administrators and for business analysts to create intelligible specifications. We introduce the Hierarchical Policy Language for Distributed Systems (HiPoLDS), which has been designed to enable the specification of security policies in distributed systems in a concise, readable, and extensible way. HiPoLDS design focuses on decentralized execution environments under the control of multiple stakeholders. It represents policy enforcement through the use of distributed reference monitors, which control the flow of information between services. HiPoLDS allows the definition of both abstract and concrete policies, expressing respectively high-level properties required and concrete implementation details to be ultimately introduced into the service implementation.
17|3||SmartK: Smart cards in operating systems at kernel level|A smart card is a tamper-resistant miniature computer that performs some basic computations on input a secret information. So far, smart cards have been widely used for securing many digital transactions (e.g., pay television, ATM machines).
17|3||Share with strangers: Privacy bubbles as user-centered privacy control for mobile content sharing applications|A continually increasing number of pictures and videos is shared in online social networks. Current sharing platforms, however, only offer limited options to define who has access to the content. Users may either share it with individuals or groups from their social graph, or make it available to the general public. Sharing content with users to which no social ties exist, even if they were physically close to the places where content was created and witnessed the same event, is however not supported by most existing platforms. We thus propose a novel approach to share content with such users based on so-called privacy bubbles. Privacy bubbles metaphorically represent the private sphere of the users and automatically confine the access to the content generated by the bubble creator to people within the bubble. Bubbles extend in both time and space, centered around the collection time and place, and their size can be adapted to the user's preferences. We confirm the user acceptance of our concept through a questionnaire-based study with 175 participants, and a prototype implementation shows the technical feasibility of our scheme.
17|3||Secure computations on non-integer values with applications to privacy-preserving sequence analysis|In this work we describe a framework which allows to perform secure computations on non-integer values. To this end, we encode values in a way similar to floating point representation and describe protocols that allow to perform efficient secure two party computations on such encoded values. We present two approaches to realize the functionality of the framework. Both approaches come with different properties and are ready to use in various application scenarios. We implemented the framework in C++ and ran several experiments. This allows for a complexity analysis and for a comparison of the two different approaches. We further describe applications to privacy-preserving computations, which greatly benefit from the use of the new framework. In particular, we show how to run an important algorithm in the context of data analysis using Hidden Markov Models (HMM), namely the Viterbi algorithm, in a secure manner.
17|4|http://www.sciencedirect.com/science/journal/13634127/17/4|ARES 2012 special issue|
17|4||Semantic analysis of role mining results and shadowed roles detection|The use of role engineering has grown in importance with the expansion of highly abstracted access control frameworks in organizations. In particular, the use of role mining techniques for the discovery of roles from previously deployed authorizations has facilitated the configuration of such frameworks. However, the literature lacks from a clear basis for appraising and leveraging the learning outcomes of the role mining process. In this paper, we provide such a formal basis. We compare sets of roles by projecting roles from one set into the other set. This approach is useful to measure how comparable the two configurations of roles are, and to interpret each role. We formally define the problem of comparing sets of roles, and prove that the problem is NP-complete. Then, we propose an algorithm to map the inherent relationship between the sets based on Boolean expressions. We demonstrate the correctness and completeness of our solution, and investigate some further issues that may benefit from our approach, such as detection of unhandled perturbations or source misconfiguration. In particular, we emphasize that the presence of shadowed roles in the role configuration increases the time complexity of sets of roles comparison. We provide a definition of the shadowed roles problem and propose a solution that detects different cases of role shadowing.
17|4||Bridging the gap between role mining and role engineering via migration guides|In the context of role-based access control (RBAC), mining approaches, such as role mining or organizational mining, can be applied to derive permissions and roles from a system's configuration or from log files. In this way, mining techniques document the current state of a system and produce current-state RBAC models. However, such current-state RBAC models most often follow from structures that have evolved over time and are not the result of a systematic rights management procedure. In contrast, role engineering is applied to define a tailored RBAC model for a particular organization or information system. Thus, role engineering techniques produce a target-state RBAC model that is customized for the business processes supported via the respective information system. The migration from a current-state RBAC model to a tailored target-state RBAC model is, however, a complex task. In this paper, we present a systematic approach to migrate current-state RBAC models to target-state RBAC models. In particular, we use model comparison techniques to identify differences between two RBAC models. Based on these differences, we derive migration rules that define which elements and element relations must be changed, added, or removed. A migration guide then includes all migration rules that need to be applied to a particular current-state RBAC model to produce the corresponding target-state RBAC model. We conducted two comparative studies to identify which visualization technique is most suitable to make migration guides available to human users. Based on the results of these comparative studies, we implemented tool support for the derivation and visualization of migration guides. Our software tool is based on the Eclipse Modeling Framework (EMF). Moreover, this paper describes the experimental evaluation of our tool.
17|4||Analyses of two end-user software vulnerability exposure metrics (extended version)|Understanding the exposure risk of software vulnerabilities is an important part of the software ecosystem. Reliable software vulnerability metrics allow end-users to make informed decisions regarding the risk posed by the choice of one software package versus another. In this article, we develop and analyze two new security metrics: median active vulnerabilities (MAV) and vulnerability free days (VFD). Both metrics take into account both the rate of vulnerability discovery and the rate at which vendors produce corresponding patches. We examine how our metrics are computed from publicly available data sets and then demonstrate their use in a case study with various vendors and products. Finally, we discuss the use of the metrics by various software stakeholders and how end-users can benefit from their use.
17|4||Analyzing settings for social identity management on Social Networking Sites: Classification, current state, and proposed developments|The rising prevalence of Social Networking Sites (SNS) and their usage in multiple contexts poses new privacy challenges and increasingly prompts users to manage their online identity. To address privacy threats stemming from interacting with other users on SNS, effective Social Identity Management (SIdM) is a key requirement. It refers to the deliberate and targeted disclosure of personal attribute values to a subset of one's contacts or other users on the SNS. Protection against other entities such as the site operator itself or advertisers and application programmers is not covered by SIdM, but could be incorporated in further refinement steps. Features and settings to perform SIdM have been proposed and subsequently implemented partly by some SNS. Yet, these are often isolated solutions that lack integration into a reference framework that states the requirements for successfully managing one's identity. In this article, such a reference framework of existing and desired SIdM settings is derived from identity theory, literature analysis, and existing SNS. Based thereupon, we examine the SIdM capabilities of prevalent SNS and highlight possible improvements. Lastly, we reason about developing a metric to objectively compare the capability of SNS in regards to their support for SIdM.
17|4||TowardÂ web-based information security knowledge sharing|Today IT security professionals are working hard to keep a high security standard for their information systems. In doing so, they often face similar problems, for which they have to create appropriate solutions. An exchange of knowledge between experts would be desirable in order to prevent developing always the same solutions by independent persons. Such an exchange could also lead to solutions of higher quality, as existing approaches could be advanced, instead of always reinventing the security wheel.
17|4||Oblivious and fair server-aided two-party computation|We show efficient, practical (server-aided) secure two-party computation protocols ensuring privacy, correctness and fairness in the presence of malicious (Byzantine) faults. Our requirements from the server are modest. To ensure privacy and correctness, we only assume a circuit evaluation service, executing an initialisation program provided by both parties. To ensure fairness, we further assume a trusted-decryption service, providing decryption service using a known public key. Our fairness-ensuring protocol is optimistic, i.e., the decryption service is invoked only in case of faults.
17|4||InnoDB database forensics: Enhanced reconstruction of data manipulation queries from redo logs|The InnoDB storage engine is one of the most widely used storage engines for MySQL. This paper discusses possibilities of utilizing the redo logs of InnoDB databases for forensic analysis, as well as the extraction of the information needed from the MySQL definition files, in order to carry out this kind of analysis. Since the redo logs are internal log files of the storage engine and thus cannot easily be changed undetected, this forensic method can be very useful against adversaries with administrator privileges, which could otherwise cover their tracks by manipulating traditional log files intended for audit and control purposes. Based on a prototype implementation, we show methods for recovering Insert, Delete and Update statements issued against a database.
17|4||On measuring the parasitic backscatter of sensor-enabled UHF RFID tags|Radio-frequency identification (RFID) tags have found their way into many applications. When tags implement cryptographic algorithms, side-channel analysis (SCA) attacks become a concern. Especially tags in the ultra-high frequency (UHF) range are susceptible to so-called parasitic-backscatter attacks that can be applied from a distance. Whereas it is known that such attacks are a threat for passive low-cost tags, no results are so far available for sensor-enabled tags. In this work, we evaluate the parasitic backscatter of wireless identification and sensing platform (WISP) tags by conducting differential electromagnetic analysis (DEMA) attacks. We apply the attacks on a passively as well as a semi-passively operated WISP tag from a distance of 30 cm and compare the results with an attack on a commercial low-cost tag. The results show that the evaluated WISP tags are less susceptible to DEMA attacks based on the parasitic backscatter than the evaluated commercial low-cost tag. Moreover, we present a measurement approach that allows to detect the weak parasitic backscatter modulated on the strong reader field without the need for an expensive hardware receiver or a dedicated demodulation circuit.
